{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.222222222222222,
  "eval_steps": 8000,
  "global_step": 56000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 12.517516136169434,
      "learning_rate": 3.9999259259259265e-05,
      "loss": 13.2674,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.809046745300293,
      "learning_rate": 3.999777777777778e-05,
      "loss": 6.5032,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.128349304199219,
      "learning_rate": 3.99962962962963e-05,
      "loss": 5.9982,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.088467597961426,
      "learning_rate": 3.999481481481482e-05,
      "loss": 5.856,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.324800491333008,
      "learning_rate": 3.9993333333333336e-05,
      "loss": 5.6993,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.254469871520996,
      "learning_rate": 3.999185185185186e-05,
      "loss": 5.4603,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.886805534362793,
      "learning_rate": 3.9990370370370374e-05,
      "loss": 5.1435,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.222864151000977,
      "learning_rate": 3.998888888888889e-05,
      "loss": 5.0102,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.705524444580078,
      "learning_rate": 3.998740740740741e-05,
      "loss": 4.8077,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.804891586303711,
      "learning_rate": 3.998592592592593e-05,
      "loss": 4.7587,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.908607482910156,
      "learning_rate": 3.9984444444444445e-05,
      "loss": 4.6866,
      "step": 110
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.027042388916016,
      "learning_rate": 3.998296296296297e-05,
      "loss": 4.5359,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.779804229736328,
      "learning_rate": 3.9981481481481484e-05,
      "loss": 4.4001,
      "step": 130
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.049907684326172,
      "learning_rate": 3.998000000000001e-05,
      "loss": 4.5024,
      "step": 140
    },
    {
      "epoch": 0.02,
      "grad_norm": 14.878626823425293,
      "learning_rate": 3.997851851851852e-05,
      "loss": 4.2932,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.31142520904541,
      "learning_rate": 3.997703703703704e-05,
      "loss": 4.2182,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.879420280456543,
      "learning_rate": 3.997555555555556e-05,
      "loss": 4.2502,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.593904495239258,
      "learning_rate": 3.997407407407408e-05,
      "loss": 4.267,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.434754371643066,
      "learning_rate": 3.9972592592592594e-05,
      "loss": 4.1847,
      "step": 190
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.733637809753418,
      "learning_rate": 3.9971111111111117e-05,
      "loss": 3.9963,
      "step": 200
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.762452125549316,
      "learning_rate": 3.996962962962963e-05,
      "loss": 4.1148,
      "step": 210
    },
    {
      "epoch": 0.02,
      "grad_norm": 13.698417663574219,
      "learning_rate": 3.996814814814815e-05,
      "loss": 4.0094,
      "step": 220
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.618663787841797,
      "learning_rate": 3.996666666666667e-05,
      "loss": 4.1163,
      "step": 230
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.712740898132324,
      "learning_rate": 3.996518518518519e-05,
      "loss": 3.929,
      "step": 240
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.766560554504395,
      "learning_rate": 3.996370370370371e-05,
      "loss": 3.9922,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.578831672668457,
      "learning_rate": 3.9962222222222226e-05,
      "loss": 4.0262,
      "step": 260
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.007604598999023,
      "learning_rate": 3.996074074074074e-05,
      "loss": 3.937,
      "step": 270
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.608046531677246,
      "learning_rate": 3.9959259259259265e-05,
      "loss": 3.9199,
      "step": 280
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.334872245788574,
      "learning_rate": 3.995777777777778e-05,
      "loss": 3.9472,
      "step": 290
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.037528991699219,
      "learning_rate": 3.99562962962963e-05,
      "loss": 3.8393,
      "step": 300
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.939407348632812,
      "learning_rate": 3.995481481481482e-05,
      "loss": 3.8756,
      "step": 310
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.083012580871582,
      "learning_rate": 3.9953333333333336e-05,
      "loss": 4.0116,
      "step": 320
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.90728759765625,
      "learning_rate": 3.995185185185185e-05,
      "loss": 3.8244,
      "step": 330
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.52015495300293,
      "learning_rate": 3.9950370370370375e-05,
      "loss": 3.8737,
      "step": 340
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.24268627166748,
      "learning_rate": 3.994888888888889e-05,
      "loss": 3.8288,
      "step": 350
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.681111335754395,
      "learning_rate": 3.9947407407407414e-05,
      "loss": 3.7728,
      "step": 360
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.475106239318848,
      "learning_rate": 3.994592592592593e-05,
      "loss": 3.8714,
      "step": 370
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.996838569641113,
      "learning_rate": 3.9944444444444446e-05,
      "loss": 3.7561,
      "step": 380
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.332202911376953,
      "learning_rate": 3.994296296296297e-05,
      "loss": 3.6587,
      "step": 390
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.6011323928833,
      "learning_rate": 3.9941481481481484e-05,
      "loss": 3.6978,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.69412612915039,
      "learning_rate": 3.994000000000001e-05,
      "loss": 3.8192,
      "step": 410
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.450457572937012,
      "learning_rate": 3.993851851851852e-05,
      "loss": 3.6908,
      "step": 420
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.368013381958008,
      "learning_rate": 3.993703703703704e-05,
      "loss": 3.7324,
      "step": 430
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.782751083374023,
      "learning_rate": 3.9935555555555555e-05,
      "loss": 3.6989,
      "step": 440
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.416330337524414,
      "learning_rate": 3.993407407407408e-05,
      "loss": 3.7083,
      "step": 450
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.797314643859863,
      "learning_rate": 3.9932592592592594e-05,
      "loss": 3.6955,
      "step": 460
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.929840087890625,
      "learning_rate": 3.993111111111112e-05,
      "loss": 3.8236,
      "step": 470
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.911569595336914,
      "learning_rate": 3.992962962962963e-05,
      "loss": 3.6986,
      "step": 480
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.63588809967041,
      "learning_rate": 3.992814814814815e-05,
      "loss": 3.5853,
      "step": 490
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.542730331420898,
      "learning_rate": 3.992666666666667e-05,
      "loss": 3.6668,
      "step": 500
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.024399757385254,
      "learning_rate": 3.992518518518519e-05,
      "loss": 3.674,
      "step": 510
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.488041877746582,
      "learning_rate": 3.992370370370371e-05,
      "loss": 3.6935,
      "step": 520
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.882766723632812,
      "learning_rate": 3.992222222222223e-05,
      "loss": 3.5832,
      "step": 530
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.98135757446289,
      "learning_rate": 3.992074074074074e-05,
      "loss": 3.6077,
      "step": 540
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.02983570098877,
      "learning_rate": 3.991925925925926e-05,
      "loss": 3.6729,
      "step": 550
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.721792221069336,
      "learning_rate": 3.991777777777778e-05,
      "loss": 3.5431,
      "step": 560
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.603412628173828,
      "learning_rate": 3.99162962962963e-05,
      "loss": 3.6339,
      "step": 570
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.820195198059082,
      "learning_rate": 3.991481481481482e-05,
      "loss": 3.6412,
      "step": 580
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.07511043548584,
      "learning_rate": 3.9913333333333336e-05,
      "loss": 3.4394,
      "step": 590
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.525965690612793,
      "learning_rate": 3.991185185185185e-05,
      "loss": 3.6442,
      "step": 600
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.182601928710938,
      "learning_rate": 3.9910370370370375e-05,
      "loss": 3.6416,
      "step": 610
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.444527626037598,
      "learning_rate": 3.990888888888889e-05,
      "loss": 3.5797,
      "step": 620
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.029617309570312,
      "learning_rate": 3.9907407407407414e-05,
      "loss": 3.6021,
      "step": 630
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.636364936828613,
      "learning_rate": 3.990592592592593e-05,
      "loss": 3.5075,
      "step": 640
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.498610496520996,
      "learning_rate": 3.9904444444444446e-05,
      "loss": 3.6261,
      "step": 650
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.297496795654297,
      "learning_rate": 3.990296296296297e-05,
      "loss": 3.5022,
      "step": 660
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.45966625213623,
      "learning_rate": 3.9901481481481485e-05,
      "loss": 3.5633,
      "step": 670
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.586499214172363,
      "learning_rate": 3.990000000000001e-05,
      "loss": 3.3576,
      "step": 680
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.938611030578613,
      "learning_rate": 3.9898518518518524e-05,
      "loss": 3.5786,
      "step": 690
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.826436996459961,
      "learning_rate": 3.989703703703704e-05,
      "loss": 3.5696,
      "step": 700
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.842984199523926,
      "learning_rate": 3.9895555555555556e-05,
      "loss": 3.6792,
      "step": 710
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.140107154846191,
      "learning_rate": 3.989407407407408e-05,
      "loss": 3.4115,
      "step": 720
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.85849666595459,
      "learning_rate": 3.9892592592592595e-05,
      "loss": 3.5142,
      "step": 730
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.181720733642578,
      "learning_rate": 3.989111111111112e-05,
      "loss": 3.5394,
      "step": 740
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.873644828796387,
      "learning_rate": 3.988962962962963e-05,
      "loss": 3.3121,
      "step": 750
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.016273498535156,
      "learning_rate": 3.988814814814815e-05,
      "loss": 3.5101,
      "step": 760
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.245368003845215,
      "learning_rate": 3.988666666666667e-05,
      "loss": 3.4442,
      "step": 770
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.049078941345215,
      "learning_rate": 3.988518518518519e-05,
      "loss": 3.4704,
      "step": 780
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.701403617858887,
      "learning_rate": 3.988370370370371e-05,
      "loss": 3.4854,
      "step": 790
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.646757125854492,
      "learning_rate": 3.988222222222223e-05,
      "loss": 3.4466,
      "step": 800
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.991663932800293,
      "learning_rate": 3.988074074074074e-05,
      "loss": 3.4493,
      "step": 810
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.93493938446045,
      "learning_rate": 3.987925925925926e-05,
      "loss": 3.4359,
      "step": 820
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.447007179260254,
      "learning_rate": 3.987777777777778e-05,
      "loss": 3.5157,
      "step": 830
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.468661308288574,
      "learning_rate": 3.98762962962963e-05,
      "loss": 3.4307,
      "step": 840
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.069402694702148,
      "learning_rate": 3.987481481481482e-05,
      "loss": 3.4551,
      "step": 850
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.92595100402832,
      "learning_rate": 3.987333333333334e-05,
      "loss": 3.422,
      "step": 860
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.993885040283203,
      "learning_rate": 3.987185185185185e-05,
      "loss": 3.5751,
      "step": 870
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.42919921875,
      "learning_rate": 3.9870370370370376e-05,
      "loss": 3.44,
      "step": 880
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.551530838012695,
      "learning_rate": 3.986888888888889e-05,
      "loss": 3.455,
      "step": 890
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.37077808380127,
      "learning_rate": 3.9867407407407414e-05,
      "loss": 3.3202,
      "step": 900
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.301070213317871,
      "learning_rate": 3.986592592592593e-05,
      "loss": 3.4363,
      "step": 910
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.226223945617676,
      "learning_rate": 3.9864444444444446e-05,
      "loss": 3.4129,
      "step": 920
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.969078063964844,
      "learning_rate": 3.986296296296296e-05,
      "loss": 3.3963,
      "step": 930
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.992286682128906,
      "learning_rate": 3.9861481481481485e-05,
      "loss": 3.3637,
      "step": 940
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.297296524047852,
      "learning_rate": 3.986000000000001e-05,
      "loss": 3.3868,
      "step": 950
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.480277061462402,
      "learning_rate": 3.9858518518518524e-05,
      "loss": 3.3775,
      "step": 960
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.653738975524902,
      "learning_rate": 3.985703703703704e-05,
      "loss": 3.5195,
      "step": 970
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.434553146362305,
      "learning_rate": 3.9855555555555556e-05,
      "loss": 3.301,
      "step": 980
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.992162704467773,
      "learning_rate": 3.985407407407408e-05,
      "loss": 3.4286,
      "step": 990
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.102975845336914,
      "learning_rate": 3.9852592592592595e-05,
      "loss": 3.2343,
      "step": 1000
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.550039291381836,
      "learning_rate": 3.985111111111112e-05,
      "loss": 3.2632,
      "step": 1010
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.150092124938965,
      "learning_rate": 3.9849629629629634e-05,
      "loss": 3.2297,
      "step": 1020
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.940215110778809,
      "learning_rate": 3.984814814814815e-05,
      "loss": 3.4528,
      "step": 1030
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.709094047546387,
      "learning_rate": 3.9846666666666666e-05,
      "loss": 3.4439,
      "step": 1040
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.19936466217041,
      "learning_rate": 3.984518518518519e-05,
      "loss": 3.2175,
      "step": 1050
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.080093383789062,
      "learning_rate": 3.984370370370371e-05,
      "loss": 3.4078,
      "step": 1060
    },
    {
      "epoch": 0.12,
      "grad_norm": 10.331694602966309,
      "learning_rate": 3.984222222222223e-05,
      "loss": 3.2933,
      "step": 1070
    },
    {
      "epoch": 0.12,
      "grad_norm": 10.346673011779785,
      "learning_rate": 3.9840740740740743e-05,
      "loss": 3.295,
      "step": 1080
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.641888618469238,
      "learning_rate": 3.983925925925926e-05,
      "loss": 3.3676,
      "step": 1090
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.735713958740234,
      "learning_rate": 3.983777777777778e-05,
      "loss": 3.2349,
      "step": 1100
    },
    {
      "epoch": 0.12,
      "grad_norm": 10.54903793334961,
      "learning_rate": 3.98362962962963e-05,
      "loss": 3.2936,
      "step": 1110
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.859968185424805,
      "learning_rate": 3.983481481481482e-05,
      "loss": 3.3171,
      "step": 1120
    },
    {
      "epoch": 0.13,
      "grad_norm": 10.644314765930176,
      "learning_rate": 3.983333333333334e-05,
      "loss": 3.3046,
      "step": 1130
    },
    {
      "epoch": 0.13,
      "grad_norm": 10.45202922821045,
      "learning_rate": 3.983185185185185e-05,
      "loss": 3.1922,
      "step": 1140
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.805963516235352,
      "learning_rate": 3.9830370370370376e-05,
      "loss": 3.3517,
      "step": 1150
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.756340026855469,
      "learning_rate": 3.982888888888889e-05,
      "loss": 3.3211,
      "step": 1160
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.80125904083252,
      "learning_rate": 3.9827407407407415e-05,
      "loss": 3.2283,
      "step": 1170
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.76554012298584,
      "learning_rate": 3.982592592592593e-05,
      "loss": 3.3732,
      "step": 1180
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.466262817382812,
      "learning_rate": 3.982444444444445e-05,
      "loss": 3.2704,
      "step": 1190
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.240140914916992,
      "learning_rate": 3.982296296296296e-05,
      "loss": 3.2539,
      "step": 1200
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.309162139892578,
      "learning_rate": 3.9821481481481486e-05,
      "loss": 3.4171,
      "step": 1210
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.134779930114746,
      "learning_rate": 3.982000000000001e-05,
      "loss": 3.2347,
      "step": 1220
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.86555290222168,
      "learning_rate": 3.9818518518518524e-05,
      "loss": 3.2292,
      "step": 1230
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.995657920837402,
      "learning_rate": 3.981703703703704e-05,
      "loss": 3.3052,
      "step": 1240
    },
    {
      "epoch": 0.14,
      "grad_norm": 10.750859260559082,
      "learning_rate": 3.9815555555555556e-05,
      "loss": 3.2142,
      "step": 1250
    },
    {
      "epoch": 0.14,
      "grad_norm": 9.928380966186523,
      "learning_rate": 3.981407407407408e-05,
      "loss": 3.1539,
      "step": 1260
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.41266918182373,
      "learning_rate": 3.9812592592592595e-05,
      "loss": 3.2496,
      "step": 1270
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.264777183532715,
      "learning_rate": 3.981111111111112e-05,
      "loss": 3.2948,
      "step": 1280
    },
    {
      "epoch": 0.14,
      "grad_norm": 10.22701644897461,
      "learning_rate": 3.9809629629629634e-05,
      "loss": 3.1279,
      "step": 1290
    },
    {
      "epoch": 0.14,
      "grad_norm": 10.39184856414795,
      "learning_rate": 3.980814814814815e-05,
      "loss": 3.1698,
      "step": 1300
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.09675121307373,
      "learning_rate": 3.9806666666666666e-05,
      "loss": 3.275,
      "step": 1310
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.194844245910645,
      "learning_rate": 3.980518518518519e-05,
      "loss": 3.2289,
      "step": 1320
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.532060623168945,
      "learning_rate": 3.980370370370371e-05,
      "loss": 3.2977,
      "step": 1330
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.306087493896484,
      "learning_rate": 3.980222222222223e-05,
      "loss": 3.3841,
      "step": 1340
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.470712661743164,
      "learning_rate": 3.9800740740740744e-05,
      "loss": 3.2593,
      "step": 1350
    },
    {
      "epoch": 0.15,
      "grad_norm": 11.099172592163086,
      "learning_rate": 3.979925925925926e-05,
      "loss": 3.1703,
      "step": 1360
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.468914985656738,
      "learning_rate": 3.979777777777778e-05,
      "loss": 3.2365,
      "step": 1370
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.478130340576172,
      "learning_rate": 3.97962962962963e-05,
      "loss": 3.3327,
      "step": 1380
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.93371868133545,
      "learning_rate": 3.979481481481482e-05,
      "loss": 3.2899,
      "step": 1390
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.497598648071289,
      "learning_rate": 3.979333333333334e-05,
      "loss": 3.1211,
      "step": 1400
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.074450492858887,
      "learning_rate": 3.9791851851851853e-05,
      "loss": 3.2194,
      "step": 1410
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.108451843261719,
      "learning_rate": 3.979037037037037e-05,
      "loss": 3.1901,
      "step": 1420
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.707980155944824,
      "learning_rate": 3.978888888888889e-05,
      "loss": 3.2247,
      "step": 1430
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.921874523162842,
      "learning_rate": 3.9787407407407415e-05,
      "loss": 3.1114,
      "step": 1440
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.733360290527344,
      "learning_rate": 3.978592592592593e-05,
      "loss": 3.1686,
      "step": 1450
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.573113441467285,
      "learning_rate": 3.978444444444445e-05,
      "loss": 3.1303,
      "step": 1460
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.193371772766113,
      "learning_rate": 3.978296296296296e-05,
      "loss": 3.0412,
      "step": 1470
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.616225242614746,
      "learning_rate": 3.9781481481481486e-05,
      "loss": 3.1319,
      "step": 1480
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.22050666809082,
      "learning_rate": 3.978e-05,
      "loss": 3.1819,
      "step": 1490
    },
    {
      "epoch": 0.17,
      "grad_norm": 11.358037948608398,
      "learning_rate": 3.9778518518518525e-05,
      "loss": 3.0188,
      "step": 1500
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.455936431884766,
      "learning_rate": 3.977703703703704e-05,
      "loss": 3.2791,
      "step": 1510
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.885708808898926,
      "learning_rate": 3.977555555555556e-05,
      "loss": 3.3137,
      "step": 1520
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.331969261169434,
      "learning_rate": 3.977407407407407e-05,
      "loss": 3.2109,
      "step": 1530
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.605935096740723,
      "learning_rate": 3.9772592592592596e-05,
      "loss": 3.1562,
      "step": 1540
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.322358131408691,
      "learning_rate": 3.977111111111112e-05,
      "loss": 3.251,
      "step": 1550
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.595991134643555,
      "learning_rate": 3.9769629629629634e-05,
      "loss": 3.0797,
      "step": 1560
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.28225040435791,
      "learning_rate": 3.976814814814815e-05,
      "loss": 3.0989,
      "step": 1570
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.744793891906738,
      "learning_rate": 3.9766666666666667e-05,
      "loss": 3.1982,
      "step": 1580
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.41189193725586,
      "learning_rate": 3.976518518518519e-05,
      "loss": 3.2559,
      "step": 1590
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.747806549072266,
      "learning_rate": 3.976370370370371e-05,
      "loss": 3.0514,
      "step": 1600
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.096758842468262,
      "learning_rate": 3.976222222222223e-05,
      "loss": 3.1519,
      "step": 1610
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.919395446777344,
      "learning_rate": 3.9760740740740744e-05,
      "loss": 3.1584,
      "step": 1620
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.153809547424316,
      "learning_rate": 3.975925925925926e-05,
      "loss": 3.0872,
      "step": 1630
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.349283218383789,
      "learning_rate": 3.9757777777777776e-05,
      "loss": 3.1208,
      "step": 1640
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.798233032226562,
      "learning_rate": 3.97562962962963e-05,
      "loss": 3.1672,
      "step": 1650
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.531973838806152,
      "learning_rate": 3.975481481481482e-05,
      "loss": 3.188,
      "step": 1660
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.373823165893555,
      "learning_rate": 3.975333333333334e-05,
      "loss": 3.0456,
      "step": 1670
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.171375274658203,
      "learning_rate": 3.9751851851851854e-05,
      "loss": 3.0991,
      "step": 1680
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.499197959899902,
      "learning_rate": 3.975037037037037e-05,
      "loss": 2.9379,
      "step": 1690
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.14909553527832,
      "learning_rate": 3.974888888888889e-05,
      "loss": 3.0937,
      "step": 1700
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.131026268005371,
      "learning_rate": 3.9747407407407415e-05,
      "loss": 3.1041,
      "step": 1710
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.77025032043457,
      "learning_rate": 3.974592592592593e-05,
      "loss": 3.138,
      "step": 1720
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.209357261657715,
      "learning_rate": 3.974444444444445e-05,
      "loss": 3.1602,
      "step": 1730
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.203293800354004,
      "learning_rate": 3.9742962962962964e-05,
      "loss": 3.1455,
      "step": 1740
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.400286674499512,
      "learning_rate": 3.9741481481481486e-05,
      "loss": 3.0949,
      "step": 1750
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.993935585021973,
      "learning_rate": 3.974e-05,
      "loss": 2.9766,
      "step": 1760
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.884932518005371,
      "learning_rate": 3.9738518518518525e-05,
      "loss": 3.1383,
      "step": 1770
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.877261638641357,
      "learning_rate": 3.973703703703704e-05,
      "loss": 3.0741,
      "step": 1780
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.125992774963379,
      "learning_rate": 3.973555555555556e-05,
      "loss": 3.1067,
      "step": 1790
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.050704002380371,
      "learning_rate": 3.973407407407407e-05,
      "loss": 3.0091,
      "step": 1800
    },
    {
      "epoch": 0.2,
      "grad_norm": 10.417173385620117,
      "learning_rate": 3.9732592592592596e-05,
      "loss": 3.1423,
      "step": 1810
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.288894653320312,
      "learning_rate": 3.973111111111112e-05,
      "loss": 3.102,
      "step": 1820
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.20827865600586,
      "learning_rate": 3.9729629629629635e-05,
      "loss": 2.9471,
      "step": 1830
    },
    {
      "epoch": 0.2,
      "grad_norm": 13.853484153747559,
      "learning_rate": 3.972814814814815e-05,
      "loss": 3.1682,
      "step": 1840
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.80193042755127,
      "learning_rate": 3.972666666666667e-05,
      "loss": 3.2143,
      "step": 1850
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.760103225708008,
      "learning_rate": 3.972518518518519e-05,
      "loss": 2.9893,
      "step": 1860
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.1332368850708,
      "learning_rate": 3.9723703703703706e-05,
      "loss": 2.9726,
      "step": 1870
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.710208892822266,
      "learning_rate": 3.972222222222223e-05,
      "loss": 3.085,
      "step": 1880
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.435288429260254,
      "learning_rate": 3.9720740740740745e-05,
      "loss": 2.9653,
      "step": 1890
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.716869354248047,
      "learning_rate": 3.971925925925926e-05,
      "loss": 3.1498,
      "step": 1900
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.31797981262207,
      "learning_rate": 3.9717777777777777e-05,
      "loss": 2.8861,
      "step": 1910
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.678060531616211,
      "learning_rate": 3.97162962962963e-05,
      "loss": 3.0262,
      "step": 1920
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.939582824707031,
      "learning_rate": 3.971481481481482e-05,
      "loss": 3.072,
      "step": 1930
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.808539390563965,
      "learning_rate": 3.971333333333334e-05,
      "loss": 2.9703,
      "step": 1940
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.359573364257812,
      "learning_rate": 3.9711851851851854e-05,
      "loss": 3.1386,
      "step": 1950
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.806715965270996,
      "learning_rate": 3.971037037037037e-05,
      "loss": 3.0367,
      "step": 1960
    },
    {
      "epoch": 0.22,
      "grad_norm": 9.080094337463379,
      "learning_rate": 3.970888888888889e-05,
      "loss": 2.9107,
      "step": 1970
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.928630828857422,
      "learning_rate": 3.970740740740741e-05,
      "loss": 3.0938,
      "step": 1980
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.588796615600586,
      "learning_rate": 3.970592592592593e-05,
      "loss": 3.0356,
      "step": 1990
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.051122665405273,
      "learning_rate": 3.970444444444445e-05,
      "loss": 3.0533,
      "step": 2000
    },
    {
      "epoch": 0.22,
      "grad_norm": 9.215961456298828,
      "learning_rate": 3.9702962962962964e-05,
      "loss": 2.933,
      "step": 2010
    },
    {
      "epoch": 0.22,
      "grad_norm": 10.40029525756836,
      "learning_rate": 3.970148148148148e-05,
      "loss": 3.1992,
      "step": 2020
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.058245658874512,
      "learning_rate": 3.97e-05,
      "loss": 3.0344,
      "step": 2030
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.152528762817383,
      "learning_rate": 3.9698518518518526e-05,
      "loss": 2.9333,
      "step": 2040
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.44598913192749,
      "learning_rate": 3.969703703703704e-05,
      "loss": 2.9222,
      "step": 2050
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.5527982711792,
      "learning_rate": 3.969555555555556e-05,
      "loss": 3.0858,
      "step": 2060
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.375369071960449,
      "learning_rate": 3.9694074074074074e-05,
      "loss": 2.9815,
      "step": 2070
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.963386535644531,
      "learning_rate": 3.9692592592592596e-05,
      "loss": 2.9207,
      "step": 2080
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.475825309753418,
      "learning_rate": 3.969111111111111e-05,
      "loss": 2.8939,
      "step": 2090
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.195822715759277,
      "learning_rate": 3.9689629629629635e-05,
      "loss": 2.9392,
      "step": 2100
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.966339588165283,
      "learning_rate": 3.968814814814815e-05,
      "loss": 2.9666,
      "step": 2110
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.474119663238525,
      "learning_rate": 3.968666666666667e-05,
      "loss": 2.9222,
      "step": 2120
    },
    {
      "epoch": 0.24,
      "grad_norm": 9.041574478149414,
      "learning_rate": 3.968518518518518e-05,
      "loss": 3.0157,
      "step": 2130
    },
    {
      "epoch": 0.24,
      "grad_norm": 9.069282531738281,
      "learning_rate": 3.9683703703703706e-05,
      "loss": 2.929,
      "step": 2140
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.640047073364258,
      "learning_rate": 3.968222222222223e-05,
      "loss": 3.085,
      "step": 2150
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.535993576049805,
      "learning_rate": 3.9680740740740745e-05,
      "loss": 2.8784,
      "step": 2160
    },
    {
      "epoch": 0.24,
      "grad_norm": 9.122293472290039,
      "learning_rate": 3.967925925925926e-05,
      "loss": 2.8377,
      "step": 2170
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.677779197692871,
      "learning_rate": 3.967777777777778e-05,
      "loss": 2.85,
      "step": 2180
    },
    {
      "epoch": 0.24,
      "grad_norm": 9.077884674072266,
      "learning_rate": 3.96762962962963e-05,
      "loss": 3.0347,
      "step": 2190
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.644420623779297,
      "learning_rate": 3.967481481481482e-05,
      "loss": 2.9293,
      "step": 2200
    },
    {
      "epoch": 0.25,
      "grad_norm": 9.217472076416016,
      "learning_rate": 3.967333333333334e-05,
      "loss": 2.7901,
      "step": 2210
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.92541790008545,
      "learning_rate": 3.9671851851851855e-05,
      "loss": 2.9327,
      "step": 2220
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.384927749633789,
      "learning_rate": 3.967037037037037e-05,
      "loss": 3.0035,
      "step": 2230
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.24972152709961,
      "learning_rate": 3.9668888888888893e-05,
      "loss": 2.9069,
      "step": 2240
    },
    {
      "epoch": 0.25,
      "grad_norm": 10.644230842590332,
      "learning_rate": 3.966740740740741e-05,
      "loss": 2.9861,
      "step": 2250
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.452095031738281,
      "learning_rate": 3.966592592592593e-05,
      "loss": 3.0905,
      "step": 2260
    },
    {
      "epoch": 0.25,
      "grad_norm": 9.765003204345703,
      "learning_rate": 3.966444444444445e-05,
      "loss": 2.9707,
      "step": 2270
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.381750106811523,
      "learning_rate": 3.9662962962962964e-05,
      "loss": 2.9441,
      "step": 2280
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.420032501220703,
      "learning_rate": 3.966148148148148e-05,
      "loss": 2.9943,
      "step": 2290
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.339471817016602,
      "learning_rate": 3.966e-05,
      "loss": 2.9215,
      "step": 2300
    },
    {
      "epoch": 0.26,
      "grad_norm": 11.791043281555176,
      "learning_rate": 3.9658518518518526e-05,
      "loss": 2.8762,
      "step": 2310
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.77083683013916,
      "learning_rate": 3.965703703703704e-05,
      "loss": 2.7743,
      "step": 2320
    },
    {
      "epoch": 0.26,
      "grad_norm": 9.488706588745117,
      "learning_rate": 3.965555555555556e-05,
      "loss": 2.824,
      "step": 2330
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.719759464263916,
      "learning_rate": 3.9654074074074074e-05,
      "loss": 2.9159,
      "step": 2340
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.957624435424805,
      "learning_rate": 3.96525925925926e-05,
      "loss": 2.8381,
      "step": 2350
    },
    {
      "epoch": 0.26,
      "grad_norm": 9.219160079956055,
      "learning_rate": 3.965111111111111e-05,
      "loss": 2.9019,
      "step": 2360
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.623549461364746,
      "learning_rate": 3.9649629629629636e-05,
      "loss": 2.729,
      "step": 2370
    },
    {
      "epoch": 0.26,
      "grad_norm": 9.067327499389648,
      "learning_rate": 3.964814814814815e-05,
      "loss": 2.8399,
      "step": 2380
    },
    {
      "epoch": 0.27,
      "grad_norm": 9.160333633422852,
      "learning_rate": 3.964666666666667e-05,
      "loss": 2.7832,
      "step": 2390
    },
    {
      "epoch": 0.27,
      "grad_norm": 10.03061580657959,
      "learning_rate": 3.9645185185185184e-05,
      "loss": 2.8845,
      "step": 2400
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.627468585968018,
      "learning_rate": 3.9643703703703706e-05,
      "loss": 2.6362,
      "step": 2410
    },
    {
      "epoch": 0.27,
      "grad_norm": 9.949913024902344,
      "learning_rate": 3.964222222222223e-05,
      "loss": 2.7789,
      "step": 2420
    },
    {
      "epoch": 0.27,
      "grad_norm": 9.615520477294922,
      "learning_rate": 3.9640740740740745e-05,
      "loss": 2.7536,
      "step": 2430
    },
    {
      "epoch": 0.27,
      "grad_norm": 10.34235954284668,
      "learning_rate": 3.963925925925926e-05,
      "loss": 2.8468,
      "step": 2440
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.962135314941406,
      "learning_rate": 3.963777777777778e-05,
      "loss": 2.7091,
      "step": 2450
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.259598731994629,
      "learning_rate": 3.96362962962963e-05,
      "loss": 2.8891,
      "step": 2460
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.196483612060547,
      "learning_rate": 3.9634814814814816e-05,
      "loss": 2.9101,
      "step": 2470
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.615795135498047,
      "learning_rate": 3.963333333333334e-05,
      "loss": 2.7095,
      "step": 2480
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.969799041748047,
      "learning_rate": 3.9631851851851855e-05,
      "loss": 2.8506,
      "step": 2490
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.3048677444458,
      "learning_rate": 3.963037037037037e-05,
      "loss": 2.7589,
      "step": 2500
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.829537391662598,
      "learning_rate": 3.962888888888889e-05,
      "loss": 2.8448,
      "step": 2510
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.655500411987305,
      "learning_rate": 3.962740740740741e-05,
      "loss": 2.8201,
      "step": 2520
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.947196006774902,
      "learning_rate": 3.962592592592593e-05,
      "loss": 2.8262,
      "step": 2530
    },
    {
      "epoch": 0.28,
      "grad_norm": 9.28722095489502,
      "learning_rate": 3.962444444444445e-05,
      "loss": 2.8709,
      "step": 2540
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.656599998474121,
      "learning_rate": 3.9622962962962965e-05,
      "loss": 2.6802,
      "step": 2550
    },
    {
      "epoch": 0.28,
      "grad_norm": 9.344256401062012,
      "learning_rate": 3.962148148148148e-05,
      "loss": 2.7155,
      "step": 2560
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.590044021606445,
      "learning_rate": 3.9620000000000004e-05,
      "loss": 2.8475,
      "step": 2570
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.301584243774414,
      "learning_rate": 3.961851851851852e-05,
      "loss": 2.6963,
      "step": 2580
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.270870208740234,
      "learning_rate": 3.961703703703704e-05,
      "loss": 2.6596,
      "step": 2590
    },
    {
      "epoch": 0.29,
      "grad_norm": 9.031251907348633,
      "learning_rate": 3.961555555555556e-05,
      "loss": 2.6518,
      "step": 2600
    },
    {
      "epoch": 0.29,
      "grad_norm": 9.456904411315918,
      "learning_rate": 3.9614074074074074e-05,
      "loss": 2.715,
      "step": 2610
    },
    {
      "epoch": 0.29,
      "grad_norm": 9.808568000793457,
      "learning_rate": 3.96125925925926e-05,
      "loss": 2.8223,
      "step": 2620
    },
    {
      "epoch": 0.29,
      "grad_norm": 10.1956787109375,
      "learning_rate": 3.961111111111111e-05,
      "loss": 2.6423,
      "step": 2630
    },
    {
      "epoch": 0.29,
      "grad_norm": 9.498592376708984,
      "learning_rate": 3.9609629629629636e-05,
      "loss": 2.6371,
      "step": 2640
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.7958402633667,
      "learning_rate": 3.960814814814815e-05,
      "loss": 2.742,
      "step": 2650
    },
    {
      "epoch": 0.3,
      "grad_norm": 9.628084182739258,
      "learning_rate": 3.960666666666667e-05,
      "loss": 2.586,
      "step": 2660
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.228590488433838,
      "learning_rate": 3.9605185185185184e-05,
      "loss": 2.6435,
      "step": 2670
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.711243629455566,
      "learning_rate": 3.960370370370371e-05,
      "loss": 2.7269,
      "step": 2680
    },
    {
      "epoch": 0.3,
      "grad_norm": 11.244153022766113,
      "learning_rate": 3.960222222222223e-05,
      "loss": 2.7149,
      "step": 2690
    },
    {
      "epoch": 0.3,
      "grad_norm": 12.35550594329834,
      "learning_rate": 3.9600740740740746e-05,
      "loss": 2.631,
      "step": 2700
    },
    {
      "epoch": 0.3,
      "grad_norm": 11.074386596679688,
      "learning_rate": 3.959925925925926e-05,
      "loss": 2.4579,
      "step": 2710
    },
    {
      "epoch": 0.3,
      "grad_norm": 10.066783905029297,
      "learning_rate": 3.959777777777778e-05,
      "loss": 2.6772,
      "step": 2720
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.827735900878906,
      "learning_rate": 3.95962962962963e-05,
      "loss": 2.552,
      "step": 2730
    },
    {
      "epoch": 0.3,
      "grad_norm": 10.444025039672852,
      "learning_rate": 3.9594814814814817e-05,
      "loss": 2.5071,
      "step": 2740
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.682965278625488,
      "learning_rate": 3.959333333333334e-05,
      "loss": 2.5894,
      "step": 2750
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.811267852783203,
      "learning_rate": 3.9591851851851855e-05,
      "loss": 2.5965,
      "step": 2760
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.65582275390625,
      "learning_rate": 3.959037037037037e-05,
      "loss": 2.679,
      "step": 2770
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.641485214233398,
      "learning_rate": 3.958888888888889e-05,
      "loss": 2.5629,
      "step": 2780
    },
    {
      "epoch": 0.31,
      "grad_norm": 9.879773139953613,
      "learning_rate": 3.958740740740741e-05,
      "loss": 2.5197,
      "step": 2790
    },
    {
      "epoch": 0.31,
      "grad_norm": 10.406843185424805,
      "learning_rate": 3.958592592592593e-05,
      "loss": 2.6061,
      "step": 2800
    },
    {
      "epoch": 0.31,
      "grad_norm": 11.245567321777344,
      "learning_rate": 3.958444444444445e-05,
      "loss": 2.3989,
      "step": 2810
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.002862930297852,
      "learning_rate": 3.9582962962962965e-05,
      "loss": 2.5763,
      "step": 2820
    },
    {
      "epoch": 0.31,
      "grad_norm": 10.168984413146973,
      "learning_rate": 3.958148148148148e-05,
      "loss": 2.4816,
      "step": 2830
    },
    {
      "epoch": 0.32,
      "grad_norm": 13.658247947692871,
      "learning_rate": 3.9580000000000004e-05,
      "loss": 2.5476,
      "step": 2840
    },
    {
      "epoch": 0.32,
      "grad_norm": 10.393209457397461,
      "learning_rate": 3.957851851851852e-05,
      "loss": 2.488,
      "step": 2850
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.353106498718262,
      "learning_rate": 3.957703703703704e-05,
      "loss": 2.5283,
      "step": 2860
    },
    {
      "epoch": 0.32,
      "grad_norm": 11.142742156982422,
      "learning_rate": 3.957555555555556e-05,
      "loss": 2.5948,
      "step": 2870
    },
    {
      "epoch": 0.32,
      "grad_norm": 11.383784294128418,
      "learning_rate": 3.9574074074074075e-05,
      "loss": 2.4877,
      "step": 2880
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.71043872833252,
      "learning_rate": 3.95725925925926e-05,
      "loss": 2.3869,
      "step": 2890
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.912959098815918,
      "learning_rate": 3.9571111111111114e-05,
      "loss": 2.4589,
      "step": 2900
    },
    {
      "epoch": 0.32,
      "grad_norm": 13.714717864990234,
      "learning_rate": 3.9569629629629636e-05,
      "loss": 2.3837,
      "step": 2910
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.052582740783691,
      "learning_rate": 3.956814814814815e-05,
      "loss": 2.4604,
      "step": 2920
    },
    {
      "epoch": 0.33,
      "grad_norm": 17.24552345275879,
      "learning_rate": 3.956666666666667e-05,
      "loss": 2.4643,
      "step": 2930
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.57468318939209,
      "learning_rate": 3.9565185185185184e-05,
      "loss": 2.3482,
      "step": 2940
    },
    {
      "epoch": 0.33,
      "grad_norm": 9.209965705871582,
      "learning_rate": 3.956370370370371e-05,
      "loss": 2.6717,
      "step": 2950
    },
    {
      "epoch": 0.33,
      "grad_norm": 10.288717269897461,
      "learning_rate": 3.956222222222222e-05,
      "loss": 2.4898,
      "step": 2960
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.75059700012207,
      "learning_rate": 3.9560740740740746e-05,
      "loss": 2.4509,
      "step": 2970
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.962786674499512,
      "learning_rate": 3.955925925925926e-05,
      "loss": 2.3838,
      "step": 2980
    },
    {
      "epoch": 0.33,
      "grad_norm": 11.95268440246582,
      "learning_rate": 3.955777777777778e-05,
      "loss": 2.3804,
      "step": 2990
    },
    {
      "epoch": 0.33,
      "grad_norm": 9.491704940795898,
      "learning_rate": 3.95562962962963e-05,
      "loss": 2.3861,
      "step": 3000
    },
    {
      "epoch": 0.33,
      "grad_norm": 12.540963172912598,
      "learning_rate": 3.955481481481482e-05,
      "loss": 2.4402,
      "step": 3010
    },
    {
      "epoch": 0.34,
      "grad_norm": 10.056488990783691,
      "learning_rate": 3.955333333333334e-05,
      "loss": 2.4801,
      "step": 3020
    },
    {
      "epoch": 0.34,
      "grad_norm": 10.56578254699707,
      "learning_rate": 3.9551851851851856e-05,
      "loss": 2.398,
      "step": 3030
    },
    {
      "epoch": 0.34,
      "grad_norm": 11.342564582824707,
      "learning_rate": 3.955037037037037e-05,
      "loss": 2.2007,
      "step": 3040
    },
    {
      "epoch": 0.34,
      "grad_norm": 10.669201850891113,
      "learning_rate": 3.954888888888889e-05,
      "loss": 2.3111,
      "step": 3050
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.760494232177734,
      "learning_rate": 3.954740740740741e-05,
      "loss": 2.4002,
      "step": 3060
    },
    {
      "epoch": 0.34,
      "grad_norm": 9.830879211425781,
      "learning_rate": 3.954592592592593e-05,
      "loss": 2.3253,
      "step": 3070
    },
    {
      "epoch": 0.34,
      "grad_norm": 10.357745170593262,
      "learning_rate": 3.954444444444445e-05,
      "loss": 2.3765,
      "step": 3080
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.82452392578125,
      "learning_rate": 3.9542962962962965e-05,
      "loss": 2.3201,
      "step": 3090
    },
    {
      "epoch": 0.34,
      "grad_norm": 10.967610359191895,
      "learning_rate": 3.954148148148148e-05,
      "loss": 2.2872,
      "step": 3100
    },
    {
      "epoch": 0.35,
      "grad_norm": 9.416655540466309,
      "learning_rate": 3.9540000000000004e-05,
      "loss": 2.3503,
      "step": 3110
    },
    {
      "epoch": 0.35,
      "grad_norm": 9.10791301727295,
      "learning_rate": 3.953851851851852e-05,
      "loss": 2.2762,
      "step": 3120
    },
    {
      "epoch": 0.35,
      "grad_norm": 11.826363563537598,
      "learning_rate": 3.953703703703704e-05,
      "loss": 2.3532,
      "step": 3130
    },
    {
      "epoch": 0.35,
      "grad_norm": 8.558765411376953,
      "learning_rate": 3.953555555555556e-05,
      "loss": 2.0978,
      "step": 3140
    },
    {
      "epoch": 0.35,
      "grad_norm": 9.71926212310791,
      "learning_rate": 3.9534074074074075e-05,
      "loss": 2.2899,
      "step": 3150
    },
    {
      "epoch": 0.35,
      "grad_norm": 11.294955253601074,
      "learning_rate": 3.95325925925926e-05,
      "loss": 2.1978,
      "step": 3160
    },
    {
      "epoch": 0.35,
      "grad_norm": 12.054023742675781,
      "learning_rate": 3.9531111111111114e-05,
      "loss": 2.2555,
      "step": 3170
    },
    {
      "epoch": 0.35,
      "grad_norm": 9.70484447479248,
      "learning_rate": 3.952962962962963e-05,
      "loss": 2.2717,
      "step": 3180
    },
    {
      "epoch": 0.35,
      "grad_norm": 8.563071250915527,
      "learning_rate": 3.952814814814815e-05,
      "loss": 2.2997,
      "step": 3190
    },
    {
      "epoch": 0.36,
      "grad_norm": 10.456141471862793,
      "learning_rate": 3.952666666666667e-05,
      "loss": 2.2703,
      "step": 3200
    },
    {
      "epoch": 0.36,
      "grad_norm": 9.042710304260254,
      "learning_rate": 3.9525185185185185e-05,
      "loss": 2.2885,
      "step": 3210
    },
    {
      "epoch": 0.36,
      "grad_norm": 10.134068489074707,
      "learning_rate": 3.952370370370371e-05,
      "loss": 2.1636,
      "step": 3220
    },
    {
      "epoch": 0.36,
      "grad_norm": 14.135106086730957,
      "learning_rate": 3.9522222222222224e-05,
      "loss": 2.1001,
      "step": 3230
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.723067283630371,
      "learning_rate": 3.9520740740740746e-05,
      "loss": 2.3105,
      "step": 3240
    },
    {
      "epoch": 0.36,
      "grad_norm": 10.993769645690918,
      "learning_rate": 3.951925925925926e-05,
      "loss": 2.0037,
      "step": 3250
    },
    {
      "epoch": 0.36,
      "grad_norm": 11.087967872619629,
      "learning_rate": 3.951777777777778e-05,
      "loss": 2.1261,
      "step": 3260
    },
    {
      "epoch": 0.36,
      "grad_norm": 11.82425594329834,
      "learning_rate": 3.95162962962963e-05,
      "loss": 2.1981,
      "step": 3270
    },
    {
      "epoch": 0.36,
      "grad_norm": 9.961017608642578,
      "learning_rate": 3.951481481481482e-05,
      "loss": 2.1061,
      "step": 3280
    },
    {
      "epoch": 0.37,
      "grad_norm": 12.024286270141602,
      "learning_rate": 3.951333333333334e-05,
      "loss": 2.178,
      "step": 3290
    },
    {
      "epoch": 0.37,
      "grad_norm": 18.64792251586914,
      "learning_rate": 3.9511851851851856e-05,
      "loss": 2.1622,
      "step": 3300
    },
    {
      "epoch": 0.37,
      "grad_norm": 16.22053337097168,
      "learning_rate": 3.951037037037037e-05,
      "loss": 2.2349,
      "step": 3310
    },
    {
      "epoch": 0.37,
      "grad_norm": 14.488202095031738,
      "learning_rate": 3.950888888888889e-05,
      "loss": 2.0222,
      "step": 3320
    },
    {
      "epoch": 0.37,
      "grad_norm": 9.32981014251709,
      "learning_rate": 3.950740740740741e-05,
      "loss": 2.1343,
      "step": 3330
    },
    {
      "epoch": 0.37,
      "grad_norm": 11.29607105255127,
      "learning_rate": 3.950592592592593e-05,
      "loss": 1.9321,
      "step": 3340
    },
    {
      "epoch": 0.37,
      "grad_norm": 16.92108726501465,
      "learning_rate": 3.950444444444445e-05,
      "loss": 2.1749,
      "step": 3350
    },
    {
      "epoch": 0.37,
      "grad_norm": 9.656216621398926,
      "learning_rate": 3.9502962962962966e-05,
      "loss": 2.2846,
      "step": 3360
    },
    {
      "epoch": 0.37,
      "grad_norm": 10.322938919067383,
      "learning_rate": 3.950148148148148e-05,
      "loss": 2.2484,
      "step": 3370
    },
    {
      "epoch": 0.38,
      "grad_norm": 11.369107246398926,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 2.1307,
      "step": 3380
    },
    {
      "epoch": 0.38,
      "grad_norm": 9.129347801208496,
      "learning_rate": 3.949851851851852e-05,
      "loss": 2.0886,
      "step": 3390
    },
    {
      "epoch": 0.38,
      "grad_norm": 8.639226913452148,
      "learning_rate": 3.9497037037037043e-05,
      "loss": 2.0188,
      "step": 3400
    },
    {
      "epoch": 0.38,
      "grad_norm": 10.664708137512207,
      "learning_rate": 3.949555555555556e-05,
      "loss": 2.1862,
      "step": 3410
    },
    {
      "epoch": 0.38,
      "grad_norm": 10.975680351257324,
      "learning_rate": 3.9494074074074076e-05,
      "loss": 2.0122,
      "step": 3420
    },
    {
      "epoch": 0.38,
      "grad_norm": 11.395440101623535,
      "learning_rate": 3.94925925925926e-05,
      "loss": 2.0537,
      "step": 3430
    },
    {
      "epoch": 0.38,
      "grad_norm": 9.790863037109375,
      "learning_rate": 3.9491111111111114e-05,
      "loss": 2.096,
      "step": 3440
    },
    {
      "epoch": 0.38,
      "grad_norm": 10.368117332458496,
      "learning_rate": 3.948962962962963e-05,
      "loss": 2.1735,
      "step": 3450
    },
    {
      "epoch": 0.38,
      "grad_norm": 10.110525131225586,
      "learning_rate": 3.948814814814815e-05,
      "loss": 2.013,
      "step": 3460
    },
    {
      "epoch": 0.39,
      "grad_norm": 10.656353950500488,
      "learning_rate": 3.948666666666667e-05,
      "loss": 1.9305,
      "step": 3470
    },
    {
      "epoch": 0.39,
      "grad_norm": 9.27166748046875,
      "learning_rate": 3.9485185185185185e-05,
      "loss": 1.9872,
      "step": 3480
    },
    {
      "epoch": 0.39,
      "grad_norm": 9.354766845703125,
      "learning_rate": 3.948370370370371e-05,
      "loss": 1.8874,
      "step": 3490
    },
    {
      "epoch": 0.39,
      "grad_norm": 21.005817413330078,
      "learning_rate": 3.9482222222222224e-05,
      "loss": 2.0347,
      "step": 3500
    },
    {
      "epoch": 0.39,
      "grad_norm": 19.796810150146484,
      "learning_rate": 3.948074074074075e-05,
      "loss": 2.0999,
      "step": 3510
    },
    {
      "epoch": 0.39,
      "grad_norm": 12.845690727233887,
      "learning_rate": 3.947925925925926e-05,
      "loss": 2.0466,
      "step": 3520
    },
    {
      "epoch": 0.39,
      "grad_norm": 10.267461776733398,
      "learning_rate": 3.947777777777778e-05,
      "loss": 1.9578,
      "step": 3530
    },
    {
      "epoch": 0.39,
      "grad_norm": 11.070473670959473,
      "learning_rate": 3.94762962962963e-05,
      "loss": 2.0504,
      "step": 3540
    },
    {
      "epoch": 0.39,
      "grad_norm": 11.784704208374023,
      "learning_rate": 3.947481481481482e-05,
      "loss": 1.9877,
      "step": 3550
    },
    {
      "epoch": 0.4,
      "grad_norm": 11.906967163085938,
      "learning_rate": 3.9473333333333334e-05,
      "loss": 1.823,
      "step": 3560
    },
    {
      "epoch": 0.4,
      "grad_norm": 12.457569122314453,
      "learning_rate": 3.9471851851851857e-05,
      "loss": 1.9822,
      "step": 3570
    },
    {
      "epoch": 0.4,
      "grad_norm": 9.318574905395508,
      "learning_rate": 3.947037037037037e-05,
      "loss": 1.9667,
      "step": 3580
    },
    {
      "epoch": 0.4,
      "grad_norm": 12.539787292480469,
      "learning_rate": 3.946888888888889e-05,
      "loss": 2.0002,
      "step": 3590
    },
    {
      "epoch": 0.4,
      "grad_norm": 17.21027946472168,
      "learning_rate": 3.946740740740741e-05,
      "loss": 2.0051,
      "step": 3600
    },
    {
      "epoch": 0.4,
      "grad_norm": 10.150635719299316,
      "learning_rate": 3.946592592592593e-05,
      "loss": 1.7952,
      "step": 3610
    },
    {
      "epoch": 0.4,
      "grad_norm": 17.282779693603516,
      "learning_rate": 3.946444444444445e-05,
      "loss": 1.8658,
      "step": 3620
    },
    {
      "epoch": 0.4,
      "grad_norm": 10.063383102416992,
      "learning_rate": 3.9462962962962966e-05,
      "loss": 1.8755,
      "step": 3630
    },
    {
      "epoch": 0.4,
      "grad_norm": 12.450075149536133,
      "learning_rate": 3.946148148148148e-05,
      "loss": 2.0159,
      "step": 3640
    },
    {
      "epoch": 0.41,
      "grad_norm": 12.748250961303711,
      "learning_rate": 3.9460000000000005e-05,
      "loss": 1.8725,
      "step": 3650
    },
    {
      "epoch": 0.41,
      "grad_norm": 11.976235389709473,
      "learning_rate": 3.945851851851852e-05,
      "loss": 1.8628,
      "step": 3660
    },
    {
      "epoch": 0.41,
      "grad_norm": 9.36638069152832,
      "learning_rate": 3.945703703703704e-05,
      "loss": 1.7652,
      "step": 3670
    },
    {
      "epoch": 0.41,
      "grad_norm": 11.52474308013916,
      "learning_rate": 3.945555555555556e-05,
      "loss": 1.894,
      "step": 3680
    },
    {
      "epoch": 0.41,
      "grad_norm": 10.776250839233398,
      "learning_rate": 3.9454074074074076e-05,
      "loss": 1.8114,
      "step": 3690
    },
    {
      "epoch": 0.41,
      "grad_norm": 10.261714935302734,
      "learning_rate": 3.94525925925926e-05,
      "loss": 1.8097,
      "step": 3700
    },
    {
      "epoch": 0.41,
      "grad_norm": 11.59403133392334,
      "learning_rate": 3.9451111111111115e-05,
      "loss": 1.7459,
      "step": 3710
    },
    {
      "epoch": 0.41,
      "grad_norm": 10.279400825500488,
      "learning_rate": 3.944962962962963e-05,
      "loss": 1.8478,
      "step": 3720
    },
    {
      "epoch": 0.41,
      "grad_norm": 11.037039756774902,
      "learning_rate": 3.9448148148148154e-05,
      "loss": 1.8075,
      "step": 3730
    },
    {
      "epoch": 0.42,
      "grad_norm": 15.490375518798828,
      "learning_rate": 3.944666666666667e-05,
      "loss": 1.802,
      "step": 3740
    },
    {
      "epoch": 0.42,
      "grad_norm": 23.431180953979492,
      "learning_rate": 3.9445185185185186e-05,
      "loss": 1.9476,
      "step": 3750
    },
    {
      "epoch": 0.42,
      "grad_norm": 12.31948184967041,
      "learning_rate": 3.944370370370371e-05,
      "loss": 1.7908,
      "step": 3760
    },
    {
      "epoch": 0.42,
      "grad_norm": 9.40516185760498,
      "learning_rate": 3.9442222222222224e-05,
      "loss": 1.8837,
      "step": 3770
    },
    {
      "epoch": 0.42,
      "grad_norm": 9.723516464233398,
      "learning_rate": 3.944074074074075e-05,
      "loss": 1.625,
      "step": 3780
    },
    {
      "epoch": 0.42,
      "grad_norm": 11.965776443481445,
      "learning_rate": 3.943925925925926e-05,
      "loss": 1.8212,
      "step": 3790
    },
    {
      "epoch": 0.42,
      "grad_norm": 10.516222953796387,
      "learning_rate": 3.943777777777778e-05,
      "loss": 1.7428,
      "step": 3800
    },
    {
      "epoch": 0.42,
      "grad_norm": 10.165887832641602,
      "learning_rate": 3.94362962962963e-05,
      "loss": 1.7382,
      "step": 3810
    },
    {
      "epoch": 0.42,
      "grad_norm": 9.90127944946289,
      "learning_rate": 3.943481481481482e-05,
      "loss": 1.8088,
      "step": 3820
    },
    {
      "epoch": 0.43,
      "grad_norm": 9.537520408630371,
      "learning_rate": 3.9433333333333334e-05,
      "loss": 1.7724,
      "step": 3830
    },
    {
      "epoch": 0.43,
      "grad_norm": 12.868382453918457,
      "learning_rate": 3.943185185185186e-05,
      "loss": 1.626,
      "step": 3840
    },
    {
      "epoch": 0.43,
      "grad_norm": 12.278215408325195,
      "learning_rate": 3.943037037037037e-05,
      "loss": 1.7146,
      "step": 3850
    },
    {
      "epoch": 0.43,
      "grad_norm": 18.029924392700195,
      "learning_rate": 3.9428888888888896e-05,
      "loss": 1.7631,
      "step": 3860
    },
    {
      "epoch": 0.43,
      "grad_norm": 9.850916862487793,
      "learning_rate": 3.942740740740741e-05,
      "loss": 1.7193,
      "step": 3870
    },
    {
      "epoch": 0.43,
      "grad_norm": 10.581864356994629,
      "learning_rate": 3.942592592592593e-05,
      "loss": 1.7512,
      "step": 3880
    },
    {
      "epoch": 0.43,
      "grad_norm": 13.839472770690918,
      "learning_rate": 3.942444444444445e-05,
      "loss": 1.8188,
      "step": 3890
    },
    {
      "epoch": 0.43,
      "grad_norm": 9.789868354797363,
      "learning_rate": 3.942296296296297e-05,
      "loss": 1.8334,
      "step": 3900
    },
    {
      "epoch": 0.43,
      "grad_norm": 12.15420913696289,
      "learning_rate": 3.942148148148148e-05,
      "loss": 1.6817,
      "step": 3910
    },
    {
      "epoch": 0.44,
      "grad_norm": 9.619365692138672,
      "learning_rate": 3.9420000000000005e-05,
      "loss": 1.6645,
      "step": 3920
    },
    {
      "epoch": 0.44,
      "grad_norm": 12.896134376525879,
      "learning_rate": 3.941851851851852e-05,
      "loss": 1.7629,
      "step": 3930
    },
    {
      "epoch": 0.44,
      "grad_norm": 10.832200050354004,
      "learning_rate": 3.941703703703704e-05,
      "loss": 1.7605,
      "step": 3940
    },
    {
      "epoch": 0.44,
      "grad_norm": 10.667073249816895,
      "learning_rate": 3.941555555555556e-05,
      "loss": 1.7822,
      "step": 3950
    },
    {
      "epoch": 0.44,
      "grad_norm": 9.906597137451172,
      "learning_rate": 3.9414074074074076e-05,
      "loss": 1.7559,
      "step": 3960
    },
    {
      "epoch": 0.44,
      "grad_norm": 10.36334228515625,
      "learning_rate": 3.94125925925926e-05,
      "loss": 1.6892,
      "step": 3970
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.762810707092285,
      "learning_rate": 3.9411111111111115e-05,
      "loss": 1.7168,
      "step": 3980
    },
    {
      "epoch": 0.44,
      "grad_norm": 12.675385475158691,
      "learning_rate": 3.940962962962963e-05,
      "loss": 1.5454,
      "step": 3990
    },
    {
      "epoch": 0.44,
      "grad_norm": 9.527888298034668,
      "learning_rate": 3.9408148148148154e-05,
      "loss": 1.5255,
      "step": 4000
    },
    {
      "epoch": 0.45,
      "grad_norm": 11.121363639831543,
      "learning_rate": 3.940666666666667e-05,
      "loss": 1.5596,
      "step": 4010
    },
    {
      "epoch": 0.45,
      "grad_norm": 13.433391571044922,
      "learning_rate": 3.9405185185185186e-05,
      "loss": 1.5253,
      "step": 4020
    },
    {
      "epoch": 0.45,
      "grad_norm": 14.072538375854492,
      "learning_rate": 3.940370370370371e-05,
      "loss": 1.4864,
      "step": 4030
    },
    {
      "epoch": 0.45,
      "grad_norm": 17.1368408203125,
      "learning_rate": 3.9402222222222225e-05,
      "loss": 1.7917,
      "step": 4040
    },
    {
      "epoch": 0.45,
      "grad_norm": 10.488892555236816,
      "learning_rate": 3.940074074074074e-05,
      "loss": 1.6618,
      "step": 4050
    },
    {
      "epoch": 0.45,
      "grad_norm": 14.367491722106934,
      "learning_rate": 3.9399259259259264e-05,
      "loss": 1.6258,
      "step": 4060
    },
    {
      "epoch": 0.45,
      "grad_norm": 12.914902687072754,
      "learning_rate": 3.939777777777778e-05,
      "loss": 1.4905,
      "step": 4070
    },
    {
      "epoch": 0.45,
      "grad_norm": 11.137133598327637,
      "learning_rate": 3.93962962962963e-05,
      "loss": 1.5801,
      "step": 4080
    },
    {
      "epoch": 0.45,
      "grad_norm": 14.604212760925293,
      "learning_rate": 3.939481481481482e-05,
      "loss": 1.5885,
      "step": 4090
    },
    {
      "epoch": 0.46,
      "grad_norm": 12.338911056518555,
      "learning_rate": 3.9393333333333335e-05,
      "loss": 1.5527,
      "step": 4100
    },
    {
      "epoch": 0.46,
      "grad_norm": 11.64016342163086,
      "learning_rate": 3.939185185185186e-05,
      "loss": 1.5921,
      "step": 4110
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.886778831481934,
      "learning_rate": 3.939037037037037e-05,
      "loss": 1.5775,
      "step": 4120
    },
    {
      "epoch": 0.46,
      "grad_norm": 13.86487102508545,
      "learning_rate": 3.9388888888888896e-05,
      "loss": 1.5322,
      "step": 4130
    },
    {
      "epoch": 0.46,
      "grad_norm": 9.567480087280273,
      "learning_rate": 3.938740740740741e-05,
      "loss": 1.6024,
      "step": 4140
    },
    {
      "epoch": 0.46,
      "grad_norm": 11.199153900146484,
      "learning_rate": 3.938592592592593e-05,
      "loss": 1.6021,
      "step": 4150
    },
    {
      "epoch": 0.46,
      "grad_norm": 10.576263427734375,
      "learning_rate": 3.9384444444444444e-05,
      "loss": 1.5702,
      "step": 4160
    },
    {
      "epoch": 0.46,
      "grad_norm": 13.215821266174316,
      "learning_rate": 3.938296296296297e-05,
      "loss": 1.531,
      "step": 4170
    },
    {
      "epoch": 0.46,
      "grad_norm": 10.950586318969727,
      "learning_rate": 3.938148148148148e-05,
      "loss": 1.4997,
      "step": 4180
    },
    {
      "epoch": 0.47,
      "grad_norm": 27.913955688476562,
      "learning_rate": 3.9380000000000006e-05,
      "loss": 1.3426,
      "step": 4190
    },
    {
      "epoch": 0.47,
      "grad_norm": 10.837875366210938,
      "learning_rate": 3.937851851851852e-05,
      "loss": 1.6354,
      "step": 4200
    },
    {
      "epoch": 0.47,
      "grad_norm": 9.251701354980469,
      "learning_rate": 3.937703703703704e-05,
      "loss": 1.6404,
      "step": 4210
    },
    {
      "epoch": 0.47,
      "grad_norm": 12.85534381866455,
      "learning_rate": 3.937555555555556e-05,
      "loss": 1.7023,
      "step": 4220
    },
    {
      "epoch": 0.47,
      "grad_norm": 11.828149795532227,
      "learning_rate": 3.937407407407408e-05,
      "loss": 1.4975,
      "step": 4230
    },
    {
      "epoch": 0.47,
      "grad_norm": 13.098090171813965,
      "learning_rate": 3.93725925925926e-05,
      "loss": 1.3408,
      "step": 4240
    },
    {
      "epoch": 0.47,
      "grad_norm": 11.795371055603027,
      "learning_rate": 3.9371111111111116e-05,
      "loss": 1.46,
      "step": 4250
    },
    {
      "epoch": 0.47,
      "grad_norm": 11.107505798339844,
      "learning_rate": 3.936962962962963e-05,
      "loss": 1.4846,
      "step": 4260
    },
    {
      "epoch": 0.47,
      "grad_norm": 13.727829933166504,
      "learning_rate": 3.936814814814815e-05,
      "loss": 1.4392,
      "step": 4270
    },
    {
      "epoch": 0.48,
      "grad_norm": 11.274778366088867,
      "learning_rate": 3.936666666666667e-05,
      "loss": 1.5739,
      "step": 4280
    },
    {
      "epoch": 0.48,
      "grad_norm": 15.929137229919434,
      "learning_rate": 3.9365185185185186e-05,
      "loss": 1.6112,
      "step": 4290
    },
    {
      "epoch": 0.48,
      "grad_norm": 10.056768417358398,
      "learning_rate": 3.936370370370371e-05,
      "loss": 1.5689,
      "step": 4300
    },
    {
      "epoch": 0.48,
      "grad_norm": 16.03415298461914,
      "learning_rate": 3.9362222222222225e-05,
      "loss": 1.4296,
      "step": 4310
    },
    {
      "epoch": 0.48,
      "grad_norm": 18.131874084472656,
      "learning_rate": 3.936074074074074e-05,
      "loss": 1.3068,
      "step": 4320
    },
    {
      "epoch": 0.48,
      "grad_norm": 10.4956636428833,
      "learning_rate": 3.9359259259259264e-05,
      "loss": 1.5557,
      "step": 4330
    },
    {
      "epoch": 0.48,
      "grad_norm": 14.596805572509766,
      "learning_rate": 3.935777777777778e-05,
      "loss": 1.4323,
      "step": 4340
    },
    {
      "epoch": 0.48,
      "grad_norm": 11.893930435180664,
      "learning_rate": 3.93562962962963e-05,
      "loss": 1.4454,
      "step": 4350
    },
    {
      "epoch": 0.48,
      "grad_norm": 13.818061828613281,
      "learning_rate": 3.935481481481482e-05,
      "loss": 1.3364,
      "step": 4360
    },
    {
      "epoch": 0.49,
      "grad_norm": 9.82767391204834,
      "learning_rate": 3.9353333333333335e-05,
      "loss": 1.453,
      "step": 4370
    },
    {
      "epoch": 0.49,
      "grad_norm": 17.521291732788086,
      "learning_rate": 3.935185185185186e-05,
      "loss": 1.5705,
      "step": 4380
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.958690643310547,
      "learning_rate": 3.9350370370370374e-05,
      "loss": 1.3942,
      "step": 4390
    },
    {
      "epoch": 0.49,
      "grad_norm": 12.021756172180176,
      "learning_rate": 3.9348888888888897e-05,
      "loss": 1.3517,
      "step": 4400
    },
    {
      "epoch": 0.49,
      "grad_norm": 15.084845542907715,
      "learning_rate": 3.934740740740741e-05,
      "loss": 1.3724,
      "step": 4410
    },
    {
      "epoch": 0.49,
      "grad_norm": 10.764163970947266,
      "learning_rate": 3.934592592592593e-05,
      "loss": 1.4816,
      "step": 4420
    },
    {
      "epoch": 0.49,
      "grad_norm": 10.510799407958984,
      "learning_rate": 3.9344444444444445e-05,
      "loss": 1.4325,
      "step": 4430
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.20040225982666,
      "learning_rate": 3.934296296296297e-05,
      "loss": 1.4153,
      "step": 4440
    },
    {
      "epoch": 0.49,
      "grad_norm": 10.594931602478027,
      "learning_rate": 3.9341481481481483e-05,
      "loss": 1.4052,
      "step": 4450
    },
    {
      "epoch": 0.5,
      "grad_norm": 9.962153434753418,
      "learning_rate": 3.9340000000000006e-05,
      "loss": 1.2967,
      "step": 4460
    },
    {
      "epoch": 0.5,
      "grad_norm": 8.188675880432129,
      "learning_rate": 3.933851851851852e-05,
      "loss": 1.1834,
      "step": 4470
    },
    {
      "epoch": 0.5,
      "grad_norm": 11.790407180786133,
      "learning_rate": 3.933703703703704e-05,
      "loss": 1.4027,
      "step": 4480
    },
    {
      "epoch": 0.5,
      "grad_norm": 9.67410659790039,
      "learning_rate": 3.933555555555556e-05,
      "loss": 1.5001,
      "step": 4490
    },
    {
      "epoch": 0.5,
      "grad_norm": 13.104813575744629,
      "learning_rate": 3.933407407407408e-05,
      "loss": 1.3912,
      "step": 4500
    },
    {
      "epoch": 0.5,
      "grad_norm": 11.63668155670166,
      "learning_rate": 3.93325925925926e-05,
      "loss": 1.446,
      "step": 4510
    },
    {
      "epoch": 0.5,
      "grad_norm": 8.630452156066895,
      "learning_rate": 3.9331111111111116e-05,
      "loss": 1.3186,
      "step": 4520
    },
    {
      "epoch": 0.5,
      "grad_norm": 9.824053764343262,
      "learning_rate": 3.932962962962963e-05,
      "loss": 1.3992,
      "step": 4530
    },
    {
      "epoch": 0.5,
      "grad_norm": 11.436803817749023,
      "learning_rate": 3.932814814814815e-05,
      "loss": 1.3142,
      "step": 4540
    },
    {
      "epoch": 0.51,
      "grad_norm": 9.151229858398438,
      "learning_rate": 3.932666666666667e-05,
      "loss": 1.3599,
      "step": 4550
    },
    {
      "epoch": 0.51,
      "grad_norm": 10.178106307983398,
      "learning_rate": 3.932518518518519e-05,
      "loss": 1.271,
      "step": 4560
    },
    {
      "epoch": 0.51,
      "grad_norm": 10.02564811706543,
      "learning_rate": 3.932370370370371e-05,
      "loss": 1.2512,
      "step": 4570
    },
    {
      "epoch": 0.51,
      "grad_norm": 10.210710525512695,
      "learning_rate": 3.9322222222222226e-05,
      "loss": 1.3975,
      "step": 4580
    },
    {
      "epoch": 0.51,
      "grad_norm": 14.401573181152344,
      "learning_rate": 3.932074074074074e-05,
      "loss": 1.4485,
      "step": 4590
    },
    {
      "epoch": 0.51,
      "grad_norm": 11.533204078674316,
      "learning_rate": 3.9319259259259264e-05,
      "loss": 1.3155,
      "step": 4600
    },
    {
      "epoch": 0.51,
      "grad_norm": 14.588835716247559,
      "learning_rate": 3.931777777777778e-05,
      "loss": 1.2074,
      "step": 4610
    },
    {
      "epoch": 0.51,
      "grad_norm": 11.139472961425781,
      "learning_rate": 3.93162962962963e-05,
      "loss": 1.3504,
      "step": 4620
    },
    {
      "epoch": 0.51,
      "grad_norm": 12.96540355682373,
      "learning_rate": 3.931481481481482e-05,
      "loss": 1.3525,
      "step": 4630
    },
    {
      "epoch": 0.52,
      "grad_norm": 13.13764476776123,
      "learning_rate": 3.9313333333333335e-05,
      "loss": 1.3928,
      "step": 4640
    },
    {
      "epoch": 0.52,
      "grad_norm": 13.194195747375488,
      "learning_rate": 3.931185185185185e-05,
      "loss": 1.2527,
      "step": 4650
    },
    {
      "epoch": 0.52,
      "grad_norm": 9.47761058807373,
      "learning_rate": 3.9310370370370374e-05,
      "loss": 1.2445,
      "step": 4660
    },
    {
      "epoch": 0.52,
      "grad_norm": 23.548486709594727,
      "learning_rate": 3.93088888888889e-05,
      "loss": 1.2756,
      "step": 4670
    },
    {
      "epoch": 0.52,
      "grad_norm": 10.267064094543457,
      "learning_rate": 3.930740740740741e-05,
      "loss": 1.087,
      "step": 4680
    },
    {
      "epoch": 0.52,
      "grad_norm": 10.554084777832031,
      "learning_rate": 3.930592592592593e-05,
      "loss": 1.287,
      "step": 4690
    },
    {
      "epoch": 0.52,
      "grad_norm": 11.703354835510254,
      "learning_rate": 3.9304444444444445e-05,
      "loss": 1.2624,
      "step": 4700
    },
    {
      "epoch": 0.52,
      "grad_norm": 15.55675220489502,
      "learning_rate": 3.930296296296297e-05,
      "loss": 1.2561,
      "step": 4710
    },
    {
      "epoch": 0.52,
      "grad_norm": 13.994488716125488,
      "learning_rate": 3.9301481481481484e-05,
      "loss": 1.3106,
      "step": 4720
    },
    {
      "epoch": 0.53,
      "grad_norm": 11.097966194152832,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 1.3727,
      "step": 4730
    },
    {
      "epoch": 0.53,
      "grad_norm": 10.126276969909668,
      "learning_rate": 3.929851851851852e-05,
      "loss": 1.1889,
      "step": 4740
    },
    {
      "epoch": 0.53,
      "grad_norm": 17.754854202270508,
      "learning_rate": 3.929703703703704e-05,
      "loss": 1.4047,
      "step": 4750
    },
    {
      "epoch": 0.53,
      "grad_norm": 9.829607963562012,
      "learning_rate": 3.9295555555555555e-05,
      "loss": 1.1653,
      "step": 4760
    },
    {
      "epoch": 0.53,
      "grad_norm": 11.250505447387695,
      "learning_rate": 3.929407407407408e-05,
      "loss": 1.1065,
      "step": 4770
    },
    {
      "epoch": 0.53,
      "grad_norm": 10.357243537902832,
      "learning_rate": 3.92925925925926e-05,
      "loss": 1.2073,
      "step": 4780
    },
    {
      "epoch": 0.53,
      "grad_norm": 9.841437339782715,
      "learning_rate": 3.9291111111111116e-05,
      "loss": 1.189,
      "step": 4790
    },
    {
      "epoch": 0.53,
      "grad_norm": 10.061138153076172,
      "learning_rate": 3.928962962962963e-05,
      "loss": 1.0145,
      "step": 4800
    },
    {
      "epoch": 0.53,
      "grad_norm": 9.122461318969727,
      "learning_rate": 3.928814814814815e-05,
      "loss": 1.2982,
      "step": 4810
    },
    {
      "epoch": 0.54,
      "grad_norm": 10.925535202026367,
      "learning_rate": 3.928666666666667e-05,
      "loss": 1.0972,
      "step": 4820
    },
    {
      "epoch": 0.54,
      "grad_norm": 13.988279342651367,
      "learning_rate": 3.928518518518519e-05,
      "loss": 1.2845,
      "step": 4830
    },
    {
      "epoch": 0.54,
      "grad_norm": 10.381525039672852,
      "learning_rate": 3.928370370370371e-05,
      "loss": 1.2814,
      "step": 4840
    },
    {
      "epoch": 0.54,
      "grad_norm": 11.099108695983887,
      "learning_rate": 3.9282222222222226e-05,
      "loss": 1.2523,
      "step": 4850
    },
    {
      "epoch": 0.54,
      "grad_norm": 9.552473068237305,
      "learning_rate": 3.928074074074074e-05,
      "loss": 1.2399,
      "step": 4860
    },
    {
      "epoch": 0.54,
      "grad_norm": 8.865412712097168,
      "learning_rate": 3.9279259259259265e-05,
      "loss": 1.1982,
      "step": 4870
    },
    {
      "epoch": 0.54,
      "grad_norm": 14.766414642333984,
      "learning_rate": 3.927777777777778e-05,
      "loss": 1.1208,
      "step": 4880
    },
    {
      "epoch": 0.54,
      "grad_norm": 12.470452308654785,
      "learning_rate": 3.9276296296296304e-05,
      "loss": 1.1283,
      "step": 4890
    },
    {
      "epoch": 0.54,
      "grad_norm": 7.363526344299316,
      "learning_rate": 3.927481481481482e-05,
      "loss": 1.1787,
      "step": 4900
    },
    {
      "epoch": 0.55,
      "grad_norm": 10.776900291442871,
      "learning_rate": 3.9273333333333336e-05,
      "loss": 1.116,
      "step": 4910
    },
    {
      "epoch": 0.55,
      "grad_norm": 11.887782096862793,
      "learning_rate": 3.927185185185185e-05,
      "loss": 1.1469,
      "step": 4920
    },
    {
      "epoch": 0.55,
      "grad_norm": 9.945992469787598,
      "learning_rate": 3.9270370370370374e-05,
      "loss": 1.1465,
      "step": 4930
    },
    {
      "epoch": 0.55,
      "grad_norm": 10.960651397705078,
      "learning_rate": 3.92688888888889e-05,
      "loss": 1.1024,
      "step": 4940
    },
    {
      "epoch": 0.55,
      "grad_norm": 19.659900665283203,
      "learning_rate": 3.926740740740741e-05,
      "loss": 1.1448,
      "step": 4950
    },
    {
      "epoch": 0.55,
      "grad_norm": 13.73064136505127,
      "learning_rate": 3.926592592592593e-05,
      "loss": 1.187,
      "step": 4960
    },
    {
      "epoch": 0.55,
      "grad_norm": 9.686802864074707,
      "learning_rate": 3.9264444444444445e-05,
      "loss": 1.1616,
      "step": 4970
    },
    {
      "epoch": 0.55,
      "grad_norm": 13.457677841186523,
      "learning_rate": 3.926296296296297e-05,
      "loss": 1.177,
      "step": 4980
    },
    {
      "epoch": 0.55,
      "grad_norm": 21.070375442504883,
      "learning_rate": 3.9261481481481484e-05,
      "loss": 1.244,
      "step": 4990
    },
    {
      "epoch": 0.56,
      "grad_norm": 19.594417572021484,
      "learning_rate": 3.926000000000001e-05,
      "loss": 1.1449,
      "step": 5000
    },
    {
      "epoch": 0.56,
      "grad_norm": 12.872036933898926,
      "learning_rate": 3.925851851851852e-05,
      "loss": 1.1799,
      "step": 5010
    },
    {
      "epoch": 0.56,
      "grad_norm": 16.85965347290039,
      "learning_rate": 3.925703703703704e-05,
      "loss": 1.2195,
      "step": 5020
    },
    {
      "epoch": 0.56,
      "grad_norm": 13.48340892791748,
      "learning_rate": 3.9255555555555555e-05,
      "loss": 1.1113,
      "step": 5030
    },
    {
      "epoch": 0.56,
      "grad_norm": 12.571405410766602,
      "learning_rate": 3.925407407407408e-05,
      "loss": 1.1486,
      "step": 5040
    },
    {
      "epoch": 0.56,
      "grad_norm": 11.16104793548584,
      "learning_rate": 3.92525925925926e-05,
      "loss": 1.0664,
      "step": 5050
    },
    {
      "epoch": 0.56,
      "grad_norm": 16.618757247924805,
      "learning_rate": 3.925111111111112e-05,
      "loss": 1.0925,
      "step": 5060
    },
    {
      "epoch": 0.56,
      "grad_norm": 11.465161323547363,
      "learning_rate": 3.924962962962963e-05,
      "loss": 1.3652,
      "step": 5070
    },
    {
      "epoch": 0.56,
      "grad_norm": 13.069283485412598,
      "learning_rate": 3.924814814814815e-05,
      "loss": 1.2783,
      "step": 5080
    },
    {
      "epoch": 0.57,
      "grad_norm": 10.859760284423828,
      "learning_rate": 3.924666666666667e-05,
      "loss": 1.0401,
      "step": 5090
    },
    {
      "epoch": 0.57,
      "grad_norm": 9.796649932861328,
      "learning_rate": 3.924518518518519e-05,
      "loss": 1.2095,
      "step": 5100
    },
    {
      "epoch": 0.57,
      "grad_norm": 10.546723365783691,
      "learning_rate": 3.924370370370371e-05,
      "loss": 1.1091,
      "step": 5110
    },
    {
      "epoch": 0.57,
      "grad_norm": 8.053108215332031,
      "learning_rate": 3.9242222222222226e-05,
      "loss": 0.9658,
      "step": 5120
    },
    {
      "epoch": 0.57,
      "grad_norm": 11.199126243591309,
      "learning_rate": 3.924074074074074e-05,
      "loss": 1.1342,
      "step": 5130
    },
    {
      "epoch": 0.57,
      "grad_norm": 16.676738739013672,
      "learning_rate": 3.923925925925926e-05,
      "loss": 1.1048,
      "step": 5140
    },
    {
      "epoch": 0.57,
      "grad_norm": 12.090263366699219,
      "learning_rate": 3.923777777777778e-05,
      "loss": 1.3327,
      "step": 5150
    },
    {
      "epoch": 0.57,
      "grad_norm": 13.214834213256836,
      "learning_rate": 3.9236296296296304e-05,
      "loss": 1.2173,
      "step": 5160
    },
    {
      "epoch": 0.57,
      "grad_norm": 10.4520263671875,
      "learning_rate": 3.923481481481482e-05,
      "loss": 1.1388,
      "step": 5170
    },
    {
      "epoch": 0.58,
      "grad_norm": 15.922431945800781,
      "learning_rate": 3.9233333333333336e-05,
      "loss": 1.1163,
      "step": 5180
    },
    {
      "epoch": 0.58,
      "grad_norm": 11.435576438903809,
      "learning_rate": 3.923185185185185e-05,
      "loss": 1.0965,
      "step": 5190
    },
    {
      "epoch": 0.58,
      "grad_norm": 11.697992324829102,
      "learning_rate": 3.9230370370370375e-05,
      "loss": 0.9979,
      "step": 5200
    },
    {
      "epoch": 0.58,
      "grad_norm": 11.037609100341797,
      "learning_rate": 3.922888888888889e-05,
      "loss": 1.131,
      "step": 5210
    },
    {
      "epoch": 0.58,
      "grad_norm": 12.664263725280762,
      "learning_rate": 3.9227407407407414e-05,
      "loss": 1.0256,
      "step": 5220
    },
    {
      "epoch": 0.58,
      "grad_norm": 13.546935081481934,
      "learning_rate": 3.922592592592593e-05,
      "loss": 1.1259,
      "step": 5230
    },
    {
      "epoch": 0.58,
      "grad_norm": 14.213713645935059,
      "learning_rate": 3.9224444444444446e-05,
      "loss": 0.9987,
      "step": 5240
    },
    {
      "epoch": 0.58,
      "grad_norm": 14.68255615234375,
      "learning_rate": 3.922296296296296e-05,
      "loss": 1.0525,
      "step": 5250
    },
    {
      "epoch": 0.58,
      "grad_norm": 19.043004989624023,
      "learning_rate": 3.9221481481481485e-05,
      "loss": 1.0206,
      "step": 5260
    },
    {
      "epoch": 0.59,
      "grad_norm": 14.66107177734375,
      "learning_rate": 3.922000000000001e-05,
      "loss": 1.1494,
      "step": 5270
    },
    {
      "epoch": 0.59,
      "grad_norm": 11.087029457092285,
      "learning_rate": 3.921851851851852e-05,
      "loss": 1.2,
      "step": 5280
    },
    {
      "epoch": 0.59,
      "grad_norm": 13.893609046936035,
      "learning_rate": 3.921703703703704e-05,
      "loss": 1.1438,
      "step": 5290
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.487399101257324,
      "learning_rate": 3.9215555555555555e-05,
      "loss": 1.1082,
      "step": 5300
    },
    {
      "epoch": 0.59,
      "grad_norm": 10.194050788879395,
      "learning_rate": 3.921407407407408e-05,
      "loss": 1.0773,
      "step": 5310
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.505914688110352,
      "learning_rate": 3.92125925925926e-05,
      "loss": 0.9297,
      "step": 5320
    },
    {
      "epoch": 0.59,
      "grad_norm": 10.786319732666016,
      "learning_rate": 3.921111111111112e-05,
      "loss": 0.9477,
      "step": 5330
    },
    {
      "epoch": 0.59,
      "grad_norm": 12.695757865905762,
      "learning_rate": 3.920962962962963e-05,
      "loss": 0.8922,
      "step": 5340
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.706798553466797,
      "learning_rate": 3.920814814814815e-05,
      "loss": 1.0739,
      "step": 5350
    },
    {
      "epoch": 0.6,
      "grad_norm": 12.798048973083496,
      "learning_rate": 3.9206666666666665e-05,
      "loss": 0.9903,
      "step": 5360
    },
    {
      "epoch": 0.6,
      "grad_norm": 17.781213760375977,
      "learning_rate": 3.920518518518519e-05,
      "loss": 1.079,
      "step": 5370
    },
    {
      "epoch": 0.6,
      "grad_norm": 10.97984790802002,
      "learning_rate": 3.920370370370371e-05,
      "loss": 1.0752,
      "step": 5380
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.638999938964844,
      "learning_rate": 3.920222222222223e-05,
      "loss": 0.9554,
      "step": 5390
    },
    {
      "epoch": 0.6,
      "grad_norm": 12.777436256408691,
      "learning_rate": 3.920074074074074e-05,
      "loss": 1.0704,
      "step": 5400
    },
    {
      "epoch": 0.6,
      "grad_norm": 15.041437149047852,
      "learning_rate": 3.919925925925926e-05,
      "loss": 0.9633,
      "step": 5410
    },
    {
      "epoch": 0.6,
      "grad_norm": 13.999786376953125,
      "learning_rate": 3.919777777777778e-05,
      "loss": 1.0725,
      "step": 5420
    },
    {
      "epoch": 0.6,
      "grad_norm": 14.286819458007812,
      "learning_rate": 3.9196296296296304e-05,
      "loss": 0.9105,
      "step": 5430
    },
    {
      "epoch": 0.6,
      "grad_norm": 17.295032501220703,
      "learning_rate": 3.919481481481482e-05,
      "loss": 1.1459,
      "step": 5440
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.73424243927002,
      "learning_rate": 3.9193333333333336e-05,
      "loss": 0.9264,
      "step": 5450
    },
    {
      "epoch": 0.61,
      "grad_norm": 17.3689022064209,
      "learning_rate": 3.919185185185185e-05,
      "loss": 0.9797,
      "step": 5460
    },
    {
      "epoch": 0.61,
      "grad_norm": 15.195535659790039,
      "learning_rate": 3.9190370370370375e-05,
      "loss": 0.9329,
      "step": 5470
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.876555442810059,
      "learning_rate": 3.918888888888889e-05,
      "loss": 1.0278,
      "step": 5480
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.032646179199219,
      "learning_rate": 3.9187407407407414e-05,
      "loss": 0.9427,
      "step": 5490
    },
    {
      "epoch": 0.61,
      "grad_norm": 20.528791427612305,
      "learning_rate": 3.918592592592593e-05,
      "loss": 1.0609,
      "step": 5500
    },
    {
      "epoch": 0.61,
      "grad_norm": 10.952814102172852,
      "learning_rate": 3.9184444444444446e-05,
      "loss": 0.984,
      "step": 5510
    },
    {
      "epoch": 0.61,
      "grad_norm": 10.180854797363281,
      "learning_rate": 3.918296296296296e-05,
      "loss": 0.9757,
      "step": 5520
    },
    {
      "epoch": 0.61,
      "grad_norm": 12.038912773132324,
      "learning_rate": 3.9181481481481485e-05,
      "loss": 0.9555,
      "step": 5530
    },
    {
      "epoch": 0.62,
      "grad_norm": 11.868927001953125,
      "learning_rate": 3.918000000000001e-05,
      "loss": 0.9302,
      "step": 5540
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.085171699523926,
      "learning_rate": 3.9178518518518524e-05,
      "loss": 1.0396,
      "step": 5550
    },
    {
      "epoch": 0.62,
      "grad_norm": 13.09546184539795,
      "learning_rate": 3.917703703703704e-05,
      "loss": 1.0498,
      "step": 5560
    },
    {
      "epoch": 0.62,
      "grad_norm": 8.312447547912598,
      "learning_rate": 3.9175555555555556e-05,
      "loss": 0.8692,
      "step": 5570
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.992683410644531,
      "learning_rate": 3.917407407407408e-05,
      "loss": 0.9779,
      "step": 5580
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.915114402770996,
      "learning_rate": 3.9172592592592595e-05,
      "loss": 0.854,
      "step": 5590
    },
    {
      "epoch": 0.62,
      "grad_norm": 10.115988731384277,
      "learning_rate": 3.917111111111112e-05,
      "loss": 0.9954,
      "step": 5600
    },
    {
      "epoch": 0.62,
      "grad_norm": 15.024950981140137,
      "learning_rate": 3.9169629629629633e-05,
      "loss": 0.9363,
      "step": 5610
    },
    {
      "epoch": 0.62,
      "grad_norm": 10.592706680297852,
      "learning_rate": 3.916814814814815e-05,
      "loss": 0.988,
      "step": 5620
    },
    {
      "epoch": 0.63,
      "grad_norm": 10.748927116394043,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.9421,
      "step": 5630
    },
    {
      "epoch": 0.63,
      "grad_norm": 9.846614837646484,
      "learning_rate": 3.916518518518519e-05,
      "loss": 0.9919,
      "step": 5640
    },
    {
      "epoch": 0.63,
      "grad_norm": 11.772971153259277,
      "learning_rate": 3.916370370370371e-05,
      "loss": 0.8995,
      "step": 5650
    },
    {
      "epoch": 0.63,
      "grad_norm": 13.222058296203613,
      "learning_rate": 3.916222222222223e-05,
      "loss": 0.8825,
      "step": 5660
    },
    {
      "epoch": 0.63,
      "grad_norm": 11.631690979003906,
      "learning_rate": 3.916074074074074e-05,
      "loss": 0.8981,
      "step": 5670
    },
    {
      "epoch": 0.63,
      "grad_norm": 8.861066818237305,
      "learning_rate": 3.915925925925926e-05,
      "loss": 0.9661,
      "step": 5680
    },
    {
      "epoch": 0.63,
      "grad_norm": 20.194738388061523,
      "learning_rate": 3.915777777777778e-05,
      "loss": 1.027,
      "step": 5690
    },
    {
      "epoch": 0.63,
      "grad_norm": 9.647290229797363,
      "learning_rate": 3.91562962962963e-05,
      "loss": 0.8664,
      "step": 5700
    },
    {
      "epoch": 0.63,
      "grad_norm": 9.334749221801758,
      "learning_rate": 3.915481481481482e-05,
      "loss": 0.8723,
      "step": 5710
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.811461925506592,
      "learning_rate": 3.915333333333334e-05,
      "loss": 0.827,
      "step": 5720
    },
    {
      "epoch": 0.64,
      "grad_norm": 14.602840423583984,
      "learning_rate": 3.915185185185185e-05,
      "loss": 0.9597,
      "step": 5730
    },
    {
      "epoch": 0.64,
      "grad_norm": 8.162829399108887,
      "learning_rate": 3.915037037037037e-05,
      "loss": 0.9082,
      "step": 5740
    },
    {
      "epoch": 0.64,
      "grad_norm": 9.422060012817383,
      "learning_rate": 3.914888888888889e-05,
      "loss": 0.9582,
      "step": 5750
    },
    {
      "epoch": 0.64,
      "grad_norm": 9.89127254486084,
      "learning_rate": 3.9147407407407414e-05,
      "loss": 0.9187,
      "step": 5760
    },
    {
      "epoch": 0.64,
      "grad_norm": 10.160965919494629,
      "learning_rate": 3.914592592592593e-05,
      "loss": 0.8492,
      "step": 5770
    },
    {
      "epoch": 0.64,
      "grad_norm": 11.17273235321045,
      "learning_rate": 3.9144444444444446e-05,
      "loss": 1.0172,
      "step": 5780
    },
    {
      "epoch": 0.64,
      "grad_norm": 8.624326705932617,
      "learning_rate": 3.914296296296296e-05,
      "loss": 1.0096,
      "step": 5790
    },
    {
      "epoch": 0.64,
      "grad_norm": 11.069864273071289,
      "learning_rate": 3.9141481481481485e-05,
      "loss": 0.9692,
      "step": 5800
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.421547889709473,
      "learning_rate": 3.914e-05,
      "loss": 0.9144,
      "step": 5810
    },
    {
      "epoch": 0.65,
      "grad_norm": 12.04540729522705,
      "learning_rate": 3.9138518518518524e-05,
      "loss": 0.8088,
      "step": 5820
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.467744827270508,
      "learning_rate": 3.913703703703704e-05,
      "loss": 0.7566,
      "step": 5830
    },
    {
      "epoch": 0.65,
      "grad_norm": 12.593409538269043,
      "learning_rate": 3.9135555555555556e-05,
      "loss": 0.8401,
      "step": 5840
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.8279390335083,
      "learning_rate": 3.913407407407407e-05,
      "loss": 0.8836,
      "step": 5850
    },
    {
      "epoch": 0.65,
      "grad_norm": 10.240060806274414,
      "learning_rate": 3.9132592592592595e-05,
      "loss": 0.8431,
      "step": 5860
    },
    {
      "epoch": 0.65,
      "grad_norm": 13.213891983032227,
      "learning_rate": 3.913111111111112e-05,
      "loss": 0.9125,
      "step": 5870
    },
    {
      "epoch": 0.65,
      "grad_norm": 14.95174789428711,
      "learning_rate": 3.9129629629629634e-05,
      "loss": 0.9496,
      "step": 5880
    },
    {
      "epoch": 0.65,
      "grad_norm": 12.65855884552002,
      "learning_rate": 3.912814814814815e-05,
      "loss": 0.9345,
      "step": 5890
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.2194185256958,
      "learning_rate": 3.9126666666666666e-05,
      "loss": 0.8963,
      "step": 5900
    },
    {
      "epoch": 0.66,
      "grad_norm": 9.705615043640137,
      "learning_rate": 3.912518518518519e-05,
      "loss": 0.9177,
      "step": 5910
    },
    {
      "epoch": 0.66,
      "grad_norm": 21.32927131652832,
      "learning_rate": 3.912370370370371e-05,
      "loss": 1.1632,
      "step": 5920
    },
    {
      "epoch": 0.66,
      "grad_norm": 13.056443214416504,
      "learning_rate": 3.912222222222223e-05,
      "loss": 0.8685,
      "step": 5930
    },
    {
      "epoch": 0.66,
      "grad_norm": 11.790135383605957,
      "learning_rate": 3.9120740740740744e-05,
      "loss": 0.8887,
      "step": 5940
    },
    {
      "epoch": 0.66,
      "grad_norm": 9.040246963500977,
      "learning_rate": 3.911925925925926e-05,
      "loss": 1.0325,
      "step": 5950
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.559757232666016,
      "learning_rate": 3.911777777777778e-05,
      "loss": 0.8794,
      "step": 5960
    },
    {
      "epoch": 0.66,
      "grad_norm": 9.055997848510742,
      "learning_rate": 3.91162962962963e-05,
      "loss": 0.8518,
      "step": 5970
    },
    {
      "epoch": 0.66,
      "grad_norm": 13.939736366271973,
      "learning_rate": 3.911481481481482e-05,
      "loss": 0.8587,
      "step": 5980
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.9491286277771,
      "learning_rate": 3.911333333333334e-05,
      "loss": 0.9212,
      "step": 5990
    },
    {
      "epoch": 0.67,
      "grad_norm": 8.384305953979492,
      "learning_rate": 3.911185185185185e-05,
      "loss": 0.7196,
      "step": 6000
    },
    {
      "epoch": 0.67,
      "grad_norm": 9.9129056930542,
      "learning_rate": 3.911037037037037e-05,
      "loss": 0.6914,
      "step": 6010
    },
    {
      "epoch": 0.67,
      "grad_norm": 11.84018611907959,
      "learning_rate": 3.910888888888889e-05,
      "loss": 0.9239,
      "step": 6020
    },
    {
      "epoch": 0.67,
      "grad_norm": 12.36434268951416,
      "learning_rate": 3.9107407407407415e-05,
      "loss": 0.8176,
      "step": 6030
    },
    {
      "epoch": 0.67,
      "grad_norm": 6.746574878692627,
      "learning_rate": 3.910592592592593e-05,
      "loss": 0.873,
      "step": 6040
    },
    {
      "epoch": 0.67,
      "grad_norm": 9.045317649841309,
      "learning_rate": 3.910444444444445e-05,
      "loss": 0.7031,
      "step": 6050
    },
    {
      "epoch": 0.67,
      "grad_norm": 9.066649436950684,
      "learning_rate": 3.910296296296296e-05,
      "loss": 0.9073,
      "step": 6060
    },
    {
      "epoch": 0.67,
      "grad_norm": 10.407571792602539,
      "learning_rate": 3.9101481481481486e-05,
      "loss": 0.922,
      "step": 6070
    },
    {
      "epoch": 0.68,
      "grad_norm": 9.536308288574219,
      "learning_rate": 3.91e-05,
      "loss": 0.9499,
      "step": 6080
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.026388168334961,
      "learning_rate": 3.9098518518518525e-05,
      "loss": 0.7754,
      "step": 6090
    },
    {
      "epoch": 0.68,
      "grad_norm": 11.476286888122559,
      "learning_rate": 3.909703703703704e-05,
      "loss": 0.9108,
      "step": 6100
    },
    {
      "epoch": 0.68,
      "grad_norm": 7.6104536056518555,
      "learning_rate": 3.9095555555555557e-05,
      "loss": 0.8447,
      "step": 6110
    },
    {
      "epoch": 0.68,
      "grad_norm": 9.002924919128418,
      "learning_rate": 3.909407407407407e-05,
      "loss": 0.7652,
      "step": 6120
    },
    {
      "epoch": 0.68,
      "grad_norm": 12.014561653137207,
      "learning_rate": 3.9092592592592595e-05,
      "loss": 0.7759,
      "step": 6130
    },
    {
      "epoch": 0.68,
      "grad_norm": 7.953012943267822,
      "learning_rate": 3.909111111111112e-05,
      "loss": 0.7552,
      "step": 6140
    },
    {
      "epoch": 0.68,
      "grad_norm": 10.831835746765137,
      "learning_rate": 3.9089629629629634e-05,
      "loss": 0.8998,
      "step": 6150
    },
    {
      "epoch": 0.68,
      "grad_norm": 15.8147554397583,
      "learning_rate": 3.908814814814815e-05,
      "loss": 0.923,
      "step": 6160
    },
    {
      "epoch": 0.69,
      "grad_norm": 11.134077072143555,
      "learning_rate": 3.9086666666666666e-05,
      "loss": 0.8171,
      "step": 6170
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.216453552246094,
      "learning_rate": 3.908518518518519e-05,
      "loss": 0.7498,
      "step": 6180
    },
    {
      "epoch": 0.69,
      "grad_norm": 12.618799209594727,
      "learning_rate": 3.9083703703703705e-05,
      "loss": 0.8482,
      "step": 6190
    },
    {
      "epoch": 0.69,
      "grad_norm": 9.920241355895996,
      "learning_rate": 3.908222222222223e-05,
      "loss": 1.0179,
      "step": 6200
    },
    {
      "epoch": 0.69,
      "grad_norm": 9.810004234313965,
      "learning_rate": 3.9080740740740744e-05,
      "loss": 0.821,
      "step": 6210
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.738715171813965,
      "learning_rate": 3.907925925925926e-05,
      "loss": 0.7546,
      "step": 6220
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.658124923706055,
      "learning_rate": 3.9077777777777776e-05,
      "loss": 0.8141,
      "step": 6230
    },
    {
      "epoch": 0.69,
      "grad_norm": 13.535277366638184,
      "learning_rate": 3.90762962962963e-05,
      "loss": 0.8545,
      "step": 6240
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.633330345153809,
      "learning_rate": 3.907481481481482e-05,
      "loss": 0.7922,
      "step": 6250
    },
    {
      "epoch": 0.7,
      "grad_norm": 8.723267555236816,
      "learning_rate": 3.907333333333334e-05,
      "loss": 0.8137,
      "step": 6260
    },
    {
      "epoch": 0.7,
      "grad_norm": 9.058823585510254,
      "learning_rate": 3.9071851851851854e-05,
      "loss": 0.8162,
      "step": 6270
    },
    {
      "epoch": 0.7,
      "grad_norm": 8.803915977478027,
      "learning_rate": 3.907037037037037e-05,
      "loss": 0.7639,
      "step": 6280
    },
    {
      "epoch": 0.7,
      "grad_norm": 13.393326759338379,
      "learning_rate": 3.906888888888889e-05,
      "loss": 0.8049,
      "step": 6290
    },
    {
      "epoch": 0.7,
      "grad_norm": 13.65100383758545,
      "learning_rate": 3.906740740740741e-05,
      "loss": 0.8747,
      "step": 6300
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.572653770446777,
      "learning_rate": 3.906592592592593e-05,
      "loss": 0.8974,
      "step": 6310
    },
    {
      "epoch": 0.7,
      "grad_norm": 14.22077465057373,
      "learning_rate": 3.906444444444445e-05,
      "loss": 0.814,
      "step": 6320
    },
    {
      "epoch": 0.7,
      "grad_norm": 10.692887306213379,
      "learning_rate": 3.906296296296296e-05,
      "loss": 0.8278,
      "step": 6330
    },
    {
      "epoch": 0.7,
      "grad_norm": 10.615623474121094,
      "learning_rate": 3.9061481481481486e-05,
      "loss": 0.6551,
      "step": 6340
    },
    {
      "epoch": 0.71,
      "grad_norm": 11.060046195983887,
      "learning_rate": 3.906e-05,
      "loss": 0.8513,
      "step": 6350
    },
    {
      "epoch": 0.71,
      "grad_norm": 10.746567726135254,
      "learning_rate": 3.9058518518518525e-05,
      "loss": 0.6767,
      "step": 6360
    },
    {
      "epoch": 0.71,
      "grad_norm": 9.701043128967285,
      "learning_rate": 3.905703703703704e-05,
      "loss": 0.7904,
      "step": 6370
    },
    {
      "epoch": 0.71,
      "grad_norm": 10.284409523010254,
      "learning_rate": 3.905555555555556e-05,
      "loss": 0.837,
      "step": 6380
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.51050853729248,
      "learning_rate": 3.905407407407407e-05,
      "loss": 0.7732,
      "step": 6390
    },
    {
      "epoch": 0.71,
      "grad_norm": 9.039822578430176,
      "learning_rate": 3.9052592592592596e-05,
      "loss": 0.9053,
      "step": 6400
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.012556076049805,
      "learning_rate": 3.905111111111112e-05,
      "loss": 0.8682,
      "step": 6410
    },
    {
      "epoch": 0.71,
      "grad_norm": 9.410929679870605,
      "learning_rate": 3.9049629629629635e-05,
      "loss": 0.8,
      "step": 6420
    },
    {
      "epoch": 0.71,
      "grad_norm": 9.112455368041992,
      "learning_rate": 3.904814814814815e-05,
      "loss": 0.7828,
      "step": 6430
    },
    {
      "epoch": 0.72,
      "grad_norm": 7.690001964569092,
      "learning_rate": 3.904666666666667e-05,
      "loss": 0.8272,
      "step": 6440
    },
    {
      "epoch": 0.72,
      "grad_norm": 10.975144386291504,
      "learning_rate": 3.904518518518519e-05,
      "loss": 0.671,
      "step": 6450
    },
    {
      "epoch": 0.72,
      "grad_norm": 12.393464088439941,
      "learning_rate": 3.9043703703703705e-05,
      "loss": 0.6915,
      "step": 6460
    },
    {
      "epoch": 0.72,
      "grad_norm": 11.71561336517334,
      "learning_rate": 3.904222222222223e-05,
      "loss": 0.8541,
      "step": 6470
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.947779655456543,
      "learning_rate": 3.9040740740740744e-05,
      "loss": 0.6446,
      "step": 6480
    },
    {
      "epoch": 0.72,
      "grad_norm": 10.966935157775879,
      "learning_rate": 3.903925925925926e-05,
      "loss": 0.8301,
      "step": 6490
    },
    {
      "epoch": 0.72,
      "grad_norm": 9.137537002563477,
      "learning_rate": 3.9037777777777776e-05,
      "loss": 0.7669,
      "step": 6500
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.953775405883789,
      "learning_rate": 3.90362962962963e-05,
      "loss": 0.811,
      "step": 6510
    },
    {
      "epoch": 0.72,
      "grad_norm": 14.860150337219238,
      "learning_rate": 3.903481481481482e-05,
      "loss": 0.8592,
      "step": 6520
    },
    {
      "epoch": 0.73,
      "grad_norm": 13.215157508850098,
      "learning_rate": 3.903333333333334e-05,
      "loss": 0.6793,
      "step": 6530
    },
    {
      "epoch": 0.73,
      "grad_norm": 11.528661727905273,
      "learning_rate": 3.9031851851851854e-05,
      "loss": 0.7518,
      "step": 6540
    },
    {
      "epoch": 0.73,
      "grad_norm": 14.623513221740723,
      "learning_rate": 3.903037037037037e-05,
      "loss": 0.8232,
      "step": 6550
    },
    {
      "epoch": 0.73,
      "grad_norm": 10.149750709533691,
      "learning_rate": 3.902888888888889e-05,
      "loss": 0.8271,
      "step": 6560
    },
    {
      "epoch": 0.73,
      "grad_norm": 10.933252334594727,
      "learning_rate": 3.902740740740741e-05,
      "loss": 0.7631,
      "step": 6570
    },
    {
      "epoch": 0.73,
      "grad_norm": 9.43549919128418,
      "learning_rate": 3.902592592592593e-05,
      "loss": 0.7743,
      "step": 6580
    },
    {
      "epoch": 0.73,
      "grad_norm": 10.486756324768066,
      "learning_rate": 3.902444444444445e-05,
      "loss": 0.8289,
      "step": 6590
    },
    {
      "epoch": 0.73,
      "grad_norm": 15.097652435302734,
      "learning_rate": 3.9022962962962964e-05,
      "loss": 0.8096,
      "step": 6600
    },
    {
      "epoch": 0.73,
      "grad_norm": 9.332826614379883,
      "learning_rate": 3.9021481481481486e-05,
      "loss": 0.678,
      "step": 6610
    },
    {
      "epoch": 0.74,
      "grad_norm": 14.606691360473633,
      "learning_rate": 3.902e-05,
      "loss": 0.7615,
      "step": 6620
    },
    {
      "epoch": 0.74,
      "grad_norm": 13.3433256149292,
      "learning_rate": 3.9018518518518525e-05,
      "loss": 0.7649,
      "step": 6630
    },
    {
      "epoch": 0.74,
      "grad_norm": 14.746365547180176,
      "learning_rate": 3.901703703703704e-05,
      "loss": 0.7038,
      "step": 6640
    },
    {
      "epoch": 0.74,
      "grad_norm": 12.00324821472168,
      "learning_rate": 3.901555555555556e-05,
      "loss": 0.7315,
      "step": 6650
    },
    {
      "epoch": 0.74,
      "grad_norm": 9.795209884643555,
      "learning_rate": 3.901407407407407e-05,
      "loss": 0.6708,
      "step": 6660
    },
    {
      "epoch": 0.74,
      "grad_norm": 12.145017623901367,
      "learning_rate": 3.9012592592592596e-05,
      "loss": 0.8885,
      "step": 6670
    },
    {
      "epoch": 0.74,
      "grad_norm": 9.276876449584961,
      "learning_rate": 3.901111111111111e-05,
      "loss": 0.7509,
      "step": 6680
    },
    {
      "epoch": 0.74,
      "grad_norm": 8.209978103637695,
      "learning_rate": 3.9009629629629635e-05,
      "loss": 0.6445,
      "step": 6690
    },
    {
      "epoch": 0.74,
      "grad_norm": 8.815139770507812,
      "learning_rate": 3.900814814814815e-05,
      "loss": 0.7653,
      "step": 6700
    },
    {
      "epoch": 0.75,
      "grad_norm": 10.487496376037598,
      "learning_rate": 3.900666666666667e-05,
      "loss": 0.8108,
      "step": 6710
    },
    {
      "epoch": 0.75,
      "grad_norm": 7.755260944366455,
      "learning_rate": 3.900518518518519e-05,
      "loss": 0.6488,
      "step": 6720
    },
    {
      "epoch": 0.75,
      "grad_norm": 16.222949981689453,
      "learning_rate": 3.9003703703703706e-05,
      "loss": 0.7944,
      "step": 6730
    },
    {
      "epoch": 0.75,
      "grad_norm": 14.019782066345215,
      "learning_rate": 3.900222222222223e-05,
      "loss": 0.7477,
      "step": 6740
    },
    {
      "epoch": 0.75,
      "grad_norm": 27.49872589111328,
      "learning_rate": 3.9000740740740745e-05,
      "loss": 0.8303,
      "step": 6750
    },
    {
      "epoch": 0.75,
      "grad_norm": 15.255969047546387,
      "learning_rate": 3.899925925925926e-05,
      "loss": 0.7143,
      "step": 6760
    },
    {
      "epoch": 0.75,
      "grad_norm": 19.749618530273438,
      "learning_rate": 3.899777777777778e-05,
      "loss": 0.8127,
      "step": 6770
    },
    {
      "epoch": 0.75,
      "grad_norm": 9.538702011108398,
      "learning_rate": 3.89962962962963e-05,
      "loss": 0.733,
      "step": 6780
    },
    {
      "epoch": 0.75,
      "grad_norm": 7.844705581665039,
      "learning_rate": 3.8994814814814816e-05,
      "loss": 0.5674,
      "step": 6790
    },
    {
      "epoch": 0.76,
      "grad_norm": 16.308977127075195,
      "learning_rate": 3.899333333333334e-05,
      "loss": 0.6568,
      "step": 6800
    },
    {
      "epoch": 0.76,
      "grad_norm": 9.516674995422363,
      "learning_rate": 3.8991851851851854e-05,
      "loss": 0.6014,
      "step": 6810
    },
    {
      "epoch": 0.76,
      "grad_norm": 13.587362289428711,
      "learning_rate": 3.899037037037037e-05,
      "loss": 0.7072,
      "step": 6820
    },
    {
      "epoch": 0.76,
      "grad_norm": 11.503567695617676,
      "learning_rate": 3.898888888888889e-05,
      "loss": 0.787,
      "step": 6830
    },
    {
      "epoch": 0.76,
      "grad_norm": 10.164631843566895,
      "learning_rate": 3.898740740740741e-05,
      "loss": 0.793,
      "step": 6840
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.288651466369629,
      "learning_rate": 3.898592592592593e-05,
      "loss": 0.6917,
      "step": 6850
    },
    {
      "epoch": 0.76,
      "grad_norm": 7.500442028045654,
      "learning_rate": 3.898444444444445e-05,
      "loss": 0.646,
      "step": 6860
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.019062995910645,
      "learning_rate": 3.8982962962962964e-05,
      "loss": 0.7459,
      "step": 6870
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.821481704711914,
      "learning_rate": 3.898148148148149e-05,
      "loss": 0.5467,
      "step": 6880
    },
    {
      "epoch": 0.77,
      "grad_norm": 8.857763290405273,
      "learning_rate": 3.898e-05,
      "loss": 0.6541,
      "step": 6890
    },
    {
      "epoch": 0.77,
      "grad_norm": 7.64695405960083,
      "learning_rate": 3.897851851851852e-05,
      "loss": 0.782,
      "step": 6900
    },
    {
      "epoch": 0.77,
      "grad_norm": 11.375186920166016,
      "learning_rate": 3.897703703703704e-05,
      "loss": 0.7153,
      "step": 6910
    },
    {
      "epoch": 0.77,
      "grad_norm": 10.708850860595703,
      "learning_rate": 3.897555555555556e-05,
      "loss": 0.7096,
      "step": 6920
    },
    {
      "epoch": 0.77,
      "grad_norm": 13.09622859954834,
      "learning_rate": 3.8974074074074074e-05,
      "loss": 0.6747,
      "step": 6930
    },
    {
      "epoch": 0.77,
      "grad_norm": 9.648839950561523,
      "learning_rate": 3.8972592592592597e-05,
      "loss": 0.7332,
      "step": 6940
    },
    {
      "epoch": 0.77,
      "grad_norm": 9.027674674987793,
      "learning_rate": 3.897111111111111e-05,
      "loss": 0.6836,
      "step": 6950
    },
    {
      "epoch": 0.77,
      "grad_norm": 8.572261810302734,
      "learning_rate": 3.8969629629629635e-05,
      "loss": 0.6888,
      "step": 6960
    },
    {
      "epoch": 0.77,
      "grad_norm": 12.415301322937012,
      "learning_rate": 3.896814814814815e-05,
      "loss": 0.6882,
      "step": 6970
    },
    {
      "epoch": 0.78,
      "grad_norm": 9.252646446228027,
      "learning_rate": 3.896666666666667e-05,
      "loss": 0.7857,
      "step": 6980
    },
    {
      "epoch": 0.78,
      "grad_norm": 9.018814086914062,
      "learning_rate": 3.896518518518519e-05,
      "loss": 0.6571,
      "step": 6990
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.649526119232178,
      "learning_rate": 3.8963703703703706e-05,
      "loss": 0.7182,
      "step": 7000
    },
    {
      "epoch": 0.78,
      "grad_norm": 9.249625205993652,
      "learning_rate": 3.896222222222223e-05,
      "loss": 0.7005,
      "step": 7010
    },
    {
      "epoch": 0.78,
      "grad_norm": 7.602297306060791,
      "learning_rate": 3.8960740740740745e-05,
      "loss": 0.6657,
      "step": 7020
    },
    {
      "epoch": 0.78,
      "grad_norm": 12.162287712097168,
      "learning_rate": 3.895925925925926e-05,
      "loss": 0.7479,
      "step": 7030
    },
    {
      "epoch": 0.78,
      "grad_norm": 8.826225280761719,
      "learning_rate": 3.895777777777778e-05,
      "loss": 0.7072,
      "step": 7040
    },
    {
      "epoch": 0.78,
      "grad_norm": 21.194904327392578,
      "learning_rate": 3.89562962962963e-05,
      "loss": 0.6895,
      "step": 7050
    },
    {
      "epoch": 0.78,
      "grad_norm": 8.99110221862793,
      "learning_rate": 3.8954814814814816e-05,
      "loss": 0.6716,
      "step": 7060
    },
    {
      "epoch": 0.79,
      "grad_norm": 9.151371955871582,
      "learning_rate": 3.895333333333334e-05,
      "loss": 0.7012,
      "step": 7070
    },
    {
      "epoch": 0.79,
      "grad_norm": 12.104565620422363,
      "learning_rate": 3.8951851851851855e-05,
      "loss": 0.7565,
      "step": 7080
    },
    {
      "epoch": 0.79,
      "grad_norm": 13.475309371948242,
      "learning_rate": 3.895037037037037e-05,
      "loss": 0.7048,
      "step": 7090
    },
    {
      "epoch": 0.79,
      "grad_norm": 7.824441909790039,
      "learning_rate": 3.8948888888888894e-05,
      "loss": 0.7187,
      "step": 7100
    },
    {
      "epoch": 0.79,
      "grad_norm": 8.134860038757324,
      "learning_rate": 3.894740740740741e-05,
      "loss": 0.6861,
      "step": 7110
    },
    {
      "epoch": 0.79,
      "grad_norm": 8.985363006591797,
      "learning_rate": 3.894592592592593e-05,
      "loss": 0.6382,
      "step": 7120
    },
    {
      "epoch": 0.79,
      "grad_norm": 9.193737983703613,
      "learning_rate": 3.894444444444445e-05,
      "loss": 0.6762,
      "step": 7130
    },
    {
      "epoch": 0.79,
      "grad_norm": 9.942545890808105,
      "learning_rate": 3.8942962962962964e-05,
      "loss": 0.7935,
      "step": 7140
    },
    {
      "epoch": 0.79,
      "grad_norm": 9.863978385925293,
      "learning_rate": 3.894148148148149e-05,
      "loss": 0.6794,
      "step": 7150
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.988286972045898,
      "learning_rate": 3.894e-05,
      "loss": 0.6078,
      "step": 7160
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.697937965393066,
      "learning_rate": 3.893851851851852e-05,
      "loss": 0.6689,
      "step": 7170
    },
    {
      "epoch": 0.8,
      "grad_norm": 13.347495079040527,
      "learning_rate": 3.893703703703704e-05,
      "loss": 0.6895,
      "step": 7180
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.251981735229492,
      "learning_rate": 3.893555555555556e-05,
      "loss": 0.6582,
      "step": 7190
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.844568252563477,
      "learning_rate": 3.8934074074074074e-05,
      "loss": 0.8146,
      "step": 7200
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.633435249328613,
      "learning_rate": 3.89325925925926e-05,
      "loss": 0.7064,
      "step": 7210
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.6192045211792,
      "learning_rate": 3.893111111111111e-05,
      "loss": 0.6656,
      "step": 7220
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.770111083984375,
      "learning_rate": 3.8929629629629636e-05,
      "loss": 0.6983,
      "step": 7230
    },
    {
      "epoch": 0.8,
      "grad_norm": 13.279027938842773,
      "learning_rate": 3.892814814814815e-05,
      "loss": 0.7636,
      "step": 7240
    },
    {
      "epoch": 0.81,
      "grad_norm": 8.272019386291504,
      "learning_rate": 3.892666666666667e-05,
      "loss": 0.4676,
      "step": 7250
    },
    {
      "epoch": 0.81,
      "grad_norm": 10.452113151550293,
      "learning_rate": 3.892518518518519e-05,
      "loss": 0.6664,
      "step": 7260
    },
    {
      "epoch": 0.81,
      "grad_norm": 8.479707717895508,
      "learning_rate": 3.892370370370371e-05,
      "loss": 0.644,
      "step": 7270
    },
    {
      "epoch": 0.81,
      "grad_norm": 9.193706512451172,
      "learning_rate": 3.892222222222222e-05,
      "loss": 0.639,
      "step": 7280
    },
    {
      "epoch": 0.81,
      "grad_norm": 10.820396423339844,
      "learning_rate": 3.8920740740740745e-05,
      "loss": 0.6028,
      "step": 7290
    },
    {
      "epoch": 0.81,
      "grad_norm": 10.643893241882324,
      "learning_rate": 3.891925925925926e-05,
      "loss": 0.62,
      "step": 7300
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.4509968757629395,
      "learning_rate": 3.891777777777778e-05,
      "loss": 0.6536,
      "step": 7310
    },
    {
      "epoch": 0.81,
      "grad_norm": 11.008721351623535,
      "learning_rate": 3.89162962962963e-05,
      "loss": 0.7497,
      "step": 7320
    },
    {
      "epoch": 0.81,
      "grad_norm": 8.047307014465332,
      "learning_rate": 3.8914814814814816e-05,
      "loss": 0.5645,
      "step": 7330
    },
    {
      "epoch": 0.82,
      "grad_norm": 10.558874130249023,
      "learning_rate": 3.891333333333334e-05,
      "loss": 0.748,
      "step": 7340
    },
    {
      "epoch": 0.82,
      "grad_norm": 8.307735443115234,
      "learning_rate": 3.8911851851851855e-05,
      "loss": 0.6235,
      "step": 7350
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.361845970153809,
      "learning_rate": 3.891037037037037e-05,
      "loss": 0.6254,
      "step": 7360
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.734726905822754,
      "learning_rate": 3.8908888888888894e-05,
      "loss": 0.578,
      "step": 7370
    },
    {
      "epoch": 0.82,
      "grad_norm": 17.941543579101562,
      "learning_rate": 3.890740740740741e-05,
      "loss": 0.6948,
      "step": 7380
    },
    {
      "epoch": 0.82,
      "grad_norm": 7.8849992752075195,
      "learning_rate": 3.8905925925925926e-05,
      "loss": 0.6246,
      "step": 7390
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.432345390319824,
      "learning_rate": 3.890444444444445e-05,
      "loss": 0.7119,
      "step": 7400
    },
    {
      "epoch": 0.82,
      "grad_norm": 7.200146198272705,
      "learning_rate": 3.8902962962962965e-05,
      "loss": 0.6829,
      "step": 7410
    },
    {
      "epoch": 0.82,
      "grad_norm": 10.565478324890137,
      "learning_rate": 3.890148148148149e-05,
      "loss": 0.6857,
      "step": 7420
    },
    {
      "epoch": 0.83,
      "grad_norm": 7.928187847137451,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.569,
      "step": 7430
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.353069305419922,
      "learning_rate": 3.889851851851852e-05,
      "loss": 0.6521,
      "step": 7440
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.15327262878418,
      "learning_rate": 3.889703703703704e-05,
      "loss": 0.6149,
      "step": 7450
    },
    {
      "epoch": 0.83,
      "grad_norm": 10.652114868164062,
      "learning_rate": 3.889555555555556e-05,
      "loss": 0.6733,
      "step": 7460
    },
    {
      "epoch": 0.83,
      "grad_norm": 14.001047134399414,
      "learning_rate": 3.8894074074074075e-05,
      "loss": 0.622,
      "step": 7470
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.108302116394043,
      "learning_rate": 3.88925925925926e-05,
      "loss": 0.6125,
      "step": 7480
    },
    {
      "epoch": 0.83,
      "grad_norm": 19.7335205078125,
      "learning_rate": 3.889111111111111e-05,
      "loss": 0.6508,
      "step": 7490
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.083661079406738,
      "learning_rate": 3.888962962962963e-05,
      "loss": 0.5962,
      "step": 7500
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.67710018157959,
      "learning_rate": 3.888814814814815e-05,
      "loss": 0.6864,
      "step": 7510
    },
    {
      "epoch": 0.84,
      "grad_norm": 12.496325492858887,
      "learning_rate": 3.888666666666667e-05,
      "loss": 0.752,
      "step": 7520
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.720130920410156,
      "learning_rate": 3.888518518518519e-05,
      "loss": 0.5671,
      "step": 7530
    },
    {
      "epoch": 0.84,
      "grad_norm": 10.511301040649414,
      "learning_rate": 3.888370370370371e-05,
      "loss": 0.6122,
      "step": 7540
    },
    {
      "epoch": 0.84,
      "grad_norm": 9.327038764953613,
      "learning_rate": 3.888222222222222e-05,
      "loss": 0.664,
      "step": 7550
    },
    {
      "epoch": 0.84,
      "grad_norm": 8.71895694732666,
      "learning_rate": 3.8880740740740746e-05,
      "loss": 0.6615,
      "step": 7560
    },
    {
      "epoch": 0.84,
      "grad_norm": 13.840829849243164,
      "learning_rate": 3.887925925925926e-05,
      "loss": 0.6162,
      "step": 7570
    },
    {
      "epoch": 0.84,
      "grad_norm": 19.846040725708008,
      "learning_rate": 3.8877777777777785e-05,
      "loss": 0.6548,
      "step": 7580
    },
    {
      "epoch": 0.84,
      "grad_norm": 8.120843887329102,
      "learning_rate": 3.88762962962963e-05,
      "loss": 0.6419,
      "step": 7590
    },
    {
      "epoch": 0.84,
      "grad_norm": 15.086203575134277,
      "learning_rate": 3.887481481481482e-05,
      "loss": 0.7107,
      "step": 7600
    },
    {
      "epoch": 0.85,
      "grad_norm": 11.81985855102539,
      "learning_rate": 3.887333333333334e-05,
      "loss": 0.6579,
      "step": 7610
    },
    {
      "epoch": 0.85,
      "grad_norm": 12.915803909301758,
      "learning_rate": 3.8871851851851856e-05,
      "loss": 0.6409,
      "step": 7620
    },
    {
      "epoch": 0.85,
      "grad_norm": 10.454395294189453,
      "learning_rate": 3.887037037037037e-05,
      "loss": 0.7169,
      "step": 7630
    },
    {
      "epoch": 0.85,
      "grad_norm": 8.379231452941895,
      "learning_rate": 3.8868888888888894e-05,
      "loss": 0.5855,
      "step": 7640
    },
    {
      "epoch": 0.85,
      "grad_norm": 8.218184471130371,
      "learning_rate": 3.886740740740741e-05,
      "loss": 0.6369,
      "step": 7650
    },
    {
      "epoch": 0.85,
      "grad_norm": 18.390701293945312,
      "learning_rate": 3.8865925925925926e-05,
      "loss": 0.7344,
      "step": 7660
    },
    {
      "epoch": 0.85,
      "grad_norm": 8.295174598693848,
      "learning_rate": 3.886444444444445e-05,
      "loss": 0.6346,
      "step": 7670
    },
    {
      "epoch": 0.85,
      "grad_norm": 6.273494720458984,
      "learning_rate": 3.8862962962962965e-05,
      "loss": 0.5711,
      "step": 7680
    },
    {
      "epoch": 0.85,
      "grad_norm": 10.947680473327637,
      "learning_rate": 3.886148148148149e-05,
      "loss": 0.5544,
      "step": 7690
    },
    {
      "epoch": 0.86,
      "grad_norm": 18.380918502807617,
      "learning_rate": 3.8860000000000004e-05,
      "loss": 0.7578,
      "step": 7700
    },
    {
      "epoch": 0.86,
      "grad_norm": 12.789039611816406,
      "learning_rate": 3.885851851851852e-05,
      "loss": 0.7638,
      "step": 7710
    },
    {
      "epoch": 0.86,
      "grad_norm": 8.360736846923828,
      "learning_rate": 3.885703703703704e-05,
      "loss": 0.7307,
      "step": 7720
    },
    {
      "epoch": 0.86,
      "grad_norm": 6.843332290649414,
      "learning_rate": 3.885555555555556e-05,
      "loss": 0.6959,
      "step": 7730
    },
    {
      "epoch": 0.86,
      "grad_norm": 8.694694519042969,
      "learning_rate": 3.8854074074074075e-05,
      "loss": 0.6222,
      "step": 7740
    },
    {
      "epoch": 0.86,
      "grad_norm": 7.214906692504883,
      "learning_rate": 3.88525925925926e-05,
      "loss": 0.6475,
      "step": 7750
    },
    {
      "epoch": 0.86,
      "grad_norm": 12.682762145996094,
      "learning_rate": 3.8851111111111114e-05,
      "loss": 0.5092,
      "step": 7760
    },
    {
      "epoch": 0.86,
      "grad_norm": 9.983016967773438,
      "learning_rate": 3.884962962962963e-05,
      "loss": 0.5444,
      "step": 7770
    },
    {
      "epoch": 0.86,
      "grad_norm": 13.085418701171875,
      "learning_rate": 3.884814814814815e-05,
      "loss": 0.5894,
      "step": 7780
    },
    {
      "epoch": 0.87,
      "grad_norm": 8.102253913879395,
      "learning_rate": 3.884666666666667e-05,
      "loss": 0.6786,
      "step": 7790
    },
    {
      "epoch": 0.87,
      "grad_norm": 7.10834264755249,
      "learning_rate": 3.884518518518519e-05,
      "loss": 0.5173,
      "step": 7800
    },
    {
      "epoch": 0.87,
      "grad_norm": 10.03274154663086,
      "learning_rate": 3.884370370370371e-05,
      "loss": 0.5097,
      "step": 7810
    },
    {
      "epoch": 0.87,
      "grad_norm": 8.477718353271484,
      "learning_rate": 3.8842222222222223e-05,
      "loss": 0.5923,
      "step": 7820
    },
    {
      "epoch": 0.87,
      "grad_norm": 8.75442886352539,
      "learning_rate": 3.8840740740740746e-05,
      "loss": 0.5241,
      "step": 7830
    },
    {
      "epoch": 0.87,
      "grad_norm": 7.935124397277832,
      "learning_rate": 3.883925925925926e-05,
      "loss": 0.6684,
      "step": 7840
    },
    {
      "epoch": 0.87,
      "grad_norm": 8.701882362365723,
      "learning_rate": 3.8837777777777785e-05,
      "loss": 0.6184,
      "step": 7850
    },
    {
      "epoch": 0.87,
      "grad_norm": 14.056007385253906,
      "learning_rate": 3.88362962962963e-05,
      "loss": 0.7556,
      "step": 7860
    },
    {
      "epoch": 0.87,
      "grad_norm": 8.603424072265625,
      "learning_rate": 3.883481481481482e-05,
      "loss": 0.6255,
      "step": 7870
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.683987617492676,
      "learning_rate": 3.883333333333333e-05,
      "loss": 0.4947,
      "step": 7880
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.639389038085938,
      "learning_rate": 3.8831851851851856e-05,
      "loss": 0.5393,
      "step": 7890
    },
    {
      "epoch": 0.88,
      "grad_norm": 14.474945068359375,
      "learning_rate": 3.883037037037037e-05,
      "loss": 0.6127,
      "step": 7900
    },
    {
      "epoch": 0.88,
      "grad_norm": 9.321672439575195,
      "learning_rate": 3.8828888888888895e-05,
      "loss": 0.6824,
      "step": 7910
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.979341983795166,
      "learning_rate": 3.882740740740741e-05,
      "loss": 0.7313,
      "step": 7920
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.736392021179199,
      "learning_rate": 3.882592592592593e-05,
      "loss": 0.5561,
      "step": 7930
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.2388153076171875,
      "learning_rate": 3.882444444444445e-05,
      "loss": 0.5189,
      "step": 7940
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.9975080490112305,
      "learning_rate": 3.8822962962962966e-05,
      "loss": 0.5116,
      "step": 7950
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.169242858886719,
      "learning_rate": 3.882148148148149e-05,
      "loss": 0.522,
      "step": 7960
    },
    {
      "epoch": 0.89,
      "grad_norm": 9.748624801635742,
      "learning_rate": 3.8820000000000004e-05,
      "loss": 0.7053,
      "step": 7970
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.57171630859375,
      "learning_rate": 3.881851851851852e-05,
      "loss": 0.5902,
      "step": 7980
    },
    {
      "epoch": 0.89,
      "grad_norm": 10.016670227050781,
      "learning_rate": 3.8817037037037036e-05,
      "loss": 0.6206,
      "step": 7990
    },
    {
      "epoch": 0.89,
      "grad_norm": 8.345054626464844,
      "learning_rate": 3.881555555555556e-05,
      "loss": 0.5166,
      "step": 8000
    },
    {
      "epoch": 0.89,
      "eval_cer": 0.11585077141609736,
      "eval_loss": 0.5159912109375,
      "eval_runtime": 1890.3488,
      "eval_samples_per_second": 4.232,
      "eval_steps_per_second": 0.529,
      "eval_wer": 0.21232640521646445,
      "step": 8000
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.895174026489258,
      "learning_rate": 3.8814074074074075e-05,
      "loss": 0.4452,
      "step": 8010
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.253664493560791,
      "learning_rate": 3.88125925925926e-05,
      "loss": 0.5695,
      "step": 8020
    },
    {
      "epoch": 0.89,
      "grad_norm": 9.275788307189941,
      "learning_rate": 3.8811111111111114e-05,
      "loss": 0.527,
      "step": 8030
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.356491565704346,
      "learning_rate": 3.880962962962963e-05,
      "loss": 0.549,
      "step": 8040
    },
    {
      "epoch": 0.89,
      "grad_norm": 9.1904878616333,
      "learning_rate": 3.880814814814815e-05,
      "loss": 0.6504,
      "step": 8050
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.716121196746826,
      "learning_rate": 3.880666666666667e-05,
      "loss": 0.5209,
      "step": 8060
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.67050552368164,
      "learning_rate": 3.880518518518519e-05,
      "loss": 0.4826,
      "step": 8070
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.254338264465332,
      "learning_rate": 3.880370370370371e-05,
      "loss": 0.6602,
      "step": 8080
    },
    {
      "epoch": 0.9,
      "grad_norm": 13.849865913391113,
      "learning_rate": 3.880237037037037e-05,
      "loss": 0.5102,
      "step": 8090
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.558410167694092,
      "learning_rate": 3.8800888888888894e-05,
      "loss": 0.554,
      "step": 8100
    },
    {
      "epoch": 0.9,
      "grad_norm": 13.92412281036377,
      "learning_rate": 3.879940740740741e-05,
      "loss": 0.5946,
      "step": 8110
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.879318237304688,
      "learning_rate": 3.8797925925925926e-05,
      "loss": 0.6071,
      "step": 8120
    },
    {
      "epoch": 0.9,
      "grad_norm": 5.028425216674805,
      "learning_rate": 3.879644444444444e-05,
      "loss": 0.5569,
      "step": 8130
    },
    {
      "epoch": 0.9,
      "grad_norm": 13.497749328613281,
      "learning_rate": 3.8794962962962965e-05,
      "loss": 0.577,
      "step": 8140
    },
    {
      "epoch": 0.91,
      "grad_norm": 12.523157119750977,
      "learning_rate": 3.879348148148149e-05,
      "loss": 0.5697,
      "step": 8150
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.676207542419434,
      "learning_rate": 3.8792000000000004e-05,
      "loss": 0.5154,
      "step": 8160
    },
    {
      "epoch": 0.91,
      "grad_norm": 10.347982406616211,
      "learning_rate": 3.879051851851852e-05,
      "loss": 0.658,
      "step": 8170
    },
    {
      "epoch": 0.91,
      "grad_norm": 15.240984916687012,
      "learning_rate": 3.8789037037037036e-05,
      "loss": 0.5254,
      "step": 8180
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.816760540008545,
      "learning_rate": 3.878755555555556e-05,
      "loss": 0.6044,
      "step": 8190
    },
    {
      "epoch": 0.91,
      "grad_norm": 8.567481994628906,
      "learning_rate": 3.8786074074074075e-05,
      "loss": 0.6118,
      "step": 8200
    },
    {
      "epoch": 0.91,
      "grad_norm": 9.112810134887695,
      "learning_rate": 3.87845925925926e-05,
      "loss": 0.5223,
      "step": 8210
    },
    {
      "epoch": 0.91,
      "grad_norm": 11.771085739135742,
      "learning_rate": 3.8783111111111114e-05,
      "loss": 0.5617,
      "step": 8220
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.0361199378967285,
      "learning_rate": 3.878162962962963e-05,
      "loss": 0.4716,
      "step": 8230
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.262333393096924,
      "learning_rate": 3.878014814814815e-05,
      "loss": 0.5375,
      "step": 8240
    },
    {
      "epoch": 0.92,
      "grad_norm": 13.921652793884277,
      "learning_rate": 3.877866666666667e-05,
      "loss": 0.5576,
      "step": 8250
    },
    {
      "epoch": 0.92,
      "grad_norm": 10.787374496459961,
      "learning_rate": 3.877718518518519e-05,
      "loss": 0.5373,
      "step": 8260
    },
    {
      "epoch": 0.92,
      "grad_norm": 11.373598098754883,
      "learning_rate": 3.877570370370371e-05,
      "loss": 0.5756,
      "step": 8270
    },
    {
      "epoch": 0.92,
      "grad_norm": 8.609334945678711,
      "learning_rate": 3.877422222222222e-05,
      "loss": 0.6069,
      "step": 8280
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.624964237213135,
      "learning_rate": 3.877274074074074e-05,
      "loss": 0.4895,
      "step": 8290
    },
    {
      "epoch": 0.92,
      "grad_norm": 5.723840236663818,
      "learning_rate": 3.877125925925926e-05,
      "loss": 0.5322,
      "step": 8300
    },
    {
      "epoch": 0.92,
      "grad_norm": 9.826207160949707,
      "learning_rate": 3.8769777777777785e-05,
      "loss": 0.4436,
      "step": 8310
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.079437255859375,
      "learning_rate": 3.87682962962963e-05,
      "loss": 0.4838,
      "step": 8320
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.031136989593506,
      "learning_rate": 3.876681481481482e-05,
      "loss": 0.5932,
      "step": 8330
    },
    {
      "epoch": 0.93,
      "grad_norm": 9.336668968200684,
      "learning_rate": 3.876533333333333e-05,
      "loss": 0.5579,
      "step": 8340
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.953619480133057,
      "learning_rate": 3.8763851851851856e-05,
      "loss": 0.4418,
      "step": 8350
    },
    {
      "epoch": 0.93,
      "grad_norm": 8.148518562316895,
      "learning_rate": 3.876237037037037e-05,
      "loss": 0.4672,
      "step": 8360
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.867109298706055,
      "learning_rate": 3.8760888888888895e-05,
      "loss": 0.4609,
      "step": 8370
    },
    {
      "epoch": 0.93,
      "grad_norm": 8.869715690612793,
      "learning_rate": 3.875940740740741e-05,
      "loss": 0.4708,
      "step": 8380
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.666236400604248,
      "learning_rate": 3.875792592592593e-05,
      "loss": 0.5562,
      "step": 8390
    },
    {
      "epoch": 0.93,
      "grad_norm": 10.368724822998047,
      "learning_rate": 3.875644444444444e-05,
      "loss": 0.5164,
      "step": 8400
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.618154525756836,
      "learning_rate": 3.8754962962962966e-05,
      "loss": 0.4561,
      "step": 8410
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.185269355773926,
      "learning_rate": 3.875348148148149e-05,
      "loss": 0.5802,
      "step": 8420
    },
    {
      "epoch": 0.94,
      "grad_norm": 14.333259582519531,
      "learning_rate": 3.8752000000000004e-05,
      "loss": 0.5435,
      "step": 8430
    },
    {
      "epoch": 0.94,
      "grad_norm": 15.397356986999512,
      "learning_rate": 3.875051851851852e-05,
      "loss": 0.5232,
      "step": 8440
    },
    {
      "epoch": 0.94,
      "grad_norm": 8.76530933380127,
      "learning_rate": 3.8749037037037036e-05,
      "loss": 0.5625,
      "step": 8450
    },
    {
      "epoch": 0.94,
      "grad_norm": 9.329562187194824,
      "learning_rate": 3.874755555555556e-05,
      "loss": 0.5867,
      "step": 8460
    },
    {
      "epoch": 0.94,
      "grad_norm": 11.754436492919922,
      "learning_rate": 3.8746074074074075e-05,
      "loss": 0.621,
      "step": 8470
    },
    {
      "epoch": 0.94,
      "grad_norm": 13.144225120544434,
      "learning_rate": 3.87445925925926e-05,
      "loss": 0.5794,
      "step": 8480
    },
    {
      "epoch": 0.94,
      "grad_norm": 11.128317832946777,
      "learning_rate": 3.8743111111111114e-05,
      "loss": 0.7038,
      "step": 8490
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.207392692565918,
      "learning_rate": 3.874162962962963e-05,
      "loss": 0.5,
      "step": 8500
    },
    {
      "epoch": 0.95,
      "grad_norm": 9.459322929382324,
      "learning_rate": 3.874014814814815e-05,
      "loss": 0.5218,
      "step": 8510
    },
    {
      "epoch": 0.95,
      "grad_norm": 8.849641799926758,
      "learning_rate": 3.873866666666667e-05,
      "loss": 0.4928,
      "step": 8520
    },
    {
      "epoch": 0.95,
      "grad_norm": 9.96163272857666,
      "learning_rate": 3.873718518518519e-05,
      "loss": 0.5736,
      "step": 8530
    },
    {
      "epoch": 0.95,
      "grad_norm": 9.952409744262695,
      "learning_rate": 3.873570370370371e-05,
      "loss": 0.4658,
      "step": 8540
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.65241003036499,
      "learning_rate": 3.8734222222222224e-05,
      "loss": 0.4159,
      "step": 8550
    },
    {
      "epoch": 0.95,
      "grad_norm": 10.615974426269531,
      "learning_rate": 3.873274074074074e-05,
      "loss": 0.5222,
      "step": 8560
    },
    {
      "epoch": 0.95,
      "grad_norm": 10.47018814086914,
      "learning_rate": 3.873125925925926e-05,
      "loss": 0.6171,
      "step": 8570
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.565589427947998,
      "learning_rate": 3.872977777777778e-05,
      "loss": 0.4603,
      "step": 8580
    },
    {
      "epoch": 0.95,
      "grad_norm": 11.442890167236328,
      "learning_rate": 3.87282962962963e-05,
      "loss": 0.505,
      "step": 8590
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.870834350585938,
      "learning_rate": 3.872681481481482e-05,
      "loss": 0.5136,
      "step": 8600
    },
    {
      "epoch": 0.96,
      "grad_norm": 12.557756423950195,
      "learning_rate": 3.8725333333333333e-05,
      "loss": 0.5126,
      "step": 8610
    },
    {
      "epoch": 0.96,
      "grad_norm": 15.910826683044434,
      "learning_rate": 3.8723851851851856e-05,
      "loss": 0.4716,
      "step": 8620
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.43799352645874,
      "learning_rate": 3.872237037037037e-05,
      "loss": 0.5873,
      "step": 8630
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.655379295349121,
      "learning_rate": 3.8720888888888895e-05,
      "loss": 0.5553,
      "step": 8640
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.610324382781982,
      "learning_rate": 3.871940740740741e-05,
      "loss": 0.531,
      "step": 8650
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.120429992675781,
      "learning_rate": 3.871792592592593e-05,
      "loss": 0.6536,
      "step": 8660
    },
    {
      "epoch": 0.96,
      "grad_norm": 8.029668807983398,
      "learning_rate": 3.871644444444445e-05,
      "loss": 0.6208,
      "step": 8670
    },
    {
      "epoch": 0.96,
      "grad_norm": 9.094101905822754,
      "learning_rate": 3.8714962962962966e-05,
      "loss": 0.5142,
      "step": 8680
    },
    {
      "epoch": 0.97,
      "grad_norm": 7.717382907867432,
      "learning_rate": 3.871348148148148e-05,
      "loss": 0.402,
      "step": 8690
    },
    {
      "epoch": 0.97,
      "grad_norm": 7.21616268157959,
      "learning_rate": 3.871214814814815e-05,
      "loss": 0.5302,
      "step": 8700
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.32387924194336,
      "learning_rate": 3.871066666666667e-05,
      "loss": 0.5334,
      "step": 8710
    },
    {
      "epoch": 0.97,
      "grad_norm": 6.7397637367248535,
      "learning_rate": 3.8709185185185185e-05,
      "loss": 0.493,
      "step": 8720
    },
    {
      "epoch": 0.97,
      "grad_norm": 10.073990821838379,
      "learning_rate": 3.870770370370371e-05,
      "loss": 0.5199,
      "step": 8730
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.272478103637695,
      "learning_rate": 3.870622222222223e-05,
      "loss": 0.5715,
      "step": 8740
    },
    {
      "epoch": 0.97,
      "grad_norm": 15.203478813171387,
      "learning_rate": 3.8704740740740746e-05,
      "loss": 0.6319,
      "step": 8750
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.045809745788574,
      "learning_rate": 3.870325925925926e-05,
      "loss": 0.5318,
      "step": 8760
    },
    {
      "epoch": 0.97,
      "grad_norm": 10.296622276306152,
      "learning_rate": 3.870177777777778e-05,
      "loss": 0.4878,
      "step": 8770
    },
    {
      "epoch": 0.98,
      "grad_norm": 11.009550094604492,
      "learning_rate": 3.87002962962963e-05,
      "loss": 0.4467,
      "step": 8780
    },
    {
      "epoch": 0.98,
      "grad_norm": 13.035384178161621,
      "learning_rate": 3.869881481481482e-05,
      "loss": 0.4862,
      "step": 8790
    },
    {
      "epoch": 0.98,
      "grad_norm": 7.605898857116699,
      "learning_rate": 3.869733333333334e-05,
      "loss": 0.4847,
      "step": 8800
    },
    {
      "epoch": 0.98,
      "grad_norm": 11.664180755615234,
      "learning_rate": 3.8695851851851856e-05,
      "loss": 0.3976,
      "step": 8810
    },
    {
      "epoch": 0.98,
      "grad_norm": 21.702617645263672,
      "learning_rate": 3.869437037037037e-05,
      "loss": 0.5177,
      "step": 8820
    },
    {
      "epoch": 0.98,
      "grad_norm": 8.676081657409668,
      "learning_rate": 3.869288888888889e-05,
      "loss": 0.5541,
      "step": 8830
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.549396514892578,
      "learning_rate": 3.869140740740741e-05,
      "loss": 0.584,
      "step": 8840
    },
    {
      "epoch": 0.98,
      "grad_norm": 8.768531799316406,
      "learning_rate": 3.8689925925925933e-05,
      "loss": 0.5434,
      "step": 8850
    },
    {
      "epoch": 0.98,
      "grad_norm": 8.2962064743042,
      "learning_rate": 3.868844444444445e-05,
      "loss": 0.5778,
      "step": 8860
    },
    {
      "epoch": 0.99,
      "grad_norm": 10.213899612426758,
      "learning_rate": 3.8686962962962966e-05,
      "loss": 0.476,
      "step": 8870
    },
    {
      "epoch": 0.99,
      "grad_norm": 7.135616302490234,
      "learning_rate": 3.868548148148148e-05,
      "loss": 0.5399,
      "step": 8880
    },
    {
      "epoch": 0.99,
      "grad_norm": 5.270388603210449,
      "learning_rate": 3.8684000000000004e-05,
      "loss": 0.5598,
      "step": 8890
    },
    {
      "epoch": 0.99,
      "grad_norm": 8.983911514282227,
      "learning_rate": 3.868251851851852e-05,
      "loss": 0.4804,
      "step": 8900
    },
    {
      "epoch": 0.99,
      "grad_norm": 14.978017807006836,
      "learning_rate": 3.868103703703704e-05,
      "loss": 0.49,
      "step": 8910
    },
    {
      "epoch": 0.99,
      "grad_norm": 8.23361873626709,
      "learning_rate": 3.867955555555556e-05,
      "loss": 0.4032,
      "step": 8920
    },
    {
      "epoch": 0.99,
      "grad_norm": 7.1249213218688965,
      "learning_rate": 3.8678074074074075e-05,
      "loss": 0.503,
      "step": 8930
    },
    {
      "epoch": 0.99,
      "grad_norm": 11.240584373474121,
      "learning_rate": 3.867659259259259e-05,
      "loss": 0.4703,
      "step": 8940
    },
    {
      "epoch": 0.99,
      "grad_norm": 7.723082542419434,
      "learning_rate": 3.8675111111111114e-05,
      "loss": 0.5268,
      "step": 8950
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.8922882080078125,
      "learning_rate": 3.867362962962964e-05,
      "loss": 0.5032,
      "step": 8960
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.708720207214355,
      "learning_rate": 3.867214814814815e-05,
      "loss": 0.4572,
      "step": 8970
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.471643447875977,
      "learning_rate": 3.867066666666667e-05,
      "loss": 0.4608,
      "step": 8980
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.903702735900879,
      "learning_rate": 3.8669185185185185e-05,
      "loss": 0.4858,
      "step": 8990
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.911187171936035,
      "learning_rate": 3.866770370370371e-05,
      "loss": 0.5471,
      "step": 9000
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.732775688171387,
      "learning_rate": 3.866622222222223e-05,
      "loss": 0.4367,
      "step": 9010
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.8799638748168945,
      "learning_rate": 3.8664740740740747e-05,
      "loss": 0.4176,
      "step": 9020
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.072989463806152,
      "learning_rate": 3.866325925925926e-05,
      "loss": 0.4145,
      "step": 9030
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.65390682220459,
      "learning_rate": 3.866177777777778e-05,
      "loss": 0.5645,
      "step": 9040
    },
    {
      "epoch": 1.01,
      "grad_norm": 9.222376823425293,
      "learning_rate": 3.8660296296296295e-05,
      "loss": 0.4461,
      "step": 9050
    },
    {
      "epoch": 1.01,
      "grad_norm": 8.213330268859863,
      "learning_rate": 3.865881481481482e-05,
      "loss": 0.4861,
      "step": 9060
    },
    {
      "epoch": 1.01,
      "grad_norm": 8.874906539916992,
      "learning_rate": 3.865733333333334e-05,
      "loss": 0.4153,
      "step": 9070
    },
    {
      "epoch": 1.01,
      "grad_norm": 19.871387481689453,
      "learning_rate": 3.8655851851851856e-05,
      "loss": 0.5011,
      "step": 9080
    },
    {
      "epoch": 1.01,
      "grad_norm": 7.775842666625977,
      "learning_rate": 3.865437037037037e-05,
      "loss": 0.4904,
      "step": 9090
    },
    {
      "epoch": 1.01,
      "grad_norm": 6.1343793869018555,
      "learning_rate": 3.865288888888889e-05,
      "loss": 0.385,
      "step": 9100
    },
    {
      "epoch": 1.01,
      "grad_norm": 11.351482391357422,
      "learning_rate": 3.865140740740741e-05,
      "loss": 0.451,
      "step": 9110
    },
    {
      "epoch": 1.01,
      "grad_norm": 10.007640838623047,
      "learning_rate": 3.8649925925925934e-05,
      "loss": 0.4283,
      "step": 9120
    },
    {
      "epoch": 1.01,
      "grad_norm": 5.51006555557251,
      "learning_rate": 3.864844444444445e-05,
      "loss": 0.3926,
      "step": 9130
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.427192211151123,
      "learning_rate": 3.8646962962962966e-05,
      "loss": 0.5327,
      "step": 9140
    },
    {
      "epoch": 1.02,
      "grad_norm": 11.214532852172852,
      "learning_rate": 3.864548148148148e-05,
      "loss": 0.4267,
      "step": 9150
    },
    {
      "epoch": 1.02,
      "grad_norm": 22.783016204833984,
      "learning_rate": 3.8644000000000005e-05,
      "loss": 0.3955,
      "step": 9160
    },
    {
      "epoch": 1.02,
      "grad_norm": 18.49878692626953,
      "learning_rate": 3.864251851851852e-05,
      "loss": 0.5862,
      "step": 9170
    },
    {
      "epoch": 1.02,
      "grad_norm": 5.811110496520996,
      "learning_rate": 3.8641037037037044e-05,
      "loss": 0.4183,
      "step": 9180
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.6556243896484375,
      "learning_rate": 3.863955555555556e-05,
      "loss": 0.3596,
      "step": 9190
    },
    {
      "epoch": 1.02,
      "grad_norm": 16.724393844604492,
      "learning_rate": 3.8638074074074076e-05,
      "loss": 0.5009,
      "step": 9200
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.285004615783691,
      "learning_rate": 3.863659259259259e-05,
      "loss": 0.4181,
      "step": 9210
    },
    {
      "epoch": 1.02,
      "grad_norm": 11.13178539276123,
      "learning_rate": 3.8635111111111114e-05,
      "loss": 0.4442,
      "step": 9220
    },
    {
      "epoch": 1.03,
      "grad_norm": 11.528122901916504,
      "learning_rate": 3.863362962962964e-05,
      "loss": 0.3938,
      "step": 9230
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.924586296081543,
      "learning_rate": 3.863214814814815e-05,
      "loss": 0.4314,
      "step": 9240
    },
    {
      "epoch": 1.03,
      "grad_norm": 5.453549385070801,
      "learning_rate": 3.863066666666667e-05,
      "loss": 0.3722,
      "step": 9250
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.522747993469238,
      "learning_rate": 3.8629185185185185e-05,
      "loss": 0.3648,
      "step": 9260
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.799539566040039,
      "learning_rate": 3.862770370370371e-05,
      "loss": 0.562,
      "step": 9270
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.256878852844238,
      "learning_rate": 3.8626222222222224e-05,
      "loss": 0.4466,
      "step": 9280
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.148460388183594,
      "learning_rate": 3.862474074074075e-05,
      "loss": 0.5188,
      "step": 9290
    },
    {
      "epoch": 1.03,
      "grad_norm": 7.242884635925293,
      "learning_rate": 3.862325925925926e-05,
      "loss": 0.4128,
      "step": 9300
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.520174503326416,
      "learning_rate": 3.862177777777778e-05,
      "loss": 0.4628,
      "step": 9310
    },
    {
      "epoch": 1.04,
      "grad_norm": 6.990639686584473,
      "learning_rate": 3.8620296296296295e-05,
      "loss": 0.3561,
      "step": 9320
    },
    {
      "epoch": 1.04,
      "grad_norm": 14.524238586425781,
      "learning_rate": 3.861881481481482e-05,
      "loss": 0.3829,
      "step": 9330
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.003584861755371,
      "learning_rate": 3.861733333333334e-05,
      "loss": 0.3861,
      "step": 9340
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.183390617370605,
      "learning_rate": 3.8615851851851857e-05,
      "loss": 0.3603,
      "step": 9350
    },
    {
      "epoch": 1.04,
      "grad_norm": 8.041651725769043,
      "learning_rate": 3.861437037037037e-05,
      "loss": 0.3855,
      "step": 9360
    },
    {
      "epoch": 1.04,
      "grad_norm": 6.25056266784668,
      "learning_rate": 3.861288888888889e-05,
      "loss": 0.3832,
      "step": 9370
    },
    {
      "epoch": 1.04,
      "grad_norm": 6.841685771942139,
      "learning_rate": 3.861140740740741e-05,
      "loss": 0.4484,
      "step": 9380
    },
    {
      "epoch": 1.04,
      "grad_norm": 8.962445259094238,
      "learning_rate": 3.860992592592593e-05,
      "loss": 0.4046,
      "step": 9390
    },
    {
      "epoch": 1.04,
      "grad_norm": 15.975396156311035,
      "learning_rate": 3.860844444444445e-05,
      "loss": 0.4466,
      "step": 9400
    },
    {
      "epoch": 1.05,
      "grad_norm": 6.789641380310059,
      "learning_rate": 3.8606962962962966e-05,
      "loss": 0.4789,
      "step": 9410
    },
    {
      "epoch": 1.05,
      "grad_norm": 7.224167346954346,
      "learning_rate": 3.860548148148148e-05,
      "loss": 0.5489,
      "step": 9420
    },
    {
      "epoch": 1.05,
      "grad_norm": 6.340092658996582,
      "learning_rate": 3.8604e-05,
      "loss": 0.4032,
      "step": 9430
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.353880882263184,
      "learning_rate": 3.860251851851852e-05,
      "loss": 0.3453,
      "step": 9440
    },
    {
      "epoch": 1.05,
      "grad_norm": 21.75094223022461,
      "learning_rate": 3.8601037037037044e-05,
      "loss": 0.4016,
      "step": 9450
    },
    {
      "epoch": 1.05,
      "grad_norm": 6.36686897277832,
      "learning_rate": 3.859955555555556e-05,
      "loss": 0.3602,
      "step": 9460
    },
    {
      "epoch": 1.05,
      "grad_norm": 5.089099884033203,
      "learning_rate": 3.8598074074074076e-05,
      "loss": 0.3775,
      "step": 9470
    },
    {
      "epoch": 1.05,
      "grad_norm": 7.14876651763916,
      "learning_rate": 3.859659259259259e-05,
      "loss": 0.4192,
      "step": 9480
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.14274787902832,
      "learning_rate": 3.8595111111111115e-05,
      "loss": 0.4325,
      "step": 9490
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.880488872528076,
      "learning_rate": 3.859362962962963e-05,
      "loss": 0.3189,
      "step": 9500
    },
    {
      "epoch": 1.06,
      "grad_norm": 14.575998306274414,
      "learning_rate": 3.8592148148148154e-05,
      "loss": 0.4625,
      "step": 9510
    },
    {
      "epoch": 1.06,
      "grad_norm": 7.9197468757629395,
      "learning_rate": 3.859066666666667e-05,
      "loss": 0.4477,
      "step": 9520
    },
    {
      "epoch": 1.06,
      "grad_norm": 8.676562309265137,
      "learning_rate": 3.8589185185185186e-05,
      "loss": 0.4769,
      "step": 9530
    },
    {
      "epoch": 1.06,
      "grad_norm": 11.519506454467773,
      "learning_rate": 3.85877037037037e-05,
      "loss": 0.5045,
      "step": 9540
    },
    {
      "epoch": 1.06,
      "grad_norm": 8.377936363220215,
      "learning_rate": 3.8586222222222224e-05,
      "loss": 0.4468,
      "step": 9550
    },
    {
      "epoch": 1.06,
      "grad_norm": 6.793701648712158,
      "learning_rate": 3.858474074074075e-05,
      "loss": 0.4112,
      "step": 9560
    },
    {
      "epoch": 1.06,
      "grad_norm": 6.207462787628174,
      "learning_rate": 3.858325925925926e-05,
      "loss": 0.3509,
      "step": 9570
    },
    {
      "epoch": 1.06,
      "grad_norm": 11.12213134765625,
      "learning_rate": 3.858177777777778e-05,
      "loss": 0.4954,
      "step": 9580
    },
    {
      "epoch": 1.07,
      "grad_norm": 8.85068130493164,
      "learning_rate": 3.8580296296296295e-05,
      "loss": 0.3745,
      "step": 9590
    },
    {
      "epoch": 1.07,
      "grad_norm": 6.852802753448486,
      "learning_rate": 3.857881481481482e-05,
      "loss": 0.4381,
      "step": 9600
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.033603191375732,
      "learning_rate": 3.857733333333334e-05,
      "loss": 0.4067,
      "step": 9610
    },
    {
      "epoch": 1.07,
      "grad_norm": 9.756012916564941,
      "learning_rate": 3.857585185185186e-05,
      "loss": 0.4123,
      "step": 9620
    },
    {
      "epoch": 1.07,
      "grad_norm": 11.613590240478516,
      "learning_rate": 3.857437037037037e-05,
      "loss": 0.4122,
      "step": 9630
    },
    {
      "epoch": 1.07,
      "grad_norm": 6.5906243324279785,
      "learning_rate": 3.857288888888889e-05,
      "loss": 0.4385,
      "step": 9640
    },
    {
      "epoch": 1.07,
      "grad_norm": 11.400528907775879,
      "learning_rate": 3.857140740740741e-05,
      "loss": 0.4538,
      "step": 9650
    },
    {
      "epoch": 1.07,
      "grad_norm": 6.272436618804932,
      "learning_rate": 3.856992592592593e-05,
      "loss": 0.3978,
      "step": 9660
    },
    {
      "epoch": 1.07,
      "grad_norm": 8.194608688354492,
      "learning_rate": 3.856844444444445e-05,
      "loss": 0.3857,
      "step": 9670
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.95863151550293,
      "learning_rate": 3.856696296296297e-05,
      "loss": 0.3721,
      "step": 9680
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.488306045532227,
      "learning_rate": 3.856548148148148e-05,
      "loss": 0.4455,
      "step": 9690
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.142848491668701,
      "learning_rate": 3.8564e-05,
      "loss": 0.4102,
      "step": 9700
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.041383743286133,
      "learning_rate": 3.856251851851852e-05,
      "loss": 0.505,
      "step": 9710
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.539383888244629,
      "learning_rate": 3.8561037037037044e-05,
      "loss": 0.4327,
      "step": 9720
    },
    {
      "epoch": 1.08,
      "grad_norm": 6.157563209533691,
      "learning_rate": 3.855955555555556e-05,
      "loss": 0.3651,
      "step": 9730
    },
    {
      "epoch": 1.08,
      "grad_norm": 6.616114616394043,
      "learning_rate": 3.8558074074074076e-05,
      "loss": 0.3734,
      "step": 9740
    },
    {
      "epoch": 1.08,
      "grad_norm": 10.222479820251465,
      "learning_rate": 3.855659259259259e-05,
      "loss": 0.4928,
      "step": 9750
    },
    {
      "epoch": 1.08,
      "grad_norm": 9.093636512756348,
      "learning_rate": 3.8555111111111115e-05,
      "loss": 0.4413,
      "step": 9760
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.49210262298584,
      "learning_rate": 3.855362962962963e-05,
      "loss": 0.4379,
      "step": 9770
    },
    {
      "epoch": 1.09,
      "grad_norm": 5.997431755065918,
      "learning_rate": 3.8552148148148154e-05,
      "loss": 0.4243,
      "step": 9780
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.511967182159424,
      "learning_rate": 3.855066666666667e-05,
      "loss": 0.5408,
      "step": 9790
    },
    {
      "epoch": 1.09,
      "grad_norm": 8.435131072998047,
      "learning_rate": 3.8549185185185186e-05,
      "loss": 0.3427,
      "step": 9800
    },
    {
      "epoch": 1.09,
      "grad_norm": 11.60425090789795,
      "learning_rate": 3.85477037037037e-05,
      "loss": 0.3196,
      "step": 9810
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.980208873748779,
      "learning_rate": 3.8546222222222225e-05,
      "loss": 0.4061,
      "step": 9820
    },
    {
      "epoch": 1.09,
      "grad_norm": 4.2438836097717285,
      "learning_rate": 3.854474074074075e-05,
      "loss": 0.3296,
      "step": 9830
    },
    {
      "epoch": 1.09,
      "grad_norm": 15.03050422668457,
      "learning_rate": 3.8543259259259264e-05,
      "loss": 0.3155,
      "step": 9840
    },
    {
      "epoch": 1.09,
      "grad_norm": 8.657160758972168,
      "learning_rate": 3.854177777777778e-05,
      "loss": 0.3722,
      "step": 9850
    },
    {
      "epoch": 1.1,
      "grad_norm": 9.020858764648438,
      "learning_rate": 3.8540296296296296e-05,
      "loss": 0.4208,
      "step": 9860
    },
    {
      "epoch": 1.1,
      "grad_norm": 11.479702949523926,
      "learning_rate": 3.853881481481482e-05,
      "loss": 0.4437,
      "step": 9870
    },
    {
      "epoch": 1.1,
      "grad_norm": 10.438939094543457,
      "learning_rate": 3.8537333333333335e-05,
      "loss": 0.348,
      "step": 9880
    },
    {
      "epoch": 1.1,
      "grad_norm": 7.916363716125488,
      "learning_rate": 3.853585185185186e-05,
      "loss": 0.3505,
      "step": 9890
    },
    {
      "epoch": 1.1,
      "grad_norm": 7.057204246520996,
      "learning_rate": 3.8534370370370373e-05,
      "loss": 0.3458,
      "step": 9900
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.772406578063965,
      "learning_rate": 3.853288888888889e-05,
      "loss": 0.4671,
      "step": 9910
    },
    {
      "epoch": 1.1,
      "grad_norm": 9.77225399017334,
      "learning_rate": 3.8531407407407405e-05,
      "loss": 0.5279,
      "step": 9920
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.137444019317627,
      "learning_rate": 3.852992592592593e-05,
      "loss": 0.4512,
      "step": 9930
    },
    {
      "epoch": 1.1,
      "grad_norm": 13.929864883422852,
      "learning_rate": 3.852844444444445e-05,
      "loss": 0.4418,
      "step": 9940
    },
    {
      "epoch": 1.11,
      "grad_norm": 22.777006149291992,
      "learning_rate": 3.852696296296297e-05,
      "loss": 0.3926,
      "step": 9950
    },
    {
      "epoch": 1.11,
      "grad_norm": 9.499545097351074,
      "learning_rate": 3.852548148148148e-05,
      "loss": 0.4888,
      "step": 9960
    },
    {
      "epoch": 1.11,
      "grad_norm": 5.694948673248291,
      "learning_rate": 3.8524e-05,
      "loss": 0.4568,
      "step": 9970
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.249129295349121,
      "learning_rate": 3.852251851851852e-05,
      "loss": 0.4762,
      "step": 9980
    },
    {
      "epoch": 1.11,
      "grad_norm": 7.729618072509766,
      "learning_rate": 3.852103703703704e-05,
      "loss": 0.3565,
      "step": 9990
    },
    {
      "epoch": 1.11,
      "grad_norm": 7.447060585021973,
      "learning_rate": 3.851955555555556e-05,
      "loss": 0.4214,
      "step": 10000
    },
    {
      "epoch": 1.11,
      "grad_norm": 6.30342435836792,
      "learning_rate": 3.851807407407408e-05,
      "loss": 0.4334,
      "step": 10010
    },
    {
      "epoch": 1.11,
      "grad_norm": 6.4106879234313965,
      "learning_rate": 3.851659259259259e-05,
      "loss": 0.3571,
      "step": 10020
    },
    {
      "epoch": 1.11,
      "grad_norm": 9.220595359802246,
      "learning_rate": 3.8515111111111116e-05,
      "loss": 0.4596,
      "step": 10030
    },
    {
      "epoch": 1.12,
      "grad_norm": 8.529336929321289,
      "learning_rate": 3.851362962962963e-05,
      "loss": 0.3889,
      "step": 10040
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.889922142028809,
      "learning_rate": 3.8512148148148154e-05,
      "loss": 0.417,
      "step": 10050
    },
    {
      "epoch": 1.12,
      "grad_norm": 5.198200225830078,
      "learning_rate": 3.851066666666667e-05,
      "loss": 0.374,
      "step": 10060
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.9464111328125,
      "learning_rate": 3.8509185185185186e-05,
      "loss": 0.3225,
      "step": 10070
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.638262748718262,
      "learning_rate": 3.85077037037037e-05,
      "loss": 0.3474,
      "step": 10080
    },
    {
      "epoch": 1.12,
      "grad_norm": 6.694983959197998,
      "learning_rate": 3.8506222222222225e-05,
      "loss": 0.5226,
      "step": 10090
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.089966297149658,
      "learning_rate": 3.850474074074075e-05,
      "loss": 0.3851,
      "step": 10100
    },
    {
      "epoch": 1.12,
      "grad_norm": 5.755124092102051,
      "learning_rate": 3.8503259259259264e-05,
      "loss": 0.3352,
      "step": 10110
    },
    {
      "epoch": 1.12,
      "grad_norm": 9.940756797790527,
      "learning_rate": 3.850177777777778e-05,
      "loss": 0.418,
      "step": 10120
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.0027852058410645,
      "learning_rate": 3.8500296296296296e-05,
      "loss": 0.371,
      "step": 10130
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.239187240600586,
      "learning_rate": 3.849881481481482e-05,
      "loss": 0.4125,
      "step": 10140
    },
    {
      "epoch": 1.13,
      "grad_norm": 13.092838287353516,
      "learning_rate": 3.8497333333333335e-05,
      "loss": 0.4292,
      "step": 10150
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.542133808135986,
      "learning_rate": 3.849585185185186e-05,
      "loss": 0.4267,
      "step": 10160
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.243257522583008,
      "learning_rate": 3.8494370370370374e-05,
      "loss": 0.3677,
      "step": 10170
    },
    {
      "epoch": 1.13,
      "grad_norm": 4.56658935546875,
      "learning_rate": 3.849288888888889e-05,
      "loss": 0.4552,
      "step": 10180
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.684246063232422,
      "learning_rate": 3.8491407407407406e-05,
      "loss": 0.414,
      "step": 10190
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.249329090118408,
      "learning_rate": 3.848992592592593e-05,
      "loss": 0.367,
      "step": 10200
    },
    {
      "epoch": 1.13,
      "grad_norm": 10.552193641662598,
      "learning_rate": 3.848844444444445e-05,
      "loss": 0.3376,
      "step": 10210
    },
    {
      "epoch": 1.14,
      "grad_norm": 8.353918075561523,
      "learning_rate": 3.848696296296297e-05,
      "loss": 0.3473,
      "step": 10220
    },
    {
      "epoch": 1.14,
      "grad_norm": 8.07681941986084,
      "learning_rate": 3.8485481481481483e-05,
      "loss": 0.3717,
      "step": 10230
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.4704365730285645,
      "learning_rate": 3.8484e-05,
      "loss": 0.3404,
      "step": 10240
    },
    {
      "epoch": 1.14,
      "grad_norm": 8.049214363098145,
      "learning_rate": 3.848251851851852e-05,
      "loss": 0.4251,
      "step": 10250
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.850310325622559,
      "learning_rate": 3.848103703703704e-05,
      "loss": 0.3311,
      "step": 10260
    },
    {
      "epoch": 1.14,
      "grad_norm": 5.753304958343506,
      "learning_rate": 3.847955555555556e-05,
      "loss": 0.4136,
      "step": 10270
    },
    {
      "epoch": 1.14,
      "grad_norm": 8.822280883789062,
      "learning_rate": 3.847807407407408e-05,
      "loss": 0.3371,
      "step": 10280
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.925329685211182,
      "learning_rate": 3.847659259259259e-05,
      "loss": 0.4098,
      "step": 10290
    },
    {
      "epoch": 1.14,
      "grad_norm": 10.0038423538208,
      "learning_rate": 3.8475111111111116e-05,
      "loss": 0.3425,
      "step": 10300
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.957236289978027,
      "learning_rate": 3.847362962962963e-05,
      "loss": 0.4569,
      "step": 10310
    },
    {
      "epoch": 1.15,
      "grad_norm": 18.877986907958984,
      "learning_rate": 3.8472148148148155e-05,
      "loss": 0.4613,
      "step": 10320
    },
    {
      "epoch": 1.15,
      "grad_norm": 13.974370002746582,
      "learning_rate": 3.847066666666667e-05,
      "loss": 0.4445,
      "step": 10330
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.589578628540039,
      "learning_rate": 3.846918518518519e-05,
      "loss": 0.3449,
      "step": 10340
    },
    {
      "epoch": 1.15,
      "grad_norm": 12.884730339050293,
      "learning_rate": 3.84677037037037e-05,
      "loss": 0.3474,
      "step": 10350
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.95278263092041,
      "learning_rate": 3.8466222222222226e-05,
      "loss": 0.4117,
      "step": 10360
    },
    {
      "epoch": 1.15,
      "grad_norm": 11.819108009338379,
      "learning_rate": 3.846474074074074e-05,
      "loss": 0.3247,
      "step": 10370
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.787742614746094,
      "learning_rate": 3.8463259259259264e-05,
      "loss": 0.359,
      "step": 10380
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.619229793548584,
      "learning_rate": 3.846177777777778e-05,
      "loss": 0.4836,
      "step": 10390
    },
    {
      "epoch": 1.16,
      "grad_norm": 9.160560607910156,
      "learning_rate": 3.8460296296296297e-05,
      "loss": 0.448,
      "step": 10400
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.9578166007995605,
      "learning_rate": 3.845881481481482e-05,
      "loss": 0.3913,
      "step": 10410
    },
    {
      "epoch": 1.16,
      "grad_norm": 6.9309563636779785,
      "learning_rate": 3.8457333333333335e-05,
      "loss": 0.3978,
      "step": 10420
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.133749008178711,
      "learning_rate": 3.845585185185186e-05,
      "loss": 0.3503,
      "step": 10430
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.326395034790039,
      "learning_rate": 3.8454370370370374e-05,
      "loss": 0.37,
      "step": 10440
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.7804484367370605,
      "learning_rate": 3.845288888888889e-05,
      "loss": 0.3788,
      "step": 10450
    },
    {
      "epoch": 1.16,
      "grad_norm": 4.943604946136475,
      "learning_rate": 3.8451407407407406e-05,
      "loss": 0.3482,
      "step": 10460
    },
    {
      "epoch": 1.16,
      "grad_norm": 6.644921779632568,
      "learning_rate": 3.844992592592593e-05,
      "loss": 0.2636,
      "step": 10470
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.797228813171387,
      "learning_rate": 3.8448444444444445e-05,
      "loss": 0.3418,
      "step": 10480
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.622817516326904,
      "learning_rate": 3.844696296296297e-05,
      "loss": 0.4006,
      "step": 10490
    },
    {
      "epoch": 1.17,
      "grad_norm": 15.09975814819336,
      "learning_rate": 3.8445481481481484e-05,
      "loss": 0.3955,
      "step": 10500
    },
    {
      "epoch": 1.17,
      "grad_norm": 8.830795288085938,
      "learning_rate": 3.8444e-05,
      "loss": 0.3028,
      "step": 10510
    },
    {
      "epoch": 1.17,
      "grad_norm": 7.352711200714111,
      "learning_rate": 3.844251851851852e-05,
      "loss": 0.38,
      "step": 10520
    },
    {
      "epoch": 1.17,
      "grad_norm": 7.42542028427124,
      "learning_rate": 3.844103703703704e-05,
      "loss": 0.3579,
      "step": 10530
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.236907482147217,
      "learning_rate": 3.843955555555556e-05,
      "loss": 0.4215,
      "step": 10540
    },
    {
      "epoch": 1.17,
      "grad_norm": 4.462195873260498,
      "learning_rate": 3.843807407407408e-05,
      "loss": 0.3462,
      "step": 10550
    },
    {
      "epoch": 1.17,
      "grad_norm": 11.149242401123047,
      "learning_rate": 3.8436592592592594e-05,
      "loss": 0.3777,
      "step": 10560
    },
    {
      "epoch": 1.17,
      "grad_norm": 17.14789581298828,
      "learning_rate": 3.8435111111111116e-05,
      "loss": 0.3651,
      "step": 10570
    },
    {
      "epoch": 1.18,
      "grad_norm": 13.299242973327637,
      "learning_rate": 3.843362962962963e-05,
      "loss": 0.438,
      "step": 10580
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.287503242492676,
      "learning_rate": 3.843214814814815e-05,
      "loss": 0.4564,
      "step": 10590
    },
    {
      "epoch": 1.18,
      "grad_norm": 9.947877883911133,
      "learning_rate": 3.843066666666667e-05,
      "loss": 0.3027,
      "step": 10600
    },
    {
      "epoch": 1.18,
      "grad_norm": 7.060145854949951,
      "learning_rate": 3.842918518518519e-05,
      "loss": 0.4223,
      "step": 10610
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.294739723205566,
      "learning_rate": 3.84277037037037e-05,
      "loss": 0.3483,
      "step": 10620
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.093279838562012,
      "learning_rate": 3.8426222222222226e-05,
      "loss": 0.3973,
      "step": 10630
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.408759117126465,
      "learning_rate": 3.842474074074074e-05,
      "loss": 0.3103,
      "step": 10640
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.164215087890625,
      "learning_rate": 3.8423259259259265e-05,
      "loss": 0.3557,
      "step": 10650
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.4428019523620605,
      "learning_rate": 3.842177777777778e-05,
      "loss": 0.3523,
      "step": 10660
    },
    {
      "epoch": 1.19,
      "grad_norm": 12.382877349853516,
      "learning_rate": 3.84202962962963e-05,
      "loss": 0.3186,
      "step": 10670
    },
    {
      "epoch": 1.19,
      "grad_norm": 8.143733978271484,
      "learning_rate": 3.841881481481482e-05,
      "loss": 0.2877,
      "step": 10680
    },
    {
      "epoch": 1.19,
      "grad_norm": 15.026750564575195,
      "learning_rate": 3.8417333333333336e-05,
      "loss": 0.399,
      "step": 10690
    },
    {
      "epoch": 1.19,
      "grad_norm": 6.609159469604492,
      "learning_rate": 3.841585185185186e-05,
      "loss": 0.3396,
      "step": 10700
    },
    {
      "epoch": 1.19,
      "grad_norm": 5.029049396514893,
      "learning_rate": 3.8414370370370375e-05,
      "loss": 0.4124,
      "step": 10710
    },
    {
      "epoch": 1.19,
      "grad_norm": 9.845846176147461,
      "learning_rate": 3.841288888888889e-05,
      "loss": 0.3557,
      "step": 10720
    },
    {
      "epoch": 1.19,
      "grad_norm": 7.351417064666748,
      "learning_rate": 3.8411407407407407e-05,
      "loss": 0.3916,
      "step": 10730
    },
    {
      "epoch": 1.19,
      "grad_norm": 7.67535924911499,
      "learning_rate": 3.840992592592593e-05,
      "loss": 0.3284,
      "step": 10740
    },
    {
      "epoch": 1.19,
      "grad_norm": 7.365250587463379,
      "learning_rate": 3.8408444444444445e-05,
      "loss": 0.4495,
      "step": 10750
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.962289333343506,
      "learning_rate": 3.840696296296297e-05,
      "loss": 0.3643,
      "step": 10760
    },
    {
      "epoch": 1.2,
      "grad_norm": 9.073960304260254,
      "learning_rate": 3.8405481481481484e-05,
      "loss": 0.4022,
      "step": 10770
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.782161235809326,
      "learning_rate": 3.8404e-05,
      "loss": 0.4737,
      "step": 10780
    },
    {
      "epoch": 1.2,
      "grad_norm": 10.044931411743164,
      "learning_rate": 3.840251851851852e-05,
      "loss": 0.4069,
      "step": 10790
    },
    {
      "epoch": 1.2,
      "grad_norm": 5.567821502685547,
      "learning_rate": 3.840103703703704e-05,
      "loss": 0.372,
      "step": 10800
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.160262584686279,
      "learning_rate": 3.839955555555556e-05,
      "loss": 0.4424,
      "step": 10810
    },
    {
      "epoch": 1.2,
      "grad_norm": 8.145163536071777,
      "learning_rate": 3.839807407407408e-05,
      "loss": 0.3848,
      "step": 10820
    },
    {
      "epoch": 1.2,
      "grad_norm": 18.074581146240234,
      "learning_rate": 3.8396592592592594e-05,
      "loss": 0.4372,
      "step": 10830
    },
    {
      "epoch": 1.2,
      "grad_norm": 10.81933879852295,
      "learning_rate": 3.839511111111112e-05,
      "loss": 0.4607,
      "step": 10840
    },
    {
      "epoch": 1.21,
      "grad_norm": 8.947245597839355,
      "learning_rate": 3.839362962962963e-05,
      "loss": 0.3627,
      "step": 10850
    },
    {
      "epoch": 1.21,
      "grad_norm": 5.741980075836182,
      "learning_rate": 3.839214814814815e-05,
      "loss": 0.2982,
      "step": 10860
    },
    {
      "epoch": 1.21,
      "grad_norm": 10.089158058166504,
      "learning_rate": 3.839066666666667e-05,
      "loss": 0.3291,
      "step": 10870
    },
    {
      "epoch": 1.21,
      "grad_norm": 9.527975082397461,
      "learning_rate": 3.838918518518519e-05,
      "loss": 0.3576,
      "step": 10880
    },
    {
      "epoch": 1.21,
      "grad_norm": 14.048431396484375,
      "learning_rate": 3.8387703703703704e-05,
      "loss": 0.3956,
      "step": 10890
    },
    {
      "epoch": 1.21,
      "grad_norm": 4.696683883666992,
      "learning_rate": 3.8386222222222226e-05,
      "loss": 0.3666,
      "step": 10900
    },
    {
      "epoch": 1.21,
      "grad_norm": 10.060957908630371,
      "learning_rate": 3.838474074074074e-05,
      "loss": 0.2895,
      "step": 10910
    },
    {
      "epoch": 1.21,
      "grad_norm": 5.90623140335083,
      "learning_rate": 3.8383259259259265e-05,
      "loss": 0.3342,
      "step": 10920
    },
    {
      "epoch": 1.21,
      "grad_norm": 7.865074157714844,
      "learning_rate": 3.838177777777778e-05,
      "loss": 0.4385,
      "step": 10930
    },
    {
      "epoch": 1.22,
      "grad_norm": 9.36683177947998,
      "learning_rate": 3.83802962962963e-05,
      "loss": 0.3655,
      "step": 10940
    },
    {
      "epoch": 1.22,
      "grad_norm": 4.829851150512695,
      "learning_rate": 3.837881481481482e-05,
      "loss": 0.3352,
      "step": 10950
    },
    {
      "epoch": 1.22,
      "grad_norm": 6.638993263244629,
      "learning_rate": 3.8377333333333336e-05,
      "loss": 0.3409,
      "step": 10960
    },
    {
      "epoch": 1.22,
      "grad_norm": 7.528842926025391,
      "learning_rate": 3.837585185185185e-05,
      "loss": 0.5456,
      "step": 10970
    },
    {
      "epoch": 1.22,
      "grad_norm": 7.793155670166016,
      "learning_rate": 3.8374370370370375e-05,
      "loss": 0.3397,
      "step": 10980
    },
    {
      "epoch": 1.22,
      "grad_norm": 6.2176289558410645,
      "learning_rate": 3.837288888888889e-05,
      "loss": 0.266,
      "step": 10990
    },
    {
      "epoch": 1.22,
      "grad_norm": 10.335031509399414,
      "learning_rate": 3.837140740740741e-05,
      "loss": 0.3512,
      "step": 11000
    },
    {
      "epoch": 1.22,
      "grad_norm": 7.859344482421875,
      "learning_rate": 3.836992592592593e-05,
      "loss": 0.3838,
      "step": 11010
    },
    {
      "epoch": 1.22,
      "grad_norm": 7.196435451507568,
      "learning_rate": 3.8368444444444446e-05,
      "loss": 0.2688,
      "step": 11020
    },
    {
      "epoch": 1.23,
      "grad_norm": 9.363191604614258,
      "learning_rate": 3.836696296296297e-05,
      "loss": 0.451,
      "step": 11030
    },
    {
      "epoch": 1.23,
      "grad_norm": 4.794438362121582,
      "learning_rate": 3.8365481481481485e-05,
      "loss": 0.2681,
      "step": 11040
    },
    {
      "epoch": 1.23,
      "grad_norm": 4.914618492126465,
      "learning_rate": 3.8364e-05,
      "loss": 0.2905,
      "step": 11050
    },
    {
      "epoch": 1.23,
      "grad_norm": 6.658641338348389,
      "learning_rate": 3.8362518518518523e-05,
      "loss": 0.3644,
      "step": 11060
    },
    {
      "epoch": 1.23,
      "grad_norm": 8.200393676757812,
      "learning_rate": 3.836103703703704e-05,
      "loss": 0.3661,
      "step": 11070
    },
    {
      "epoch": 1.23,
      "grad_norm": 5.588313579559326,
      "learning_rate": 3.8359555555555555e-05,
      "loss": 0.3096,
      "step": 11080
    },
    {
      "epoch": 1.23,
      "grad_norm": 4.932088851928711,
      "learning_rate": 3.835807407407408e-05,
      "loss": 0.374,
      "step": 11090
    },
    {
      "epoch": 1.23,
      "grad_norm": 6.781541347503662,
      "learning_rate": 3.8356592592592594e-05,
      "loss": 0.2963,
      "step": 11100
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.476441860198975,
      "learning_rate": 3.835511111111112e-05,
      "loss": 0.3661,
      "step": 11110
    },
    {
      "epoch": 1.24,
      "grad_norm": 7.1858625411987305,
      "learning_rate": 3.835362962962963e-05,
      "loss": 0.4353,
      "step": 11120
    },
    {
      "epoch": 1.24,
      "grad_norm": 7.685534477233887,
      "learning_rate": 3.835214814814815e-05,
      "loss": 0.4053,
      "step": 11130
    },
    {
      "epoch": 1.24,
      "grad_norm": 5.4130096435546875,
      "learning_rate": 3.835066666666667e-05,
      "loss": 0.2992,
      "step": 11140
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.588077545166016,
      "learning_rate": 3.834918518518519e-05,
      "loss": 0.372,
      "step": 11150
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.1004719734191895,
      "learning_rate": 3.8347703703703704e-05,
      "loss": 0.3266,
      "step": 11160
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.357631206512451,
      "learning_rate": 3.834622222222223e-05,
      "loss": 0.4718,
      "step": 11170
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.829164981842041,
      "learning_rate": 3.834474074074074e-05,
      "loss": 0.3218,
      "step": 11180
    },
    {
      "epoch": 1.24,
      "grad_norm": 5.482743740081787,
      "learning_rate": 3.8343259259259266e-05,
      "loss": 0.3429,
      "step": 11190
    },
    {
      "epoch": 1.24,
      "grad_norm": 13.590310096740723,
      "learning_rate": 3.834177777777778e-05,
      "loss": 0.3219,
      "step": 11200
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.387820720672607,
      "learning_rate": 3.83402962962963e-05,
      "loss": 0.3101,
      "step": 11210
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.238279819488525,
      "learning_rate": 3.833881481481482e-05,
      "loss": 0.282,
      "step": 11220
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.735343933105469,
      "learning_rate": 3.8337333333333336e-05,
      "loss": 0.3735,
      "step": 11230
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.839629173278809,
      "learning_rate": 3.833585185185185e-05,
      "loss": 0.3694,
      "step": 11240
    },
    {
      "epoch": 1.25,
      "grad_norm": 7.5394792556762695,
      "learning_rate": 3.8334370370370375e-05,
      "loss": 0.4638,
      "step": 11250
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.624313831329346,
      "learning_rate": 3.833288888888889e-05,
      "loss": 0.3206,
      "step": 11260
    },
    {
      "epoch": 1.25,
      "grad_norm": 7.5791916847229,
      "learning_rate": 3.8331407407407414e-05,
      "loss": 0.3795,
      "step": 11270
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.170955657958984,
      "learning_rate": 3.832992592592593e-05,
      "loss": 0.3483,
      "step": 11280
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.57469367980957,
      "learning_rate": 3.8328444444444446e-05,
      "loss": 0.265,
      "step": 11290
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.705079555511475,
      "learning_rate": 3.832696296296297e-05,
      "loss": 0.2953,
      "step": 11300
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.412593841552734,
      "learning_rate": 3.8325481481481485e-05,
      "loss": 0.3398,
      "step": 11310
    },
    {
      "epoch": 1.26,
      "grad_norm": 6.789371490478516,
      "learning_rate": 3.8324e-05,
      "loss": 0.3583,
      "step": 11320
    },
    {
      "epoch": 1.26,
      "grad_norm": 6.64001989364624,
      "learning_rate": 3.8322518518518524e-05,
      "loss": 0.2216,
      "step": 11330
    },
    {
      "epoch": 1.26,
      "grad_norm": 9.025979995727539,
      "learning_rate": 3.832103703703704e-05,
      "loss": 0.2797,
      "step": 11340
    },
    {
      "epoch": 1.26,
      "grad_norm": 6.647562503814697,
      "learning_rate": 3.8319555555555556e-05,
      "loss": 0.3984,
      "step": 11350
    },
    {
      "epoch": 1.26,
      "grad_norm": 6.6306071281433105,
      "learning_rate": 3.831807407407408e-05,
      "loss": 0.3431,
      "step": 11360
    },
    {
      "epoch": 1.26,
      "grad_norm": 11.462629318237305,
      "learning_rate": 3.8316592592592595e-05,
      "loss": 0.2998,
      "step": 11370
    },
    {
      "epoch": 1.26,
      "grad_norm": 8.481039047241211,
      "learning_rate": 3.831511111111112e-05,
      "loss": 0.3097,
      "step": 11380
    },
    {
      "epoch": 1.27,
      "grad_norm": 5.767840385437012,
      "learning_rate": 3.8313629629629634e-05,
      "loss": 0.3938,
      "step": 11390
    },
    {
      "epoch": 1.27,
      "grad_norm": 4.5816802978515625,
      "learning_rate": 3.831214814814815e-05,
      "loss": 0.2825,
      "step": 11400
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.088091850280762,
      "learning_rate": 3.831066666666667e-05,
      "loss": 0.3672,
      "step": 11410
    },
    {
      "epoch": 1.27,
      "grad_norm": 9.732797622680664,
      "learning_rate": 3.830918518518519e-05,
      "loss": 0.386,
      "step": 11420
    },
    {
      "epoch": 1.27,
      "grad_norm": 8.146998405456543,
      "learning_rate": 3.8307703703703704e-05,
      "loss": 0.3998,
      "step": 11430
    },
    {
      "epoch": 1.27,
      "grad_norm": 6.936861991882324,
      "learning_rate": 3.830622222222223e-05,
      "loss": 0.3014,
      "step": 11440
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.912440299987793,
      "learning_rate": 3.830474074074074e-05,
      "loss": 0.247,
      "step": 11450
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.255584239959717,
      "learning_rate": 3.830325925925926e-05,
      "loss": 0.317,
      "step": 11460
    },
    {
      "epoch": 1.27,
      "grad_norm": 6.990943908691406,
      "learning_rate": 3.830177777777778e-05,
      "loss": 0.3023,
      "step": 11470
    },
    {
      "epoch": 1.28,
      "grad_norm": 8.51522159576416,
      "learning_rate": 3.83002962962963e-05,
      "loss": 0.3875,
      "step": 11480
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.662038803100586,
      "learning_rate": 3.829881481481482e-05,
      "loss": 0.3918,
      "step": 11490
    },
    {
      "epoch": 1.28,
      "grad_norm": 5.788614273071289,
      "learning_rate": 3.829733333333334e-05,
      "loss": 0.3071,
      "step": 11500
    },
    {
      "epoch": 1.28,
      "grad_norm": 5.1614089012146,
      "learning_rate": 3.829585185185185e-05,
      "loss": 0.3607,
      "step": 11510
    },
    {
      "epoch": 1.28,
      "grad_norm": 9.410386085510254,
      "learning_rate": 3.8294370370370376e-05,
      "loss": 0.3697,
      "step": 11520
    },
    {
      "epoch": 1.28,
      "grad_norm": 6.138025283813477,
      "learning_rate": 3.829288888888889e-05,
      "loss": 0.2895,
      "step": 11530
    },
    {
      "epoch": 1.28,
      "grad_norm": 6.840214252471924,
      "learning_rate": 3.8291407407407415e-05,
      "loss": 0.2963,
      "step": 11540
    },
    {
      "epoch": 1.28,
      "grad_norm": 5.753291130065918,
      "learning_rate": 3.828992592592593e-05,
      "loss": 0.3321,
      "step": 11550
    },
    {
      "epoch": 1.28,
      "grad_norm": 8.141007423400879,
      "learning_rate": 3.8288444444444447e-05,
      "loss": 0.3493,
      "step": 11560
    },
    {
      "epoch": 1.29,
      "grad_norm": 6.490895748138428,
      "learning_rate": 3.828696296296296e-05,
      "loss": 0.2356,
      "step": 11570
    },
    {
      "epoch": 1.29,
      "grad_norm": 6.685452938079834,
      "learning_rate": 3.8285481481481485e-05,
      "loss": 0.3592,
      "step": 11580
    },
    {
      "epoch": 1.29,
      "grad_norm": 6.938776969909668,
      "learning_rate": 3.8284e-05,
      "loss": 0.4051,
      "step": 11590
    },
    {
      "epoch": 1.29,
      "grad_norm": 8.304866790771484,
      "learning_rate": 3.8282518518518524e-05,
      "loss": 0.3354,
      "step": 11600
    },
    {
      "epoch": 1.29,
      "grad_norm": 5.802887916564941,
      "learning_rate": 3.828103703703704e-05,
      "loss": 0.3522,
      "step": 11610
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.8527445793151855,
      "learning_rate": 3.8279555555555556e-05,
      "loss": 0.328,
      "step": 11620
    },
    {
      "epoch": 1.29,
      "grad_norm": 5.655869960784912,
      "learning_rate": 3.827807407407408e-05,
      "loss": 0.3402,
      "step": 11630
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.620169639587402,
      "learning_rate": 3.8276592592592595e-05,
      "loss": 0.3254,
      "step": 11640
    },
    {
      "epoch": 1.29,
      "grad_norm": 14.466789245605469,
      "learning_rate": 3.827511111111112e-05,
      "loss": 0.2948,
      "step": 11650
    },
    {
      "epoch": 1.3,
      "grad_norm": 6.533048152923584,
      "learning_rate": 3.8273629629629634e-05,
      "loss": 0.3053,
      "step": 11660
    },
    {
      "epoch": 1.3,
      "grad_norm": 11.047866821289062,
      "learning_rate": 3.827214814814815e-05,
      "loss": 0.4329,
      "step": 11670
    },
    {
      "epoch": 1.3,
      "grad_norm": 9.19172191619873,
      "learning_rate": 3.8270666666666666e-05,
      "loss": 0.3918,
      "step": 11680
    },
    {
      "epoch": 1.3,
      "grad_norm": 8.391640663146973,
      "learning_rate": 3.826918518518519e-05,
      "loss": 0.2792,
      "step": 11690
    },
    {
      "epoch": 1.3,
      "grad_norm": 13.008016586303711,
      "learning_rate": 3.8267703703703705e-05,
      "loss": 0.3533,
      "step": 11700
    },
    {
      "epoch": 1.3,
      "grad_norm": 10.80078411102295,
      "learning_rate": 3.826622222222223e-05,
      "loss": 0.3424,
      "step": 11710
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.504002571105957,
      "learning_rate": 3.8264740740740744e-05,
      "loss": 0.2453,
      "step": 11720
    },
    {
      "epoch": 1.3,
      "grad_norm": 7.47637414932251,
      "learning_rate": 3.826325925925926e-05,
      "loss": 0.3514,
      "step": 11730
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.5874578952789307,
      "learning_rate": 3.826177777777778e-05,
      "loss": 0.331,
      "step": 11740
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.61840295791626,
      "learning_rate": 3.82602962962963e-05,
      "loss": 0.3714,
      "step": 11750
    },
    {
      "epoch": 1.31,
      "grad_norm": 7.724117279052734,
      "learning_rate": 3.825881481481482e-05,
      "loss": 0.2649,
      "step": 11760
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.503408908843994,
      "learning_rate": 3.825733333333334e-05,
      "loss": 0.3107,
      "step": 11770
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.3467020988464355,
      "learning_rate": 3.825585185185185e-05,
      "loss": 0.2848,
      "step": 11780
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.459346294403076,
      "learning_rate": 3.8254370370370376e-05,
      "loss": 0.3168,
      "step": 11790
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.845561981201172,
      "learning_rate": 3.825288888888889e-05,
      "loss": 0.2904,
      "step": 11800
    },
    {
      "epoch": 1.31,
      "grad_norm": 10.180567741394043,
      "learning_rate": 3.8251407407407415e-05,
      "loss": 0.3171,
      "step": 11810
    },
    {
      "epoch": 1.31,
      "grad_norm": 5.6520280838012695,
      "learning_rate": 3.824992592592593e-05,
      "loss": 0.3262,
      "step": 11820
    },
    {
      "epoch": 1.31,
      "grad_norm": 7.590063095092773,
      "learning_rate": 3.824844444444445e-05,
      "loss": 0.3656,
      "step": 11830
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.5719709396362305,
      "learning_rate": 3.824696296296296e-05,
      "loss": 0.2643,
      "step": 11840
    },
    {
      "epoch": 1.32,
      "grad_norm": 5.963966369628906,
      "learning_rate": 3.8245481481481486e-05,
      "loss": 0.2638,
      "step": 11850
    },
    {
      "epoch": 1.32,
      "grad_norm": 8.526849746704102,
      "learning_rate": 3.8244e-05,
      "loss": 0.3281,
      "step": 11860
    },
    {
      "epoch": 1.32,
      "grad_norm": 6.714353084564209,
      "learning_rate": 3.8242518518518525e-05,
      "loss": 0.3527,
      "step": 11870
    },
    {
      "epoch": 1.32,
      "grad_norm": 5.850368022918701,
      "learning_rate": 3.824103703703704e-05,
      "loss": 0.2336,
      "step": 11880
    },
    {
      "epoch": 1.32,
      "grad_norm": 6.965834617614746,
      "learning_rate": 3.823955555555556e-05,
      "loss": 0.3287,
      "step": 11890
    },
    {
      "epoch": 1.32,
      "grad_norm": 5.713979721069336,
      "learning_rate": 3.823807407407408e-05,
      "loss": 0.328,
      "step": 11900
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.8775501251220703,
      "learning_rate": 3.8236592592592595e-05,
      "loss": 0.3373,
      "step": 11910
    },
    {
      "epoch": 1.32,
      "grad_norm": 4.670176982879639,
      "learning_rate": 3.823511111111112e-05,
      "loss": 0.2527,
      "step": 11920
    },
    {
      "epoch": 1.33,
      "grad_norm": 9.143009185791016,
      "learning_rate": 3.8233629629629634e-05,
      "loss": 0.3282,
      "step": 11930
    },
    {
      "epoch": 1.33,
      "grad_norm": 6.810607433319092,
      "learning_rate": 3.823214814814815e-05,
      "loss": 0.2238,
      "step": 11940
    },
    {
      "epoch": 1.33,
      "grad_norm": 8.313437461853027,
      "learning_rate": 3.8230666666666666e-05,
      "loss": 0.2815,
      "step": 11950
    },
    {
      "epoch": 1.33,
      "grad_norm": 6.313443183898926,
      "learning_rate": 3.822918518518519e-05,
      "loss": 0.241,
      "step": 11960
    },
    {
      "epoch": 1.33,
      "grad_norm": 5.145537376403809,
      "learning_rate": 3.8227703703703705e-05,
      "loss": 0.3203,
      "step": 11970
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.041615962982178,
      "learning_rate": 3.822622222222223e-05,
      "loss": 0.3352,
      "step": 11980
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.8498921394348145,
      "learning_rate": 3.8224740740740744e-05,
      "loss": 0.4585,
      "step": 11990
    },
    {
      "epoch": 1.33,
      "grad_norm": 4.921926498413086,
      "learning_rate": 3.822325925925926e-05,
      "loss": 0.2753,
      "step": 12000
    },
    {
      "epoch": 1.33,
      "grad_norm": 14.054656982421875,
      "learning_rate": 3.822177777777778e-05,
      "loss": 0.3791,
      "step": 12010
    },
    {
      "epoch": 1.34,
      "grad_norm": 5.920035362243652,
      "learning_rate": 3.82202962962963e-05,
      "loss": 0.3238,
      "step": 12020
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.539295673370361,
      "learning_rate": 3.821881481481482e-05,
      "loss": 0.4239,
      "step": 12030
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.169020652770996,
      "learning_rate": 3.821733333333334e-05,
      "loss": 0.3365,
      "step": 12040
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.310255289077759,
      "learning_rate": 3.8215851851851854e-05,
      "loss": 0.2583,
      "step": 12050
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.83965539932251,
      "learning_rate": 3.821437037037037e-05,
      "loss": 0.2956,
      "step": 12060
    },
    {
      "epoch": 1.34,
      "grad_norm": 6.167235374450684,
      "learning_rate": 3.821288888888889e-05,
      "loss": 0.3129,
      "step": 12070
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.3226118087768555,
      "learning_rate": 3.8211407407407415e-05,
      "loss": 0.2467,
      "step": 12080
    },
    {
      "epoch": 1.34,
      "grad_norm": 6.609787940979004,
      "learning_rate": 3.820992592592593e-05,
      "loss": 0.3345,
      "step": 12090
    },
    {
      "epoch": 1.34,
      "grad_norm": 14.547428131103516,
      "learning_rate": 3.820844444444445e-05,
      "loss": 0.2818,
      "step": 12100
    },
    {
      "epoch": 1.35,
      "grad_norm": 7.783980846405029,
      "learning_rate": 3.820696296296296e-05,
      "loss": 0.3358,
      "step": 12110
    },
    {
      "epoch": 1.35,
      "grad_norm": 8.26767349243164,
      "learning_rate": 3.8205481481481486e-05,
      "loss": 0.2811,
      "step": 12120
    },
    {
      "epoch": 1.35,
      "grad_norm": 8.710611343383789,
      "learning_rate": 3.8204e-05,
      "loss": 0.2307,
      "step": 12130
    },
    {
      "epoch": 1.35,
      "grad_norm": 11.349750518798828,
      "learning_rate": 3.8202518518518525e-05,
      "loss": 0.3909,
      "step": 12140
    },
    {
      "epoch": 1.35,
      "grad_norm": 4.45496940612793,
      "learning_rate": 3.820103703703704e-05,
      "loss": 0.2373,
      "step": 12150
    },
    {
      "epoch": 1.35,
      "grad_norm": 9.39566707611084,
      "learning_rate": 3.819955555555556e-05,
      "loss": 0.3198,
      "step": 12160
    },
    {
      "epoch": 1.35,
      "grad_norm": 7.02341890335083,
      "learning_rate": 3.819807407407407e-05,
      "loss": 0.3342,
      "step": 12170
    },
    {
      "epoch": 1.35,
      "grad_norm": 8.540351867675781,
      "learning_rate": 3.8196592592592596e-05,
      "loss": 0.3696,
      "step": 12180
    },
    {
      "epoch": 1.35,
      "grad_norm": 4.763578414916992,
      "learning_rate": 3.819511111111112e-05,
      "loss": 0.3538,
      "step": 12190
    },
    {
      "epoch": 1.36,
      "grad_norm": 7.026571273803711,
      "learning_rate": 3.8193629629629635e-05,
      "loss": 0.3635,
      "step": 12200
    },
    {
      "epoch": 1.36,
      "grad_norm": 17.57232666015625,
      "learning_rate": 3.819214814814815e-05,
      "loss": 0.2952,
      "step": 12210
    },
    {
      "epoch": 1.36,
      "grad_norm": 6.304068088531494,
      "learning_rate": 3.819066666666667e-05,
      "loss": 0.401,
      "step": 12220
    },
    {
      "epoch": 1.36,
      "grad_norm": 10.308530807495117,
      "learning_rate": 3.818918518518519e-05,
      "loss": 0.3776,
      "step": 12230
    },
    {
      "epoch": 1.36,
      "grad_norm": 5.3264617919921875,
      "learning_rate": 3.8187703703703706e-05,
      "loss": 0.3357,
      "step": 12240
    },
    {
      "epoch": 1.36,
      "grad_norm": 6.818848609924316,
      "learning_rate": 3.818622222222223e-05,
      "loss": 0.3076,
      "step": 12250
    },
    {
      "epoch": 1.36,
      "grad_norm": 5.484085559844971,
      "learning_rate": 3.8184740740740744e-05,
      "loss": 0.264,
      "step": 12260
    },
    {
      "epoch": 1.36,
      "grad_norm": 9.382577896118164,
      "learning_rate": 3.818325925925926e-05,
      "loss": 0.2648,
      "step": 12270
    },
    {
      "epoch": 1.36,
      "grad_norm": 13.259805679321289,
      "learning_rate": 3.818177777777778e-05,
      "loss": 0.3385,
      "step": 12280
    },
    {
      "epoch": 1.37,
      "grad_norm": 4.130603313446045,
      "learning_rate": 3.81802962962963e-05,
      "loss": 0.2664,
      "step": 12290
    },
    {
      "epoch": 1.37,
      "grad_norm": 8.455592155456543,
      "learning_rate": 3.817881481481482e-05,
      "loss": 0.3143,
      "step": 12300
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.702455520629883,
      "learning_rate": 3.817733333333334e-05,
      "loss": 0.299,
      "step": 12310
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.588178634643555,
      "learning_rate": 3.8175851851851854e-05,
      "loss": 0.3446,
      "step": 12320
    },
    {
      "epoch": 1.37,
      "grad_norm": 4.811978340148926,
      "learning_rate": 3.817437037037037e-05,
      "loss": 0.2719,
      "step": 12330
    },
    {
      "epoch": 1.37,
      "grad_norm": 4.0776286125183105,
      "learning_rate": 3.817288888888889e-05,
      "loss": 0.3071,
      "step": 12340
    },
    {
      "epoch": 1.37,
      "grad_norm": 8.965675354003906,
      "learning_rate": 3.8171407407407416e-05,
      "loss": 0.287,
      "step": 12350
    },
    {
      "epoch": 1.37,
      "grad_norm": 9.654728889465332,
      "learning_rate": 3.816992592592593e-05,
      "loss": 0.2805,
      "step": 12360
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.17775297164917,
      "learning_rate": 3.816844444444445e-05,
      "loss": 0.366,
      "step": 12370
    },
    {
      "epoch": 1.38,
      "grad_norm": 8.980216026306152,
      "learning_rate": 3.8166962962962964e-05,
      "loss": 0.3468,
      "step": 12380
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.1483821868896484,
      "learning_rate": 3.8165481481481487e-05,
      "loss": 0.3074,
      "step": 12390
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.485195636749268,
      "learning_rate": 3.8164e-05,
      "loss": 0.2692,
      "step": 12400
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.160122394561768,
      "learning_rate": 3.8162518518518525e-05,
      "loss": 0.321,
      "step": 12410
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.301706314086914,
      "learning_rate": 3.816103703703704e-05,
      "loss": 0.3635,
      "step": 12420
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.286314010620117,
      "learning_rate": 3.815955555555556e-05,
      "loss": 0.4061,
      "step": 12430
    },
    {
      "epoch": 1.38,
      "grad_norm": 5.7986040115356445,
      "learning_rate": 3.8158074074074073e-05,
      "loss": 0.2636,
      "step": 12440
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.191418647766113,
      "learning_rate": 3.8156592592592596e-05,
      "loss": 0.2524,
      "step": 12450
    },
    {
      "epoch": 1.38,
      "grad_norm": 13.626387596130371,
      "learning_rate": 3.815511111111112e-05,
      "loss": 0.2705,
      "step": 12460
    },
    {
      "epoch": 1.39,
      "grad_norm": 4.688857078552246,
      "learning_rate": 3.8153629629629635e-05,
      "loss": 0.3502,
      "step": 12470
    },
    {
      "epoch": 1.39,
      "grad_norm": 11.266449928283691,
      "learning_rate": 3.815214814814815e-05,
      "loss": 0.2848,
      "step": 12480
    },
    {
      "epoch": 1.39,
      "grad_norm": 8.537737846374512,
      "learning_rate": 3.815066666666667e-05,
      "loss": 0.3198,
      "step": 12490
    },
    {
      "epoch": 1.39,
      "grad_norm": 4.94442081451416,
      "learning_rate": 3.814918518518519e-05,
      "loss": 0.24,
      "step": 12500
    },
    {
      "epoch": 1.39,
      "grad_norm": 7.662704944610596,
      "learning_rate": 3.8147703703703706e-05,
      "loss": 0.3026,
      "step": 12510
    },
    {
      "epoch": 1.39,
      "grad_norm": 9.19649887084961,
      "learning_rate": 3.814622222222223e-05,
      "loss": 0.3538,
      "step": 12520
    },
    {
      "epoch": 1.39,
      "grad_norm": 4.2533860206604,
      "learning_rate": 3.8144740740740745e-05,
      "loss": 0.3511,
      "step": 12530
    },
    {
      "epoch": 1.39,
      "grad_norm": 6.437538146972656,
      "learning_rate": 3.814325925925926e-05,
      "loss": 0.3251,
      "step": 12540
    },
    {
      "epoch": 1.39,
      "grad_norm": 7.572300910949707,
      "learning_rate": 3.814177777777778e-05,
      "loss": 0.2196,
      "step": 12550
    },
    {
      "epoch": 1.4,
      "grad_norm": 10.108550071716309,
      "learning_rate": 3.81402962962963e-05,
      "loss": 0.3154,
      "step": 12560
    },
    {
      "epoch": 1.4,
      "grad_norm": 5.5012898445129395,
      "learning_rate": 3.813881481481482e-05,
      "loss": 0.2704,
      "step": 12570
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.719030857086182,
      "learning_rate": 3.813733333333334e-05,
      "loss": 0.3185,
      "step": 12580
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.05047082901001,
      "learning_rate": 3.8135851851851854e-05,
      "loss": 0.2673,
      "step": 12590
    },
    {
      "epoch": 1.4,
      "grad_norm": 7.9198808670043945,
      "learning_rate": 3.813437037037037e-05,
      "loss": 0.271,
      "step": 12600
    },
    {
      "epoch": 1.4,
      "grad_norm": 9.197402954101562,
      "learning_rate": 3.813288888888889e-05,
      "loss": 0.2111,
      "step": 12610
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.793116807937622,
      "learning_rate": 3.813140740740741e-05,
      "loss": 0.2704,
      "step": 12620
    },
    {
      "epoch": 1.4,
      "grad_norm": 5.379014492034912,
      "learning_rate": 3.812992592592593e-05,
      "loss": 0.2958,
      "step": 12630
    },
    {
      "epoch": 1.4,
      "grad_norm": 7.576214790344238,
      "learning_rate": 3.812844444444445e-05,
      "loss": 0.2976,
      "step": 12640
    },
    {
      "epoch": 1.41,
      "grad_norm": 9.271206855773926,
      "learning_rate": 3.8126962962962964e-05,
      "loss": 0.315,
      "step": 12650
    },
    {
      "epoch": 1.41,
      "grad_norm": 4.714664459228516,
      "learning_rate": 3.812548148148148e-05,
      "loss": 0.2925,
      "step": 12660
    },
    {
      "epoch": 1.41,
      "grad_norm": 7.41905403137207,
      "learning_rate": 3.8124e-05,
      "loss": 0.3338,
      "step": 12670
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.1648430824279785,
      "learning_rate": 3.8122518518518526e-05,
      "loss": 0.2829,
      "step": 12680
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.15065860748291,
      "learning_rate": 3.812103703703704e-05,
      "loss": 0.3371,
      "step": 12690
    },
    {
      "epoch": 1.41,
      "grad_norm": 10.135515213012695,
      "learning_rate": 3.811955555555556e-05,
      "loss": 0.3392,
      "step": 12700
    },
    {
      "epoch": 1.41,
      "grad_norm": 6.893573760986328,
      "learning_rate": 3.8118074074074074e-05,
      "loss": 0.261,
      "step": 12710
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.373927116394043,
      "learning_rate": 3.8116592592592597e-05,
      "loss": 0.3448,
      "step": 12720
    },
    {
      "epoch": 1.41,
      "grad_norm": 7.142219066619873,
      "learning_rate": 3.811511111111112e-05,
      "loss": 0.3269,
      "step": 12730
    },
    {
      "epoch": 1.42,
      "grad_norm": 10.231715202331543,
      "learning_rate": 3.811377777777778e-05,
      "loss": 0.2992,
      "step": 12740
    },
    {
      "epoch": 1.42,
      "grad_norm": 11.667793273925781,
      "learning_rate": 3.81122962962963e-05,
      "loss": 0.2771,
      "step": 12750
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.599761009216309,
      "learning_rate": 3.8110814814814815e-05,
      "loss": 0.2791,
      "step": 12760
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.324714660644531,
      "learning_rate": 3.810933333333334e-05,
      "loss": 0.3489,
      "step": 12770
    },
    {
      "epoch": 1.42,
      "grad_norm": 3.225349187850952,
      "learning_rate": 3.8107851851851854e-05,
      "loss": 0.2241,
      "step": 12780
    },
    {
      "epoch": 1.42,
      "grad_norm": 7.505183696746826,
      "learning_rate": 3.810637037037037e-05,
      "loss": 0.2781,
      "step": 12790
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.529924392700195,
      "learning_rate": 3.810488888888889e-05,
      "loss": 0.3867,
      "step": 12800
    },
    {
      "epoch": 1.42,
      "grad_norm": 7.233731746673584,
      "learning_rate": 3.810340740740741e-05,
      "loss": 0.2908,
      "step": 12810
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.53199577331543,
      "learning_rate": 3.810192592592593e-05,
      "loss": 0.3449,
      "step": 12820
    },
    {
      "epoch": 1.43,
      "grad_norm": 13.063246726989746,
      "learning_rate": 3.810044444444445e-05,
      "loss": 0.2909,
      "step": 12830
    },
    {
      "epoch": 1.43,
      "grad_norm": 5.116014003753662,
      "learning_rate": 3.8098962962962964e-05,
      "loss": 0.3029,
      "step": 12840
    },
    {
      "epoch": 1.43,
      "grad_norm": 8.123571395874023,
      "learning_rate": 3.8097481481481487e-05,
      "loss": 0.3262,
      "step": 12850
    },
    {
      "epoch": 1.43,
      "grad_norm": 9.063239097595215,
      "learning_rate": 3.8096e-05,
      "loss": 0.3504,
      "step": 12860
    },
    {
      "epoch": 1.43,
      "grad_norm": 7.092245101928711,
      "learning_rate": 3.809451851851852e-05,
      "loss": 0.2366,
      "step": 12870
    },
    {
      "epoch": 1.43,
      "grad_norm": 5.8103837966918945,
      "learning_rate": 3.809303703703704e-05,
      "loss": 0.3128,
      "step": 12880
    },
    {
      "epoch": 1.43,
      "grad_norm": 5.114670276641846,
      "learning_rate": 3.809155555555556e-05,
      "loss": 0.3137,
      "step": 12890
    },
    {
      "epoch": 1.43,
      "grad_norm": 9.060196876525879,
      "learning_rate": 3.809007407407408e-05,
      "loss": 0.2963,
      "step": 12900
    },
    {
      "epoch": 1.43,
      "grad_norm": 5.911299705505371,
      "learning_rate": 3.8088592592592596e-05,
      "loss": 0.3062,
      "step": 12910
    },
    {
      "epoch": 1.44,
      "grad_norm": 5.570688724517822,
      "learning_rate": 3.808711111111111e-05,
      "loss": 0.2678,
      "step": 12920
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.331660747528076,
      "learning_rate": 3.8085629629629635e-05,
      "loss": 0.2217,
      "step": 12930
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.047771453857422,
      "learning_rate": 3.808414814814815e-05,
      "loss": 0.2547,
      "step": 12940
    },
    {
      "epoch": 1.44,
      "grad_norm": 6.833774089813232,
      "learning_rate": 3.808266666666667e-05,
      "loss": 0.2677,
      "step": 12950
    },
    {
      "epoch": 1.44,
      "grad_norm": 5.515222549438477,
      "learning_rate": 3.808118518518519e-05,
      "loss": 0.3032,
      "step": 12960
    },
    {
      "epoch": 1.44,
      "grad_norm": 5.384603023529053,
      "learning_rate": 3.8079703703703706e-05,
      "loss": 0.2993,
      "step": 12970
    },
    {
      "epoch": 1.44,
      "grad_norm": 12.88186264038086,
      "learning_rate": 3.807822222222223e-05,
      "loss": 0.2884,
      "step": 12980
    },
    {
      "epoch": 1.44,
      "grad_norm": 8.875260353088379,
      "learning_rate": 3.8076740740740745e-05,
      "loss": 0.2687,
      "step": 12990
    },
    {
      "epoch": 1.44,
      "grad_norm": 5.6580915451049805,
      "learning_rate": 3.807525925925926e-05,
      "loss": 0.3298,
      "step": 13000
    },
    {
      "epoch": 1.45,
      "grad_norm": 5.772375106811523,
      "learning_rate": 3.8073777777777784e-05,
      "loss": 0.3497,
      "step": 13010
    },
    {
      "epoch": 1.45,
      "grad_norm": 5.462180137634277,
      "learning_rate": 3.80722962962963e-05,
      "loss": 0.2837,
      "step": 13020
    },
    {
      "epoch": 1.45,
      "grad_norm": 5.437563419342041,
      "learning_rate": 3.8070814814814816e-05,
      "loss": 0.2454,
      "step": 13030
    },
    {
      "epoch": 1.45,
      "grad_norm": 6.308688163757324,
      "learning_rate": 3.806933333333334e-05,
      "loss": 0.3778,
      "step": 13040
    },
    {
      "epoch": 1.45,
      "grad_norm": 4.8970723152160645,
      "learning_rate": 3.8067851851851854e-05,
      "loss": 0.3078,
      "step": 13050
    },
    {
      "epoch": 1.45,
      "grad_norm": 7.5608954429626465,
      "learning_rate": 3.806637037037037e-05,
      "loss": 0.2856,
      "step": 13060
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.8057572841644287,
      "learning_rate": 3.806488888888889e-05,
      "loss": 0.2066,
      "step": 13070
    },
    {
      "epoch": 1.45,
      "grad_norm": 4.645084857940674,
      "learning_rate": 3.806340740740741e-05,
      "loss": 0.2296,
      "step": 13080
    },
    {
      "epoch": 1.45,
      "grad_norm": 11.246318817138672,
      "learning_rate": 3.806192592592593e-05,
      "loss": 0.3461,
      "step": 13090
    },
    {
      "epoch": 1.46,
      "grad_norm": 4.9364776611328125,
      "learning_rate": 3.806044444444445e-05,
      "loss": 0.2182,
      "step": 13100
    },
    {
      "epoch": 1.46,
      "grad_norm": 6.295677661895752,
      "learning_rate": 3.8058962962962964e-05,
      "loss": 0.3679,
      "step": 13110
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.7921195030212402,
      "learning_rate": 3.805748148148149e-05,
      "loss": 0.2275,
      "step": 13120
    },
    {
      "epoch": 1.46,
      "grad_norm": 21.381635665893555,
      "learning_rate": 3.8056e-05,
      "loss": 0.3563,
      "step": 13130
    },
    {
      "epoch": 1.46,
      "grad_norm": 5.245030403137207,
      "learning_rate": 3.805451851851852e-05,
      "loss": 0.2221,
      "step": 13140
    },
    {
      "epoch": 1.46,
      "grad_norm": 10.37803840637207,
      "learning_rate": 3.805303703703704e-05,
      "loss": 0.3426,
      "step": 13150
    },
    {
      "epoch": 1.46,
      "grad_norm": 6.6441969871521,
      "learning_rate": 3.805155555555556e-05,
      "loss": 0.3281,
      "step": 13160
    },
    {
      "epoch": 1.46,
      "grad_norm": 4.782589912414551,
      "learning_rate": 3.805007407407408e-05,
      "loss": 0.3379,
      "step": 13170
    },
    {
      "epoch": 1.46,
      "grad_norm": 7.343582630157471,
      "learning_rate": 3.8048592592592597e-05,
      "loss": 0.2719,
      "step": 13180
    },
    {
      "epoch": 1.47,
      "grad_norm": 3.6326639652252197,
      "learning_rate": 3.804711111111111e-05,
      "loss": 0.3495,
      "step": 13190
    },
    {
      "epoch": 1.47,
      "grad_norm": 5.638052463531494,
      "learning_rate": 3.8045629629629635e-05,
      "loss": 0.2716,
      "step": 13200
    },
    {
      "epoch": 1.47,
      "grad_norm": 7.0911946296691895,
      "learning_rate": 3.804414814814815e-05,
      "loss": 0.2575,
      "step": 13210
    },
    {
      "epoch": 1.47,
      "grad_norm": 6.621525287628174,
      "learning_rate": 3.804266666666667e-05,
      "loss": 0.3061,
      "step": 13220
    },
    {
      "epoch": 1.47,
      "grad_norm": 5.280242919921875,
      "learning_rate": 3.804118518518519e-05,
      "loss": 0.2888,
      "step": 13230
    },
    {
      "epoch": 1.47,
      "grad_norm": 6.763650894165039,
      "learning_rate": 3.8039703703703706e-05,
      "loss": 0.2949,
      "step": 13240
    },
    {
      "epoch": 1.47,
      "grad_norm": 5.545172214508057,
      "learning_rate": 3.803822222222222e-05,
      "loss": 0.218,
      "step": 13250
    },
    {
      "epoch": 1.47,
      "grad_norm": 8.554854393005371,
      "learning_rate": 3.8036740740740745e-05,
      "loss": 0.2869,
      "step": 13260
    },
    {
      "epoch": 1.47,
      "grad_norm": 8.675322532653809,
      "learning_rate": 3.803525925925926e-05,
      "loss": 0.2745,
      "step": 13270
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.640238285064697,
      "learning_rate": 3.8033777777777784e-05,
      "loss": 0.2363,
      "step": 13280
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.523107528686523,
      "learning_rate": 3.80322962962963e-05,
      "loss": 0.2518,
      "step": 13290
    },
    {
      "epoch": 1.48,
      "grad_norm": 5.624398231506348,
      "learning_rate": 3.8030814814814816e-05,
      "loss": 0.2789,
      "step": 13300
    },
    {
      "epoch": 1.48,
      "grad_norm": 10.120597839355469,
      "learning_rate": 3.802933333333334e-05,
      "loss": 0.3748,
      "step": 13310
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.023673057556152,
      "learning_rate": 3.8027851851851855e-05,
      "loss": 0.3463,
      "step": 13320
    },
    {
      "epoch": 1.48,
      "grad_norm": 5.424792766571045,
      "learning_rate": 3.802637037037037e-05,
      "loss": 0.3249,
      "step": 13330
    },
    {
      "epoch": 1.48,
      "grad_norm": 6.500078201293945,
      "learning_rate": 3.8024888888888894e-05,
      "loss": 0.2481,
      "step": 13340
    },
    {
      "epoch": 1.48,
      "grad_norm": 8.709976196289062,
      "learning_rate": 3.802340740740741e-05,
      "loss": 0.2523,
      "step": 13350
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.699772357940674,
      "learning_rate": 3.8021925925925926e-05,
      "loss": 0.3101,
      "step": 13360
    },
    {
      "epoch": 1.49,
      "grad_norm": 13.270419120788574,
      "learning_rate": 3.802044444444445e-05,
      "loss": 0.267,
      "step": 13370
    },
    {
      "epoch": 1.49,
      "grad_norm": 3.9525985717773438,
      "learning_rate": 3.8018962962962964e-05,
      "loss": 0.1999,
      "step": 13380
    },
    {
      "epoch": 1.49,
      "grad_norm": 8.502537727355957,
      "learning_rate": 3.801748148148149e-05,
      "loss": 0.2412,
      "step": 13390
    },
    {
      "epoch": 1.49,
      "grad_norm": 4.240847110748291,
      "learning_rate": 3.8016e-05,
      "loss": 0.2133,
      "step": 13400
    },
    {
      "epoch": 1.49,
      "grad_norm": 9.28016185760498,
      "learning_rate": 3.801451851851852e-05,
      "loss": 0.2878,
      "step": 13410
    },
    {
      "epoch": 1.49,
      "grad_norm": 5.26170539855957,
      "learning_rate": 3.801303703703704e-05,
      "loss": 0.2851,
      "step": 13420
    },
    {
      "epoch": 1.49,
      "grad_norm": 7.258017063140869,
      "learning_rate": 3.801155555555556e-05,
      "loss": 0.2728,
      "step": 13430
    },
    {
      "epoch": 1.49,
      "grad_norm": 5.407118320465088,
      "learning_rate": 3.801007407407408e-05,
      "loss": 0.2181,
      "step": 13440
    },
    {
      "epoch": 1.49,
      "grad_norm": 5.420740127563477,
      "learning_rate": 3.80085925925926e-05,
      "loss": 0.3201,
      "step": 13450
    },
    {
      "epoch": 1.5,
      "grad_norm": 12.844779014587402,
      "learning_rate": 3.800711111111111e-05,
      "loss": 0.2809,
      "step": 13460
    },
    {
      "epoch": 1.5,
      "grad_norm": 5.791540622711182,
      "learning_rate": 3.800562962962963e-05,
      "loss": 0.2038,
      "step": 13470
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.911581039428711,
      "learning_rate": 3.800414814814815e-05,
      "loss": 0.3376,
      "step": 13480
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.802919864654541,
      "learning_rate": 3.800266666666667e-05,
      "loss": 0.3242,
      "step": 13490
    },
    {
      "epoch": 1.5,
      "grad_norm": 9.510709762573242,
      "learning_rate": 3.800118518518519e-05,
      "loss": 0.338,
      "step": 13500
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.1855692863464355,
      "learning_rate": 3.799970370370371e-05,
      "loss": 0.2398,
      "step": 13510
    },
    {
      "epoch": 1.5,
      "grad_norm": 8.655426025390625,
      "learning_rate": 3.799822222222222e-05,
      "loss": 0.2452,
      "step": 13520
    },
    {
      "epoch": 1.5,
      "grad_norm": 4.451411724090576,
      "learning_rate": 3.7996740740740745e-05,
      "loss": 0.2558,
      "step": 13530
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.574514865875244,
      "learning_rate": 3.799525925925926e-05,
      "loss": 0.2376,
      "step": 13540
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.2842159271240234,
      "learning_rate": 3.7993777777777784e-05,
      "loss": 0.2221,
      "step": 13550
    },
    {
      "epoch": 1.51,
      "grad_norm": 8.005062103271484,
      "learning_rate": 3.79922962962963e-05,
      "loss": 0.3559,
      "step": 13560
    },
    {
      "epoch": 1.51,
      "grad_norm": 4.068796157836914,
      "learning_rate": 3.7990814814814816e-05,
      "loss": 0.2756,
      "step": 13570
    },
    {
      "epoch": 1.51,
      "grad_norm": 6.941952705383301,
      "learning_rate": 3.798933333333334e-05,
      "loss": 0.3075,
      "step": 13580
    },
    {
      "epoch": 1.51,
      "grad_norm": 5.858592510223389,
      "learning_rate": 3.7987851851851855e-05,
      "loss": 0.3425,
      "step": 13590
    },
    {
      "epoch": 1.51,
      "grad_norm": 4.917572975158691,
      "learning_rate": 3.798637037037038e-05,
      "loss": 0.2442,
      "step": 13600
    },
    {
      "epoch": 1.51,
      "grad_norm": 6.366485118865967,
      "learning_rate": 3.7984888888888894e-05,
      "loss": 0.2439,
      "step": 13610
    },
    {
      "epoch": 1.51,
      "grad_norm": 8.289124488830566,
      "learning_rate": 3.798340740740741e-05,
      "loss": 0.2965,
      "step": 13620
    },
    {
      "epoch": 1.51,
      "grad_norm": 7.528180122375488,
      "learning_rate": 3.7981925925925926e-05,
      "loss": 0.2947,
      "step": 13630
    },
    {
      "epoch": 1.52,
      "grad_norm": 4.310825824737549,
      "learning_rate": 3.798044444444445e-05,
      "loss": 0.4004,
      "step": 13640
    },
    {
      "epoch": 1.52,
      "grad_norm": 10.794581413269043,
      "learning_rate": 3.7978962962962965e-05,
      "loss": 0.3602,
      "step": 13650
    },
    {
      "epoch": 1.52,
      "grad_norm": 11.26417350769043,
      "learning_rate": 3.797748148148149e-05,
      "loss": 0.2429,
      "step": 13660
    },
    {
      "epoch": 1.52,
      "grad_norm": 6.240018367767334,
      "learning_rate": 3.7976000000000004e-05,
      "loss": 0.2411,
      "step": 13670
    },
    {
      "epoch": 1.52,
      "grad_norm": 5.069386959075928,
      "learning_rate": 3.797451851851852e-05,
      "loss": 0.2962,
      "step": 13680
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.681340217590332,
      "learning_rate": 3.797303703703704e-05,
      "loss": 0.4341,
      "step": 13690
    },
    {
      "epoch": 1.52,
      "grad_norm": 5.0986409187316895,
      "learning_rate": 3.797155555555556e-05,
      "loss": 0.2405,
      "step": 13700
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.994532585144043,
      "learning_rate": 3.797007407407408e-05,
      "loss": 0.2514,
      "step": 13710
    },
    {
      "epoch": 1.52,
      "grad_norm": 5.787960052490234,
      "learning_rate": 3.79685925925926e-05,
      "loss": 0.2545,
      "step": 13720
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.118607044219971,
      "learning_rate": 3.796711111111111e-05,
      "loss": 0.3233,
      "step": 13730
    },
    {
      "epoch": 1.53,
      "grad_norm": 4.514687538146973,
      "learning_rate": 3.796562962962963e-05,
      "loss": 0.2916,
      "step": 13740
    },
    {
      "epoch": 1.53,
      "grad_norm": 4.527995586395264,
      "learning_rate": 3.796414814814815e-05,
      "loss": 0.2659,
      "step": 13750
    },
    {
      "epoch": 1.53,
      "grad_norm": 8.229962348937988,
      "learning_rate": 3.796266666666667e-05,
      "loss": 0.3074,
      "step": 13760
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.999031066894531,
      "learning_rate": 3.796118518518519e-05,
      "loss": 0.2591,
      "step": 13770
    },
    {
      "epoch": 1.53,
      "grad_norm": 5.253654479980469,
      "learning_rate": 3.795970370370371e-05,
      "loss": 0.2404,
      "step": 13780
    },
    {
      "epoch": 1.53,
      "grad_norm": 7.03729248046875,
      "learning_rate": 3.795822222222222e-05,
      "loss": 0.2125,
      "step": 13790
    },
    {
      "epoch": 1.53,
      "grad_norm": 9.40735912322998,
      "learning_rate": 3.7956740740740746e-05,
      "loss": 0.2758,
      "step": 13800
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.383701324462891,
      "learning_rate": 3.795525925925926e-05,
      "loss": 0.286,
      "step": 13810
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.8032941818237305,
      "learning_rate": 3.7953777777777785e-05,
      "loss": 0.2227,
      "step": 13820
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.5069804191589355,
      "learning_rate": 3.79522962962963e-05,
      "loss": 0.3332,
      "step": 13830
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.0865628719329834,
      "learning_rate": 3.795081481481482e-05,
      "loss": 0.2964,
      "step": 13840
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.9249186515808105,
      "learning_rate": 3.794933333333333e-05,
      "loss": 0.2498,
      "step": 13850
    },
    {
      "epoch": 1.54,
      "grad_norm": 5.60332727432251,
      "learning_rate": 3.7947851851851856e-05,
      "loss": 0.2642,
      "step": 13860
    },
    {
      "epoch": 1.54,
      "grad_norm": 6.952177047729492,
      "learning_rate": 3.794637037037038e-05,
      "loss": 0.2304,
      "step": 13870
    },
    {
      "epoch": 1.54,
      "grad_norm": 9.140254020690918,
      "learning_rate": 3.7944888888888894e-05,
      "loss": 0.2792,
      "step": 13880
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.865719795227051,
      "learning_rate": 3.794340740740741e-05,
      "loss": 0.247,
      "step": 13890
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.493063449859619,
      "learning_rate": 3.7941925925925926e-05,
      "loss": 0.2778,
      "step": 13900
    },
    {
      "epoch": 1.55,
      "grad_norm": 8.651774406433105,
      "learning_rate": 3.794044444444445e-05,
      "loss": 0.2769,
      "step": 13910
    },
    {
      "epoch": 1.55,
      "grad_norm": 5.7436442375183105,
      "learning_rate": 3.7938962962962965e-05,
      "loss": 0.2241,
      "step": 13920
    },
    {
      "epoch": 1.55,
      "grad_norm": 5.568580150604248,
      "learning_rate": 3.793748148148149e-05,
      "loss": 0.2787,
      "step": 13930
    },
    {
      "epoch": 1.55,
      "grad_norm": 5.213535785675049,
      "learning_rate": 3.7936000000000004e-05,
      "loss": 0.2804,
      "step": 13940
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.320863723754883,
      "learning_rate": 3.793451851851852e-05,
      "loss": 0.2317,
      "step": 13950
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.057603359222412,
      "learning_rate": 3.7933037037037036e-05,
      "loss": 0.2329,
      "step": 13960
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.6795504093170166,
      "learning_rate": 3.793155555555556e-05,
      "loss": 0.3535,
      "step": 13970
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.386004447937012,
      "learning_rate": 3.793007407407408e-05,
      "loss": 0.2458,
      "step": 13980
    },
    {
      "epoch": 1.55,
      "grad_norm": 10.20531177520752,
      "learning_rate": 3.79285925925926e-05,
      "loss": 0.3181,
      "step": 13990
    },
    {
      "epoch": 1.56,
      "grad_norm": Infinity,
      "learning_rate": 3.792725925925926e-05,
      "loss": 0.2339,
      "step": 14000
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.913139343261719,
      "learning_rate": 3.7925777777777784e-05,
      "loss": 0.2557,
      "step": 14010
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.088980197906494,
      "learning_rate": 3.79242962962963e-05,
      "loss": 0.2605,
      "step": 14020
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.102736473083496,
      "learning_rate": 3.7922814814814816e-05,
      "loss": 0.3165,
      "step": 14030
    },
    {
      "epoch": 1.56,
      "grad_norm": 5.146620750427246,
      "learning_rate": 3.792133333333333e-05,
      "loss": 0.1854,
      "step": 14040
    },
    {
      "epoch": 1.56,
      "grad_norm": 4.669408798217773,
      "learning_rate": 3.7919851851851855e-05,
      "loss": 0.3144,
      "step": 14050
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.3133015632629395,
      "learning_rate": 3.791837037037037e-05,
      "loss": 0.2278,
      "step": 14060
    },
    {
      "epoch": 1.56,
      "grad_norm": 4.583451747894287,
      "learning_rate": 3.7916888888888894e-05,
      "loss": 0.2073,
      "step": 14070
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.244093894958496,
      "learning_rate": 3.791540740740741e-05,
      "loss": 0.2929,
      "step": 14080
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.7859268188476562,
      "learning_rate": 3.7913925925925926e-05,
      "loss": 0.266,
      "step": 14090
    },
    {
      "epoch": 1.57,
      "grad_norm": 4.565273761749268,
      "learning_rate": 3.791244444444445e-05,
      "loss": 0.2389,
      "step": 14100
    },
    {
      "epoch": 1.57,
      "grad_norm": 6.275096416473389,
      "learning_rate": 3.7910962962962965e-05,
      "loss": 0.2404,
      "step": 14110
    },
    {
      "epoch": 1.57,
      "grad_norm": 5.781737327575684,
      "learning_rate": 3.790948148148149e-05,
      "loss": 0.2863,
      "step": 14120
    },
    {
      "epoch": 1.57,
      "grad_norm": 4.265106201171875,
      "learning_rate": 3.7908000000000004e-05,
      "loss": 0.1838,
      "step": 14130
    },
    {
      "epoch": 1.57,
      "grad_norm": 4.9921674728393555,
      "learning_rate": 3.790651851851852e-05,
      "loss": 0.3607,
      "step": 14140
    },
    {
      "epoch": 1.57,
      "grad_norm": 11.013779640197754,
      "learning_rate": 3.7905037037037036e-05,
      "loss": 0.2897,
      "step": 14150
    },
    {
      "epoch": 1.57,
      "grad_norm": 18.913330078125,
      "learning_rate": 3.790355555555556e-05,
      "loss": 0.3498,
      "step": 14160
    },
    {
      "epoch": 1.57,
      "grad_norm": 5.6513543128967285,
      "learning_rate": 3.7902074074074075e-05,
      "loss": 0.2534,
      "step": 14170
    },
    {
      "epoch": 1.58,
      "grad_norm": 6.502739906311035,
      "learning_rate": 3.79005925925926e-05,
      "loss": 0.2169,
      "step": 14180
    },
    {
      "epoch": 1.58,
      "grad_norm": 7.205427169799805,
      "learning_rate": 3.789911111111111e-05,
      "loss": 0.2618,
      "step": 14190
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.953550338745117,
      "learning_rate": 3.789762962962963e-05,
      "loss": 0.2845,
      "step": 14200
    },
    {
      "epoch": 1.58,
      "grad_norm": 4.504332065582275,
      "learning_rate": 3.789614814814815e-05,
      "loss": 0.2027,
      "step": 14210
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.850872039794922,
      "learning_rate": 3.789466666666667e-05,
      "loss": 0.3934,
      "step": 14220
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.644900798797607,
      "learning_rate": 3.789318518518519e-05,
      "loss": 0.2536,
      "step": 14230
    },
    {
      "epoch": 1.58,
      "grad_norm": 9.457565307617188,
      "learning_rate": 3.789170370370371e-05,
      "loss": 0.2091,
      "step": 14240
    },
    {
      "epoch": 1.58,
      "grad_norm": 8.264693260192871,
      "learning_rate": 3.789022222222222e-05,
      "loss": 0.3308,
      "step": 14250
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.53718900680542,
      "learning_rate": 3.7888740740740746e-05,
      "loss": 0.2957,
      "step": 14260
    },
    {
      "epoch": 1.59,
      "grad_norm": 5.926372051239014,
      "learning_rate": 3.788725925925926e-05,
      "loss": 0.2674,
      "step": 14270
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.834352016448975,
      "learning_rate": 3.7885777777777785e-05,
      "loss": 0.2271,
      "step": 14280
    },
    {
      "epoch": 1.59,
      "grad_norm": 5.878925323486328,
      "learning_rate": 3.78842962962963e-05,
      "loss": 0.2903,
      "step": 14290
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.1546125411987305,
      "learning_rate": 3.788281481481482e-05,
      "loss": 0.3224,
      "step": 14300
    },
    {
      "epoch": 1.59,
      "grad_norm": 4.434199810028076,
      "learning_rate": 3.788133333333333e-05,
      "loss": 0.1874,
      "step": 14310
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.392284870147705,
      "learning_rate": 3.7879851851851856e-05,
      "loss": 0.2367,
      "step": 14320
    },
    {
      "epoch": 1.59,
      "grad_norm": 9.05721378326416,
      "learning_rate": 3.787837037037037e-05,
      "loss": 0.2316,
      "step": 14330
    },
    {
      "epoch": 1.59,
      "grad_norm": 5.8984479904174805,
      "learning_rate": 3.7876888888888894e-05,
      "loss": 0.2298,
      "step": 14340
    },
    {
      "epoch": 1.59,
      "grad_norm": 11.124168395996094,
      "learning_rate": 3.787540740740741e-05,
      "loss": 0.284,
      "step": 14350
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.628866195678711,
      "learning_rate": 3.7873925925925926e-05,
      "loss": 0.3231,
      "step": 14360
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.31190299987793,
      "learning_rate": 3.787244444444445e-05,
      "loss": 0.2188,
      "step": 14370
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.788844585418701,
      "learning_rate": 3.7870962962962965e-05,
      "loss": 0.1895,
      "step": 14380
    },
    {
      "epoch": 1.6,
      "grad_norm": 10.263758659362793,
      "learning_rate": 3.786948148148149e-05,
      "loss": 0.2709,
      "step": 14390
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.78428316116333,
      "learning_rate": 3.7868000000000004e-05,
      "loss": 0.2238,
      "step": 14400
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.72458028793335,
      "learning_rate": 3.786651851851852e-05,
      "loss": 0.2779,
      "step": 14410
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.343071460723877,
      "learning_rate": 3.7865037037037036e-05,
      "loss": 0.16,
      "step": 14420
    },
    {
      "epoch": 1.6,
      "grad_norm": 5.149965763092041,
      "learning_rate": 3.786355555555556e-05,
      "loss": 0.2681,
      "step": 14430
    },
    {
      "epoch": 1.6,
      "grad_norm": 12.487878799438477,
      "learning_rate": 3.7862074074074075e-05,
      "loss": 0.2751,
      "step": 14440
    },
    {
      "epoch": 1.61,
      "grad_norm": 4.784041881561279,
      "learning_rate": 3.78605925925926e-05,
      "loss": 0.3182,
      "step": 14450
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.9877264499664307,
      "learning_rate": 3.7859111111111114e-05,
      "loss": 0.2169,
      "step": 14460
    },
    {
      "epoch": 1.61,
      "grad_norm": 6.164282321929932,
      "learning_rate": 3.785762962962963e-05,
      "loss": 0.3101,
      "step": 14470
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.8429861068725586,
      "learning_rate": 3.785614814814815e-05,
      "loss": 0.2885,
      "step": 14480
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.310050010681152,
      "learning_rate": 3.785466666666667e-05,
      "loss": 0.2648,
      "step": 14490
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.659331321716309,
      "learning_rate": 3.785318518518519e-05,
      "loss": 0.3223,
      "step": 14500
    },
    {
      "epoch": 1.61,
      "grad_norm": 6.512695789337158,
      "learning_rate": 3.785170370370371e-05,
      "loss": 0.2745,
      "step": 14510
    },
    {
      "epoch": 1.61,
      "grad_norm": 6.90071964263916,
      "learning_rate": 3.7850222222222223e-05,
      "loss": 0.3851,
      "step": 14520
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.351049423217773,
      "learning_rate": 3.7848740740740746e-05,
      "loss": 0.2389,
      "step": 14530
    },
    {
      "epoch": 1.62,
      "grad_norm": 4.483468532562256,
      "learning_rate": 3.784725925925926e-05,
      "loss": 0.1698,
      "step": 14540
    },
    {
      "epoch": 1.62,
      "grad_norm": 5.473097801208496,
      "learning_rate": 3.784577777777778e-05,
      "loss": 0.2343,
      "step": 14550
    },
    {
      "epoch": 1.62,
      "grad_norm": 6.736785411834717,
      "learning_rate": 3.78442962962963e-05,
      "loss": 0.3145,
      "step": 14560
    },
    {
      "epoch": 1.62,
      "grad_norm": 5.886663436889648,
      "learning_rate": 3.784281481481482e-05,
      "loss": 0.1939,
      "step": 14570
    },
    {
      "epoch": 1.62,
      "grad_norm": 5.460041046142578,
      "learning_rate": 3.784133333333333e-05,
      "loss": 0.2834,
      "step": 14580
    },
    {
      "epoch": 1.62,
      "grad_norm": 5.109501361846924,
      "learning_rate": 3.7839851851851856e-05,
      "loss": 0.262,
      "step": 14590
    },
    {
      "epoch": 1.62,
      "grad_norm": 6.374119281768799,
      "learning_rate": 3.783837037037037e-05,
      "loss": 0.2279,
      "step": 14600
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.4673964977264404,
      "learning_rate": 3.7836888888888895e-05,
      "loss": 0.2336,
      "step": 14610
    },
    {
      "epoch": 1.62,
      "grad_norm": 6.299696922302246,
      "learning_rate": 3.783540740740741e-05,
      "loss": 0.2215,
      "step": 14620
    },
    {
      "epoch": 1.63,
      "grad_norm": 6.551189422607422,
      "learning_rate": 3.783392592592593e-05,
      "loss": 0.2342,
      "step": 14630
    },
    {
      "epoch": 1.63,
      "grad_norm": 6.129661560058594,
      "learning_rate": 3.783244444444445e-05,
      "loss": 0.278,
      "step": 14640
    },
    {
      "epoch": 1.63,
      "grad_norm": 5.03411340713501,
      "learning_rate": 3.7830962962962966e-05,
      "loss": 0.2417,
      "step": 14650
    },
    {
      "epoch": 1.63,
      "grad_norm": 4.103920936584473,
      "learning_rate": 3.782948148148148e-05,
      "loss": 0.2169,
      "step": 14660
    },
    {
      "epoch": 1.63,
      "grad_norm": 7.97397518157959,
      "learning_rate": 3.7828000000000004e-05,
      "loss": 0.2178,
      "step": 14670
    },
    {
      "epoch": 1.63,
      "grad_norm": 7.439573764801025,
      "learning_rate": 3.782651851851852e-05,
      "loss": 0.2493,
      "step": 14680
    },
    {
      "epoch": 1.63,
      "grad_norm": 8.595451354980469,
      "learning_rate": 3.782503703703704e-05,
      "loss": 0.3402,
      "step": 14690
    },
    {
      "epoch": 1.63,
      "grad_norm": 10.653813362121582,
      "learning_rate": 3.782355555555556e-05,
      "loss": 0.2674,
      "step": 14700
    },
    {
      "epoch": 1.63,
      "grad_norm": 7.40258264541626,
      "learning_rate": 3.7822074074074075e-05,
      "loss": 0.3169,
      "step": 14710
    },
    {
      "epoch": 1.64,
      "grad_norm": 4.88026237487793,
      "learning_rate": 3.78205925925926e-05,
      "loss": 0.3074,
      "step": 14720
    },
    {
      "epoch": 1.64,
      "grad_norm": 5.829007148742676,
      "learning_rate": 3.7819111111111114e-05,
      "loss": 0.29,
      "step": 14730
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.258248805999756,
      "learning_rate": 3.781762962962963e-05,
      "loss": 0.2005,
      "step": 14740
    },
    {
      "epoch": 1.64,
      "grad_norm": 5.513956069946289,
      "learning_rate": 3.781614814814815e-05,
      "loss": 0.2629,
      "step": 14750
    },
    {
      "epoch": 1.64,
      "grad_norm": 4.889338970184326,
      "learning_rate": 3.781466666666667e-05,
      "loss": 0.2666,
      "step": 14760
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.594244956970215,
      "learning_rate": 3.7813185185185185e-05,
      "loss": 0.2539,
      "step": 14770
    },
    {
      "epoch": 1.64,
      "grad_norm": 4.710623264312744,
      "learning_rate": 3.781170370370371e-05,
      "loss": 0.2042,
      "step": 14780
    },
    {
      "epoch": 1.64,
      "grad_norm": 4.338715076446533,
      "learning_rate": 3.7810222222222224e-05,
      "loss": 0.1987,
      "step": 14790
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.135221481323242,
      "learning_rate": 3.7808740740740747e-05,
      "loss": 0.3242,
      "step": 14800
    },
    {
      "epoch": 1.65,
      "grad_norm": 5.183295726776123,
      "learning_rate": 3.780725925925926e-05,
      "loss": 0.2477,
      "step": 14810
    },
    {
      "epoch": 1.65,
      "grad_norm": 8.054662704467773,
      "learning_rate": 3.780577777777778e-05,
      "loss": 0.2751,
      "step": 14820
    },
    {
      "epoch": 1.65,
      "grad_norm": 7.933039665222168,
      "learning_rate": 3.78042962962963e-05,
      "loss": 0.2018,
      "step": 14830
    },
    {
      "epoch": 1.65,
      "grad_norm": 10.436087608337402,
      "learning_rate": 3.780281481481482e-05,
      "loss": 0.2677,
      "step": 14840
    },
    {
      "epoch": 1.65,
      "grad_norm": 11.928635597229004,
      "learning_rate": 3.7801333333333333e-05,
      "loss": 0.2453,
      "step": 14850
    },
    {
      "epoch": 1.65,
      "grad_norm": 7.015312194824219,
      "learning_rate": 3.7799851851851856e-05,
      "loss": 0.1872,
      "step": 14860
    },
    {
      "epoch": 1.65,
      "grad_norm": 7.347282409667969,
      "learning_rate": 3.779837037037037e-05,
      "loss": 0.3175,
      "step": 14870
    },
    {
      "epoch": 1.65,
      "grad_norm": 5.855535984039307,
      "learning_rate": 3.7796888888888895e-05,
      "loss": 0.2368,
      "step": 14880
    },
    {
      "epoch": 1.65,
      "grad_norm": 6.9136481285095215,
      "learning_rate": 3.779540740740741e-05,
      "loss": 0.1956,
      "step": 14890
    },
    {
      "epoch": 1.66,
      "grad_norm": 9.453289031982422,
      "learning_rate": 3.779392592592593e-05,
      "loss": 0.2581,
      "step": 14900
    },
    {
      "epoch": 1.66,
      "grad_norm": 9.422033309936523,
      "learning_rate": 3.779244444444445e-05,
      "loss": 0.2605,
      "step": 14910
    },
    {
      "epoch": 1.66,
      "grad_norm": 7.770582675933838,
      "learning_rate": 3.7790962962962966e-05,
      "loss": 0.1914,
      "step": 14920
    },
    {
      "epoch": 1.66,
      "grad_norm": 4.9256768226623535,
      "learning_rate": 3.778948148148148e-05,
      "loss": 0.2485,
      "step": 14930
    },
    {
      "epoch": 1.66,
      "grad_norm": 7.1417388916015625,
      "learning_rate": 3.7788000000000005e-05,
      "loss": 0.2203,
      "step": 14940
    },
    {
      "epoch": 1.66,
      "grad_norm": 6.260376453399658,
      "learning_rate": 3.778651851851852e-05,
      "loss": 0.2715,
      "step": 14950
    },
    {
      "epoch": 1.66,
      "grad_norm": 5.324334621429443,
      "learning_rate": 3.7785037037037044e-05,
      "loss": 0.1897,
      "step": 14960
    },
    {
      "epoch": 1.66,
      "grad_norm": 4.51039457321167,
      "learning_rate": 3.778355555555556e-05,
      "loss": 0.1892,
      "step": 14970
    },
    {
      "epoch": 1.66,
      "grad_norm": 6.209696292877197,
      "learning_rate": 3.7782074074074076e-05,
      "loss": 0.2199,
      "step": 14980
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.295356750488281,
      "learning_rate": 3.77805925925926e-05,
      "loss": 0.2433,
      "step": 14990
    },
    {
      "epoch": 1.67,
      "grad_norm": 8.796171188354492,
      "learning_rate": 3.7779111111111114e-05,
      "loss": 0.251,
      "step": 15000
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.352392196655273,
      "learning_rate": 3.777762962962963e-05,
      "loss": 0.2249,
      "step": 15010
    },
    {
      "epoch": 1.67,
      "grad_norm": 5.218151092529297,
      "learning_rate": 3.777614814814815e-05,
      "loss": 0.1998,
      "step": 15020
    },
    {
      "epoch": 1.67,
      "grad_norm": 7.460936546325684,
      "learning_rate": 3.777466666666667e-05,
      "loss": 0.2723,
      "step": 15030
    },
    {
      "epoch": 1.67,
      "grad_norm": 5.368382930755615,
      "learning_rate": 3.7773185185185185e-05,
      "loss": 0.2326,
      "step": 15040
    },
    {
      "epoch": 1.67,
      "grad_norm": 4.056036472320557,
      "learning_rate": 3.777170370370371e-05,
      "loss": 0.2129,
      "step": 15050
    },
    {
      "epoch": 1.67,
      "grad_norm": 5.9705681800842285,
      "learning_rate": 3.7770222222222224e-05,
      "loss": 0.2188,
      "step": 15060
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.7600388526916504,
      "learning_rate": 3.776874074074075e-05,
      "loss": 0.2242,
      "step": 15070
    },
    {
      "epoch": 1.68,
      "grad_norm": 5.356111526489258,
      "learning_rate": 3.776725925925926e-05,
      "loss": 0.1609,
      "step": 15080
    },
    {
      "epoch": 1.68,
      "grad_norm": 4.062240123748779,
      "learning_rate": 3.776577777777778e-05,
      "loss": 0.2093,
      "step": 15090
    },
    {
      "epoch": 1.68,
      "grad_norm": 6.568592548370361,
      "learning_rate": 3.77642962962963e-05,
      "loss": 0.221,
      "step": 15100
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.345240354537964,
      "learning_rate": 3.776281481481482e-05,
      "loss": 0.2563,
      "step": 15110
    },
    {
      "epoch": 1.68,
      "grad_norm": 6.331508636474609,
      "learning_rate": 3.7761333333333334e-05,
      "loss": 0.2498,
      "step": 15120
    },
    {
      "epoch": 1.68,
      "grad_norm": 9.820893287658691,
      "learning_rate": 3.775985185185186e-05,
      "loss": 0.2871,
      "step": 15130
    },
    {
      "epoch": 1.68,
      "grad_norm": 8.682122230529785,
      "learning_rate": 3.775837037037037e-05,
      "loss": 0.1853,
      "step": 15140
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.027029991149902,
      "learning_rate": 3.775688888888889e-05,
      "loss": 0.2951,
      "step": 15150
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.024669170379639,
      "learning_rate": 3.775540740740741e-05,
      "loss": 0.2402,
      "step": 15160
    },
    {
      "epoch": 1.69,
      "grad_norm": 4.598591327667236,
      "learning_rate": 3.775392592592593e-05,
      "loss": 0.2756,
      "step": 15170
    },
    {
      "epoch": 1.69,
      "grad_norm": 7.935941219329834,
      "learning_rate": 3.775244444444445e-05,
      "loss": 0.2047,
      "step": 15180
    },
    {
      "epoch": 1.69,
      "grad_norm": 5.287304401397705,
      "learning_rate": 3.7750962962962966e-05,
      "loss": 0.1906,
      "step": 15190
    },
    {
      "epoch": 1.69,
      "grad_norm": 6.384408950805664,
      "learning_rate": 3.774948148148148e-05,
      "loss": 0.2373,
      "step": 15200
    },
    {
      "epoch": 1.69,
      "grad_norm": 6.038087844848633,
      "learning_rate": 3.7748000000000005e-05,
      "loss": 0.2716,
      "step": 15210
    },
    {
      "epoch": 1.69,
      "grad_norm": 6.896978378295898,
      "learning_rate": 3.774651851851852e-05,
      "loss": 0.2047,
      "step": 15220
    },
    {
      "epoch": 1.69,
      "grad_norm": 5.143301486968994,
      "learning_rate": 3.7745037037037044e-05,
      "loss": 0.233,
      "step": 15230
    },
    {
      "epoch": 1.69,
      "grad_norm": 4.751521587371826,
      "learning_rate": 3.774355555555556e-05,
      "loss": 0.2105,
      "step": 15240
    },
    {
      "epoch": 1.69,
      "grad_norm": 5.106103420257568,
      "learning_rate": 3.7742074074074076e-05,
      "loss": 0.2255,
      "step": 15250
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.617889881134033,
      "learning_rate": 3.774059259259259e-05,
      "loss": 0.2296,
      "step": 15260
    },
    {
      "epoch": 1.7,
      "grad_norm": 8.19290542602539,
      "learning_rate": 3.7739111111111115e-05,
      "loss": 0.327,
      "step": 15270
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.508632183074951,
      "learning_rate": 3.773762962962963e-05,
      "loss": 0.282,
      "step": 15280
    },
    {
      "epoch": 1.7,
      "grad_norm": 8.644975662231445,
      "learning_rate": 3.7736148148148154e-05,
      "loss": 0.3072,
      "step": 15290
    },
    {
      "epoch": 1.7,
      "grad_norm": 5.722525119781494,
      "learning_rate": 3.773466666666667e-05,
      "loss": 0.2684,
      "step": 15300
    },
    {
      "epoch": 1.7,
      "grad_norm": 6.257424354553223,
      "learning_rate": 3.7733185185185186e-05,
      "loss": 0.248,
      "step": 15310
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.1832661628723145,
      "learning_rate": 3.773170370370371e-05,
      "loss": 0.2223,
      "step": 15320
    },
    {
      "epoch": 1.7,
      "grad_norm": 6.003061294555664,
      "learning_rate": 3.7730222222222225e-05,
      "loss": 0.2649,
      "step": 15330
    },
    {
      "epoch": 1.7,
      "grad_norm": 6.786721706390381,
      "learning_rate": 3.772874074074075e-05,
      "loss": 0.2606,
      "step": 15340
    },
    {
      "epoch": 1.71,
      "grad_norm": 4.358381271362305,
      "learning_rate": 3.772725925925926e-05,
      "loss": 0.2727,
      "step": 15350
    },
    {
      "epoch": 1.71,
      "grad_norm": 5.574453830718994,
      "learning_rate": 3.772577777777778e-05,
      "loss": 0.1678,
      "step": 15360
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.004737377166748,
      "learning_rate": 3.77242962962963e-05,
      "loss": 0.2158,
      "step": 15370
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.067342281341553,
      "learning_rate": 3.772281481481482e-05,
      "loss": 0.1935,
      "step": 15380
    },
    {
      "epoch": 1.71,
      "grad_norm": 8.875375747680664,
      "learning_rate": 3.7721333333333334e-05,
      "loss": 0.175,
      "step": 15390
    },
    {
      "epoch": 1.71,
      "grad_norm": 9.592453002929688,
      "learning_rate": 3.771985185185186e-05,
      "loss": 0.2412,
      "step": 15400
    },
    {
      "epoch": 1.71,
      "grad_norm": 29.35028648376465,
      "learning_rate": 3.771837037037037e-05,
      "loss": 0.2297,
      "step": 15410
    },
    {
      "epoch": 1.71,
      "grad_norm": 10.219193458557129,
      "learning_rate": 3.771688888888889e-05,
      "loss": 0.2352,
      "step": 15420
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.361117362976074,
      "learning_rate": 3.771540740740741e-05,
      "loss": 0.2266,
      "step": 15430
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.778552532196045,
      "learning_rate": 3.771392592592593e-05,
      "loss": 0.22,
      "step": 15440
    },
    {
      "epoch": 1.72,
      "grad_norm": 8.03083610534668,
      "learning_rate": 3.771244444444445e-05,
      "loss": 0.219,
      "step": 15450
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.320089817047119,
      "learning_rate": 3.771096296296297e-05,
      "loss": 0.2267,
      "step": 15460
    },
    {
      "epoch": 1.72,
      "grad_norm": 5.2501397132873535,
      "learning_rate": 3.770948148148148e-05,
      "loss": 0.2504,
      "step": 15470
    },
    {
      "epoch": 1.72,
      "grad_norm": 11.722472190856934,
      "learning_rate": 3.7708000000000006e-05,
      "loss": 0.2643,
      "step": 15480
    },
    {
      "epoch": 1.72,
      "grad_norm": 9.771991729736328,
      "learning_rate": 3.770651851851852e-05,
      "loss": 0.2688,
      "step": 15490
    },
    {
      "epoch": 1.72,
      "grad_norm": 4.996528625488281,
      "learning_rate": 3.7705037037037044e-05,
      "loss": 0.2106,
      "step": 15500
    },
    {
      "epoch": 1.72,
      "grad_norm": 22.059186935424805,
      "learning_rate": 3.770355555555556e-05,
      "loss": 0.3257,
      "step": 15510
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.887209415435791,
      "learning_rate": 3.7702074074074076e-05,
      "loss": 0.2554,
      "step": 15520
    },
    {
      "epoch": 1.73,
      "grad_norm": 10.72792911529541,
      "learning_rate": 3.770059259259259e-05,
      "loss": 0.2106,
      "step": 15530
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.335036277770996,
      "learning_rate": 3.7699111111111115e-05,
      "loss": 0.174,
      "step": 15540
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.632218837738037,
      "learning_rate": 3.769762962962963e-05,
      "loss": 0.2423,
      "step": 15550
    },
    {
      "epoch": 1.73,
      "grad_norm": 4.684844493865967,
      "learning_rate": 3.7696148148148154e-05,
      "loss": 0.2067,
      "step": 15560
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.134133338928223,
      "learning_rate": 3.769466666666667e-05,
      "loss": 0.2251,
      "step": 15570
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.7617533206939697,
      "learning_rate": 3.7693185185185186e-05,
      "loss": 0.2522,
      "step": 15580
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.52340030670166,
      "learning_rate": 3.769170370370371e-05,
      "loss": 0.1884,
      "step": 15590
    },
    {
      "epoch": 1.73,
      "grad_norm": 4.845880031585693,
      "learning_rate": 3.7690222222222225e-05,
      "loss": 0.2966,
      "step": 15600
    },
    {
      "epoch": 1.73,
      "grad_norm": 3.066518783569336,
      "learning_rate": 3.768874074074075e-05,
      "loss": 0.2454,
      "step": 15610
    },
    {
      "epoch": 1.74,
      "grad_norm": 10.658546447753906,
      "learning_rate": 3.7687259259259264e-05,
      "loss": 0.2021,
      "step": 15620
    },
    {
      "epoch": 1.74,
      "grad_norm": 5.6802897453308105,
      "learning_rate": 3.768577777777778e-05,
      "loss": 0.3331,
      "step": 15630
    },
    {
      "epoch": 1.74,
      "grad_norm": 6.710152626037598,
      "learning_rate": 3.7684296296296296e-05,
      "loss": 0.1695,
      "step": 15640
    },
    {
      "epoch": 1.74,
      "grad_norm": 9.360337257385254,
      "learning_rate": 3.768281481481482e-05,
      "loss": 0.2508,
      "step": 15650
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.4080119132995605,
      "learning_rate": 3.7681333333333335e-05,
      "loss": 0.1914,
      "step": 15660
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.9510698318481445,
      "learning_rate": 3.767985185185186e-05,
      "loss": 0.1805,
      "step": 15670
    },
    {
      "epoch": 1.74,
      "grad_norm": 8.940245628356934,
      "learning_rate": 3.7678370370370373e-05,
      "loss": 0.1955,
      "step": 15680
    },
    {
      "epoch": 1.74,
      "grad_norm": 8.468565940856934,
      "learning_rate": 3.767688888888889e-05,
      "loss": 0.2137,
      "step": 15690
    },
    {
      "epoch": 1.74,
      "grad_norm": 10.3035306930542,
      "learning_rate": 3.767540740740741e-05,
      "loss": 0.3009,
      "step": 15700
    },
    {
      "epoch": 1.75,
      "grad_norm": 6.7792582511901855,
      "learning_rate": 3.767392592592593e-05,
      "loss": 0.1772,
      "step": 15710
    },
    {
      "epoch": 1.75,
      "grad_norm": 4.883055686950684,
      "learning_rate": 3.767244444444445e-05,
      "loss": 0.2409,
      "step": 15720
    },
    {
      "epoch": 1.75,
      "grad_norm": 5.9167633056640625,
      "learning_rate": 3.767096296296297e-05,
      "loss": 0.2536,
      "step": 15730
    },
    {
      "epoch": 1.75,
      "grad_norm": 6.969970226287842,
      "learning_rate": 3.766948148148148e-05,
      "loss": 0.266,
      "step": 15740
    },
    {
      "epoch": 1.75,
      "grad_norm": 8.10385799407959,
      "learning_rate": 3.7668e-05,
      "loss": 0.1992,
      "step": 15750
    },
    {
      "epoch": 1.75,
      "grad_norm": 9.45322322845459,
      "learning_rate": 3.766651851851852e-05,
      "loss": 0.2033,
      "step": 15760
    },
    {
      "epoch": 1.75,
      "grad_norm": 7.937780857086182,
      "learning_rate": 3.7665037037037045e-05,
      "loss": 0.1655,
      "step": 15770
    },
    {
      "epoch": 1.75,
      "grad_norm": 7.0518012046813965,
      "learning_rate": 3.766355555555556e-05,
      "loss": 0.268,
      "step": 15780
    },
    {
      "epoch": 1.75,
      "grad_norm": 6.509581089019775,
      "learning_rate": 3.766207407407408e-05,
      "loss": 0.326,
      "step": 15790
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.8154306411743164,
      "learning_rate": 3.766059259259259e-05,
      "loss": 0.2536,
      "step": 15800
    },
    {
      "epoch": 1.76,
      "grad_norm": 9.096983909606934,
      "learning_rate": 3.7659111111111116e-05,
      "loss": 0.3481,
      "step": 15810
    },
    {
      "epoch": 1.76,
      "grad_norm": 8.287631034851074,
      "learning_rate": 3.765762962962963e-05,
      "loss": 0.2872,
      "step": 15820
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.5070369243621826,
      "learning_rate": 3.7656148148148154e-05,
      "loss": 0.1299,
      "step": 15830
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.186820983886719,
      "learning_rate": 3.765466666666667e-05,
      "loss": 0.2171,
      "step": 15840
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.216125965118408,
      "learning_rate": 3.7653185185185187e-05,
      "loss": 0.2405,
      "step": 15850
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.522106647491455,
      "learning_rate": 3.76517037037037e-05,
      "loss": 0.2723,
      "step": 15860
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.272106647491455,
      "learning_rate": 3.7650222222222225e-05,
      "loss": 0.2011,
      "step": 15870
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.77445125579834,
      "learning_rate": 3.764874074074075e-05,
      "loss": 0.1928,
      "step": 15880
    },
    {
      "epoch": 1.77,
      "grad_norm": 4.1629157066345215,
      "learning_rate": 3.7647259259259264e-05,
      "loss": 0.2537,
      "step": 15890
    },
    {
      "epoch": 1.77,
      "grad_norm": 4.854632377624512,
      "learning_rate": 3.764577777777778e-05,
      "loss": 0.2945,
      "step": 15900
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.7314202785491943,
      "learning_rate": 3.7644296296296296e-05,
      "loss": 0.1943,
      "step": 15910
    },
    {
      "epoch": 1.77,
      "grad_norm": 6.421901702880859,
      "learning_rate": 3.764281481481482e-05,
      "loss": 0.2292,
      "step": 15920
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.505371570587158,
      "learning_rate": 3.764133333333334e-05,
      "loss": 0.2673,
      "step": 15930
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.7091915607452393,
      "learning_rate": 3.763985185185186e-05,
      "loss": 0.1799,
      "step": 15940
    },
    {
      "epoch": 1.77,
      "grad_norm": 7.5676422119140625,
      "learning_rate": 3.7638370370370374e-05,
      "loss": 0.2237,
      "step": 15950
    },
    {
      "epoch": 1.77,
      "grad_norm": 8.91102123260498,
      "learning_rate": 3.763688888888889e-05,
      "loss": 0.2062,
      "step": 15960
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.4151968955993652,
      "learning_rate": 3.763540740740741e-05,
      "loss": 0.2774,
      "step": 15970
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.795180559158325,
      "learning_rate": 3.763392592592593e-05,
      "loss": 0.2208,
      "step": 15980
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.808274507522583,
      "learning_rate": 3.763244444444445e-05,
      "loss": 0.1883,
      "step": 15990
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.503747940063477,
      "learning_rate": 3.763096296296297e-05,
      "loss": 0.1881,
      "step": 16000
    },
    {
      "epoch": 1.78,
      "eval_cer": 0.042853716878916266,
      "eval_loss": 0.30799323320388794,
      "eval_runtime": 1960.5484,
      "eval_samples_per_second": 4.08,
      "eval_steps_per_second": 0.51,
      "eval_wer": 0.09213454967240352,
      "step": 16000
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.476154804229736,
      "learning_rate": 3.762962962962963e-05,
      "loss": 0.2518,
      "step": 16010
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.536484718322754,
      "learning_rate": 3.7628148148148154e-05,
      "loss": 0.2168,
      "step": 16020
    },
    {
      "epoch": 1.78,
      "grad_norm": 10.491071701049805,
      "learning_rate": 3.762666666666667e-05,
      "loss": 0.2614,
      "step": 16030
    },
    {
      "epoch": 1.78,
      "grad_norm": 10.4257230758667,
      "learning_rate": 3.7625185185185186e-05,
      "loss": 0.2308,
      "step": 16040
    },
    {
      "epoch": 1.78,
      "grad_norm": 7.124039649963379,
      "learning_rate": 3.762385185185186e-05,
      "loss": 0.2437,
      "step": 16050
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.226616382598877,
      "learning_rate": 3.762237037037037e-05,
      "loss": 0.2431,
      "step": 16060
    },
    {
      "epoch": 1.79,
      "grad_norm": 6.642496109008789,
      "learning_rate": 3.7620888888888895e-05,
      "loss": 0.2614,
      "step": 16070
    },
    {
      "epoch": 1.79,
      "grad_norm": 8.72159194946289,
      "learning_rate": 3.761940740740741e-05,
      "loss": 0.1791,
      "step": 16080
    },
    {
      "epoch": 1.79,
      "grad_norm": 6.688590049743652,
      "learning_rate": 3.761792592592593e-05,
      "loss": 0.2041,
      "step": 16090
    },
    {
      "epoch": 1.79,
      "grad_norm": 4.927996635437012,
      "learning_rate": 3.7616444444444444e-05,
      "loss": 0.2616,
      "step": 16100
    },
    {
      "epoch": 1.79,
      "grad_norm": 9.751022338867188,
      "learning_rate": 3.7614962962962966e-05,
      "loss": 0.2388,
      "step": 16110
    },
    {
      "epoch": 1.79,
      "grad_norm": 10.233339309692383,
      "learning_rate": 3.761348148148149e-05,
      "loss": 0.2027,
      "step": 16120
    },
    {
      "epoch": 1.79,
      "grad_norm": 6.057961940765381,
      "learning_rate": 3.7612000000000005e-05,
      "loss": 0.2929,
      "step": 16130
    },
    {
      "epoch": 1.79,
      "grad_norm": 11.986190795898438,
      "learning_rate": 3.761051851851852e-05,
      "loss": 0.2589,
      "step": 16140
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.376904249191284,
      "learning_rate": 3.760903703703704e-05,
      "loss": 0.2268,
      "step": 16150
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.941825866699219,
      "learning_rate": 3.760755555555556e-05,
      "loss": 0.2148,
      "step": 16160
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.485267639160156,
      "learning_rate": 3.7606074074074076e-05,
      "loss": 0.2565,
      "step": 16170
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.588691234588623,
      "learning_rate": 3.76045925925926e-05,
      "loss": 0.2602,
      "step": 16180
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.921292781829834,
      "learning_rate": 3.7603111111111115e-05,
      "loss": 0.2718,
      "step": 16190
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.378948211669922,
      "learning_rate": 3.760162962962963e-05,
      "loss": 0.2259,
      "step": 16200
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.920993804931641,
      "learning_rate": 3.760014814814815e-05,
      "loss": 0.2425,
      "step": 16210
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.755133152008057,
      "learning_rate": 3.759866666666667e-05,
      "loss": 0.2822,
      "step": 16220
    },
    {
      "epoch": 1.8,
      "grad_norm": 4.162927627563477,
      "learning_rate": 3.759718518518519e-05,
      "loss": 0.1771,
      "step": 16230
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.241484642028809,
      "learning_rate": 3.759570370370371e-05,
      "loss": 0.1925,
      "step": 16240
    },
    {
      "epoch": 1.81,
      "grad_norm": 4.647750377655029,
      "learning_rate": 3.7594222222222225e-05,
      "loss": 0.211,
      "step": 16250
    },
    {
      "epoch": 1.81,
      "grad_norm": 4.057383060455322,
      "learning_rate": 3.759274074074074e-05,
      "loss": 0.2283,
      "step": 16260
    },
    {
      "epoch": 1.81,
      "grad_norm": 11.327302932739258,
      "learning_rate": 3.759125925925926e-05,
      "loss": 0.232,
      "step": 16270
    },
    {
      "epoch": 1.81,
      "grad_norm": 4.80183219909668,
      "learning_rate": 3.7589777777777786e-05,
      "loss": 0.2595,
      "step": 16280
    },
    {
      "epoch": 1.81,
      "grad_norm": 6.202078819274902,
      "learning_rate": 3.75882962962963e-05,
      "loss": 0.2471,
      "step": 16290
    },
    {
      "epoch": 1.81,
      "grad_norm": 5.845904350280762,
      "learning_rate": 3.758681481481482e-05,
      "loss": 0.2087,
      "step": 16300
    },
    {
      "epoch": 1.81,
      "grad_norm": 8.52416706085205,
      "learning_rate": 3.7585333333333334e-05,
      "loss": 0.3444,
      "step": 16310
    },
    {
      "epoch": 1.81,
      "grad_norm": 4.9122490882873535,
      "learning_rate": 3.758385185185185e-05,
      "loss": 0.1737,
      "step": 16320
    },
    {
      "epoch": 1.81,
      "grad_norm": 6.016897678375244,
      "learning_rate": 3.758237037037037e-05,
      "loss": 0.3201,
      "step": 16330
    },
    {
      "epoch": 1.82,
      "grad_norm": 5.326581001281738,
      "learning_rate": 3.7580888888888896e-05,
      "loss": 0.2353,
      "step": 16340
    },
    {
      "epoch": 1.82,
      "grad_norm": 5.890840530395508,
      "learning_rate": 3.757940740740741e-05,
      "loss": 0.248,
      "step": 16350
    },
    {
      "epoch": 1.82,
      "grad_norm": 4.492626667022705,
      "learning_rate": 3.757792592592593e-05,
      "loss": 0.178,
      "step": 16360
    },
    {
      "epoch": 1.82,
      "grad_norm": 6.135429859161377,
      "learning_rate": 3.7576444444444444e-05,
      "loss": 0.1594,
      "step": 16370
    },
    {
      "epoch": 1.82,
      "grad_norm": 10.114482879638672,
      "learning_rate": 3.757496296296297e-05,
      "loss": 0.2772,
      "step": 16380
    },
    {
      "epoch": 1.82,
      "grad_norm": 4.158794403076172,
      "learning_rate": 3.757348148148149e-05,
      "loss": 0.1975,
      "step": 16390
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.36622953414917,
      "learning_rate": 3.7572000000000006e-05,
      "loss": 0.2416,
      "step": 16400
    },
    {
      "epoch": 1.82,
      "grad_norm": 5.910545349121094,
      "learning_rate": 3.757051851851852e-05,
      "loss": 0.3376,
      "step": 16410
    },
    {
      "epoch": 1.82,
      "grad_norm": 10.344347953796387,
      "learning_rate": 3.756903703703704e-05,
      "loss": 0.1964,
      "step": 16420
    },
    {
      "epoch": 1.83,
      "grad_norm": 7.4035468101501465,
      "learning_rate": 3.756755555555556e-05,
      "loss": 0.2531,
      "step": 16430
    },
    {
      "epoch": 1.83,
      "grad_norm": 5.7195515632629395,
      "learning_rate": 3.7566074074074076e-05,
      "loss": 0.2732,
      "step": 16440
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.683587551116943,
      "learning_rate": 3.75645925925926e-05,
      "loss": 0.1494,
      "step": 16450
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.78508996963501,
      "learning_rate": 3.7563111111111115e-05,
      "loss": 0.2145,
      "step": 16460
    },
    {
      "epoch": 1.83,
      "grad_norm": 4.995345592498779,
      "learning_rate": 3.756162962962963e-05,
      "loss": 0.2338,
      "step": 16470
    },
    {
      "epoch": 1.83,
      "grad_norm": 5.784249305725098,
      "learning_rate": 3.756014814814815e-05,
      "loss": 0.2402,
      "step": 16480
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.1636106967926025,
      "learning_rate": 3.755866666666667e-05,
      "loss": 0.2154,
      "step": 16490
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.947176456451416,
      "learning_rate": 3.755718518518519e-05,
      "loss": 0.2501,
      "step": 16500
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.4185845851898193,
      "learning_rate": 3.7555851851851857e-05,
      "loss": 0.285,
      "step": 16510
    },
    {
      "epoch": 1.84,
      "grad_norm": 5.187685012817383,
      "learning_rate": 3.755437037037037e-05,
      "loss": 0.2777,
      "step": 16520
    },
    {
      "epoch": 1.84,
      "grad_norm": 5.594552516937256,
      "learning_rate": 3.7552888888888895e-05,
      "loss": 0.1859,
      "step": 16530
    },
    {
      "epoch": 1.84,
      "grad_norm": 8.881726264953613,
      "learning_rate": 3.755140740740741e-05,
      "loss": 0.2343,
      "step": 16540
    },
    {
      "epoch": 1.84,
      "grad_norm": 5.427679061889648,
      "learning_rate": 3.754992592592593e-05,
      "loss": 0.1696,
      "step": 16550
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.9505503177642822,
      "learning_rate": 3.754844444444445e-05,
      "loss": 0.2077,
      "step": 16560
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.702087163925171,
      "learning_rate": 3.7546962962962966e-05,
      "loss": 0.1892,
      "step": 16570
    },
    {
      "epoch": 1.84,
      "grad_norm": 6.342713832855225,
      "learning_rate": 3.754548148148148e-05,
      "loss": 0.2121,
      "step": 16580
    },
    {
      "epoch": 1.84,
      "grad_norm": 4.078697681427002,
      "learning_rate": 3.7544000000000005e-05,
      "loss": 0.1984,
      "step": 16590
    },
    {
      "epoch": 1.84,
      "grad_norm": 4.828070163726807,
      "learning_rate": 3.754251851851852e-05,
      "loss": 0.2152,
      "step": 16600
    },
    {
      "epoch": 1.85,
      "grad_norm": 6.444660186767578,
      "learning_rate": 3.754103703703704e-05,
      "loss": 0.2098,
      "step": 16610
    },
    {
      "epoch": 1.85,
      "grad_norm": 7.036742210388184,
      "learning_rate": 3.753955555555556e-05,
      "loss": 0.1838,
      "step": 16620
    },
    {
      "epoch": 1.85,
      "grad_norm": 3.7885189056396484,
      "learning_rate": 3.7538074074074076e-05,
      "loss": 0.1348,
      "step": 16630
    },
    {
      "epoch": 1.85,
      "grad_norm": 3.990793228149414,
      "learning_rate": 3.75365925925926e-05,
      "loss": 0.2747,
      "step": 16640
    },
    {
      "epoch": 1.85,
      "grad_norm": 6.009840965270996,
      "learning_rate": 3.7535111111111115e-05,
      "loss": 0.2571,
      "step": 16650
    },
    {
      "epoch": 1.85,
      "grad_norm": 4.763193130493164,
      "learning_rate": 3.753362962962963e-05,
      "loss": 0.2726,
      "step": 16660
    },
    {
      "epoch": 1.85,
      "grad_norm": 6.52029275894165,
      "learning_rate": 3.7532148148148154e-05,
      "loss": 0.1915,
      "step": 16670
    },
    {
      "epoch": 1.85,
      "grad_norm": 4.115714073181152,
      "learning_rate": 3.753066666666667e-05,
      "loss": 0.1874,
      "step": 16680
    },
    {
      "epoch": 1.85,
      "grad_norm": 8.903682708740234,
      "learning_rate": 3.7529185185185186e-05,
      "loss": 0.2402,
      "step": 16690
    },
    {
      "epoch": 1.86,
      "grad_norm": 3.840029716491699,
      "learning_rate": 3.752770370370371e-05,
      "loss": 0.2142,
      "step": 16700
    },
    {
      "epoch": 1.86,
      "grad_norm": 5.581429958343506,
      "learning_rate": 3.7526222222222224e-05,
      "loss": 0.2133,
      "step": 16710
    },
    {
      "epoch": 1.86,
      "grad_norm": 7.373830795288086,
      "learning_rate": 3.752474074074075e-05,
      "loss": 0.1966,
      "step": 16720
    },
    {
      "epoch": 1.86,
      "grad_norm": 6.738040447235107,
      "learning_rate": 3.752325925925926e-05,
      "loss": 0.2185,
      "step": 16730
    },
    {
      "epoch": 1.86,
      "grad_norm": 5.1982550621032715,
      "learning_rate": 3.752177777777778e-05,
      "loss": 0.1833,
      "step": 16740
    },
    {
      "epoch": 1.86,
      "grad_norm": NaN,
      "learning_rate": 3.752044444444445e-05,
      "loss": 0.2094,
      "step": 16750
    },
    {
      "epoch": 1.86,
      "grad_norm": 6.659735202789307,
      "learning_rate": 3.7518962962962966e-05,
      "loss": 0.2159,
      "step": 16760
    },
    {
      "epoch": 1.86,
      "grad_norm": 4.094351291656494,
      "learning_rate": 3.751748148148148e-05,
      "loss": 0.2608,
      "step": 16770
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.5496227741241455,
      "learning_rate": 3.7516000000000005e-05,
      "loss": 0.1536,
      "step": 16780
    },
    {
      "epoch": 1.87,
      "grad_norm": 3.624894857406616,
      "learning_rate": 3.751451851851852e-05,
      "loss": 0.2039,
      "step": 16790
    },
    {
      "epoch": 1.87,
      "grad_norm": 10.070208549499512,
      "learning_rate": 3.7513037037037044e-05,
      "loss": 0.3499,
      "step": 16800
    },
    {
      "epoch": 1.87,
      "grad_norm": 6.250762462615967,
      "learning_rate": 3.751155555555556e-05,
      "loss": 0.1895,
      "step": 16810
    },
    {
      "epoch": 1.87,
      "grad_norm": 3.49192476272583,
      "learning_rate": 3.7510074074074076e-05,
      "loss": 0.2171,
      "step": 16820
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.120008945465088,
      "learning_rate": 3.750859259259259e-05,
      "loss": 0.1571,
      "step": 16830
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.151638984680176,
      "learning_rate": 3.7507111111111114e-05,
      "loss": 0.2797,
      "step": 16840
    },
    {
      "epoch": 1.87,
      "grad_norm": 3.899632453918457,
      "learning_rate": 3.750562962962964e-05,
      "loss": 0.1858,
      "step": 16850
    },
    {
      "epoch": 1.87,
      "grad_norm": 4.14327335357666,
      "learning_rate": 3.750414814814815e-05,
      "loss": 0.2276,
      "step": 16860
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.211568832397461,
      "learning_rate": 3.750266666666667e-05,
      "loss": 0.2138,
      "step": 16870
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.45182466506958,
      "learning_rate": 3.7501185185185185e-05,
      "loss": 0.1612,
      "step": 16880
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.9234161376953125,
      "learning_rate": 3.749970370370371e-05,
      "loss": 0.2562,
      "step": 16890
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.006935119628906,
      "learning_rate": 3.7498222222222224e-05,
      "loss": 0.2284,
      "step": 16900
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.873478889465332,
      "learning_rate": 3.749674074074075e-05,
      "loss": 0.2802,
      "step": 16910
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.375298500061035,
      "learning_rate": 3.749525925925926e-05,
      "loss": 0.2282,
      "step": 16920
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.4113504886627197,
      "learning_rate": 3.749377777777778e-05,
      "loss": 0.217,
      "step": 16930
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.19577693939209,
      "learning_rate": 3.7492296296296295e-05,
      "loss": 0.1762,
      "step": 16940
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.944116115570068,
      "learning_rate": 3.749081481481482e-05,
      "loss": 0.2557,
      "step": 16950
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.798059940338135,
      "learning_rate": 3.748933333333334e-05,
      "loss": 0.1963,
      "step": 16960
    },
    {
      "epoch": 1.89,
      "grad_norm": 7.357752799987793,
      "learning_rate": 3.7487851851851857e-05,
      "loss": 0.2185,
      "step": 16970
    },
    {
      "epoch": 1.89,
      "grad_norm": 5.588787078857422,
      "learning_rate": 3.748637037037037e-05,
      "loss": 0.1655,
      "step": 16980
    },
    {
      "epoch": 1.89,
      "grad_norm": 6.37213134765625,
      "learning_rate": 3.748488888888889e-05,
      "loss": 0.1961,
      "step": 16990
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.507909774780273,
      "learning_rate": 3.748340740740741e-05,
      "loss": 0.2144,
      "step": 17000
    },
    {
      "epoch": 1.89,
      "grad_norm": 4.874027729034424,
      "learning_rate": 3.748192592592593e-05,
      "loss": 0.1957,
      "step": 17010
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.174901247024536,
      "learning_rate": 3.748044444444445e-05,
      "loss": 0.1657,
      "step": 17020
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.884996175765991,
      "learning_rate": 3.7478962962962966e-05,
      "loss": 0.1617,
      "step": 17030
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.1679553985595703,
      "learning_rate": 3.747748148148148e-05,
      "loss": 0.2334,
      "step": 17040
    },
    {
      "epoch": 1.89,
      "grad_norm": 6.682048320770264,
      "learning_rate": 3.7476e-05,
      "loss": 0.216,
      "step": 17050
    },
    {
      "epoch": 1.9,
      "grad_norm": 6.497320175170898,
      "learning_rate": 3.747451851851852e-05,
      "loss": 0.2553,
      "step": 17060
    },
    {
      "epoch": 1.9,
      "grad_norm": 10.640181541442871,
      "learning_rate": 3.7473037037037044e-05,
      "loss": 0.2071,
      "step": 17070
    },
    {
      "epoch": 1.9,
      "grad_norm": 8.165472030639648,
      "learning_rate": 3.747155555555556e-05,
      "loss": 0.2359,
      "step": 17080
    },
    {
      "epoch": 1.9,
      "grad_norm": 5.833947658538818,
      "learning_rate": 3.7470074074074076e-05,
      "loss": 0.1641,
      "step": 17090
    },
    {
      "epoch": 1.9,
      "grad_norm": 5.349508762359619,
      "learning_rate": 3.746859259259259e-05,
      "loss": 0.2326,
      "step": 17100
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.422163963317871,
      "learning_rate": 3.7467111111111115e-05,
      "loss": 0.1954,
      "step": 17110
    },
    {
      "epoch": 1.9,
      "grad_norm": 5.618747234344482,
      "learning_rate": 3.746562962962963e-05,
      "loss": 0.2797,
      "step": 17120
    },
    {
      "epoch": 1.9,
      "grad_norm": 6.096242904663086,
      "learning_rate": 3.7464148148148154e-05,
      "loss": 0.1931,
      "step": 17130
    },
    {
      "epoch": 1.9,
      "grad_norm": 4.72717809677124,
      "learning_rate": 3.746266666666667e-05,
      "loss": 0.1539,
      "step": 17140
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.8633670806884766,
      "learning_rate": 3.7461185185185186e-05,
      "loss": 0.1818,
      "step": 17150
    },
    {
      "epoch": 1.91,
      "grad_norm": 6.543739318847656,
      "learning_rate": 3.74597037037037e-05,
      "loss": 0.2176,
      "step": 17160
    },
    {
      "epoch": 1.91,
      "grad_norm": 6.882781028747559,
      "learning_rate": 3.7458222222222224e-05,
      "loss": 0.2163,
      "step": 17170
    },
    {
      "epoch": 1.91,
      "grad_norm": 6.7153191566467285,
      "learning_rate": 3.745674074074075e-05,
      "loss": 0.1904,
      "step": 17180
    },
    {
      "epoch": 1.91,
      "grad_norm": 4.585796356201172,
      "learning_rate": 3.745525925925926e-05,
      "loss": 0.1625,
      "step": 17190
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.774092435836792,
      "learning_rate": 3.745377777777778e-05,
      "loss": 0.2454,
      "step": 17200
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.771526575088501,
      "learning_rate": 3.7452296296296295e-05,
      "loss": 0.2451,
      "step": 17210
    },
    {
      "epoch": 1.91,
      "grad_norm": 4.707483291625977,
      "learning_rate": 3.745081481481482e-05,
      "loss": 0.2067,
      "step": 17220
    },
    {
      "epoch": 1.91,
      "grad_norm": 5.649863243103027,
      "learning_rate": 3.744933333333334e-05,
      "loss": 0.2079,
      "step": 17230
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.449159860610962,
      "learning_rate": 3.744785185185186e-05,
      "loss": 0.2615,
      "step": 17240
    },
    {
      "epoch": 1.92,
      "grad_norm": 6.093457221984863,
      "learning_rate": 3.744637037037037e-05,
      "loss": 0.2648,
      "step": 17250
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.753657102584839,
      "learning_rate": 3.744488888888889e-05,
      "loss": 0.2006,
      "step": 17260
    },
    {
      "epoch": 1.92,
      "grad_norm": 4.057849884033203,
      "learning_rate": 3.7443407407407405e-05,
      "loss": 0.1906,
      "step": 17270
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.399219036102295,
      "learning_rate": 3.744192592592593e-05,
      "loss": 0.188,
      "step": 17280
    },
    {
      "epoch": 1.92,
      "grad_norm": 4.817751884460449,
      "learning_rate": 3.744044444444445e-05,
      "loss": 0.2042,
      "step": 17290
    },
    {
      "epoch": 1.92,
      "grad_norm": 4.387088775634766,
      "learning_rate": 3.743896296296297e-05,
      "loss": 0.2066,
      "step": 17300
    },
    {
      "epoch": 1.92,
      "grad_norm": 6.415285587310791,
      "learning_rate": 3.743748148148148e-05,
      "loss": 0.1401,
      "step": 17310
    },
    {
      "epoch": 1.92,
      "grad_norm": 9.282095909118652,
      "learning_rate": 3.7436e-05,
      "loss": 0.2629,
      "step": 17320
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.7708587646484375,
      "learning_rate": 3.743451851851852e-05,
      "loss": 0.2349,
      "step": 17330
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.403245449066162,
      "learning_rate": 3.7433037037037044e-05,
      "loss": 0.1558,
      "step": 17340
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.208767890930176,
      "learning_rate": 3.743155555555556e-05,
      "loss": 0.2643,
      "step": 17350
    },
    {
      "epoch": 1.93,
      "grad_norm": 4.121683120727539,
      "learning_rate": 3.7430074074074076e-05,
      "loss": 0.2364,
      "step": 17360
    },
    {
      "epoch": 1.93,
      "grad_norm": 5.755234718322754,
      "learning_rate": 3.742859259259259e-05,
      "loss": 0.1776,
      "step": 17370
    },
    {
      "epoch": 1.93,
      "grad_norm": 9.85157585144043,
      "learning_rate": 3.7427111111111115e-05,
      "loss": 0.3129,
      "step": 17380
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.3071491718292236,
      "learning_rate": 3.742562962962963e-05,
      "loss": 0.1699,
      "step": 17390
    },
    {
      "epoch": 1.93,
      "grad_norm": 5.764566898345947,
      "learning_rate": 3.7424148148148154e-05,
      "loss": 0.1579,
      "step": 17400
    },
    {
      "epoch": 1.93,
      "grad_norm": 6.901421070098877,
      "learning_rate": 3.742266666666667e-05,
      "loss": 0.2143,
      "step": 17410
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.674208164215088,
      "learning_rate": 3.7421185185185186e-05,
      "loss": 0.2323,
      "step": 17420
    },
    {
      "epoch": 1.94,
      "grad_norm": 8.143163681030273,
      "learning_rate": 3.74197037037037e-05,
      "loss": 0.2454,
      "step": 17430
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.6919145584106445,
      "learning_rate": 3.7418222222222225e-05,
      "loss": 0.1604,
      "step": 17440
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.111953258514404,
      "learning_rate": 3.741674074074075e-05,
      "loss": 0.1799,
      "step": 17450
    },
    {
      "epoch": 1.94,
      "grad_norm": 10.167609214782715,
      "learning_rate": 3.7415259259259264e-05,
      "loss": 0.2707,
      "step": 17460
    },
    {
      "epoch": 1.94,
      "grad_norm": 5.1940789222717285,
      "learning_rate": 3.741377777777778e-05,
      "loss": 0.2443,
      "step": 17470
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.837597846984863,
      "learning_rate": 3.7412296296296296e-05,
      "loss": 0.1983,
      "step": 17480
    },
    {
      "epoch": 1.94,
      "grad_norm": 7.621363639831543,
      "learning_rate": 3.741081481481482e-05,
      "loss": 0.2383,
      "step": 17490
    },
    {
      "epoch": 1.94,
      "grad_norm": 13.3228759765625,
      "learning_rate": 3.7409333333333335e-05,
      "loss": 0.2628,
      "step": 17500
    },
    {
      "epoch": 1.95,
      "grad_norm": 9.697541236877441,
      "learning_rate": 3.740785185185186e-05,
      "loss": 0.1612,
      "step": 17510
    },
    {
      "epoch": 1.95,
      "grad_norm": 4.045478343963623,
      "learning_rate": 3.740637037037037e-05,
      "loss": 0.1806,
      "step": 17520
    },
    {
      "epoch": 1.95,
      "grad_norm": 7.452085971832275,
      "learning_rate": 3.740488888888889e-05,
      "loss": 0.1403,
      "step": 17530
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.372085094451904,
      "learning_rate": 3.7403407407407405e-05,
      "loss": 0.2216,
      "step": 17540
    },
    {
      "epoch": 1.95,
      "grad_norm": 9.691858291625977,
      "learning_rate": 3.740192592592593e-05,
      "loss": 0.3149,
      "step": 17550
    },
    {
      "epoch": 1.95,
      "grad_norm": 7.007753372192383,
      "learning_rate": 3.740044444444445e-05,
      "loss": 0.2675,
      "step": 17560
    },
    {
      "epoch": 1.95,
      "grad_norm": 3.3535044193267822,
      "learning_rate": 3.739896296296297e-05,
      "loss": 0.2103,
      "step": 17570
    },
    {
      "epoch": 1.95,
      "grad_norm": 15.793194770812988,
      "learning_rate": 3.739748148148148e-05,
      "loss": 0.373,
      "step": 17580
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.570029258728027,
      "learning_rate": 3.7396e-05,
      "loss": 0.1374,
      "step": 17590
    },
    {
      "epoch": 1.96,
      "grad_norm": 7.1923370361328125,
      "learning_rate": 3.739451851851852e-05,
      "loss": 0.2397,
      "step": 17600
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.755126953125,
      "learning_rate": 3.739303703703704e-05,
      "loss": 0.1733,
      "step": 17610
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.8654425144195557,
      "learning_rate": 3.739155555555556e-05,
      "loss": 0.2328,
      "step": 17620
    },
    {
      "epoch": 1.96,
      "grad_norm": 22.550996780395508,
      "learning_rate": 3.739007407407408e-05,
      "loss": 0.2124,
      "step": 17630
    },
    {
      "epoch": 1.96,
      "grad_norm": 7.112233638763428,
      "learning_rate": 3.738859259259259e-05,
      "loss": 0.2291,
      "step": 17640
    },
    {
      "epoch": 1.96,
      "grad_norm": 9.526899337768555,
      "learning_rate": 3.7387111111111116e-05,
      "loss": 0.2822,
      "step": 17650
    },
    {
      "epoch": 1.96,
      "grad_norm": 20.997661590576172,
      "learning_rate": 3.738562962962963e-05,
      "loss": 0.2148,
      "step": 17660
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.467328071594238,
      "learning_rate": 3.7384148148148154e-05,
      "loss": 0.1692,
      "step": 17670
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.672001361846924,
      "learning_rate": 3.738266666666667e-05,
      "loss": 0.2525,
      "step": 17680
    },
    {
      "epoch": 1.97,
      "grad_norm": 7.142001152038574,
      "learning_rate": 3.7381185185185186e-05,
      "loss": 0.1656,
      "step": 17690
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.952859401702881,
      "learning_rate": 3.73797037037037e-05,
      "loss": 0.1986,
      "step": 17700
    },
    {
      "epoch": 1.97,
      "grad_norm": 6.643860816955566,
      "learning_rate": 3.7378222222222225e-05,
      "loss": 0.2257,
      "step": 17710
    },
    {
      "epoch": 1.97,
      "grad_norm": 8.628996849060059,
      "learning_rate": 3.737674074074074e-05,
      "loss": 0.1891,
      "step": 17720
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.903526306152344,
      "learning_rate": 3.7375259259259264e-05,
      "loss": 0.2643,
      "step": 17730
    },
    {
      "epoch": 1.97,
      "grad_norm": 3.059074640274048,
      "learning_rate": 3.737377777777778e-05,
      "loss": 0.2094,
      "step": 17740
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.660693645477295,
      "learning_rate": 3.7372296296296296e-05,
      "loss": 0.2318,
      "step": 17750
    },
    {
      "epoch": 1.97,
      "grad_norm": 3.46571946144104,
      "learning_rate": 3.737081481481482e-05,
      "loss": 0.2158,
      "step": 17760
    },
    {
      "epoch": 1.97,
      "grad_norm": 10.607864379882812,
      "learning_rate": 3.7369333333333335e-05,
      "loss": 0.2145,
      "step": 17770
    },
    {
      "epoch": 1.98,
      "grad_norm": 6.328174591064453,
      "learning_rate": 3.736785185185186e-05,
      "loss": 0.2557,
      "step": 17780
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.2591395378112793,
      "learning_rate": 3.7366370370370374e-05,
      "loss": 0.185,
      "step": 17790
    },
    {
      "epoch": 1.98,
      "grad_norm": 4.1044464111328125,
      "learning_rate": 3.736488888888889e-05,
      "loss": 0.2481,
      "step": 17800
    },
    {
      "epoch": 1.98,
      "grad_norm": 4.309983730316162,
      "learning_rate": 3.736340740740741e-05,
      "loss": 0.2229,
      "step": 17810
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.784903049468994,
      "learning_rate": 3.736192592592593e-05,
      "loss": 0.179,
      "step": 17820
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.3723230361938477,
      "learning_rate": 3.736044444444445e-05,
      "loss": 0.2516,
      "step": 17830
    },
    {
      "epoch": 1.98,
      "grad_norm": 7.104909896850586,
      "learning_rate": 3.735896296296297e-05,
      "loss": 0.2978,
      "step": 17840
    },
    {
      "epoch": 1.98,
      "grad_norm": 8.20688247680664,
      "learning_rate": 3.7357481481481483e-05,
      "loss": 0.19,
      "step": 17850
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.515603542327881,
      "learning_rate": 3.7356e-05,
      "loss": 0.1303,
      "step": 17860
    },
    {
      "epoch": 1.99,
      "grad_norm": 4.5807108879089355,
      "learning_rate": 3.735451851851852e-05,
      "loss": 0.2087,
      "step": 17870
    },
    {
      "epoch": 1.99,
      "grad_norm": 6.7327494621276855,
      "learning_rate": 3.735303703703704e-05,
      "loss": 0.2272,
      "step": 17880
    },
    {
      "epoch": 1.99,
      "grad_norm": 5.01894998550415,
      "learning_rate": 3.735155555555556e-05,
      "loss": 0.2022,
      "step": 17890
    },
    {
      "epoch": 1.99,
      "grad_norm": 4.818329334259033,
      "learning_rate": 3.735007407407408e-05,
      "loss": 0.2056,
      "step": 17900
    },
    {
      "epoch": 1.99,
      "grad_norm": 6.821875095367432,
      "learning_rate": 3.734859259259259e-05,
      "loss": 0.2059,
      "step": 17910
    },
    {
      "epoch": 1.99,
      "grad_norm": 14.05761432647705,
      "learning_rate": 3.7347111111111116e-05,
      "loss": 0.2129,
      "step": 17920
    },
    {
      "epoch": 1.99,
      "grad_norm": 11.957764625549316,
      "learning_rate": 3.734562962962963e-05,
      "loss": 0.2049,
      "step": 17930
    },
    {
      "epoch": 1.99,
      "grad_norm": 7.0969719886779785,
      "learning_rate": 3.7344148148148155e-05,
      "loss": 0.1899,
      "step": 17940
    },
    {
      "epoch": 1.99,
      "grad_norm": 14.093178749084473,
      "learning_rate": 3.734266666666667e-05,
      "loss": 0.2549,
      "step": 17950
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.258735179901123,
      "learning_rate": 3.734118518518519e-05,
      "loss": 0.1547,
      "step": 17960
    },
    {
      "epoch": 2.0,
      "grad_norm": 20.081424713134766,
      "learning_rate": 3.73397037037037e-05,
      "loss": 0.2309,
      "step": 17970
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.950385093688965,
      "learning_rate": 3.7338222222222226e-05,
      "loss": 0.213,
      "step": 17980
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.6847825050354,
      "learning_rate": 3.733674074074074e-05,
      "loss": 0.1521,
      "step": 17990
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.835033893585205,
      "learning_rate": 3.7335259259259264e-05,
      "loss": 0.1936,
      "step": 18000
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.609956741333008,
      "learning_rate": 3.733377777777778e-05,
      "loss": 0.1547,
      "step": 18010
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.58598518371582,
      "learning_rate": 3.7332296296296296e-05,
      "loss": 0.2162,
      "step": 18020
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.700955867767334,
      "learning_rate": 3.733081481481482e-05,
      "loss": 0.1721,
      "step": 18030
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.266186475753784,
      "learning_rate": 3.7329333333333335e-05,
      "loss": 0.1488,
      "step": 18040
    },
    {
      "epoch": 2.01,
      "grad_norm": 4.756746768951416,
      "learning_rate": 3.732785185185186e-05,
      "loss": 0.1577,
      "step": 18050
    },
    {
      "epoch": 2.01,
      "grad_norm": 8.285916328430176,
      "learning_rate": 3.7326370370370374e-05,
      "loss": 0.2246,
      "step": 18060
    },
    {
      "epoch": 2.01,
      "grad_norm": 6.987370491027832,
      "learning_rate": 3.732488888888889e-05,
      "loss": 0.1775,
      "step": 18070
    },
    {
      "epoch": 2.01,
      "grad_norm": 3.881911277770996,
      "learning_rate": 3.732340740740741e-05,
      "loss": 0.1451,
      "step": 18080
    },
    {
      "epoch": 2.01,
      "grad_norm": 4.183847427368164,
      "learning_rate": 3.732192592592593e-05,
      "loss": 0.2129,
      "step": 18090
    },
    {
      "epoch": 2.01,
      "grad_norm": 6.3769354820251465,
      "learning_rate": 3.7320444444444445e-05,
      "loss": 0.1919,
      "step": 18100
    },
    {
      "epoch": 2.01,
      "grad_norm": 5.573307991027832,
      "learning_rate": 3.731896296296297e-05,
      "loss": 0.201,
      "step": 18110
    },
    {
      "epoch": 2.01,
      "grad_norm": 7.09466552734375,
      "learning_rate": 3.7317481481481484e-05,
      "loss": 0.1846,
      "step": 18120
    },
    {
      "epoch": 2.01,
      "grad_norm": 5.351788520812988,
      "learning_rate": 3.7316e-05,
      "loss": 0.1631,
      "step": 18130
    },
    {
      "epoch": 2.02,
      "grad_norm": 5.5557756423950195,
      "learning_rate": 3.731451851851852e-05,
      "loss": 0.1457,
      "step": 18140
    },
    {
      "epoch": 2.02,
      "grad_norm": 4.667614936828613,
      "learning_rate": 3.731303703703704e-05,
      "loss": 0.1549,
      "step": 18150
    },
    {
      "epoch": 2.02,
      "grad_norm": 5.478329658508301,
      "learning_rate": 3.731155555555556e-05,
      "loss": 0.2606,
      "step": 18160
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.812778949737549,
      "learning_rate": 3.731007407407408e-05,
      "loss": 0.153,
      "step": 18170
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.4699389934539795,
      "learning_rate": 3.7308592592592593e-05,
      "loss": 0.1589,
      "step": 18180
    },
    {
      "epoch": 2.02,
      "grad_norm": 4.8763885498046875,
      "learning_rate": 3.7307111111111116e-05,
      "loss": 0.1746,
      "step": 18190
    },
    {
      "epoch": 2.02,
      "grad_norm": 5.986353397369385,
      "learning_rate": 3.730562962962963e-05,
      "loss": 0.1644,
      "step": 18200
    },
    {
      "epoch": 2.02,
      "grad_norm": 6.406972408294678,
      "learning_rate": 3.730414814814815e-05,
      "loss": 0.2179,
      "step": 18210
    },
    {
      "epoch": 2.02,
      "grad_norm": 5.656270980834961,
      "learning_rate": 3.730266666666667e-05,
      "loss": 0.1388,
      "step": 18220
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.979858875274658,
      "learning_rate": 3.730118518518519e-05,
      "loss": 0.1606,
      "step": 18230
    },
    {
      "epoch": 2.03,
      "grad_norm": 4.439589500427246,
      "learning_rate": 3.72997037037037e-05,
      "loss": 0.1706,
      "step": 18240
    },
    {
      "epoch": 2.03,
      "grad_norm": 5.797213554382324,
      "learning_rate": 3.7298222222222226e-05,
      "loss": 0.1942,
      "step": 18250
    },
    {
      "epoch": 2.03,
      "grad_norm": 6.2532243728637695,
      "learning_rate": 3.729674074074074e-05,
      "loss": 0.2519,
      "step": 18260
    },
    {
      "epoch": 2.03,
      "grad_norm": 4.59304141998291,
      "learning_rate": 3.7295259259259265e-05,
      "loss": 0.1534,
      "step": 18270
    },
    {
      "epoch": 2.03,
      "grad_norm": 6.359073162078857,
      "learning_rate": 3.729377777777778e-05,
      "loss": 0.1887,
      "step": 18280
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.416429042816162,
      "learning_rate": 3.72922962962963e-05,
      "loss": 0.1325,
      "step": 18290
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.8985979557037354,
      "learning_rate": 3.729081481481482e-05,
      "loss": 0.1881,
      "step": 18300
    },
    {
      "epoch": 2.03,
      "grad_norm": 4.16657829284668,
      "learning_rate": 3.7289333333333336e-05,
      "loss": 0.1196,
      "step": 18310
    },
    {
      "epoch": 2.04,
      "grad_norm": 9.414929389953613,
      "learning_rate": 3.728785185185185e-05,
      "loss": 0.2032,
      "step": 18320
    },
    {
      "epoch": 2.04,
      "grad_norm": 6.699867248535156,
      "learning_rate": 3.7286370370370375e-05,
      "loss": 0.2031,
      "step": 18330
    },
    {
      "epoch": 2.04,
      "grad_norm": 5.181422233581543,
      "learning_rate": 3.728488888888889e-05,
      "loss": 0.1999,
      "step": 18340
    },
    {
      "epoch": 2.04,
      "grad_norm": 4.9230756759643555,
      "learning_rate": 3.728340740740741e-05,
      "loss": 0.1779,
      "step": 18350
    },
    {
      "epoch": 2.04,
      "grad_norm": 4.199841022491455,
      "learning_rate": 3.728192592592593e-05,
      "loss": 0.24,
      "step": 18360
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.712825059890747,
      "learning_rate": 3.7280444444444445e-05,
      "loss": 0.2109,
      "step": 18370
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.3591294288635254,
      "learning_rate": 3.727896296296297e-05,
      "loss": 0.179,
      "step": 18380
    },
    {
      "epoch": 2.04,
      "grad_norm": 5.829606056213379,
      "learning_rate": 3.7277481481481484e-05,
      "loss": 0.16,
      "step": 18390
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.3948729038238525,
      "learning_rate": 3.7276e-05,
      "loss": 0.1823,
      "step": 18400
    },
    {
      "epoch": 2.05,
      "grad_norm": 6.12743616104126,
      "learning_rate": 3.727451851851852e-05,
      "loss": 0.2217,
      "step": 18410
    },
    {
      "epoch": 2.05,
      "grad_norm": 4.848946571350098,
      "learning_rate": 3.727303703703704e-05,
      "loss": 0.2126,
      "step": 18420
    },
    {
      "epoch": 2.05,
      "grad_norm": 4.502725124359131,
      "learning_rate": 3.727155555555556e-05,
      "loss": 0.1549,
      "step": 18430
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.4720828533172607,
      "learning_rate": 3.727007407407408e-05,
      "loss": 0.1481,
      "step": 18440
    },
    {
      "epoch": 2.05,
      "grad_norm": 5.3718647956848145,
      "learning_rate": 3.7268592592592594e-05,
      "loss": 0.2558,
      "step": 18450
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.3671512603759766,
      "learning_rate": 3.726711111111112e-05,
      "loss": 0.2488,
      "step": 18460
    },
    {
      "epoch": 2.05,
      "grad_norm": 5.043278217315674,
      "learning_rate": 3.726562962962963e-05,
      "loss": 0.1367,
      "step": 18470
    },
    {
      "epoch": 2.05,
      "grad_norm": 6.060026168823242,
      "learning_rate": 3.726414814814815e-05,
      "loss": 0.1909,
      "step": 18480
    },
    {
      "epoch": 2.05,
      "grad_norm": 6.16595983505249,
      "learning_rate": 3.726266666666667e-05,
      "loss": 0.2178,
      "step": 18490
    },
    {
      "epoch": 2.06,
      "grad_norm": 5.751243591308594,
      "learning_rate": 3.726118518518519e-05,
      "loss": 0.1289,
      "step": 18500
    },
    {
      "epoch": 2.06,
      "grad_norm": 4.722750186920166,
      "learning_rate": 3.7259703703703704e-05,
      "loss": 0.1521,
      "step": 18510
    },
    {
      "epoch": 2.06,
      "grad_norm": 4.883881092071533,
      "learning_rate": 3.7258222222222226e-05,
      "loss": 0.1227,
      "step": 18520
    },
    {
      "epoch": 2.06,
      "grad_norm": 5.192779064178467,
      "learning_rate": 3.725674074074074e-05,
      "loss": 0.1762,
      "step": 18530
    },
    {
      "epoch": 2.06,
      "grad_norm": 4.554765224456787,
      "learning_rate": 3.7255259259259265e-05,
      "loss": 0.1431,
      "step": 18540
    },
    {
      "epoch": 2.06,
      "grad_norm": 8.57808780670166,
      "learning_rate": 3.725377777777778e-05,
      "loss": 0.2206,
      "step": 18550
    },
    {
      "epoch": 2.06,
      "grad_norm": 7.816667079925537,
      "learning_rate": 3.72522962962963e-05,
      "loss": 0.2252,
      "step": 18560
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.4289470911026,
      "learning_rate": 3.725081481481482e-05,
      "loss": 0.1195,
      "step": 18570
    },
    {
      "epoch": 2.06,
      "grad_norm": 4.854651927947998,
      "learning_rate": 3.7249333333333336e-05,
      "loss": 0.1403,
      "step": 18580
    },
    {
      "epoch": 2.07,
      "grad_norm": 6.850257396697998,
      "learning_rate": 3.724785185185185e-05,
      "loss": 0.1509,
      "step": 18590
    },
    {
      "epoch": 2.07,
      "grad_norm": 7.126335620880127,
      "learning_rate": 3.7246370370370375e-05,
      "loss": 0.2206,
      "step": 18600
    },
    {
      "epoch": 2.07,
      "grad_norm": 4.953832626342773,
      "learning_rate": 3.724488888888889e-05,
      "loss": 0.2033,
      "step": 18610
    },
    {
      "epoch": 2.07,
      "grad_norm": 5.264251708984375,
      "learning_rate": 3.7243407407407414e-05,
      "loss": 0.1855,
      "step": 18620
    },
    {
      "epoch": 2.07,
      "grad_norm": 7.1256794929504395,
      "learning_rate": 3.724192592592593e-05,
      "loss": 0.1402,
      "step": 18630
    },
    {
      "epoch": 2.07,
      "grad_norm": 6.47678804397583,
      "learning_rate": 3.7240444444444446e-05,
      "loss": 0.2175,
      "step": 18640
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.486701250076294,
      "learning_rate": 3.723896296296297e-05,
      "loss": 0.1527,
      "step": 18650
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.7214932441711426,
      "learning_rate": 3.7237481481481485e-05,
      "loss": 0.159,
      "step": 18660
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.4096081256866455,
      "learning_rate": 3.7236e-05,
      "loss": 0.1346,
      "step": 18670
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.417422294616699,
      "learning_rate": 3.7234518518518523e-05,
      "loss": 0.1135,
      "step": 18680
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.5370934009552,
      "learning_rate": 3.723303703703704e-05,
      "loss": 0.1875,
      "step": 18690
    },
    {
      "epoch": 2.08,
      "grad_norm": 6.803208351135254,
      "learning_rate": 3.7231555555555555e-05,
      "loss": 0.1435,
      "step": 18700
    },
    {
      "epoch": 2.08,
      "grad_norm": 4.385333061218262,
      "learning_rate": 3.723007407407408e-05,
      "loss": 0.1575,
      "step": 18710
    },
    {
      "epoch": 2.08,
      "grad_norm": 6.190812110900879,
      "learning_rate": 3.7228592592592594e-05,
      "loss": 0.182,
      "step": 18720
    },
    {
      "epoch": 2.08,
      "grad_norm": 4.136590957641602,
      "learning_rate": 3.722711111111112e-05,
      "loss": 0.2502,
      "step": 18730
    },
    {
      "epoch": 2.08,
      "grad_norm": 4.250097751617432,
      "learning_rate": 3.722562962962963e-05,
      "loss": 0.1414,
      "step": 18740
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.994785785675049,
      "learning_rate": 3.722414814814815e-05,
      "loss": 0.1637,
      "step": 18750
    },
    {
      "epoch": 2.08,
      "grad_norm": 5.198977470397949,
      "learning_rate": 3.722266666666667e-05,
      "loss": 0.1122,
      "step": 18760
    },
    {
      "epoch": 2.09,
      "grad_norm": 4.268502235412598,
      "learning_rate": 3.722118518518519e-05,
      "loss": 0.149,
      "step": 18770
    },
    {
      "epoch": 2.09,
      "grad_norm": 3.6209399700164795,
      "learning_rate": 3.7219703703703704e-05,
      "loss": 0.1281,
      "step": 18780
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.8229820728302,
      "learning_rate": 3.721822222222223e-05,
      "loss": 0.1821,
      "step": 18790
    },
    {
      "epoch": 2.09,
      "grad_norm": 3.013378620147705,
      "learning_rate": 3.721674074074074e-05,
      "loss": 0.1292,
      "step": 18800
    },
    {
      "epoch": 2.09,
      "grad_norm": 9.702104568481445,
      "learning_rate": 3.721525925925926e-05,
      "loss": 0.1828,
      "step": 18810
    },
    {
      "epoch": 2.09,
      "grad_norm": 5.20055627822876,
      "learning_rate": 3.721377777777778e-05,
      "loss": 0.1967,
      "step": 18820
    },
    {
      "epoch": 2.09,
      "grad_norm": 4.8614182472229,
      "learning_rate": 3.72122962962963e-05,
      "loss": 0.1419,
      "step": 18830
    },
    {
      "epoch": 2.09,
      "grad_norm": 4.531073093414307,
      "learning_rate": 3.721081481481482e-05,
      "loss": 0.1938,
      "step": 18840
    },
    {
      "epoch": 2.09,
      "grad_norm": 4.054672718048096,
      "learning_rate": 3.7209333333333336e-05,
      "loss": 0.1406,
      "step": 18850
    },
    {
      "epoch": 2.1,
      "grad_norm": 6.4186553955078125,
      "learning_rate": 3.720785185185185e-05,
      "loss": 0.2101,
      "step": 18860
    },
    {
      "epoch": 2.1,
      "grad_norm": 4.790351390838623,
      "learning_rate": 3.7206370370370375e-05,
      "loss": 0.1355,
      "step": 18870
    },
    {
      "epoch": 2.1,
      "grad_norm": 4.927545070648193,
      "learning_rate": 3.720488888888889e-05,
      "loss": 0.2229,
      "step": 18880
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.10520339012146,
      "learning_rate": 3.7203407407407414e-05,
      "loss": 0.1303,
      "step": 18890
    },
    {
      "epoch": 2.1,
      "grad_norm": 5.689721584320068,
      "learning_rate": 3.720192592592593e-05,
      "loss": 0.1583,
      "step": 18900
    },
    {
      "epoch": 2.1,
      "grad_norm": 5.085310935974121,
      "learning_rate": 3.7200444444444446e-05,
      "loss": 0.1735,
      "step": 18910
    },
    {
      "epoch": 2.1,
      "grad_norm": 4.014113903045654,
      "learning_rate": 3.719896296296297e-05,
      "loss": 0.1632,
      "step": 18920
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.6315550804138184,
      "learning_rate": 3.7197481481481485e-05,
      "loss": 0.1752,
      "step": 18930
    },
    {
      "epoch": 2.1,
      "grad_norm": 5.882089138031006,
      "learning_rate": 3.7196e-05,
      "loss": 0.1478,
      "step": 18940
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.9813456535339355,
      "learning_rate": 3.7194518518518524e-05,
      "loss": 0.194,
      "step": 18950
    },
    {
      "epoch": 2.11,
      "grad_norm": 8.440157890319824,
      "learning_rate": 3.719303703703704e-05,
      "loss": 0.1476,
      "step": 18960
    },
    {
      "epoch": 2.11,
      "grad_norm": 6.612590312957764,
      "learning_rate": 3.7191555555555556e-05,
      "loss": 0.2489,
      "step": 18970
    },
    {
      "epoch": 2.11,
      "grad_norm": 10.727387428283691,
      "learning_rate": 3.719007407407408e-05,
      "loss": 0.2166,
      "step": 18980
    },
    {
      "epoch": 2.11,
      "grad_norm": 8.903470993041992,
      "learning_rate": 3.7188592592592595e-05,
      "loss": 0.1821,
      "step": 18990
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.572596549987793,
      "learning_rate": 3.718711111111112e-05,
      "loss": 0.1152,
      "step": 19000
    },
    {
      "epoch": 2.11,
      "grad_norm": 6.160028457641602,
      "learning_rate": 3.7185629629629633e-05,
      "loss": 0.1832,
      "step": 19010
    },
    {
      "epoch": 2.11,
      "grad_norm": 5.483214855194092,
      "learning_rate": 3.718414814814815e-05,
      "loss": 0.1376,
      "step": 19020
    },
    {
      "epoch": 2.11,
      "grad_norm": 4.082290172576904,
      "learning_rate": 3.718266666666667e-05,
      "loss": 0.1213,
      "step": 19030
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.3010361194610596,
      "learning_rate": 3.718118518518519e-05,
      "loss": 0.1491,
      "step": 19040
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.7216312885284424,
      "learning_rate": 3.717970370370371e-05,
      "loss": 0.1668,
      "step": 19050
    },
    {
      "epoch": 2.12,
      "grad_norm": 6.783689975738525,
      "learning_rate": 3.717822222222223e-05,
      "loss": 0.2437,
      "step": 19060
    },
    {
      "epoch": 2.12,
      "grad_norm": 4.048670768737793,
      "learning_rate": 3.717674074074074e-05,
      "loss": 0.1603,
      "step": 19070
    },
    {
      "epoch": 2.12,
      "grad_norm": 4.778066635131836,
      "learning_rate": 3.717525925925926e-05,
      "loss": 0.1307,
      "step": 19080
    },
    {
      "epoch": 2.12,
      "grad_norm": 7.01826286315918,
      "learning_rate": 3.717377777777778e-05,
      "loss": 0.1462,
      "step": 19090
    },
    {
      "epoch": 2.12,
      "grad_norm": 9.564069747924805,
      "learning_rate": 3.71722962962963e-05,
      "loss": 0.1274,
      "step": 19100
    },
    {
      "epoch": 2.12,
      "grad_norm": 4.804183483123779,
      "learning_rate": 3.717081481481482e-05,
      "loss": 0.2033,
      "step": 19110
    },
    {
      "epoch": 2.12,
      "grad_norm": 5.732161521911621,
      "learning_rate": 3.716933333333334e-05,
      "loss": 0.1543,
      "step": 19120
    },
    {
      "epoch": 2.13,
      "grad_norm": 3.794140338897705,
      "learning_rate": 3.716785185185185e-05,
      "loss": 0.1088,
      "step": 19130
    },
    {
      "epoch": 2.13,
      "grad_norm": 4.3427581787109375,
      "learning_rate": 3.7166370370370376e-05,
      "loss": 0.1687,
      "step": 19140
    },
    {
      "epoch": 2.13,
      "grad_norm": 5.6392693519592285,
      "learning_rate": 3.716488888888889e-05,
      "loss": 0.1763,
      "step": 19150
    },
    {
      "epoch": 2.13,
      "grad_norm": 3.333263397216797,
      "learning_rate": 3.7163407407407414e-05,
      "loss": 0.1367,
      "step": 19160
    },
    {
      "epoch": 2.13,
      "grad_norm": 4.927886486053467,
      "learning_rate": 3.716192592592593e-05,
      "loss": 0.2099,
      "step": 19170
    },
    {
      "epoch": 2.13,
      "grad_norm": 8.190305709838867,
      "learning_rate": 3.7160444444444447e-05,
      "loss": 0.2054,
      "step": 19180
    },
    {
      "epoch": 2.13,
      "grad_norm": 9.969003677368164,
      "learning_rate": 3.715896296296296e-05,
      "loss": 0.1371,
      "step": 19190
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.606257200241089,
      "learning_rate": 3.7157481481481485e-05,
      "loss": 0.1018,
      "step": 19200
    },
    {
      "epoch": 2.13,
      "grad_norm": 5.3859639167785645,
      "learning_rate": 3.7156e-05,
      "loss": 0.136,
      "step": 19210
    },
    {
      "epoch": 2.14,
      "grad_norm": 7.09428596496582,
      "learning_rate": 3.7154518518518524e-05,
      "loss": 0.1892,
      "step": 19220
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.1062867641448975,
      "learning_rate": 3.715303703703704e-05,
      "loss": 0.1268,
      "step": 19230
    },
    {
      "epoch": 2.14,
      "grad_norm": 9.114774703979492,
      "learning_rate": 3.7151555555555556e-05,
      "loss": 0.1306,
      "step": 19240
    },
    {
      "epoch": 2.14,
      "grad_norm": 12.55887222290039,
      "learning_rate": 3.715007407407408e-05,
      "loss": 0.2047,
      "step": 19250
    },
    {
      "epoch": 2.14,
      "grad_norm": 7.192256450653076,
      "learning_rate": 3.7148592592592595e-05,
      "loss": 0.2196,
      "step": 19260
    },
    {
      "epoch": 2.14,
      "grad_norm": 6.277883529663086,
      "learning_rate": 3.714711111111112e-05,
      "loss": 0.165,
      "step": 19270
    },
    {
      "epoch": 2.14,
      "grad_norm": 12.024935722351074,
      "learning_rate": 3.7145629629629634e-05,
      "loss": 0.1894,
      "step": 19280
    },
    {
      "epoch": 2.14,
      "grad_norm": 4.361408710479736,
      "learning_rate": 3.714414814814815e-05,
      "loss": 0.2723,
      "step": 19290
    },
    {
      "epoch": 2.14,
      "grad_norm": 5.025430202484131,
      "learning_rate": 3.7142666666666666e-05,
      "loss": 0.1672,
      "step": 19300
    },
    {
      "epoch": 2.15,
      "grad_norm": 11.516121864318848,
      "learning_rate": 3.714118518518519e-05,
      "loss": 0.2286,
      "step": 19310
    },
    {
      "epoch": 2.15,
      "grad_norm": 6.529665946960449,
      "learning_rate": 3.713970370370371e-05,
      "loss": 0.239,
      "step": 19320
    },
    {
      "epoch": 2.15,
      "grad_norm": 5.47437858581543,
      "learning_rate": 3.713822222222223e-05,
      "loss": 0.1886,
      "step": 19330
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.9871652126312256,
      "learning_rate": 3.7136740740740744e-05,
      "loss": 0.1124,
      "step": 19340
    },
    {
      "epoch": 2.15,
      "grad_norm": 5.204163074493408,
      "learning_rate": 3.713525925925926e-05,
      "loss": 0.1547,
      "step": 19350
    },
    {
      "epoch": 2.15,
      "grad_norm": 5.730163097381592,
      "learning_rate": 3.713377777777778e-05,
      "loss": 0.1774,
      "step": 19360
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.398942232131958,
      "learning_rate": 3.71322962962963e-05,
      "loss": 0.1499,
      "step": 19370
    },
    {
      "epoch": 2.15,
      "grad_norm": 7.374938011169434,
      "learning_rate": 3.713081481481482e-05,
      "loss": 0.157,
      "step": 19380
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.7487282752990723,
      "learning_rate": 3.712933333333334e-05,
      "loss": 0.1646,
      "step": 19390
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.3619961738586426,
      "learning_rate": 3.712785185185185e-05,
      "loss": 0.2213,
      "step": 19400
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.451754093170166,
      "learning_rate": 3.712637037037037e-05,
      "loss": 0.0948,
      "step": 19410
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.020397663116455,
      "learning_rate": 3.712488888888889e-05,
      "loss": 0.1338,
      "step": 19420
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.387329578399658,
      "learning_rate": 3.7123407407407415e-05,
      "loss": 0.1259,
      "step": 19430
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.401520252227783,
      "learning_rate": 3.712192592592593e-05,
      "loss": 0.1802,
      "step": 19440
    },
    {
      "epoch": 2.16,
      "grad_norm": 13.35765552520752,
      "learning_rate": 3.712044444444445e-05,
      "loss": 0.2066,
      "step": 19450
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.818341255187988,
      "learning_rate": 3.711896296296296e-05,
      "loss": 0.1628,
      "step": 19460
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.9871299266815186,
      "learning_rate": 3.7117481481481486e-05,
      "loss": 0.1894,
      "step": 19470
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.561305999755859,
      "learning_rate": 3.7116e-05,
      "loss": 0.1629,
      "step": 19480
    },
    {
      "epoch": 2.17,
      "grad_norm": 4.542253494262695,
      "learning_rate": 3.7114518518518525e-05,
      "loss": 0.0991,
      "step": 19490
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.0368757247924805,
      "learning_rate": 3.711303703703704e-05,
      "loss": 0.1232,
      "step": 19500
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.0892956256866455,
      "learning_rate": 3.7111555555555557e-05,
      "loss": 0.1574,
      "step": 19510
    },
    {
      "epoch": 2.17,
      "grad_norm": 4.707788467407227,
      "learning_rate": 3.711007407407408e-05,
      "loss": 0.175,
      "step": 19520
    },
    {
      "epoch": 2.17,
      "grad_norm": 4.713564395904541,
      "learning_rate": 3.7108592592592595e-05,
      "loss": 0.1912,
      "step": 19530
    },
    {
      "epoch": 2.17,
      "grad_norm": 8.093647003173828,
      "learning_rate": 3.710711111111112e-05,
      "loss": 0.1513,
      "step": 19540
    },
    {
      "epoch": 2.17,
      "grad_norm": 7.113605499267578,
      "learning_rate": 3.7105629629629634e-05,
      "loss": 0.1362,
      "step": 19550
    },
    {
      "epoch": 2.17,
      "grad_norm": 5.358397483825684,
      "learning_rate": 3.710414814814815e-05,
      "loss": 0.1441,
      "step": 19560
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.077868700027466,
      "learning_rate": 3.7102666666666666e-05,
      "loss": 0.1786,
      "step": 19570
    },
    {
      "epoch": 2.18,
      "grad_norm": 8.898362159729004,
      "learning_rate": 3.710118518518519e-05,
      "loss": 0.2016,
      "step": 19580
    },
    {
      "epoch": 2.18,
      "grad_norm": 5.361053466796875,
      "learning_rate": 3.709970370370371e-05,
      "loss": 0.1653,
      "step": 19590
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.322758197784424,
      "learning_rate": 3.709822222222223e-05,
      "loss": 0.1598,
      "step": 19600
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.320735454559326,
      "learning_rate": 3.7096740740740744e-05,
      "loss": 0.2039,
      "step": 19610
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.681929349899292,
      "learning_rate": 3.709525925925926e-05,
      "loss": 0.1572,
      "step": 19620
    },
    {
      "epoch": 2.18,
      "grad_norm": 6.218933582305908,
      "learning_rate": 3.709377777777778e-05,
      "loss": 0.2527,
      "step": 19630
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.7938120365142822,
      "learning_rate": 3.70922962962963e-05,
      "loss": 0.2229,
      "step": 19640
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.070725440979004,
      "learning_rate": 3.709081481481482e-05,
      "loss": 0.2357,
      "step": 19650
    },
    {
      "epoch": 2.18,
      "grad_norm": 4.785543441772461,
      "learning_rate": 3.708933333333334e-05,
      "loss": 0.1644,
      "step": 19660
    },
    {
      "epoch": 2.19,
      "grad_norm": 4.084092617034912,
      "learning_rate": 3.7087851851851854e-05,
      "loss": 0.1351,
      "step": 19670
    },
    {
      "epoch": 2.19,
      "grad_norm": 7.543709754943848,
      "learning_rate": 3.708637037037037e-05,
      "loss": 0.1486,
      "step": 19680
    },
    {
      "epoch": 2.19,
      "grad_norm": 4.484403133392334,
      "learning_rate": 3.708488888888889e-05,
      "loss": 0.12,
      "step": 19690
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.744419574737549,
      "learning_rate": 3.7083407407407415e-05,
      "loss": 0.0977,
      "step": 19700
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.343486785888672,
      "learning_rate": 3.708192592592593e-05,
      "loss": 0.1318,
      "step": 19710
    },
    {
      "epoch": 2.19,
      "grad_norm": 7.086743354797363,
      "learning_rate": 3.708044444444445e-05,
      "loss": 0.2053,
      "step": 19720
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.9167630672454834,
      "learning_rate": 3.707896296296296e-05,
      "loss": 0.1318,
      "step": 19730
    },
    {
      "epoch": 2.19,
      "grad_norm": 7.072518825531006,
      "learning_rate": 3.7077481481481486e-05,
      "loss": 0.1158,
      "step": 19740
    },
    {
      "epoch": 2.19,
      "grad_norm": 4.407532215118408,
      "learning_rate": 3.7076e-05,
      "loss": 0.1754,
      "step": 19750
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.422454595565796,
      "learning_rate": 3.7074518518518525e-05,
      "loss": 0.1784,
      "step": 19760
    },
    {
      "epoch": 2.2,
      "grad_norm": 5.002436637878418,
      "learning_rate": 3.707303703703704e-05,
      "loss": 0.1659,
      "step": 19770
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.0613183975219727,
      "learning_rate": 3.707155555555556e-05,
      "loss": 0.1373,
      "step": 19780
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.666123628616333,
      "learning_rate": 3.707007407407407e-05,
      "loss": 0.1491,
      "step": 19790
    },
    {
      "epoch": 2.2,
      "grad_norm": 4.780859470367432,
      "learning_rate": 3.7068592592592596e-05,
      "loss": 0.1634,
      "step": 19800
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.5820837020874023,
      "learning_rate": 3.706711111111112e-05,
      "loss": 0.1347,
      "step": 19810
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.7745890617370605,
      "learning_rate": 3.7065629629629635e-05,
      "loss": 0.0993,
      "step": 19820
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.867453694343567,
      "learning_rate": 3.706414814814815e-05,
      "loss": 0.1542,
      "step": 19830
    },
    {
      "epoch": 2.2,
      "grad_norm": 5.856311798095703,
      "learning_rate": 3.706266666666667e-05,
      "loss": 0.1552,
      "step": 19840
    },
    {
      "epoch": 2.21,
      "grad_norm": 7.076959609985352,
      "learning_rate": 3.706118518518519e-05,
      "loss": 0.1307,
      "step": 19850
    },
    {
      "epoch": 2.21,
      "grad_norm": 6.002938270568848,
      "learning_rate": 3.7059703703703705e-05,
      "loss": 0.1514,
      "step": 19860
    },
    {
      "epoch": 2.21,
      "grad_norm": 5.523087024688721,
      "learning_rate": 3.705822222222223e-05,
      "loss": 0.1684,
      "step": 19870
    },
    {
      "epoch": 2.21,
      "grad_norm": 3.1860673427581787,
      "learning_rate": 3.7056740740740744e-05,
      "loss": 0.1474,
      "step": 19880
    },
    {
      "epoch": 2.21,
      "grad_norm": 3.2399797439575195,
      "learning_rate": 3.705525925925926e-05,
      "loss": 0.1398,
      "step": 19890
    },
    {
      "epoch": 2.21,
      "grad_norm": 6.326497554779053,
      "learning_rate": 3.7053777777777776e-05,
      "loss": 0.1888,
      "step": 19900
    },
    {
      "epoch": 2.21,
      "grad_norm": 4.669792175292969,
      "learning_rate": 3.70522962962963e-05,
      "loss": 0.1853,
      "step": 19910
    },
    {
      "epoch": 2.21,
      "grad_norm": 7.6302385330200195,
      "learning_rate": 3.705081481481482e-05,
      "loss": 0.1997,
      "step": 19920
    },
    {
      "epoch": 2.21,
      "grad_norm": 7.547342777252197,
      "learning_rate": 3.704933333333334e-05,
      "loss": 0.188,
      "step": 19930
    },
    {
      "epoch": 2.22,
      "grad_norm": 5.530910491943359,
      "learning_rate": 3.7047851851851854e-05,
      "loss": 0.179,
      "step": 19940
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.264264106750488,
      "learning_rate": 3.704637037037037e-05,
      "loss": 0.2151,
      "step": 19950
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.658613204956055,
      "learning_rate": 3.704488888888889e-05,
      "loss": 0.144,
      "step": 19960
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.0698516368865967,
      "learning_rate": 3.7043407407407416e-05,
      "loss": 0.1237,
      "step": 19970
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.6591250896453857,
      "learning_rate": 3.704192592592593e-05,
      "loss": 0.1824,
      "step": 19980
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.734140396118164,
      "learning_rate": 3.704044444444445e-05,
      "loss": 0.1288,
      "step": 19990
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.012487888336182,
      "learning_rate": 3.7038962962962964e-05,
      "loss": 0.1451,
      "step": 20000
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.145804405212402,
      "learning_rate": 3.7037481481481486e-05,
      "loss": 0.1474,
      "step": 20010
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.9158663749694824,
      "learning_rate": 3.7036e-05,
      "loss": 0.0931,
      "step": 20020
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.9495909214019775,
      "learning_rate": 3.7034518518518525e-05,
      "loss": 0.1547,
      "step": 20030
    },
    {
      "epoch": 2.23,
      "grad_norm": 4.265417575836182,
      "learning_rate": 3.703303703703704e-05,
      "loss": 0.1406,
      "step": 20040
    },
    {
      "epoch": 2.23,
      "grad_norm": 8.700950622558594,
      "learning_rate": 3.703155555555556e-05,
      "loss": 0.2038,
      "step": 20050
    },
    {
      "epoch": 2.23,
      "grad_norm": 3.4240033626556396,
      "learning_rate": 3.703007407407407e-05,
      "loss": 0.1568,
      "step": 20060
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.3108431100845337,
      "learning_rate": 3.7028592592592596e-05,
      "loss": 0.1306,
      "step": 20070
    },
    {
      "epoch": 2.23,
      "grad_norm": 4.889814853668213,
      "learning_rate": 3.702711111111112e-05,
      "loss": 0.124,
      "step": 20080
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.7144893407821655,
      "learning_rate": 3.7025629629629635e-05,
      "loss": 0.1481,
      "step": 20090
    },
    {
      "epoch": 2.23,
      "grad_norm": 4.378849029541016,
      "learning_rate": 3.702414814814815e-05,
      "loss": 0.1814,
      "step": 20100
    },
    {
      "epoch": 2.23,
      "grad_norm": 8.712234497070312,
      "learning_rate": 3.702266666666667e-05,
      "loss": 0.1652,
      "step": 20110
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.795669078826904,
      "learning_rate": 3.702118518518519e-05,
      "loss": 0.1689,
      "step": 20120
    },
    {
      "epoch": 2.24,
      "grad_norm": 7.152431964874268,
      "learning_rate": 3.7019703703703706e-05,
      "loss": 0.1915,
      "step": 20130
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.906538724899292,
      "learning_rate": 3.701822222222223e-05,
      "loss": 0.1737,
      "step": 20140
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.016230583190918,
      "learning_rate": 3.7016740740740745e-05,
      "loss": 0.1323,
      "step": 20150
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.8696138858795166,
      "learning_rate": 3.701525925925926e-05,
      "loss": 0.1453,
      "step": 20160
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.4916653633117676,
      "learning_rate": 3.701377777777778e-05,
      "loss": 0.1117,
      "step": 20170
    },
    {
      "epoch": 2.24,
      "grad_norm": 5.088127136230469,
      "learning_rate": 3.70122962962963e-05,
      "loss": 0.1312,
      "step": 20180
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.3639981746673584,
      "learning_rate": 3.701081481481482e-05,
      "loss": 0.1249,
      "step": 20190
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.249131202697754,
      "learning_rate": 3.700933333333334e-05,
      "loss": 0.1572,
      "step": 20200
    },
    {
      "epoch": 2.25,
      "grad_norm": 5.648683547973633,
      "learning_rate": 3.7007851851851854e-05,
      "loss": 0.178,
      "step": 20210
    },
    {
      "epoch": 2.25,
      "grad_norm": 6.1392822265625,
      "learning_rate": 3.700637037037037e-05,
      "loss": 0.1616,
      "step": 20220
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.9505648612976074,
      "learning_rate": 3.700488888888889e-05,
      "loss": 0.1867,
      "step": 20230
    },
    {
      "epoch": 2.25,
      "grad_norm": 4.573972225189209,
      "learning_rate": 3.700340740740741e-05,
      "loss": 0.1258,
      "step": 20240
    },
    {
      "epoch": 2.25,
      "grad_norm": 7.017350196838379,
      "learning_rate": 3.700192592592593e-05,
      "loss": 0.173,
      "step": 20250
    },
    {
      "epoch": 2.25,
      "grad_norm": 9.145187377929688,
      "learning_rate": 3.700044444444445e-05,
      "loss": 0.155,
      "step": 20260
    },
    {
      "epoch": 2.25,
      "grad_norm": 5.4980645179748535,
      "learning_rate": 3.6998962962962964e-05,
      "loss": 0.1311,
      "step": 20270
    },
    {
      "epoch": 2.25,
      "grad_norm": 4.489023685455322,
      "learning_rate": 3.699748148148148e-05,
      "loss": 0.1616,
      "step": 20280
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.1613224744796753,
      "learning_rate": 3.6996e-05,
      "loss": 0.183,
      "step": 20290
    },
    {
      "epoch": 2.26,
      "grad_norm": 5.362281322479248,
      "learning_rate": 3.6994518518518526e-05,
      "loss": 0.1974,
      "step": 20300
    },
    {
      "epoch": 2.26,
      "grad_norm": 4.873135566711426,
      "learning_rate": 3.699303703703704e-05,
      "loss": 0.146,
      "step": 20310
    },
    {
      "epoch": 2.26,
      "grad_norm": 4.4933648109436035,
      "learning_rate": 3.699155555555556e-05,
      "loss": 0.1202,
      "step": 20320
    },
    {
      "epoch": 2.26,
      "grad_norm": 5.779356479644775,
      "learning_rate": 3.6990074074074074e-05,
      "loss": 0.145,
      "step": 20330
    },
    {
      "epoch": 2.26,
      "grad_norm": 9.76185131072998,
      "learning_rate": 3.6988592592592597e-05,
      "loss": 0.1273,
      "step": 20340
    },
    {
      "epoch": 2.26,
      "grad_norm": 4.709029674530029,
      "learning_rate": 3.698711111111111e-05,
      "loss": 0.1733,
      "step": 20350
    },
    {
      "epoch": 2.26,
      "grad_norm": 4.498940467834473,
      "learning_rate": 3.6985629629629635e-05,
      "loss": 0.1799,
      "step": 20360
    },
    {
      "epoch": 2.26,
      "grad_norm": 8.350542068481445,
      "learning_rate": 3.698414814814815e-05,
      "loss": 0.143,
      "step": 20370
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.628077745437622,
      "learning_rate": 3.698266666666667e-05,
      "loss": 0.1121,
      "step": 20380
    },
    {
      "epoch": 2.27,
      "grad_norm": 6.673351287841797,
      "learning_rate": 3.6981185185185183e-05,
      "loss": 0.1346,
      "step": 20390
    },
    {
      "epoch": 2.27,
      "grad_norm": 5.169328689575195,
      "learning_rate": 3.6979703703703706e-05,
      "loss": 0.1367,
      "step": 20400
    },
    {
      "epoch": 2.27,
      "grad_norm": 9.192126274108887,
      "learning_rate": 3.697822222222223e-05,
      "loss": 0.1016,
      "step": 20410
    },
    {
      "epoch": 2.27,
      "grad_norm": 6.60711145401001,
      "learning_rate": 3.6976740740740745e-05,
      "loss": 0.1619,
      "step": 20420
    },
    {
      "epoch": 2.27,
      "grad_norm": 4.900904655456543,
      "learning_rate": 3.697525925925926e-05,
      "loss": 0.1559,
      "step": 20430
    },
    {
      "epoch": 2.27,
      "grad_norm": 5.806543827056885,
      "learning_rate": 3.697377777777778e-05,
      "loss": 0.1449,
      "step": 20440
    },
    {
      "epoch": 2.27,
      "grad_norm": 9.11133098602295,
      "learning_rate": 3.69722962962963e-05,
      "loss": 0.1623,
      "step": 20450
    },
    {
      "epoch": 2.27,
      "grad_norm": 7.059417247772217,
      "learning_rate": 3.697081481481482e-05,
      "loss": 0.1774,
      "step": 20460
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.798625946044922,
      "learning_rate": 3.696933333333334e-05,
      "loss": 0.1458,
      "step": 20470
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.5959997177124023,
      "learning_rate": 3.6967851851851855e-05,
      "loss": 0.1862,
      "step": 20480
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.675048589706421,
      "learning_rate": 3.696637037037037e-05,
      "loss": 0.2284,
      "step": 20490
    },
    {
      "epoch": 2.28,
      "grad_norm": 4.569884777069092,
      "learning_rate": 3.696488888888889e-05,
      "loss": 0.2096,
      "step": 20500
    },
    {
      "epoch": 2.28,
      "grad_norm": 6.10481071472168,
      "learning_rate": 3.696340740740741e-05,
      "loss": 0.1728,
      "step": 20510
    },
    {
      "epoch": 2.28,
      "grad_norm": 5.284879684448242,
      "learning_rate": 3.696192592592593e-05,
      "loss": 0.0969,
      "step": 20520
    },
    {
      "epoch": 2.28,
      "grad_norm": 7.4961628913879395,
      "learning_rate": 3.696044444444445e-05,
      "loss": 0.1868,
      "step": 20530
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.9464495182037354,
      "learning_rate": 3.6958962962962964e-05,
      "loss": 0.1208,
      "step": 20540
    },
    {
      "epoch": 2.28,
      "grad_norm": 6.789309024810791,
      "learning_rate": 3.695748148148148e-05,
      "loss": 0.1664,
      "step": 20550
    },
    {
      "epoch": 2.28,
      "grad_norm": 4.359598159790039,
      "learning_rate": 3.6956e-05,
      "loss": 0.2323,
      "step": 20560
    },
    {
      "epoch": 2.29,
      "grad_norm": 6.743140697479248,
      "learning_rate": 3.6954518518518526e-05,
      "loss": 0.1357,
      "step": 20570
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.1577939987182617,
      "learning_rate": 3.695303703703704e-05,
      "loss": 0.1399,
      "step": 20580
    },
    {
      "epoch": 2.29,
      "grad_norm": 12.9386568069458,
      "learning_rate": 3.695155555555556e-05,
      "loss": 0.1661,
      "step": 20590
    },
    {
      "epoch": 2.29,
      "grad_norm": 4.037735462188721,
      "learning_rate": 3.6950074074074074e-05,
      "loss": 0.1475,
      "step": 20600
    },
    {
      "epoch": 2.29,
      "grad_norm": 5.5880818367004395,
      "learning_rate": 3.69485925925926e-05,
      "loss": 0.2015,
      "step": 20610
    },
    {
      "epoch": 2.29,
      "grad_norm": 4.655415058135986,
      "learning_rate": 3.694711111111111e-05,
      "loss": 0.1437,
      "step": 20620
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.2298665046691895,
      "learning_rate": 3.6945629629629636e-05,
      "loss": 0.1421,
      "step": 20630
    },
    {
      "epoch": 2.29,
      "grad_norm": 7.030397891998291,
      "learning_rate": 3.694414814814815e-05,
      "loss": 0.1342,
      "step": 20640
    },
    {
      "epoch": 2.29,
      "grad_norm": 5.824885368347168,
      "learning_rate": 3.694266666666667e-05,
      "loss": 0.101,
      "step": 20650
    },
    {
      "epoch": 2.3,
      "grad_norm": 12.46861457824707,
      "learning_rate": 3.6941185185185184e-05,
      "loss": 0.1126,
      "step": 20660
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.538817882537842,
      "learning_rate": 3.693970370370371e-05,
      "loss": 0.1899,
      "step": 20670
    },
    {
      "epoch": 2.3,
      "grad_norm": 6.542492389678955,
      "learning_rate": 3.693822222222223e-05,
      "loss": 0.2233,
      "step": 20680
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.1129813194274902,
      "learning_rate": 3.6936740740740745e-05,
      "loss": 0.0761,
      "step": 20690
    },
    {
      "epoch": 2.3,
      "grad_norm": 5.866992950439453,
      "learning_rate": 3.693525925925926e-05,
      "loss": 0.2038,
      "step": 20700
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.551212787628174,
      "learning_rate": 3.693377777777778e-05,
      "loss": 0.177,
      "step": 20710
    },
    {
      "epoch": 2.3,
      "grad_norm": 5.160986423492432,
      "learning_rate": 3.69322962962963e-05,
      "loss": 0.2322,
      "step": 20720
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.1871817111968994,
      "learning_rate": 3.6930814814814816e-05,
      "loss": 0.1159,
      "step": 20730
    },
    {
      "epoch": 2.3,
      "grad_norm": 12.417072296142578,
      "learning_rate": 3.692933333333334e-05,
      "loss": 0.1892,
      "step": 20740
    },
    {
      "epoch": 2.31,
      "grad_norm": 7.114819049835205,
      "learning_rate": 3.6927851851851855e-05,
      "loss": 0.1745,
      "step": 20750
    },
    {
      "epoch": 2.31,
      "grad_norm": 5.647595405578613,
      "learning_rate": 3.692637037037037e-05,
      "loss": 0.1456,
      "step": 20760
    },
    {
      "epoch": 2.31,
      "grad_norm": 4.438359260559082,
      "learning_rate": 3.692488888888889e-05,
      "loss": 0.1231,
      "step": 20770
    },
    {
      "epoch": 2.31,
      "grad_norm": 5.7896575927734375,
      "learning_rate": 3.692340740740741e-05,
      "loss": 0.1822,
      "step": 20780
    },
    {
      "epoch": 2.31,
      "grad_norm": 4.957798004150391,
      "learning_rate": 3.692192592592593e-05,
      "loss": 0.1697,
      "step": 20790
    },
    {
      "epoch": 2.31,
      "grad_norm": 4.171646595001221,
      "learning_rate": 3.692044444444445e-05,
      "loss": 0.1728,
      "step": 20800
    },
    {
      "epoch": 2.31,
      "grad_norm": 4.640166759490967,
      "learning_rate": 3.6918962962962965e-05,
      "loss": 0.2338,
      "step": 20810
    },
    {
      "epoch": 2.31,
      "grad_norm": 5.871973991394043,
      "learning_rate": 3.691748148148148e-05,
      "loss": 0.1362,
      "step": 20820
    },
    {
      "epoch": 2.31,
      "grad_norm": 4.379329681396484,
      "learning_rate": 3.6916000000000004e-05,
      "loss": 0.1767,
      "step": 20830
    },
    {
      "epoch": 2.32,
      "grad_norm": 14.145885467529297,
      "learning_rate": 3.691451851851852e-05,
      "loss": 0.1295,
      "step": 20840
    },
    {
      "epoch": 2.32,
      "grad_norm": 8.944133758544922,
      "learning_rate": 3.691303703703704e-05,
      "loss": 0.1493,
      "step": 20850
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.1927947998046875,
      "learning_rate": 3.691155555555556e-05,
      "loss": 0.1327,
      "step": 20860
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.4623613357543945,
      "learning_rate": 3.6910074074074075e-05,
      "loss": 0.1228,
      "step": 20870
    },
    {
      "epoch": 2.32,
      "grad_norm": 4.5399489402771,
      "learning_rate": 3.690859259259259e-05,
      "loss": 0.1283,
      "step": 20880
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.4974381923675537,
      "learning_rate": 3.690711111111111e-05,
      "loss": 0.184,
      "step": 20890
    },
    {
      "epoch": 2.32,
      "grad_norm": 5.7275800704956055,
      "learning_rate": 3.6905629629629636e-05,
      "loss": 0.1445,
      "step": 20900
    },
    {
      "epoch": 2.32,
      "grad_norm": 4.6143798828125,
      "learning_rate": 3.690414814814815e-05,
      "loss": 0.1322,
      "step": 20910
    },
    {
      "epoch": 2.32,
      "grad_norm": 7.417469024658203,
      "learning_rate": 3.690266666666667e-05,
      "loss": 0.1185,
      "step": 20920
    },
    {
      "epoch": 2.33,
      "grad_norm": 5.555258274078369,
      "learning_rate": 3.6901185185185184e-05,
      "loss": 0.1321,
      "step": 20930
    },
    {
      "epoch": 2.33,
      "grad_norm": 10.819682121276855,
      "learning_rate": 3.689970370370371e-05,
      "loss": 0.1401,
      "step": 20940
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.771075487136841,
      "learning_rate": 3.689822222222222e-05,
      "loss": 0.1421,
      "step": 20950
    },
    {
      "epoch": 2.33,
      "grad_norm": 9.459030151367188,
      "learning_rate": 3.6896740740740746e-05,
      "loss": 0.156,
      "step": 20960
    },
    {
      "epoch": 2.33,
      "grad_norm": 6.183594703674316,
      "learning_rate": 3.689525925925926e-05,
      "loss": 0.1618,
      "step": 20970
    },
    {
      "epoch": 2.33,
      "grad_norm": 11.80563735961914,
      "learning_rate": 3.689377777777778e-05,
      "loss": 0.2213,
      "step": 20980
    },
    {
      "epoch": 2.33,
      "grad_norm": 4.610330104827881,
      "learning_rate": 3.6892296296296294e-05,
      "loss": 0.1725,
      "step": 20990
    },
    {
      "epoch": 2.33,
      "grad_norm": 5.378998279571533,
      "learning_rate": 3.689081481481482e-05,
      "loss": 0.1287,
      "step": 21000
    },
    {
      "epoch": 2.33,
      "grad_norm": 4.895559787750244,
      "learning_rate": 3.688933333333334e-05,
      "loss": 0.138,
      "step": 21010
    },
    {
      "epoch": 2.34,
      "grad_norm": 4.141921043395996,
      "learning_rate": 3.6887851851851856e-05,
      "loss": 0.1958,
      "step": 21020
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.2576348781585693,
      "learning_rate": 3.688637037037037e-05,
      "loss": 0.1623,
      "step": 21030
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.926645278930664,
      "learning_rate": 3.688488888888889e-05,
      "loss": 0.179,
      "step": 21040
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.7543537616729736,
      "learning_rate": 3.688340740740741e-05,
      "loss": 0.126,
      "step": 21050
    },
    {
      "epoch": 2.34,
      "grad_norm": 4.853913307189941,
      "learning_rate": 3.688192592592593e-05,
      "loss": 0.1541,
      "step": 21060
    },
    {
      "epoch": 2.34,
      "grad_norm": 4.0748748779296875,
      "learning_rate": 3.688044444444445e-05,
      "loss": 0.1912,
      "step": 21070
    },
    {
      "epoch": 2.34,
      "grad_norm": 6.664370059967041,
      "learning_rate": 3.6878962962962965e-05,
      "loss": 0.1347,
      "step": 21080
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.682812452316284,
      "learning_rate": 3.687748148148148e-05,
      "loss": 0.1153,
      "step": 21090
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.617424726486206,
      "learning_rate": 3.6876000000000004e-05,
      "loss": 0.1268,
      "step": 21100
    },
    {
      "epoch": 2.35,
      "grad_norm": 6.098857879638672,
      "learning_rate": 3.687451851851852e-05,
      "loss": 0.0995,
      "step": 21110
    },
    {
      "epoch": 2.35,
      "grad_norm": 7.8118181228637695,
      "learning_rate": 3.687303703703704e-05,
      "loss": 0.1639,
      "step": 21120
    },
    {
      "epoch": 2.35,
      "grad_norm": 4.306530952453613,
      "learning_rate": 3.687155555555556e-05,
      "loss": 0.1681,
      "step": 21130
    },
    {
      "epoch": 2.35,
      "grad_norm": 6.504919528961182,
      "learning_rate": 3.6870074074074075e-05,
      "loss": 0.1814,
      "step": 21140
    },
    {
      "epoch": 2.35,
      "grad_norm": 4.242783069610596,
      "learning_rate": 3.686859259259259e-05,
      "loss": 0.1795,
      "step": 21150
    },
    {
      "epoch": 2.35,
      "grad_norm": 4.150498867034912,
      "learning_rate": 3.6867111111111114e-05,
      "loss": 0.1916,
      "step": 21160
    },
    {
      "epoch": 2.35,
      "grad_norm": 6.220030307769775,
      "learning_rate": 3.6865629629629637e-05,
      "loss": 0.2197,
      "step": 21170
    },
    {
      "epoch": 2.35,
      "grad_norm": 6.048750400543213,
      "learning_rate": 3.686414814814815e-05,
      "loss": 0.1343,
      "step": 21180
    },
    {
      "epoch": 2.35,
      "grad_norm": 8.301722526550293,
      "learning_rate": 3.686266666666667e-05,
      "loss": 0.1459,
      "step": 21190
    },
    {
      "epoch": 2.36,
      "grad_norm": 5.9921956062316895,
      "learning_rate": 3.6861185185185185e-05,
      "loss": 0.2285,
      "step": 21200
    },
    {
      "epoch": 2.36,
      "grad_norm": 5.4893951416015625,
      "learning_rate": 3.685970370370371e-05,
      "loss": 0.1698,
      "step": 21210
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.820952415466309,
      "learning_rate": 3.6858222222222223e-05,
      "loss": 0.219,
      "step": 21220
    },
    {
      "epoch": 2.36,
      "grad_norm": 8.025317192077637,
      "learning_rate": 3.6856740740740746e-05,
      "loss": 0.1538,
      "step": 21230
    },
    {
      "epoch": 2.36,
      "grad_norm": 5.8614888191223145,
      "learning_rate": 3.685525925925926e-05,
      "loss": 0.1293,
      "step": 21240
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.180739164352417,
      "learning_rate": 3.685377777777778e-05,
      "loss": 0.1339,
      "step": 21250
    },
    {
      "epoch": 2.36,
      "grad_norm": 7.758269309997559,
      "learning_rate": 3.6852296296296294e-05,
      "loss": 0.2429,
      "step": 21260
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.384237289428711,
      "learning_rate": 3.685081481481482e-05,
      "loss": 0.1288,
      "step": 21270
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.7087466716766357,
      "learning_rate": 3.684933333333334e-05,
      "loss": 0.1199,
      "step": 21280
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.3601529598236084,
      "learning_rate": 3.6847851851851856e-05,
      "loss": 0.1515,
      "step": 21290
    },
    {
      "epoch": 2.37,
      "grad_norm": 6.691339492797852,
      "learning_rate": 3.684637037037037e-05,
      "loss": 0.1393,
      "step": 21300
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.5649030208587646,
      "learning_rate": 3.684488888888889e-05,
      "loss": 0.1883,
      "step": 21310
    },
    {
      "epoch": 2.37,
      "grad_norm": 5.271393775939941,
      "learning_rate": 3.684340740740741e-05,
      "loss": 0.1994,
      "step": 21320
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.0435333251953125,
      "learning_rate": 3.684192592592593e-05,
      "loss": 0.1372,
      "step": 21330
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.3661301136016846,
      "learning_rate": 3.684044444444445e-05,
      "loss": 0.1331,
      "step": 21340
    },
    {
      "epoch": 2.37,
      "grad_norm": 4.621549606323242,
      "learning_rate": 3.6838962962962966e-05,
      "loss": 0.1003,
      "step": 21350
    },
    {
      "epoch": 2.37,
      "grad_norm": 5.213135242462158,
      "learning_rate": 3.683748148148148e-05,
      "loss": 0.1454,
      "step": 21360
    },
    {
      "epoch": 2.37,
      "grad_norm": 5.614800453186035,
      "learning_rate": 3.6836000000000004e-05,
      "loss": 0.1257,
      "step": 21370
    },
    {
      "epoch": 2.38,
      "grad_norm": 4.983404636383057,
      "learning_rate": 3.683451851851852e-05,
      "loss": 0.135,
      "step": 21380
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.816023349761963,
      "learning_rate": 3.683303703703704e-05,
      "loss": 0.1762,
      "step": 21390
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.6753108501434326,
      "learning_rate": 3.683155555555556e-05,
      "loss": 0.1319,
      "step": 21400
    },
    {
      "epoch": 2.38,
      "grad_norm": 21.29224395751953,
      "learning_rate": 3.6830074074074075e-05,
      "loss": 0.1732,
      "step": 21410
    },
    {
      "epoch": 2.38,
      "grad_norm": 6.400593280792236,
      "learning_rate": 3.682859259259259e-05,
      "loss": 0.1408,
      "step": 21420
    },
    {
      "epoch": 2.38,
      "grad_norm": 4.306851387023926,
      "learning_rate": 3.6827111111111114e-05,
      "loss": 0.1174,
      "step": 21430
    },
    {
      "epoch": 2.38,
      "grad_norm": 4.361336708068848,
      "learning_rate": 3.682562962962963e-05,
      "loss": 0.0978,
      "step": 21440
    },
    {
      "epoch": 2.38,
      "grad_norm": 7.587943077087402,
      "learning_rate": 3.682414814814815e-05,
      "loss": 0.1232,
      "step": 21450
    },
    {
      "epoch": 2.38,
      "grad_norm": 10.515349388122559,
      "learning_rate": 3.682266666666667e-05,
      "loss": 0.1996,
      "step": 21460
    },
    {
      "epoch": 2.39,
      "grad_norm": 4.623218059539795,
      "learning_rate": 3.6821185185185185e-05,
      "loss": 0.1535,
      "step": 21470
    },
    {
      "epoch": 2.39,
      "grad_norm": 5.071479320526123,
      "learning_rate": 3.681970370370371e-05,
      "loss": 0.1298,
      "step": 21480
    },
    {
      "epoch": 2.39,
      "grad_norm": 10.828104019165039,
      "learning_rate": 3.6818222222222224e-05,
      "loss": 0.2315,
      "step": 21490
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.7454662322998047,
      "learning_rate": 3.6816740740740747e-05,
      "loss": 0.1885,
      "step": 21500
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.806549072265625,
      "learning_rate": 3.681525925925926e-05,
      "loss": 0.1557,
      "step": 21510
    },
    {
      "epoch": 2.39,
      "grad_norm": 7.837257385253906,
      "learning_rate": 3.6813925925925926e-05,
      "loss": 0.124,
      "step": 21520
    },
    {
      "epoch": 2.39,
      "grad_norm": 6.956483840942383,
      "learning_rate": 3.681244444444445e-05,
      "loss": 0.1324,
      "step": 21530
    },
    {
      "epoch": 2.39,
      "grad_norm": 4.499880790710449,
      "learning_rate": 3.6810962962962965e-05,
      "loss": 0.1439,
      "step": 21540
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.6080269813537598,
      "learning_rate": 3.680948148148149e-05,
      "loss": 0.1513,
      "step": 21550
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.233954906463623,
      "learning_rate": 3.6808000000000004e-05,
      "loss": 0.1994,
      "step": 21560
    },
    {
      "epoch": 2.4,
      "grad_norm": 4.539602756500244,
      "learning_rate": 3.680651851851852e-05,
      "loss": 0.1921,
      "step": 21570
    },
    {
      "epoch": 2.4,
      "grad_norm": 6.3526930809021,
      "learning_rate": 3.6805037037037036e-05,
      "loss": 0.1593,
      "step": 21580
    },
    {
      "epoch": 2.4,
      "grad_norm": 7.383999824523926,
      "learning_rate": 3.680355555555556e-05,
      "loss": 0.1766,
      "step": 21590
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.686567783355713,
      "learning_rate": 3.680207407407408e-05,
      "loss": 0.1455,
      "step": 21600
    },
    {
      "epoch": 2.4,
      "grad_norm": 8.371685028076172,
      "learning_rate": 3.68005925925926e-05,
      "loss": 0.1442,
      "step": 21610
    },
    {
      "epoch": 2.4,
      "grad_norm": 8.181124687194824,
      "learning_rate": 3.6799111111111114e-05,
      "loss": 0.1372,
      "step": 21620
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.510460615158081,
      "learning_rate": 3.679762962962963e-05,
      "loss": 0.1462,
      "step": 21630
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.0692715644836426,
      "learning_rate": 3.679614814814815e-05,
      "loss": 0.1201,
      "step": 21640
    },
    {
      "epoch": 2.41,
      "grad_norm": 4.175316333770752,
      "learning_rate": 3.679466666666667e-05,
      "loss": 0.1376,
      "step": 21650
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.7567806243896484,
      "learning_rate": 3.679318518518519e-05,
      "loss": 0.1402,
      "step": 21660
    },
    {
      "epoch": 2.41,
      "grad_norm": 7.032208442687988,
      "learning_rate": 3.679170370370371e-05,
      "loss": 0.1277,
      "step": 21670
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.467207670211792,
      "learning_rate": 3.6790222222222223e-05,
      "loss": 0.1518,
      "step": 21680
    },
    {
      "epoch": 2.41,
      "grad_norm": 7.04228401184082,
      "learning_rate": 3.678874074074074e-05,
      "loss": 0.138,
      "step": 21690
    },
    {
      "epoch": 2.41,
      "grad_norm": 8.116674423217773,
      "learning_rate": 3.678725925925926e-05,
      "loss": 0.1261,
      "step": 21700
    },
    {
      "epoch": 2.41,
      "grad_norm": 6.2623677253723145,
      "learning_rate": 3.6785777777777785e-05,
      "loss": 0.192,
      "step": 21710
    },
    {
      "epoch": 2.41,
      "grad_norm": 8.193257331848145,
      "learning_rate": 3.67842962962963e-05,
      "loss": 0.1317,
      "step": 21720
    },
    {
      "epoch": 2.41,
      "grad_norm": 6.057547569274902,
      "learning_rate": 3.678281481481482e-05,
      "loss": 0.1737,
      "step": 21730
    },
    {
      "epoch": 2.42,
      "grad_norm": 7.1721415519714355,
      "learning_rate": 3.678133333333333e-05,
      "loss": 0.1437,
      "step": 21740
    },
    {
      "epoch": 2.42,
      "grad_norm": 4.193636894226074,
      "learning_rate": 3.6779851851851856e-05,
      "loss": 0.1161,
      "step": 21750
    },
    {
      "epoch": 2.42,
      "grad_norm": 7.011367321014404,
      "learning_rate": 3.677837037037038e-05,
      "loss": 0.135,
      "step": 21760
    },
    {
      "epoch": 2.42,
      "grad_norm": 4.139821529388428,
      "learning_rate": 3.6776888888888895e-05,
      "loss": 0.1241,
      "step": 21770
    },
    {
      "epoch": 2.42,
      "grad_norm": 10.368637084960938,
      "learning_rate": 3.677540740740741e-05,
      "loss": 0.1652,
      "step": 21780
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.9638659954071045,
      "learning_rate": 3.677392592592593e-05,
      "loss": 0.1462,
      "step": 21790
    },
    {
      "epoch": 2.42,
      "grad_norm": 4.231836795806885,
      "learning_rate": 3.677244444444444e-05,
      "loss": 0.1199,
      "step": 21800
    },
    {
      "epoch": 2.42,
      "grad_norm": 6.490869522094727,
      "learning_rate": 3.6770962962962966e-05,
      "loss": 0.163,
      "step": 21810
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.9785943031311035,
      "learning_rate": 3.676948148148149e-05,
      "loss": 0.1082,
      "step": 21820
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.090127944946289,
      "learning_rate": 3.6768000000000004e-05,
      "loss": 0.1574,
      "step": 21830
    },
    {
      "epoch": 2.43,
      "grad_norm": 5.34945011138916,
      "learning_rate": 3.676651851851852e-05,
      "loss": 0.1551,
      "step": 21840
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.764254570007324,
      "learning_rate": 3.6765037037037036e-05,
      "loss": 0.1142,
      "step": 21850
    },
    {
      "epoch": 2.43,
      "grad_norm": 6.061626434326172,
      "learning_rate": 3.676355555555556e-05,
      "loss": 0.0947,
      "step": 21860
    },
    {
      "epoch": 2.43,
      "grad_norm": 3.643580675125122,
      "learning_rate": 3.676207407407408e-05,
      "loss": 0.1071,
      "step": 21870
    },
    {
      "epoch": 2.43,
      "grad_norm": 5.65805721282959,
      "learning_rate": 3.67605925925926e-05,
      "loss": 0.1677,
      "step": 21880
    },
    {
      "epoch": 2.43,
      "grad_norm": 6.838265419006348,
      "learning_rate": 3.6759111111111114e-05,
      "loss": 0.134,
      "step": 21890
    },
    {
      "epoch": 2.43,
      "grad_norm": 4.088230133056641,
      "learning_rate": 3.675762962962963e-05,
      "loss": 0.195,
      "step": 21900
    },
    {
      "epoch": 2.43,
      "grad_norm": 6.379063606262207,
      "learning_rate": 3.675614814814815e-05,
      "loss": 0.1748,
      "step": 21910
    },
    {
      "epoch": 2.44,
      "grad_norm": 8.61935806274414,
      "learning_rate": 3.675466666666667e-05,
      "loss": 0.1636,
      "step": 21920
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.149125814437866,
      "learning_rate": 3.675318518518519e-05,
      "loss": 0.1459,
      "step": 21930
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.3721425533294678,
      "learning_rate": 3.675170370370371e-05,
      "loss": 0.1538,
      "step": 21940
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.0782861709594727,
      "learning_rate": 3.6750222222222224e-05,
      "loss": 0.2615,
      "step": 21950
    },
    {
      "epoch": 2.44,
      "grad_norm": 4.864093780517578,
      "learning_rate": 3.674874074074074e-05,
      "loss": 0.1176,
      "step": 21960
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.586381435394287,
      "learning_rate": 3.674725925925926e-05,
      "loss": 0.2381,
      "step": 21970
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.1136391162872314,
      "learning_rate": 3.6745777777777785e-05,
      "loss": 0.1139,
      "step": 21980
    },
    {
      "epoch": 2.44,
      "grad_norm": 5.074638366699219,
      "learning_rate": 3.67442962962963e-05,
      "loss": 0.1458,
      "step": 21990
    },
    {
      "epoch": 2.44,
      "grad_norm": 6.377234935760498,
      "learning_rate": 3.674281481481482e-05,
      "loss": 0.1109,
      "step": 22000
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.703174114227295,
      "learning_rate": 3.6741333333333333e-05,
      "loss": 0.101,
      "step": 22010
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.6459767818450928,
      "learning_rate": 3.6739851851851856e-05,
      "loss": 0.2026,
      "step": 22020
    },
    {
      "epoch": 2.45,
      "grad_norm": 7.931601047515869,
      "learning_rate": 3.673837037037037e-05,
      "loss": 0.158,
      "step": 22030
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.485443115234375,
      "learning_rate": 3.6736888888888895e-05,
      "loss": 0.1669,
      "step": 22040
    },
    {
      "epoch": 2.45,
      "grad_norm": 6.892032623291016,
      "learning_rate": 3.673540740740741e-05,
      "loss": 0.1531,
      "step": 22050
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.731147050857544,
      "learning_rate": 3.673392592592593e-05,
      "loss": 0.1364,
      "step": 22060
    },
    {
      "epoch": 2.45,
      "grad_norm": 6.434473514556885,
      "learning_rate": 3.673244444444444e-05,
      "loss": 0.1556,
      "step": 22070
    },
    {
      "epoch": 2.45,
      "grad_norm": 4.2975616455078125,
      "learning_rate": 3.6730962962962966e-05,
      "loss": 0.1913,
      "step": 22080
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.2356443405151367,
      "learning_rate": 3.672948148148149e-05,
      "loss": 0.1243,
      "step": 22090
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.8178486824035645,
      "learning_rate": 3.6728000000000005e-05,
      "loss": 0.1452,
      "step": 22100
    },
    {
      "epoch": 2.46,
      "grad_norm": 4.2468366622924805,
      "learning_rate": 3.672651851851852e-05,
      "loss": 0.1604,
      "step": 22110
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.2309811115264893,
      "learning_rate": 3.672503703703704e-05,
      "loss": 0.1086,
      "step": 22120
    },
    {
      "epoch": 2.46,
      "grad_norm": 7.499702453613281,
      "learning_rate": 3.672355555555556e-05,
      "loss": 0.1165,
      "step": 22130
    },
    {
      "epoch": 2.46,
      "grad_norm": 10.496139526367188,
      "learning_rate": 3.6722074074074076e-05,
      "loss": 0.1407,
      "step": 22140
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.255756378173828,
      "learning_rate": 3.67205925925926e-05,
      "loss": 0.1887,
      "step": 22150
    },
    {
      "epoch": 2.46,
      "grad_norm": 30.55783462524414,
      "learning_rate": 3.6719111111111114e-05,
      "loss": 0.1582,
      "step": 22160
    },
    {
      "epoch": 2.46,
      "grad_norm": 4.229049205780029,
      "learning_rate": 3.671762962962963e-05,
      "loss": 0.1516,
      "step": 22170
    },
    {
      "epoch": 2.46,
      "grad_norm": 4.570924758911133,
      "learning_rate": 3.6716148148148147e-05,
      "loss": 0.1652,
      "step": 22180
    },
    {
      "epoch": 2.47,
      "grad_norm": 10.824444770812988,
      "learning_rate": 3.671466666666667e-05,
      "loss": 0.1916,
      "step": 22190
    },
    {
      "epoch": 2.47,
      "grad_norm": 4.1878862380981445,
      "learning_rate": 3.671318518518519e-05,
      "loss": 0.3564,
      "step": 22200
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.826570510864258,
      "learning_rate": 3.671170370370371e-05,
      "loss": 0.1792,
      "step": 22210
    },
    {
      "epoch": 2.47,
      "grad_norm": 5.263749599456787,
      "learning_rate": 3.6710222222222224e-05,
      "loss": 0.1851,
      "step": 22220
    },
    {
      "epoch": 2.47,
      "grad_norm": 6.162879467010498,
      "learning_rate": 3.670874074074074e-05,
      "loss": 0.1439,
      "step": 22230
    },
    {
      "epoch": 2.47,
      "grad_norm": 5.140616416931152,
      "learning_rate": 3.670725925925926e-05,
      "loss": 0.1294,
      "step": 22240
    },
    {
      "epoch": 2.47,
      "grad_norm": 6.413549900054932,
      "learning_rate": 3.670577777777778e-05,
      "loss": 0.135,
      "step": 22250
    },
    {
      "epoch": 2.47,
      "grad_norm": 6.039766788482666,
      "learning_rate": 3.67042962962963e-05,
      "loss": 0.1436,
      "step": 22260
    },
    {
      "epoch": 2.47,
      "grad_norm": 4.120485782623291,
      "learning_rate": 3.670281481481482e-05,
      "loss": 0.1332,
      "step": 22270
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.36944580078125,
      "learning_rate": 3.6701333333333334e-05,
      "loss": 0.2827,
      "step": 22280
    },
    {
      "epoch": 2.48,
      "grad_norm": 4.115939140319824,
      "learning_rate": 3.669985185185185e-05,
      "loss": 0.1476,
      "step": 22290
    },
    {
      "epoch": 2.48,
      "grad_norm": 4.065490245819092,
      "learning_rate": 3.669837037037037e-05,
      "loss": 0.1728,
      "step": 22300
    },
    {
      "epoch": 2.48,
      "grad_norm": 8.066642761230469,
      "learning_rate": 3.6696888888888895e-05,
      "loss": 0.1848,
      "step": 22310
    },
    {
      "epoch": 2.48,
      "grad_norm": 5.231774806976318,
      "learning_rate": 3.669540740740741e-05,
      "loss": 0.1883,
      "step": 22320
    },
    {
      "epoch": 2.48,
      "grad_norm": 5.852473258972168,
      "learning_rate": 3.669392592592593e-05,
      "loss": 0.2039,
      "step": 22330
    },
    {
      "epoch": 2.48,
      "grad_norm": 6.319518566131592,
      "learning_rate": 3.6692444444444444e-05,
      "loss": 0.1293,
      "step": 22340
    },
    {
      "epoch": 2.48,
      "grad_norm": 4.666987895965576,
      "learning_rate": 3.6690962962962966e-05,
      "loss": 0.1289,
      "step": 22350
    },
    {
      "epoch": 2.48,
      "grad_norm": 6.08138370513916,
      "learning_rate": 3.668948148148149e-05,
      "loss": 0.228,
      "step": 22360
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.483366012573242,
      "learning_rate": 3.6688000000000005e-05,
      "loss": 0.2079,
      "step": 22370
    },
    {
      "epoch": 2.49,
      "grad_norm": 4.701045513153076,
      "learning_rate": 3.668651851851852e-05,
      "loss": 0.1665,
      "step": 22380
    },
    {
      "epoch": 2.49,
      "grad_norm": 4.364370346069336,
      "learning_rate": 3.668503703703704e-05,
      "loss": 0.1571,
      "step": 22390
    },
    {
      "epoch": 2.49,
      "grad_norm": 5.477409839630127,
      "learning_rate": 3.668355555555556e-05,
      "loss": 0.2742,
      "step": 22400
    },
    {
      "epoch": 2.49,
      "grad_norm": 6.257665634155273,
      "learning_rate": 3.6682074074074076e-05,
      "loss": 0.104,
      "step": 22410
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.3734445571899414,
      "learning_rate": 3.66805925925926e-05,
      "loss": 0.1766,
      "step": 22420
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.741055488586426,
      "learning_rate": 3.6679111111111115e-05,
      "loss": 0.1872,
      "step": 22430
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.287705898284912,
      "learning_rate": 3.667762962962963e-05,
      "loss": 0.1602,
      "step": 22440
    },
    {
      "epoch": 2.49,
      "grad_norm": 6.212148666381836,
      "learning_rate": 3.667614814814815e-05,
      "loss": 0.1877,
      "step": 22450
    },
    {
      "epoch": 2.5,
      "grad_norm": 8.544134140014648,
      "learning_rate": 3.667466666666667e-05,
      "loss": 0.2168,
      "step": 22460
    },
    {
      "epoch": 2.5,
      "grad_norm": 16.389402389526367,
      "learning_rate": 3.6673333333333333e-05,
      "loss": 0.231,
      "step": 22470
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.4179251194000244,
      "learning_rate": 3.6671851851851856e-05,
      "loss": 0.1033,
      "step": 22480
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.728844165802002,
      "learning_rate": 3.667037037037037e-05,
      "loss": 0.1316,
      "step": 22490
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.895745277404785,
      "learning_rate": 3.666888888888889e-05,
      "loss": 0.17,
      "step": 22500
    },
    {
      "epoch": 2.5,
      "grad_norm": 6.321317195892334,
      "learning_rate": 3.666740740740741e-05,
      "loss": 0.1327,
      "step": 22510
    },
    {
      "epoch": 2.5,
      "grad_norm": 5.100096702575684,
      "learning_rate": 3.666592592592593e-05,
      "loss": 0.1168,
      "step": 22520
    },
    {
      "epoch": 2.5,
      "grad_norm": 6.51657247543335,
      "learning_rate": 3.666444444444445e-05,
      "loss": 0.1373,
      "step": 22530
    },
    {
      "epoch": 2.5,
      "grad_norm": 7.959985256195068,
      "learning_rate": 3.6662962962962966e-05,
      "loss": 0.1991,
      "step": 22540
    },
    {
      "epoch": 2.51,
      "grad_norm": 4.679101467132568,
      "learning_rate": 3.666148148148148e-05,
      "loss": 0.1417,
      "step": 22550
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.778778076171875,
      "learning_rate": 3.6660000000000005e-05,
      "loss": 0.1562,
      "step": 22560
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.824251413345337,
      "learning_rate": 3.665851851851852e-05,
      "loss": 0.2188,
      "step": 22570
    },
    {
      "epoch": 2.51,
      "grad_norm": 8.729702949523926,
      "learning_rate": 3.6657037037037044e-05,
      "loss": 0.1418,
      "step": 22580
    },
    {
      "epoch": 2.51,
      "grad_norm": 4.5920233726501465,
      "learning_rate": 3.665555555555556e-05,
      "loss": 0.2132,
      "step": 22590
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.5525705814361572,
      "learning_rate": 3.6654074074074076e-05,
      "loss": 0.1432,
      "step": 22600
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.0502989292144775,
      "learning_rate": 3.66525925925926e-05,
      "loss": 0.1363,
      "step": 22610
    },
    {
      "epoch": 2.51,
      "grad_norm": 9.30213737487793,
      "learning_rate": 3.6651111111111114e-05,
      "loss": 0.168,
      "step": 22620
    },
    {
      "epoch": 2.51,
      "grad_norm": 5.254415512084961,
      "learning_rate": 3.664962962962963e-05,
      "loss": 0.1696,
      "step": 22630
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.023953676223755,
      "learning_rate": 3.664814814814815e-05,
      "loss": 0.1715,
      "step": 22640
    },
    {
      "epoch": 2.52,
      "grad_norm": 5.701396465301514,
      "learning_rate": 3.664666666666667e-05,
      "loss": 0.1493,
      "step": 22650
    },
    {
      "epoch": 2.52,
      "grad_norm": 4.242996692657471,
      "learning_rate": 3.6645185185185185e-05,
      "loss": 0.1639,
      "step": 22660
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.3461928367614746,
      "learning_rate": 3.664370370370371e-05,
      "loss": 0.134,
      "step": 22670
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.8201897144317627,
      "learning_rate": 3.6642222222222224e-05,
      "loss": 0.153,
      "step": 22680
    },
    {
      "epoch": 2.52,
      "grad_norm": 4.236590385437012,
      "learning_rate": 3.664074074074075e-05,
      "loss": 0.1397,
      "step": 22690
    },
    {
      "epoch": 2.52,
      "grad_norm": 4.126434326171875,
      "learning_rate": 3.663925925925926e-05,
      "loss": 0.1228,
      "step": 22700
    },
    {
      "epoch": 2.52,
      "grad_norm": 11.603171348571777,
      "learning_rate": 3.663777777777778e-05,
      "loss": 0.1191,
      "step": 22710
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.7348172664642334,
      "learning_rate": 3.66362962962963e-05,
      "loss": 0.0769,
      "step": 22720
    },
    {
      "epoch": 2.53,
      "grad_norm": 4.153537750244141,
      "learning_rate": 3.663481481481482e-05,
      "loss": 0.1246,
      "step": 22730
    },
    {
      "epoch": 2.53,
      "grad_norm": 2.933446168899536,
      "learning_rate": 3.663333333333334e-05,
      "loss": 0.1254,
      "step": 22740
    },
    {
      "epoch": 2.53,
      "grad_norm": 2.38765287399292,
      "learning_rate": 3.663185185185186e-05,
      "loss": 0.1346,
      "step": 22750
    },
    {
      "epoch": 2.53,
      "grad_norm": 6.034593105316162,
      "learning_rate": 3.663037037037037e-05,
      "loss": 0.1694,
      "step": 22760
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.904473304748535,
      "learning_rate": 3.662888888888889e-05,
      "loss": 0.1639,
      "step": 22770
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.9042861461639404,
      "learning_rate": 3.662740740740741e-05,
      "loss": 0.1406,
      "step": 22780
    },
    {
      "epoch": 2.53,
      "grad_norm": 8.79568099975586,
      "learning_rate": 3.662592592592593e-05,
      "loss": 0.1499,
      "step": 22790
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.832542896270752,
      "learning_rate": 3.662444444444445e-05,
      "loss": 0.1444,
      "step": 22800
    },
    {
      "epoch": 2.53,
      "grad_norm": 7.9429497718811035,
      "learning_rate": 3.6622962962962966e-05,
      "loss": 0.1313,
      "step": 22810
    },
    {
      "epoch": 2.54,
      "grad_norm": 5.121323585510254,
      "learning_rate": 3.662148148148148e-05,
      "loss": 0.1212,
      "step": 22820
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.2146730422973633,
      "learning_rate": 3.6620000000000005e-05,
      "loss": 0.1171,
      "step": 22830
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.544347286224365,
      "learning_rate": 3.661851851851852e-05,
      "loss": 0.1264,
      "step": 22840
    },
    {
      "epoch": 2.54,
      "grad_norm": 5.550280570983887,
      "learning_rate": 3.6617037037037044e-05,
      "loss": 0.1327,
      "step": 22850
    },
    {
      "epoch": 2.54,
      "grad_norm": 6.167060375213623,
      "learning_rate": 3.661555555555556e-05,
      "loss": 0.153,
      "step": 22860
    },
    {
      "epoch": 2.54,
      "grad_norm": 8.192483901977539,
      "learning_rate": 3.6614074074074076e-05,
      "loss": 0.1989,
      "step": 22870
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.799616575241089,
      "learning_rate": 3.661259259259259e-05,
      "loss": 0.143,
      "step": 22880
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.520330905914307,
      "learning_rate": 3.6611111111111115e-05,
      "loss": 0.2363,
      "step": 22890
    },
    {
      "epoch": 2.54,
      "grad_norm": 5.1227641105651855,
      "learning_rate": 3.660962962962963e-05,
      "loss": 0.162,
      "step": 22900
    },
    {
      "epoch": 2.55,
      "grad_norm": 6.5000224113464355,
      "learning_rate": 3.6608148148148154e-05,
      "loss": 0.1833,
      "step": 22910
    },
    {
      "epoch": 2.55,
      "grad_norm": 4.25619649887085,
      "learning_rate": 3.660666666666667e-05,
      "loss": 0.0853,
      "step": 22920
    },
    {
      "epoch": 2.55,
      "grad_norm": 7.8766655921936035,
      "learning_rate": 3.6605185185185186e-05,
      "loss": 0.1377,
      "step": 22930
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.9598031044006348,
      "learning_rate": 3.660370370370371e-05,
      "loss": 0.1625,
      "step": 22940
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.258199691772461,
      "learning_rate": 3.6602222222222225e-05,
      "loss": 0.1956,
      "step": 22950
    },
    {
      "epoch": 2.55,
      "grad_norm": 5.956855297088623,
      "learning_rate": 3.660074074074075e-05,
      "loss": 0.1987,
      "step": 22960
    },
    {
      "epoch": 2.55,
      "grad_norm": 6.147748947143555,
      "learning_rate": 3.659925925925926e-05,
      "loss": 0.1829,
      "step": 22970
    },
    {
      "epoch": 2.55,
      "grad_norm": 5.865852355957031,
      "learning_rate": 3.659777777777778e-05,
      "loss": 0.12,
      "step": 22980
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.3432624340057373,
      "learning_rate": 3.6596296296296295e-05,
      "loss": 0.1007,
      "step": 22990
    },
    {
      "epoch": 2.56,
      "grad_norm": 7.289905548095703,
      "learning_rate": 3.659481481481482e-05,
      "loss": 0.1388,
      "step": 23000
    },
    {
      "epoch": 2.56,
      "grad_norm": 4.239346027374268,
      "learning_rate": 3.659333333333334e-05,
      "loss": 0.1519,
      "step": 23010
    },
    {
      "epoch": 2.56,
      "grad_norm": 4.378974437713623,
      "learning_rate": 3.659185185185186e-05,
      "loss": 0.1265,
      "step": 23020
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.4544591903686523,
      "learning_rate": 3.659037037037037e-05,
      "loss": 0.1063,
      "step": 23030
    },
    {
      "epoch": 2.56,
      "grad_norm": 5.649878025054932,
      "learning_rate": 3.658888888888889e-05,
      "loss": 0.1314,
      "step": 23040
    },
    {
      "epoch": 2.56,
      "grad_norm": 4.7859015464782715,
      "learning_rate": 3.658740740740741e-05,
      "loss": 0.0987,
      "step": 23050
    },
    {
      "epoch": 2.56,
      "grad_norm": 5.2940568923950195,
      "learning_rate": 3.658592592592593e-05,
      "loss": 0.1066,
      "step": 23060
    },
    {
      "epoch": 2.56,
      "grad_norm": 4.186454772949219,
      "learning_rate": 3.658444444444445e-05,
      "loss": 0.1741,
      "step": 23070
    },
    {
      "epoch": 2.56,
      "grad_norm": 5.090880393981934,
      "learning_rate": 3.658296296296297e-05,
      "loss": 0.135,
      "step": 23080
    },
    {
      "epoch": 2.57,
      "grad_norm": 5.011006832122803,
      "learning_rate": 3.658148148148148e-05,
      "loss": 0.1305,
      "step": 23090
    },
    {
      "epoch": 2.57,
      "grad_norm": 3.6104114055633545,
      "learning_rate": 3.6580000000000006e-05,
      "loss": 0.1435,
      "step": 23100
    },
    {
      "epoch": 2.57,
      "grad_norm": 3.5331082344055176,
      "learning_rate": 3.657851851851852e-05,
      "loss": 0.1882,
      "step": 23110
    },
    {
      "epoch": 2.57,
      "grad_norm": 3.0259664058685303,
      "learning_rate": 3.6577037037037044e-05,
      "loss": 0.1345,
      "step": 23120
    },
    {
      "epoch": 2.57,
      "grad_norm": 4.740349769592285,
      "learning_rate": 3.657555555555556e-05,
      "loss": 0.118,
      "step": 23130
    },
    {
      "epoch": 2.57,
      "grad_norm": 5.015686988830566,
      "learning_rate": 3.6574074074074076e-05,
      "loss": 0.21,
      "step": 23140
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.6466031074523926,
      "learning_rate": 3.657259259259259e-05,
      "loss": 0.1578,
      "step": 23150
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.8712106943130493,
      "learning_rate": 3.6571111111111115e-05,
      "loss": 0.1494,
      "step": 23160
    },
    {
      "epoch": 2.57,
      "grad_norm": 5.046088695526123,
      "learning_rate": 3.656962962962963e-05,
      "loss": 0.0989,
      "step": 23170
    },
    {
      "epoch": 2.58,
      "grad_norm": 11.153037071228027,
      "learning_rate": 3.6568148148148154e-05,
      "loss": 0.1297,
      "step": 23180
    },
    {
      "epoch": 2.58,
      "grad_norm": 5.296872615814209,
      "learning_rate": 3.656666666666667e-05,
      "loss": 0.1344,
      "step": 23190
    },
    {
      "epoch": 2.58,
      "grad_norm": 4.738117694854736,
      "learning_rate": 3.6565185185185186e-05,
      "loss": 0.169,
      "step": 23200
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.5765273571014404,
      "learning_rate": 3.656370370370371e-05,
      "loss": 0.1652,
      "step": 23210
    },
    {
      "epoch": 2.58,
      "grad_norm": 7.164355278015137,
      "learning_rate": 3.6562222222222225e-05,
      "loss": 0.1169,
      "step": 23220
    },
    {
      "epoch": 2.58,
      "grad_norm": 4.3632893562316895,
      "learning_rate": 3.656074074074075e-05,
      "loss": 0.1214,
      "step": 23230
    },
    {
      "epoch": 2.58,
      "grad_norm": 1.202051043510437,
      "learning_rate": 3.6559259259259264e-05,
      "loss": 0.1008,
      "step": 23240
    },
    {
      "epoch": 2.58,
      "grad_norm": 7.517845630645752,
      "learning_rate": 3.655777777777778e-05,
      "loss": 0.1899,
      "step": 23250
    },
    {
      "epoch": 2.58,
      "grad_norm": 4.764884948730469,
      "learning_rate": 3.6556296296296296e-05,
      "loss": 0.1405,
      "step": 23260
    },
    {
      "epoch": 2.59,
      "grad_norm": 5.42442512512207,
      "learning_rate": 3.655481481481482e-05,
      "loss": 0.1382,
      "step": 23270
    },
    {
      "epoch": 2.59,
      "grad_norm": 4.027772903442383,
      "learning_rate": 3.655333333333334e-05,
      "loss": 0.1093,
      "step": 23280
    },
    {
      "epoch": 2.59,
      "grad_norm": 5.160824298858643,
      "learning_rate": 3.655185185185186e-05,
      "loss": 0.1899,
      "step": 23290
    },
    {
      "epoch": 2.59,
      "grad_norm": 4.236495018005371,
      "learning_rate": 3.6550370370370373e-05,
      "loss": 0.1488,
      "step": 23300
    },
    {
      "epoch": 2.59,
      "grad_norm": 1.8960634469985962,
      "learning_rate": 3.654888888888889e-05,
      "loss": 0.1339,
      "step": 23310
    },
    {
      "epoch": 2.59,
      "grad_norm": 8.770813941955566,
      "learning_rate": 3.654740740740741e-05,
      "loss": 0.1769,
      "step": 23320
    },
    {
      "epoch": 2.59,
      "grad_norm": 4.690045356750488,
      "learning_rate": 3.654592592592593e-05,
      "loss": 0.1134,
      "step": 23330
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.9459652304649353,
      "learning_rate": 3.654444444444445e-05,
      "loss": 0.1155,
      "step": 23340
    },
    {
      "epoch": 2.59,
      "grad_norm": 3.245678663253784,
      "learning_rate": 3.654296296296297e-05,
      "loss": 0.0672,
      "step": 23350
    },
    {
      "epoch": 2.6,
      "grad_norm": 5.28546667098999,
      "learning_rate": 3.654148148148148e-05,
      "loss": 0.1464,
      "step": 23360
    },
    {
      "epoch": 2.6,
      "grad_norm": 6.809525489807129,
      "learning_rate": 3.654e-05,
      "loss": 0.2535,
      "step": 23370
    },
    {
      "epoch": 2.6,
      "grad_norm": 6.568632125854492,
      "learning_rate": 3.653851851851852e-05,
      "loss": 0.1874,
      "step": 23380
    },
    {
      "epoch": 2.6,
      "grad_norm": 8.377902030944824,
      "learning_rate": 3.6537037037037045e-05,
      "loss": 0.1359,
      "step": 23390
    },
    {
      "epoch": 2.6,
      "grad_norm": 5.182032585144043,
      "learning_rate": 3.653555555555556e-05,
      "loss": 0.1702,
      "step": 23400
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.501002311706543,
      "learning_rate": 3.653407407407408e-05,
      "loss": 0.0996,
      "step": 23410
    },
    {
      "epoch": 2.6,
      "grad_norm": 8.647382736206055,
      "learning_rate": 3.653259259259259e-05,
      "loss": 0.1203,
      "step": 23420
    },
    {
      "epoch": 2.6,
      "grad_norm": 15.083319664001465,
      "learning_rate": 3.6531111111111116e-05,
      "loss": 0.0893,
      "step": 23430
    },
    {
      "epoch": 2.6,
      "grad_norm": 6.745669841766357,
      "learning_rate": 3.652962962962963e-05,
      "loss": 0.1538,
      "step": 23440
    },
    {
      "epoch": 2.61,
      "grad_norm": 6.784995079040527,
      "learning_rate": 3.6528148148148154e-05,
      "loss": 0.2251,
      "step": 23450
    },
    {
      "epoch": 2.61,
      "grad_norm": 4.0986151695251465,
      "learning_rate": 3.652666666666667e-05,
      "loss": 0.1132,
      "step": 23460
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.8595284819602966,
      "learning_rate": 3.6525185185185186e-05,
      "loss": 0.1066,
      "step": 23470
    },
    {
      "epoch": 2.61,
      "grad_norm": 12.637909889221191,
      "learning_rate": 3.65237037037037e-05,
      "loss": 0.1344,
      "step": 23480
    },
    {
      "epoch": 2.61,
      "grad_norm": 4.573282718658447,
      "learning_rate": 3.6522222222222225e-05,
      "loss": 0.134,
      "step": 23490
    },
    {
      "epoch": 2.61,
      "grad_norm": 4.564329147338867,
      "learning_rate": 3.652074074074075e-05,
      "loss": 0.1623,
      "step": 23500
    },
    {
      "epoch": 2.61,
      "grad_norm": 3.4461004734039307,
      "learning_rate": 3.6519259259259264e-05,
      "loss": 0.1627,
      "step": 23510
    },
    {
      "epoch": 2.61,
      "grad_norm": 3.485738515853882,
      "learning_rate": 3.651777777777778e-05,
      "loss": 0.1296,
      "step": 23520
    },
    {
      "epoch": 2.61,
      "grad_norm": 7.214849948883057,
      "learning_rate": 3.6516296296296296e-05,
      "loss": 0.2709,
      "step": 23530
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.980832815170288,
      "learning_rate": 3.651481481481482e-05,
      "loss": 0.1545,
      "step": 23540
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.734438419342041,
      "learning_rate": 3.651333333333334e-05,
      "loss": 0.1035,
      "step": 23550
    },
    {
      "epoch": 2.62,
      "grad_norm": 7.128347396850586,
      "learning_rate": 3.651185185185186e-05,
      "loss": 0.1504,
      "step": 23560
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.5820939540863037,
      "learning_rate": 3.6510370370370374e-05,
      "loss": 0.0864,
      "step": 23570
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.5132415294647217,
      "learning_rate": 3.650888888888889e-05,
      "loss": 0.0947,
      "step": 23580
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.496229648590088,
      "learning_rate": 3.6507407407407406e-05,
      "loss": 0.113,
      "step": 23590
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.2182118892669678,
      "learning_rate": 3.650592592592593e-05,
      "loss": 0.1132,
      "step": 23600
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.4860548973083496,
      "learning_rate": 3.650444444444445e-05,
      "loss": 0.122,
      "step": 23610
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.6392784118652344,
      "learning_rate": 3.650296296296297e-05,
      "loss": 0.1375,
      "step": 23620
    },
    {
      "epoch": 2.63,
      "grad_norm": 3.328803300857544,
      "learning_rate": 3.6501481481481483e-05,
      "loss": 0.1459,
      "step": 23630
    },
    {
      "epoch": 2.63,
      "grad_norm": 9.43816089630127,
      "learning_rate": 3.65e-05,
      "loss": 0.1186,
      "step": 23640
    },
    {
      "epoch": 2.63,
      "grad_norm": 4.52034330368042,
      "learning_rate": 3.649851851851852e-05,
      "loss": 0.103,
      "step": 23650
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.5785434246063232,
      "learning_rate": 3.6497037037037045e-05,
      "loss": 0.134,
      "step": 23660
    },
    {
      "epoch": 2.63,
      "grad_norm": 5.132134437561035,
      "learning_rate": 3.649555555555556e-05,
      "loss": 0.1143,
      "step": 23670
    },
    {
      "epoch": 2.63,
      "grad_norm": 8.600895881652832,
      "learning_rate": 3.649407407407408e-05,
      "loss": 0.1624,
      "step": 23680
    },
    {
      "epoch": 2.63,
      "grad_norm": 5.7407708168029785,
      "learning_rate": 3.649259259259259e-05,
      "loss": 0.1319,
      "step": 23690
    },
    {
      "epoch": 2.63,
      "grad_norm": 5.6186628341674805,
      "learning_rate": 3.6491111111111116e-05,
      "loss": 0.0964,
      "step": 23700
    },
    {
      "epoch": 2.63,
      "grad_norm": 6.465671062469482,
      "learning_rate": 3.648962962962963e-05,
      "loss": 0.1917,
      "step": 23710
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.9644644260406494,
      "learning_rate": 3.6488148148148155e-05,
      "loss": 0.1451,
      "step": 23720
    },
    {
      "epoch": 2.64,
      "grad_norm": 6.569754600524902,
      "learning_rate": 3.648666666666667e-05,
      "loss": 0.1078,
      "step": 23730
    },
    {
      "epoch": 2.64,
      "grad_norm": 9.506814002990723,
      "learning_rate": 3.648518518518519e-05,
      "loss": 0.1461,
      "step": 23740
    },
    {
      "epoch": 2.64,
      "grad_norm": 7.576257228851318,
      "learning_rate": 3.64837037037037e-05,
      "loss": 0.2189,
      "step": 23750
    },
    {
      "epoch": 2.64,
      "grad_norm": 4.213441848754883,
      "learning_rate": 3.6482222222222226e-05,
      "loss": 0.1729,
      "step": 23760
    },
    {
      "epoch": 2.64,
      "grad_norm": 6.164421558380127,
      "learning_rate": 3.648074074074075e-05,
      "loss": 0.1274,
      "step": 23770
    },
    {
      "epoch": 2.64,
      "grad_norm": 5.741630554199219,
      "learning_rate": 3.6479259259259264e-05,
      "loss": 0.1101,
      "step": 23780
    },
    {
      "epoch": 2.64,
      "grad_norm": 7.231008529663086,
      "learning_rate": 3.647777777777778e-05,
      "loss": 0.1421,
      "step": 23790
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.1138017177581787,
      "learning_rate": 3.6476296296296297e-05,
      "loss": 0.1189,
      "step": 23800
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.8068654537200928,
      "learning_rate": 3.647481481481482e-05,
      "loss": 0.1245,
      "step": 23810
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.163304090499878,
      "learning_rate": 3.6473333333333335e-05,
      "loss": 0.1544,
      "step": 23820
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.6737998723983765,
      "learning_rate": 3.647185185185186e-05,
      "loss": 0.1358,
      "step": 23830
    },
    {
      "epoch": 2.65,
      "grad_norm": 6.744998455047607,
      "learning_rate": 3.6470370370370374e-05,
      "loss": 0.2058,
      "step": 23840
    },
    {
      "epoch": 2.65,
      "grad_norm": 4.356563568115234,
      "learning_rate": 3.646888888888889e-05,
      "loss": 0.1578,
      "step": 23850
    },
    {
      "epoch": 2.65,
      "grad_norm": 4.265315532684326,
      "learning_rate": 3.6467407407407406e-05,
      "loss": 0.135,
      "step": 23860
    },
    {
      "epoch": 2.65,
      "grad_norm": 3.7863681316375732,
      "learning_rate": 3.646592592592593e-05,
      "loss": 0.146,
      "step": 23870
    },
    {
      "epoch": 2.65,
      "grad_norm": 5.778019905090332,
      "learning_rate": 3.646444444444445e-05,
      "loss": 0.1416,
      "step": 23880
    },
    {
      "epoch": 2.65,
      "grad_norm": 3.114736795425415,
      "learning_rate": 3.646296296296297e-05,
      "loss": 0.1683,
      "step": 23890
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.8932706117630005,
      "learning_rate": 3.6461481481481484e-05,
      "loss": 0.1188,
      "step": 23900
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.6966896057128906,
      "learning_rate": 3.646e-05,
      "loss": 0.1272,
      "step": 23910
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.7996017932891846,
      "learning_rate": 3.645851851851852e-05,
      "loss": 0.1663,
      "step": 23920
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.779496431350708,
      "learning_rate": 3.645703703703704e-05,
      "loss": 0.0926,
      "step": 23930
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.8786075115203857,
      "learning_rate": 3.645555555555556e-05,
      "loss": 0.1475,
      "step": 23940
    },
    {
      "epoch": 2.66,
      "grad_norm": 5.724342346191406,
      "learning_rate": 3.645407407407408e-05,
      "loss": 0.0825,
      "step": 23950
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.231832265853882,
      "learning_rate": 3.6452592592592594e-05,
      "loss": 0.1019,
      "step": 23960
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.8850462436676025,
      "learning_rate": 3.645111111111111e-05,
      "loss": 0.1369,
      "step": 23970
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.4427897930145264,
      "learning_rate": 3.644962962962963e-05,
      "loss": 0.1179,
      "step": 23980
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.9290802478790283,
      "learning_rate": 3.6448148148148155e-05,
      "loss": 0.1509,
      "step": 23990
    },
    {
      "epoch": 2.67,
      "grad_norm": 5.21633243560791,
      "learning_rate": 3.644666666666667e-05,
      "loss": 0.1548,
      "step": 24000
    },
    {
      "epoch": 2.67,
      "eval_cer": 0.02246607183485731,
      "eval_loss": 0.22889390587806702,
      "eval_runtime": 1959.0734,
      "eval_samples_per_second": 4.084,
      "eval_steps_per_second": 0.51,
      "eval_wer": 0.05446879212514499,
      "step": 24000
    },
    {
      "epoch": 2.67,
      "grad_norm": 6.319427013397217,
      "learning_rate": 3.644518518518519e-05,
      "loss": 0.0857,
      "step": 24010
    },
    {
      "epoch": 2.67,
      "grad_norm": 5.6445207595825195,
      "learning_rate": 3.64437037037037e-05,
      "loss": 0.1312,
      "step": 24020
    },
    {
      "epoch": 2.67,
      "grad_norm": 5.04653263092041,
      "learning_rate": 3.6442222222222226e-05,
      "loss": 0.1103,
      "step": 24030
    },
    {
      "epoch": 2.67,
      "grad_norm": 5.321788311004639,
      "learning_rate": 3.644074074074074e-05,
      "loss": 0.1262,
      "step": 24040
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.528766632080078,
      "learning_rate": 3.6439259259259265e-05,
      "loss": 0.2799,
      "step": 24050
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.9792990684509277,
      "learning_rate": 3.643777777777778e-05,
      "loss": 0.1101,
      "step": 24060
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.521632194519043,
      "learning_rate": 3.64362962962963e-05,
      "loss": 0.1082,
      "step": 24070
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.432051658630371,
      "learning_rate": 3.643481481481481e-05,
      "loss": 0.1237,
      "step": 24080
    },
    {
      "epoch": 2.68,
      "grad_norm": 4.365174293518066,
      "learning_rate": 3.6433333333333336e-05,
      "loss": 0.1145,
      "step": 24090
    },
    {
      "epoch": 2.68,
      "grad_norm": 4.341193675994873,
      "learning_rate": 3.643185185185186e-05,
      "loss": 0.1347,
      "step": 24100
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.684141159057617,
      "learning_rate": 3.6430370370370375e-05,
      "loss": 0.0964,
      "step": 24110
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.5487431287765503,
      "learning_rate": 3.642888888888889e-05,
      "loss": 0.1437,
      "step": 24120
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.217578172683716,
      "learning_rate": 3.6427407407407407e-05,
      "loss": 0.1918,
      "step": 24130
    },
    {
      "epoch": 2.68,
      "grad_norm": 4.2293572425842285,
      "learning_rate": 3.642592592592593e-05,
      "loss": 0.1274,
      "step": 24140
    },
    {
      "epoch": 2.68,
      "grad_norm": 8.01664924621582,
      "learning_rate": 3.642444444444445e-05,
      "loss": 0.1486,
      "step": 24150
    },
    {
      "epoch": 2.68,
      "grad_norm": 4.524827480316162,
      "learning_rate": 3.642296296296297e-05,
      "loss": 0.1549,
      "step": 24160
    },
    {
      "epoch": 2.69,
      "grad_norm": 7.563170909881592,
      "learning_rate": 3.6421481481481484e-05,
      "loss": 0.1364,
      "step": 24170
    },
    {
      "epoch": 2.69,
      "grad_norm": 4.038071632385254,
      "learning_rate": 3.642e-05,
      "loss": 0.1153,
      "step": 24180
    },
    {
      "epoch": 2.69,
      "grad_norm": 1.590304970741272,
      "learning_rate": 3.641851851851852e-05,
      "loss": 0.1497,
      "step": 24190
    },
    {
      "epoch": 2.69,
      "grad_norm": 6.057286262512207,
      "learning_rate": 3.641703703703704e-05,
      "loss": 0.17,
      "step": 24200
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.505535840988159,
      "learning_rate": 3.641555555555556e-05,
      "loss": 0.1849,
      "step": 24210
    },
    {
      "epoch": 2.69,
      "grad_norm": 3.9798784255981445,
      "learning_rate": 3.641407407407408e-05,
      "loss": 0.1413,
      "step": 24220
    },
    {
      "epoch": 2.69,
      "grad_norm": 4.242466449737549,
      "learning_rate": 3.6412592592592594e-05,
      "loss": 0.1644,
      "step": 24230
    },
    {
      "epoch": 2.69,
      "grad_norm": 3.5441031455993652,
      "learning_rate": 3.641111111111111e-05,
      "loss": 0.1849,
      "step": 24240
    },
    {
      "epoch": 2.69,
      "grad_norm": 4.441892623901367,
      "learning_rate": 3.640962962962963e-05,
      "loss": 0.117,
      "step": 24250
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.724120855331421,
      "learning_rate": 3.6408148148148156e-05,
      "loss": 0.1562,
      "step": 24260
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.651416063308716,
      "learning_rate": 3.640666666666667e-05,
      "loss": 0.141,
      "step": 24270
    },
    {
      "epoch": 2.7,
      "grad_norm": 5.152577877044678,
      "learning_rate": 3.640518518518519e-05,
      "loss": 0.1255,
      "step": 24280
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.4815640449523926,
      "learning_rate": 3.6403703703703704e-05,
      "loss": 0.1576,
      "step": 24290
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.9859087467193604,
      "learning_rate": 3.6402222222222226e-05,
      "loss": 0.1721,
      "step": 24300
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.8418362140655518,
      "learning_rate": 3.640074074074074e-05,
      "loss": 0.1532,
      "step": 24310
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.275785207748413,
      "learning_rate": 3.6399259259259265e-05,
      "loss": 0.0952,
      "step": 24320
    },
    {
      "epoch": 2.7,
      "grad_norm": 5.303145885467529,
      "learning_rate": 3.639777777777778e-05,
      "loss": 0.1093,
      "step": 24330
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.942319393157959,
      "learning_rate": 3.63962962962963e-05,
      "loss": 0.1198,
      "step": 24340
    },
    {
      "epoch": 2.71,
      "grad_norm": 7.111110687255859,
      "learning_rate": 3.639481481481481e-05,
      "loss": 0.1551,
      "step": 24350
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.5515317916870117,
      "learning_rate": 3.6393333333333336e-05,
      "loss": 0.0986,
      "step": 24360
    },
    {
      "epoch": 2.71,
      "grad_norm": 11.236434936523438,
      "learning_rate": 3.639185185185186e-05,
      "loss": 0.1692,
      "step": 24370
    },
    {
      "epoch": 2.71,
      "grad_norm": 4.458117961883545,
      "learning_rate": 3.6390370370370375e-05,
      "loss": 0.1503,
      "step": 24380
    },
    {
      "epoch": 2.71,
      "grad_norm": 5.566336154937744,
      "learning_rate": 3.638888888888889e-05,
      "loss": 0.1211,
      "step": 24390
    },
    {
      "epoch": 2.71,
      "grad_norm": 10.33338737487793,
      "learning_rate": 3.638740740740741e-05,
      "loss": 0.1069,
      "step": 24400
    },
    {
      "epoch": 2.71,
      "grad_norm": 4.750764846801758,
      "learning_rate": 3.638592592592593e-05,
      "loss": 0.1582,
      "step": 24410
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.9479987621307373,
      "learning_rate": 3.6384444444444446e-05,
      "loss": 0.1299,
      "step": 24420
    },
    {
      "epoch": 2.71,
      "grad_norm": 5.142323017120361,
      "learning_rate": 3.638296296296297e-05,
      "loss": 0.1331,
      "step": 24430
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.2487144470214844,
      "learning_rate": 3.6381481481481485e-05,
      "loss": 0.1159,
      "step": 24440
    },
    {
      "epoch": 2.72,
      "grad_norm": 5.18833589553833,
      "learning_rate": 3.638e-05,
      "loss": 0.1638,
      "step": 24450
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.5325927734375,
      "learning_rate": 3.637851851851852e-05,
      "loss": 0.119,
      "step": 24460
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.563469171524048,
      "learning_rate": 3.637703703703704e-05,
      "loss": 0.122,
      "step": 24470
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.1893482208251953,
      "learning_rate": 3.637555555555556e-05,
      "loss": 0.1164,
      "step": 24480
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.1016199588775635,
      "learning_rate": 3.637407407407408e-05,
      "loss": 0.1312,
      "step": 24490
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.6784989833831787,
      "learning_rate": 3.6372592592592594e-05,
      "loss": 0.1473,
      "step": 24500
    },
    {
      "epoch": 2.72,
      "grad_norm": 5.9094390869140625,
      "learning_rate": 3.637111111111111e-05,
      "loss": 0.1585,
      "step": 24510
    },
    {
      "epoch": 2.72,
      "grad_norm": 1.008065938949585,
      "learning_rate": 3.636962962962963e-05,
      "loss": 0.1003,
      "step": 24520
    },
    {
      "epoch": 2.73,
      "grad_norm": 7.89514684677124,
      "learning_rate": 3.636814814814815e-05,
      "loss": 0.1207,
      "step": 24530
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.7287801504135132,
      "learning_rate": 3.636666666666667e-05,
      "loss": 0.1295,
      "step": 24540
    },
    {
      "epoch": 2.73,
      "grad_norm": 10.164671897888184,
      "learning_rate": 3.636518518518519e-05,
      "loss": 0.147,
      "step": 24550
    },
    {
      "epoch": 2.73,
      "grad_norm": 3.1610708236694336,
      "learning_rate": 3.6363703703703704e-05,
      "loss": 0.1994,
      "step": 24560
    },
    {
      "epoch": 2.73,
      "grad_norm": 5.134650230407715,
      "learning_rate": 3.636222222222222e-05,
      "loss": 0.1682,
      "step": 24570
    },
    {
      "epoch": 2.73,
      "grad_norm": 11.939937591552734,
      "learning_rate": 3.636074074074074e-05,
      "loss": 0.1198,
      "step": 24580
    },
    {
      "epoch": 2.73,
      "grad_norm": 9.399080276489258,
      "learning_rate": 3.6359259259259266e-05,
      "loss": 0.1026,
      "step": 24590
    },
    {
      "epoch": 2.73,
      "grad_norm": 3.069286346435547,
      "learning_rate": 3.635777777777778e-05,
      "loss": 0.1212,
      "step": 24600
    },
    {
      "epoch": 2.73,
      "grad_norm": 4.206995487213135,
      "learning_rate": 3.63562962962963e-05,
      "loss": 0.1555,
      "step": 24610
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.9211409091949463,
      "learning_rate": 3.6354814814814814e-05,
      "loss": 0.1409,
      "step": 24620
    },
    {
      "epoch": 2.74,
      "grad_norm": 5.171745777130127,
      "learning_rate": 3.6353333333333337e-05,
      "loss": 0.1293,
      "step": 24630
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.745845317840576,
      "learning_rate": 3.635185185185186e-05,
      "loss": 0.1608,
      "step": 24640
    },
    {
      "epoch": 2.74,
      "grad_norm": 7.494288921356201,
      "learning_rate": 3.6350370370370375e-05,
      "loss": 0.1421,
      "step": 24650
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.641392230987549,
      "learning_rate": 3.634888888888889e-05,
      "loss": 0.1583,
      "step": 24660
    },
    {
      "epoch": 2.74,
      "grad_norm": 4.941939830780029,
      "learning_rate": 3.634740740740741e-05,
      "loss": 0.124,
      "step": 24670
    },
    {
      "epoch": 2.74,
      "grad_norm": 4.356220722198486,
      "learning_rate": 3.6345925925925923e-05,
      "loss": 0.1223,
      "step": 24680
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.5829122066497803,
      "learning_rate": 3.6344444444444446e-05,
      "loss": 0.1196,
      "step": 24690
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.9303946495056152,
      "learning_rate": 3.634296296296297e-05,
      "loss": 0.1374,
      "step": 24700
    },
    {
      "epoch": 2.75,
      "grad_norm": 4.978567600250244,
      "learning_rate": 3.6341481481481485e-05,
      "loss": 0.1638,
      "step": 24710
    },
    {
      "epoch": 2.75,
      "grad_norm": 7.001963138580322,
      "learning_rate": 3.634e-05,
      "loss": 0.1442,
      "step": 24720
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.1896796226501465,
      "learning_rate": 3.633851851851852e-05,
      "loss": 0.1217,
      "step": 24730
    },
    {
      "epoch": 2.75,
      "grad_norm": 5.026862621307373,
      "learning_rate": 3.633703703703704e-05,
      "loss": 0.1357,
      "step": 24740
    },
    {
      "epoch": 2.75,
      "grad_norm": 8.397210121154785,
      "learning_rate": 3.633555555555556e-05,
      "loss": 0.1169,
      "step": 24750
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.4050452709198,
      "learning_rate": 3.633407407407408e-05,
      "loss": 0.122,
      "step": 24760
    },
    {
      "epoch": 2.75,
      "grad_norm": 4.166116237640381,
      "learning_rate": 3.6332592592592595e-05,
      "loss": 0.1441,
      "step": 24770
    },
    {
      "epoch": 2.75,
      "grad_norm": 6.232882976531982,
      "learning_rate": 3.633111111111111e-05,
      "loss": 0.1981,
      "step": 24780
    },
    {
      "epoch": 2.75,
      "grad_norm": 9.570356369018555,
      "learning_rate": 3.6329629629629634e-05,
      "loss": 0.1072,
      "step": 24790
    },
    {
      "epoch": 2.76,
      "grad_norm": 5.141983985900879,
      "learning_rate": 3.632814814814815e-05,
      "loss": 0.1504,
      "step": 24800
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.329453468322754,
      "learning_rate": 3.632666666666667e-05,
      "loss": 0.1095,
      "step": 24810
    },
    {
      "epoch": 2.76,
      "grad_norm": 6.266613960266113,
      "learning_rate": 3.632518518518519e-05,
      "loss": 0.1815,
      "step": 24820
    },
    {
      "epoch": 2.76,
      "grad_norm": 3.9065768718719482,
      "learning_rate": 3.6323703703703704e-05,
      "loss": 0.2002,
      "step": 24830
    },
    {
      "epoch": 2.76,
      "grad_norm": 3.75019907951355,
      "learning_rate": 3.632222222222222e-05,
      "loss": 0.192,
      "step": 24840
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.382540702819824,
      "learning_rate": 3.632074074074074e-05,
      "loss": 0.162,
      "step": 24850
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.724137783050537,
      "learning_rate": 3.6319259259259266e-05,
      "loss": 0.1101,
      "step": 24860
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.0207695960998535,
      "learning_rate": 3.631777777777778e-05,
      "loss": 0.1654,
      "step": 24870
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.57820200920105,
      "learning_rate": 3.63162962962963e-05,
      "loss": 0.1756,
      "step": 24880
    },
    {
      "epoch": 2.77,
      "grad_norm": 4.161977291107178,
      "learning_rate": 3.6314814814814814e-05,
      "loss": 0.114,
      "step": 24890
    },
    {
      "epoch": 2.77,
      "grad_norm": 7.400020122528076,
      "learning_rate": 3.631333333333334e-05,
      "loss": 0.1031,
      "step": 24900
    },
    {
      "epoch": 2.77,
      "grad_norm": 7.423303127288818,
      "learning_rate": 3.631185185185185e-05,
      "loss": 0.1907,
      "step": 24910
    },
    {
      "epoch": 2.77,
      "grad_norm": 3.964862585067749,
      "learning_rate": 3.6310370370370376e-05,
      "loss": 0.1482,
      "step": 24920
    },
    {
      "epoch": 2.77,
      "grad_norm": 1.8640763759613037,
      "learning_rate": 3.630888888888889e-05,
      "loss": 0.182,
      "step": 24930
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.133240222930908,
      "learning_rate": 3.630740740740741e-05,
      "loss": 0.112,
      "step": 24940
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.547952890396118,
      "learning_rate": 3.6305925925925924e-05,
      "loss": 0.1556,
      "step": 24950
    },
    {
      "epoch": 2.77,
      "grad_norm": 3.8404996395111084,
      "learning_rate": 3.6304444444444447e-05,
      "loss": 0.108,
      "step": 24960
    },
    {
      "epoch": 2.77,
      "grad_norm": 7.7401604652404785,
      "learning_rate": 3.630296296296297e-05,
      "loss": 0.1511,
      "step": 24970
    },
    {
      "epoch": 2.78,
      "grad_norm": 5.5811076164245605,
      "learning_rate": 3.6301481481481485e-05,
      "loss": 0.1366,
      "step": 24980
    },
    {
      "epoch": 2.78,
      "grad_norm": 4.307908535003662,
      "learning_rate": 3.63e-05,
      "loss": 0.0905,
      "step": 24990
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.9915878772735596,
      "learning_rate": 3.629851851851852e-05,
      "loss": 0.1379,
      "step": 25000
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.084109306335449,
      "learning_rate": 3.629703703703704e-05,
      "loss": 0.1324,
      "step": 25010
    },
    {
      "epoch": 2.78,
      "grad_norm": 4.938820838928223,
      "learning_rate": 3.6295555555555556e-05,
      "loss": 0.1367,
      "step": 25020
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.768695592880249,
      "learning_rate": 3.629407407407408e-05,
      "loss": 0.0903,
      "step": 25030
    },
    {
      "epoch": 2.78,
      "grad_norm": 5.181077003479004,
      "learning_rate": 3.6292592592592595e-05,
      "loss": 0.1911,
      "step": 25040
    },
    {
      "epoch": 2.78,
      "grad_norm": 6.903205394744873,
      "learning_rate": 3.629111111111111e-05,
      "loss": 0.1786,
      "step": 25050
    },
    {
      "epoch": 2.78,
      "grad_norm": 4.748798847198486,
      "learning_rate": 3.6289629629629634e-05,
      "loss": 0.1104,
      "step": 25060
    },
    {
      "epoch": 2.79,
      "grad_norm": 6.963956356048584,
      "learning_rate": 3.628814814814815e-05,
      "loss": 0.1511,
      "step": 25070
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.0030462741851807,
      "learning_rate": 3.628666666666667e-05,
      "loss": 0.0995,
      "step": 25080
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.5693771839141846,
      "learning_rate": 3.628518518518519e-05,
      "loss": 0.0924,
      "step": 25090
    },
    {
      "epoch": 2.79,
      "grad_norm": 5.927159309387207,
      "learning_rate": 3.6283703703703705e-05,
      "loss": 0.1267,
      "step": 25100
    },
    {
      "epoch": 2.79,
      "grad_norm": 4.335912704467773,
      "learning_rate": 3.628222222222222e-05,
      "loss": 0.2111,
      "step": 25110
    },
    {
      "epoch": 2.79,
      "grad_norm": 5.753701210021973,
      "learning_rate": 3.6280740740740744e-05,
      "loss": 0.1398,
      "step": 25120
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.8263840675354004,
      "learning_rate": 3.627925925925926e-05,
      "loss": 0.1687,
      "step": 25130
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.0528340339660645,
      "learning_rate": 3.627777777777778e-05,
      "loss": 0.116,
      "step": 25140
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.456047296524048,
      "learning_rate": 3.62762962962963e-05,
      "loss": 0.1195,
      "step": 25150
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.793745756149292,
      "learning_rate": 3.6274814814814814e-05,
      "loss": 0.1791,
      "step": 25160
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.307863235473633,
      "learning_rate": 3.627333333333334e-05,
      "loss": 0.1561,
      "step": 25170
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.0054585933685303,
      "learning_rate": 3.627185185185185e-05,
      "loss": 0.0901,
      "step": 25180
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.213437080383301,
      "learning_rate": 3.6270370370370376e-05,
      "loss": 0.1229,
      "step": 25190
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.639013767242432,
      "learning_rate": 3.626888888888889e-05,
      "loss": 0.146,
      "step": 25200
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.207720756530762,
      "learning_rate": 3.626740740740741e-05,
      "loss": 0.1059,
      "step": 25210
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.9593913555145264,
      "learning_rate": 3.626592592592593e-05,
      "loss": 0.1206,
      "step": 25220
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.8897639513015747,
      "learning_rate": 3.626444444444445e-05,
      "loss": 0.1492,
      "step": 25230
    },
    {
      "epoch": 2.8,
      "grad_norm": 5.61798620223999,
      "learning_rate": 3.626296296296297e-05,
      "loss": 0.1673,
      "step": 25240
    },
    {
      "epoch": 2.81,
      "grad_norm": 5.216662883758545,
      "learning_rate": 3.6261481481481486e-05,
      "loss": 0.114,
      "step": 25250
    },
    {
      "epoch": 2.81,
      "grad_norm": 3.327927589416504,
      "learning_rate": 3.626e-05,
      "loss": 0.1235,
      "step": 25260
    },
    {
      "epoch": 2.81,
      "grad_norm": 4.2049880027771,
      "learning_rate": 3.625851851851852e-05,
      "loss": 0.1054,
      "step": 25270
    },
    {
      "epoch": 2.81,
      "grad_norm": 5.8310651779174805,
      "learning_rate": 3.625703703703704e-05,
      "loss": 0.12,
      "step": 25280
    },
    {
      "epoch": 2.81,
      "grad_norm": 4.431541442871094,
      "learning_rate": 3.625555555555556e-05,
      "loss": 0.1587,
      "step": 25290
    },
    {
      "epoch": 2.81,
      "grad_norm": 4.568608283996582,
      "learning_rate": 3.625407407407408e-05,
      "loss": 0.2175,
      "step": 25300
    },
    {
      "epoch": 2.81,
      "grad_norm": 4.186354160308838,
      "learning_rate": 3.6252592592592595e-05,
      "loss": 0.1285,
      "step": 25310
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.9538979530334473,
      "learning_rate": 3.625111111111111e-05,
      "loss": 0.1132,
      "step": 25320
    },
    {
      "epoch": 2.81,
      "grad_norm": 5.353548526763916,
      "learning_rate": 3.6249629629629634e-05,
      "loss": 0.1331,
      "step": 25330
    },
    {
      "epoch": 2.82,
      "grad_norm": 5.692407608032227,
      "learning_rate": 3.624814814814815e-05,
      "loss": 0.1419,
      "step": 25340
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.275639772415161,
      "learning_rate": 3.624666666666667e-05,
      "loss": 0.1314,
      "step": 25350
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.6530213356018066,
      "learning_rate": 3.624518518518519e-05,
      "loss": 0.1369,
      "step": 25360
    },
    {
      "epoch": 2.82,
      "grad_norm": 5.4472336769104,
      "learning_rate": 3.6243703703703705e-05,
      "loss": 0.1489,
      "step": 25370
    },
    {
      "epoch": 2.82,
      "grad_norm": 16.005229949951172,
      "learning_rate": 3.624222222222222e-05,
      "loss": 0.1496,
      "step": 25380
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.5891242027282715,
      "learning_rate": 3.6240740740740744e-05,
      "loss": 0.0675,
      "step": 25390
    },
    {
      "epoch": 2.82,
      "grad_norm": 7.0347371101379395,
      "learning_rate": 3.623925925925926e-05,
      "loss": 0.0975,
      "step": 25400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.2366442680358887,
      "learning_rate": 3.623777777777778e-05,
      "loss": 0.137,
      "step": 25410
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.424067735671997,
      "learning_rate": 3.62362962962963e-05,
      "loss": 0.1444,
      "step": 25420
    },
    {
      "epoch": 2.83,
      "grad_norm": 6.180366516113281,
      "learning_rate": 3.6234814814814815e-05,
      "loss": 0.132,
      "step": 25430
    },
    {
      "epoch": 2.83,
      "grad_norm": 5.437134265899658,
      "learning_rate": 3.623333333333334e-05,
      "loss": 0.1363,
      "step": 25440
    },
    {
      "epoch": 2.83,
      "grad_norm": 7.9608564376831055,
      "learning_rate": 3.6231851851851854e-05,
      "loss": 0.1165,
      "step": 25450
    },
    {
      "epoch": 2.83,
      "grad_norm": 4.125000476837158,
      "learning_rate": 3.6230370370370376e-05,
      "loss": 0.1253,
      "step": 25460
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.8985183238983154,
      "learning_rate": 3.622888888888889e-05,
      "loss": 0.2262,
      "step": 25470
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.953582525253296,
      "learning_rate": 3.622740740740741e-05,
      "loss": 0.1473,
      "step": 25480
    },
    {
      "epoch": 2.83,
      "grad_norm": 6.327591896057129,
      "learning_rate": 3.622592592592593e-05,
      "loss": 0.168,
      "step": 25490
    },
    {
      "epoch": 2.83,
      "grad_norm": 4.5755839347839355,
      "learning_rate": 3.622444444444445e-05,
      "loss": 0.1221,
      "step": 25500
    },
    {
      "epoch": 2.83,
      "grad_norm": 8.231592178344727,
      "learning_rate": 3.622296296296296e-05,
      "loss": 0.1551,
      "step": 25510
    },
    {
      "epoch": 2.84,
      "grad_norm": 6.36031436920166,
      "learning_rate": 3.6221481481481486e-05,
      "loss": 0.1581,
      "step": 25520
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.3717141151428223,
      "learning_rate": 3.622e-05,
      "loss": 0.1258,
      "step": 25530
    },
    {
      "epoch": 2.84,
      "grad_norm": 3.5877878665924072,
      "learning_rate": 3.621851851851852e-05,
      "loss": 0.1029,
      "step": 25540
    },
    {
      "epoch": 2.84,
      "grad_norm": 5.927879333496094,
      "learning_rate": 3.621703703703704e-05,
      "loss": 0.0942,
      "step": 25550
    },
    {
      "epoch": 2.84,
      "grad_norm": 6.126453876495361,
      "learning_rate": 3.621555555555556e-05,
      "loss": 0.1196,
      "step": 25560
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.8340716361999512,
      "learning_rate": 3.621407407407408e-05,
      "loss": 0.1032,
      "step": 25570
    },
    {
      "epoch": 2.84,
      "grad_norm": 6.010654926300049,
      "learning_rate": 3.6212592592592596e-05,
      "loss": 0.1087,
      "step": 25580
    },
    {
      "epoch": 2.84,
      "grad_norm": 9.439353942871094,
      "learning_rate": 3.621111111111111e-05,
      "loss": 0.2115,
      "step": 25590
    },
    {
      "epoch": 2.84,
      "grad_norm": 3.6266226768493652,
      "learning_rate": 3.6209629629629635e-05,
      "loss": 0.0907,
      "step": 25600
    },
    {
      "epoch": 2.85,
      "grad_norm": 5.290782451629639,
      "learning_rate": 3.620814814814815e-05,
      "loss": 0.1004,
      "step": 25610
    },
    {
      "epoch": 2.85,
      "grad_norm": 6.654951572418213,
      "learning_rate": 3.620666666666667e-05,
      "loss": 0.102,
      "step": 25620
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.0523040294647217,
      "learning_rate": 3.620518518518519e-05,
      "loss": 0.0745,
      "step": 25630
    },
    {
      "epoch": 2.85,
      "grad_norm": 3.58483624458313,
      "learning_rate": 3.6203703703703706e-05,
      "loss": 0.1044,
      "step": 25640
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.169933557510376,
      "learning_rate": 3.620222222222222e-05,
      "loss": 0.1282,
      "step": 25650
    },
    {
      "epoch": 2.85,
      "grad_norm": 4.192273139953613,
      "learning_rate": 3.6200740740740744e-05,
      "loss": 0.1308,
      "step": 25660
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.0492467880249023,
      "learning_rate": 3.619925925925926e-05,
      "loss": 0.0909,
      "step": 25670
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.9251396656036377,
      "learning_rate": 3.619777777777778e-05,
      "loss": 0.0983,
      "step": 25680
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.603682518005371,
      "learning_rate": 3.61962962962963e-05,
      "loss": 0.0954,
      "step": 25690
    },
    {
      "epoch": 2.86,
      "grad_norm": 6.049173831939697,
      "learning_rate": 3.6194814814814815e-05,
      "loss": 0.1229,
      "step": 25700
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.368194580078125,
      "learning_rate": 3.619333333333334e-05,
      "loss": 0.1231,
      "step": 25710
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.5051889419555664,
      "learning_rate": 3.6191851851851854e-05,
      "loss": 0.0997,
      "step": 25720
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.759416103363037,
      "learning_rate": 3.619037037037038e-05,
      "loss": 0.1303,
      "step": 25730
    },
    {
      "epoch": 2.86,
      "grad_norm": 12.124552726745605,
      "learning_rate": 3.618888888888889e-05,
      "loss": 0.1085,
      "step": 25740
    },
    {
      "epoch": 2.86,
      "grad_norm": 4.03745174407959,
      "learning_rate": 3.618740740740741e-05,
      "loss": 0.0796,
      "step": 25750
    },
    {
      "epoch": 2.86,
      "grad_norm": 4.838521957397461,
      "learning_rate": 3.618592592592593e-05,
      "loss": 0.2115,
      "step": 25760
    },
    {
      "epoch": 2.86,
      "grad_norm": 4.59420919418335,
      "learning_rate": 3.618444444444445e-05,
      "loss": 0.1153,
      "step": 25770
    },
    {
      "epoch": 2.86,
      "grad_norm": 4.554746150970459,
      "learning_rate": 3.6182962962962964e-05,
      "loss": 0.1135,
      "step": 25780
    },
    {
      "epoch": 2.87,
      "grad_norm": 4.796485900878906,
      "learning_rate": 3.6181481481481487e-05,
      "loss": 0.1459,
      "step": 25790
    },
    {
      "epoch": 2.87,
      "grad_norm": 9.750985145568848,
      "learning_rate": 3.618e-05,
      "loss": 0.1212,
      "step": 25800
    },
    {
      "epoch": 2.87,
      "grad_norm": 3.5175840854644775,
      "learning_rate": 3.617851851851852e-05,
      "loss": 0.0986,
      "step": 25810
    },
    {
      "epoch": 2.87,
      "grad_norm": 4.302727222442627,
      "learning_rate": 3.617703703703704e-05,
      "loss": 0.1418,
      "step": 25820
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.9535908699035645,
      "learning_rate": 3.617555555555556e-05,
      "loss": 0.1762,
      "step": 25830
    },
    {
      "epoch": 2.87,
      "grad_norm": 7.238755702972412,
      "learning_rate": 3.617407407407408e-05,
      "loss": 0.1342,
      "step": 25840
    },
    {
      "epoch": 2.87,
      "grad_norm": 3.702833890914917,
      "learning_rate": 3.6172592592592596e-05,
      "loss": 0.1158,
      "step": 25850
    },
    {
      "epoch": 2.87,
      "grad_norm": 10.475317001342773,
      "learning_rate": 3.617111111111111e-05,
      "loss": 0.1141,
      "step": 25860
    },
    {
      "epoch": 2.87,
      "grad_norm": 3.202634334564209,
      "learning_rate": 3.6169629629629635e-05,
      "loss": 0.1175,
      "step": 25870
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.5426942110061646,
      "learning_rate": 3.616814814814815e-05,
      "loss": 0.0806,
      "step": 25880
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.938397169113159,
      "learning_rate": 3.616666666666667e-05,
      "loss": 0.1166,
      "step": 25890
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.6444427967071533,
      "learning_rate": 3.616518518518519e-05,
      "loss": 0.1104,
      "step": 25900
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.114993095397949,
      "learning_rate": 3.6163703703703706e-05,
      "loss": 0.1215,
      "step": 25910
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.7567763328552246,
      "learning_rate": 3.616222222222222e-05,
      "loss": 0.1396,
      "step": 25920
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.895822525024414,
      "learning_rate": 3.6160740740740745e-05,
      "loss": 0.0762,
      "step": 25930
    },
    {
      "epoch": 2.88,
      "grad_norm": 6.450811862945557,
      "learning_rate": 3.615925925925926e-05,
      "loss": 0.1174,
      "step": 25940
    },
    {
      "epoch": 2.88,
      "grad_norm": 6.392150402069092,
      "learning_rate": 3.6157777777777784e-05,
      "loss": 0.1183,
      "step": 25950
    },
    {
      "epoch": 2.88,
      "grad_norm": 6.316891670227051,
      "learning_rate": 3.61562962962963e-05,
      "loss": 0.2135,
      "step": 25960
    },
    {
      "epoch": 2.89,
      "grad_norm": 4.6607818603515625,
      "learning_rate": 3.6154814814814816e-05,
      "loss": 0.1101,
      "step": 25970
    },
    {
      "epoch": 2.89,
      "grad_norm": 3.4064292907714844,
      "learning_rate": 3.615333333333334e-05,
      "loss": 0.1489,
      "step": 25980
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.2236496210098267,
      "learning_rate": 3.6151851851851854e-05,
      "loss": 0.1496,
      "step": 25990
    },
    {
      "epoch": 2.89,
      "grad_norm": 3.477461814880371,
      "learning_rate": 3.6150518518518525e-05,
      "loss": 0.1568,
      "step": 26000
    },
    {
      "epoch": 2.89,
      "grad_norm": 6.560485363006592,
      "learning_rate": 3.614903703703704e-05,
      "loss": 0.1286,
      "step": 26010
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.7344744205474854,
      "learning_rate": 3.614755555555556e-05,
      "loss": 0.1728,
      "step": 26020
    },
    {
      "epoch": 2.89,
      "grad_norm": 8.06457233428955,
      "learning_rate": 3.614607407407407e-05,
      "loss": 0.1256,
      "step": 26030
    },
    {
      "epoch": 2.89,
      "grad_norm": 3.034677028656006,
      "learning_rate": 3.6144592592592596e-05,
      "loss": 0.1422,
      "step": 26040
    },
    {
      "epoch": 2.89,
      "grad_norm": 14.992198944091797,
      "learning_rate": 3.614311111111112e-05,
      "loss": 0.1328,
      "step": 26050
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.6730692386627197,
      "learning_rate": 3.6141629629629635e-05,
      "loss": 0.1397,
      "step": 26060
    },
    {
      "epoch": 2.9,
      "grad_norm": 4.507098197937012,
      "learning_rate": 3.614014814814815e-05,
      "loss": 0.1186,
      "step": 26070
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.9760353565216064,
      "learning_rate": 3.613866666666667e-05,
      "loss": 0.1472,
      "step": 26080
    },
    {
      "epoch": 2.9,
      "grad_norm": 5.622183322906494,
      "learning_rate": 3.613718518518519e-05,
      "loss": 0.2211,
      "step": 26090
    },
    {
      "epoch": 2.9,
      "grad_norm": 6.201216697692871,
      "learning_rate": 3.6135703703703706e-05,
      "loss": 0.1006,
      "step": 26100
    },
    {
      "epoch": 2.9,
      "grad_norm": 4.166996002197266,
      "learning_rate": 3.613422222222223e-05,
      "loss": 0.1236,
      "step": 26110
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.2819600105285645,
      "learning_rate": 3.6132740740740744e-05,
      "loss": 0.06,
      "step": 26120
    },
    {
      "epoch": 2.9,
      "grad_norm": 8.020792007446289,
      "learning_rate": 3.613125925925926e-05,
      "loss": 0.1267,
      "step": 26130
    },
    {
      "epoch": 2.9,
      "grad_norm": 5.891378879547119,
      "learning_rate": 3.6129777777777776e-05,
      "loss": 0.1225,
      "step": 26140
    },
    {
      "epoch": 2.91,
      "grad_norm": 4.041037082672119,
      "learning_rate": 3.61282962962963e-05,
      "loss": 0.162,
      "step": 26150
    },
    {
      "epoch": 2.91,
      "grad_norm": 3.6519672870635986,
      "learning_rate": 3.612681481481482e-05,
      "loss": 0.1138,
      "step": 26160
    },
    {
      "epoch": 2.91,
      "grad_norm": 5.50513219833374,
      "learning_rate": 3.612533333333334e-05,
      "loss": 0.1132,
      "step": 26170
    },
    {
      "epoch": 2.91,
      "grad_norm": 4.714187145233154,
      "learning_rate": 3.6123851851851854e-05,
      "loss": 0.1042,
      "step": 26180
    },
    {
      "epoch": 2.91,
      "grad_norm": 4.055461883544922,
      "learning_rate": 3.612237037037037e-05,
      "loss": 0.0644,
      "step": 26190
    },
    {
      "epoch": 2.91,
      "grad_norm": 5.545734882354736,
      "learning_rate": 3.612088888888889e-05,
      "loss": 0.179,
      "step": 26200
    },
    {
      "epoch": 2.91,
      "grad_norm": 3.2647011280059814,
      "learning_rate": 3.611940740740741e-05,
      "loss": 0.0936,
      "step": 26210
    },
    {
      "epoch": 2.91,
      "grad_norm": 5.794928550720215,
      "learning_rate": 3.611792592592593e-05,
      "loss": 0.1356,
      "step": 26220
    },
    {
      "epoch": 2.91,
      "grad_norm": 6.870677471160889,
      "learning_rate": 3.611644444444445e-05,
      "loss": 0.1191,
      "step": 26230
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.201869249343872,
      "learning_rate": 3.6114962962962964e-05,
      "loss": 0.1155,
      "step": 26240
    },
    {
      "epoch": 2.92,
      "grad_norm": 3.809891939163208,
      "learning_rate": 3.611348148148148e-05,
      "loss": 0.092,
      "step": 26250
    },
    {
      "epoch": 2.92,
      "grad_norm": 7.531983852386475,
      "learning_rate": 3.6112e-05,
      "loss": 0.1325,
      "step": 26260
    },
    {
      "epoch": 2.92,
      "grad_norm": 4.504090785980225,
      "learning_rate": 3.6110518518518525e-05,
      "loss": 0.132,
      "step": 26270
    },
    {
      "epoch": 2.92,
      "grad_norm": 4.684814929962158,
      "learning_rate": 3.610903703703704e-05,
      "loss": 0.1092,
      "step": 26280
    },
    {
      "epoch": 2.92,
      "grad_norm": 6.292591094970703,
      "learning_rate": 3.610755555555556e-05,
      "loss": 0.1659,
      "step": 26290
    },
    {
      "epoch": 2.92,
      "grad_norm": 3.920771837234497,
      "learning_rate": 3.6106074074074073e-05,
      "loss": 0.1289,
      "step": 26300
    },
    {
      "epoch": 2.92,
      "grad_norm": 15.364521026611328,
      "learning_rate": 3.6104592592592596e-05,
      "loss": 0.1534,
      "step": 26310
    },
    {
      "epoch": 2.92,
      "grad_norm": 4.070230007171631,
      "learning_rate": 3.610311111111111e-05,
      "loss": 0.1009,
      "step": 26320
    },
    {
      "epoch": 2.93,
      "grad_norm": 4.820766448974609,
      "learning_rate": 3.6101629629629635e-05,
      "loss": 0.1033,
      "step": 26330
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.305223226547241,
      "learning_rate": 3.610014814814815e-05,
      "loss": 0.0968,
      "step": 26340
    },
    {
      "epoch": 2.93,
      "grad_norm": 4.311330318450928,
      "learning_rate": 3.609866666666667e-05,
      "loss": 0.1279,
      "step": 26350
    },
    {
      "epoch": 2.93,
      "grad_norm": 1.406590223312378,
      "learning_rate": 3.609718518518518e-05,
      "loss": 0.1485,
      "step": 26360
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.3421292304992676,
      "learning_rate": 3.6095703703703706e-05,
      "loss": 0.1461,
      "step": 26370
    },
    {
      "epoch": 2.93,
      "grad_norm": 5.455613136291504,
      "learning_rate": 3.609422222222223e-05,
      "loss": 0.1729,
      "step": 26380
    },
    {
      "epoch": 2.93,
      "grad_norm": 4.414776802062988,
      "learning_rate": 3.6092740740740745e-05,
      "loss": 0.1405,
      "step": 26390
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.915130853652954,
      "learning_rate": 3.609125925925926e-05,
      "loss": 0.1521,
      "step": 26400
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.1139683723449707,
      "learning_rate": 3.608977777777778e-05,
      "loss": 0.1463,
      "step": 26410
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.0474063158035278,
      "learning_rate": 3.60882962962963e-05,
      "loss": 0.1223,
      "step": 26420
    },
    {
      "epoch": 2.94,
      "grad_norm": 4.904597282409668,
      "learning_rate": 3.6086814814814816e-05,
      "loss": 0.1919,
      "step": 26430
    },
    {
      "epoch": 2.94,
      "grad_norm": 10.679489135742188,
      "learning_rate": 3.608533333333334e-05,
      "loss": 0.1826,
      "step": 26440
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.6405479907989502,
      "learning_rate": 3.6083851851851854e-05,
      "loss": 0.1247,
      "step": 26450
    },
    {
      "epoch": 2.94,
      "grad_norm": 6.165153980255127,
      "learning_rate": 3.608237037037037e-05,
      "loss": 0.1498,
      "step": 26460
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.1124166250228882,
      "learning_rate": 3.6080888888888886e-05,
      "loss": 0.1208,
      "step": 26470
    },
    {
      "epoch": 2.94,
      "grad_norm": 3.5284438133239746,
      "learning_rate": 3.607940740740741e-05,
      "loss": 0.1289,
      "step": 26480
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.9644153118133545,
      "learning_rate": 3.607792592592593e-05,
      "loss": 0.1127,
      "step": 26490
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.8404674530029297,
      "learning_rate": 3.607644444444445e-05,
      "loss": 0.078,
      "step": 26500
    },
    {
      "epoch": 2.95,
      "grad_norm": 7.363889217376709,
      "learning_rate": 3.6074962962962964e-05,
      "loss": 0.0945,
      "step": 26510
    },
    {
      "epoch": 2.95,
      "grad_norm": 7.990746974945068,
      "learning_rate": 3.607348148148148e-05,
      "loss": 0.1242,
      "step": 26520
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.6991946697235107,
      "learning_rate": 3.6072e-05,
      "loss": 0.1874,
      "step": 26530
    },
    {
      "epoch": 2.95,
      "grad_norm": 11.276959419250488,
      "learning_rate": 3.6070518518518526e-05,
      "loss": 0.1282,
      "step": 26540
    },
    {
      "epoch": 2.95,
      "grad_norm": 7.107789993286133,
      "learning_rate": 3.606903703703704e-05,
      "loss": 0.1405,
      "step": 26550
    },
    {
      "epoch": 2.95,
      "grad_norm": 3.4869048595428467,
      "learning_rate": 3.606755555555556e-05,
      "loss": 0.1216,
      "step": 26560
    },
    {
      "epoch": 2.95,
      "grad_norm": 3.914085626602173,
      "learning_rate": 3.6066074074074074e-05,
      "loss": 0.1211,
      "step": 26570
    },
    {
      "epoch": 2.95,
      "grad_norm": 7.443077087402344,
      "learning_rate": 3.6064592592592597e-05,
      "loss": 0.2029,
      "step": 26580
    },
    {
      "epoch": 2.95,
      "grad_norm": 5.145357131958008,
      "learning_rate": 3.606311111111111e-05,
      "loss": 0.1273,
      "step": 26590
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.8387770652770996,
      "learning_rate": 3.6061629629629635e-05,
      "loss": 0.0807,
      "step": 26600
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.2144200801849365,
      "learning_rate": 3.606014814814815e-05,
      "loss": 0.1049,
      "step": 26610
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.6957576274871826,
      "learning_rate": 3.605866666666667e-05,
      "loss": 0.0895,
      "step": 26620
    },
    {
      "epoch": 2.96,
      "grad_norm": 8.21674919128418,
      "learning_rate": 3.6057185185185183e-05,
      "loss": 0.0889,
      "step": 26630
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.3391788005828857,
      "learning_rate": 3.6055703703703706e-05,
      "loss": 0.1056,
      "step": 26640
    },
    {
      "epoch": 2.96,
      "grad_norm": 4.273170471191406,
      "learning_rate": 3.605422222222223e-05,
      "loss": 0.1012,
      "step": 26650
    },
    {
      "epoch": 2.96,
      "grad_norm": 5.345382213592529,
      "learning_rate": 3.6052740740740745e-05,
      "loss": 0.1142,
      "step": 26660
    },
    {
      "epoch": 2.96,
      "grad_norm": 5.628386497497559,
      "learning_rate": 3.605125925925926e-05,
      "loss": 0.1078,
      "step": 26670
    },
    {
      "epoch": 2.96,
      "grad_norm": 7.032826900482178,
      "learning_rate": 3.604977777777778e-05,
      "loss": 0.1034,
      "step": 26680
    },
    {
      "epoch": 2.97,
      "grad_norm": 6.404637813568115,
      "learning_rate": 3.60482962962963e-05,
      "loss": 0.1301,
      "step": 26690
    },
    {
      "epoch": 2.97,
      "grad_norm": 2.854705810546875,
      "learning_rate": 3.6046814814814816e-05,
      "loss": 0.163,
      "step": 26700
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.984243869781494,
      "learning_rate": 3.604533333333334e-05,
      "loss": 0.1305,
      "step": 26710
    },
    {
      "epoch": 2.97,
      "grad_norm": 4.990270614624023,
      "learning_rate": 3.6043851851851855e-05,
      "loss": 0.1575,
      "step": 26720
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.357855796813965,
      "learning_rate": 3.604237037037037e-05,
      "loss": 0.0971,
      "step": 26730
    },
    {
      "epoch": 2.97,
      "grad_norm": 2.3061232566833496,
      "learning_rate": 3.604088888888889e-05,
      "loss": 0.0863,
      "step": 26740
    },
    {
      "epoch": 2.97,
      "grad_norm": 5.1098432540893555,
      "learning_rate": 3.603940740740741e-05,
      "loss": 0.154,
      "step": 26750
    },
    {
      "epoch": 2.97,
      "grad_norm": 1.9724408388137817,
      "learning_rate": 3.603792592592593e-05,
      "loss": 0.1085,
      "step": 26760
    },
    {
      "epoch": 2.97,
      "grad_norm": 6.777991771697998,
      "learning_rate": 3.603644444444445e-05,
      "loss": 0.1425,
      "step": 26770
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.5532281398773193,
      "learning_rate": 3.6034962962962964e-05,
      "loss": 0.0992,
      "step": 26780
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.5294159650802612,
      "learning_rate": 3.603348148148148e-05,
      "loss": 0.1003,
      "step": 26790
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.5532355308532715,
      "learning_rate": 3.6032e-05,
      "loss": 0.169,
      "step": 26800
    },
    {
      "epoch": 2.98,
      "grad_norm": 10.417555809020996,
      "learning_rate": 3.603051851851852e-05,
      "loss": 0.1312,
      "step": 26810
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.6569199562072754,
      "learning_rate": 3.602903703703704e-05,
      "loss": 0.1274,
      "step": 26820
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.516411781311035,
      "learning_rate": 3.602755555555556e-05,
      "loss": 0.0973,
      "step": 26830
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.4837844371795654,
      "learning_rate": 3.6026074074074074e-05,
      "loss": 0.1193,
      "step": 26840
    },
    {
      "epoch": 2.98,
      "grad_norm": 6.007740497589111,
      "learning_rate": 3.60245925925926e-05,
      "loss": 0.1574,
      "step": 26850
    },
    {
      "epoch": 2.98,
      "grad_norm": 10.00847339630127,
      "learning_rate": 3.602311111111111e-05,
      "loss": 0.1587,
      "step": 26860
    },
    {
      "epoch": 2.99,
      "grad_norm": 4.966377258300781,
      "learning_rate": 3.6021629629629636e-05,
      "loss": 0.159,
      "step": 26870
    },
    {
      "epoch": 2.99,
      "grad_norm": 4.64454460144043,
      "learning_rate": 3.602014814814815e-05,
      "loss": 0.0943,
      "step": 26880
    },
    {
      "epoch": 2.99,
      "grad_norm": 5.939497947692871,
      "learning_rate": 3.601866666666667e-05,
      "loss": 0.1525,
      "step": 26890
    },
    {
      "epoch": 2.99,
      "grad_norm": 4.379024505615234,
      "learning_rate": 3.6017185185185184e-05,
      "loss": 0.0993,
      "step": 26900
    },
    {
      "epoch": 2.99,
      "grad_norm": 3.5705182552337646,
      "learning_rate": 3.601570370370371e-05,
      "loss": 0.1401,
      "step": 26910
    },
    {
      "epoch": 2.99,
      "grad_norm": 2.8200695514678955,
      "learning_rate": 3.601422222222222e-05,
      "loss": 0.1233,
      "step": 26920
    },
    {
      "epoch": 2.99,
      "grad_norm": 2.038069486618042,
      "learning_rate": 3.6012740740740745e-05,
      "loss": 0.2587,
      "step": 26930
    },
    {
      "epoch": 2.99,
      "grad_norm": 4.505091667175293,
      "learning_rate": 3.601125925925926e-05,
      "loss": 0.0927,
      "step": 26940
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.41518211364746094,
      "learning_rate": 3.600977777777778e-05,
      "loss": 0.1309,
      "step": 26950
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.000232458114624,
      "learning_rate": 3.60082962962963e-05,
      "loss": 0.1454,
      "step": 26960
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.6526036262512207,
      "learning_rate": 3.6006814814814816e-05,
      "loss": 0.1227,
      "step": 26970
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.213796854019165,
      "learning_rate": 3.600533333333334e-05,
      "loss": 0.0994,
      "step": 26980
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.068812608718872,
      "learning_rate": 3.6003851851851855e-05,
      "loss": 0.1417,
      "step": 26990
    },
    {
      "epoch": 3.0,
      "grad_norm": 7.395107269287109,
      "learning_rate": 3.600237037037037e-05,
      "loss": 0.2459,
      "step": 27000
    },
    {
      "epoch": 3.0,
      "grad_norm": 5.238884925842285,
      "learning_rate": 3.600088888888889e-05,
      "loss": 0.1144,
      "step": 27010
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.3436777591705322,
      "learning_rate": 3.599940740740741e-05,
      "loss": 0.087,
      "step": 27020
    },
    {
      "epoch": 3.0,
      "grad_norm": 5.159295082092285,
      "learning_rate": 3.599792592592593e-05,
      "loss": 0.0804,
      "step": 27030
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.4308230876922607,
      "learning_rate": 3.599644444444445e-05,
      "loss": 0.0678,
      "step": 27040
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3274396061897278,
      "learning_rate": 3.5994962962962965e-05,
      "loss": 0.1112,
      "step": 27050
    },
    {
      "epoch": 3.01,
      "grad_norm": 4.429105281829834,
      "learning_rate": 3.599348148148148e-05,
      "loss": 0.1179,
      "step": 27060
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.271683692932129,
      "learning_rate": 3.5992000000000004e-05,
      "loss": 0.1322,
      "step": 27070
    },
    {
      "epoch": 3.01,
      "grad_norm": 2.526839256286621,
      "learning_rate": 3.599051851851852e-05,
      "loss": 0.0716,
      "step": 27080
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.2792930603027344,
      "learning_rate": 3.598903703703704e-05,
      "loss": 0.1152,
      "step": 27090
    },
    {
      "epoch": 3.01,
      "grad_norm": 2.9484848976135254,
      "learning_rate": 3.598755555555556e-05,
      "loss": 0.0933,
      "step": 27100
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.749356508255005,
      "learning_rate": 3.5986074074074075e-05,
      "loss": 0.0925,
      "step": 27110
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.3982808589935303,
      "learning_rate": 3.59845925925926e-05,
      "loss": 0.1011,
      "step": 27120
    },
    {
      "epoch": 3.01,
      "grad_norm": 4.866115570068359,
      "learning_rate": 3.5983111111111113e-05,
      "loss": 0.0916,
      "step": 27130
    },
    {
      "epoch": 3.02,
      "grad_norm": 3.823267936706543,
      "learning_rate": 3.5981629629629636e-05,
      "loss": 0.0711,
      "step": 27140
    },
    {
      "epoch": 3.02,
      "grad_norm": 5.252922534942627,
      "learning_rate": 3.598014814814815e-05,
      "loss": 0.1431,
      "step": 27150
    },
    {
      "epoch": 3.02,
      "grad_norm": 7.115972518920898,
      "learning_rate": 3.597866666666667e-05,
      "loss": 0.1076,
      "step": 27160
    },
    {
      "epoch": 3.02,
      "grad_norm": 9.417159080505371,
      "learning_rate": 3.5977185185185184e-05,
      "loss": 0.0838,
      "step": 27170
    },
    {
      "epoch": 3.02,
      "grad_norm": 3.145028591156006,
      "learning_rate": 3.597570370370371e-05,
      "loss": 0.1327,
      "step": 27180
    },
    {
      "epoch": 3.02,
      "grad_norm": 4.079567909240723,
      "learning_rate": 3.597422222222222e-05,
      "loss": 0.0911,
      "step": 27190
    },
    {
      "epoch": 3.02,
      "grad_norm": 7.604653358459473,
      "learning_rate": 3.5972740740740746e-05,
      "loss": 0.0705,
      "step": 27200
    },
    {
      "epoch": 3.02,
      "grad_norm": 5.595006465911865,
      "learning_rate": 3.597125925925926e-05,
      "loss": 0.1303,
      "step": 27210
    },
    {
      "epoch": 3.02,
      "grad_norm": 3.4988114833831787,
      "learning_rate": 3.596977777777778e-05,
      "loss": 0.173,
      "step": 27220
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.244656801223755,
      "learning_rate": 3.59682962962963e-05,
      "loss": 0.1146,
      "step": 27230
    },
    {
      "epoch": 3.03,
      "grad_norm": 6.101324558258057,
      "learning_rate": 3.596681481481482e-05,
      "loss": 0.1244,
      "step": 27240
    },
    {
      "epoch": 3.03,
      "grad_norm": 1.983475685119629,
      "learning_rate": 3.596533333333334e-05,
      "loss": 0.1011,
      "step": 27250
    },
    {
      "epoch": 3.03,
      "grad_norm": 5.149451732635498,
      "learning_rate": 3.5963851851851856e-05,
      "loss": 0.0727,
      "step": 27260
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.572598934173584,
      "learning_rate": 3.596237037037037e-05,
      "loss": 0.1625,
      "step": 27270
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.607853651046753,
      "learning_rate": 3.596088888888889e-05,
      "loss": 0.0716,
      "step": 27280
    },
    {
      "epoch": 3.03,
      "grad_norm": 6.839369297027588,
      "learning_rate": 3.595940740740741e-05,
      "loss": 0.1472,
      "step": 27290
    },
    {
      "epoch": 3.03,
      "grad_norm": 10.470086097717285,
      "learning_rate": 3.5957925925925926e-05,
      "loss": 0.0792,
      "step": 27300
    },
    {
      "epoch": 3.03,
      "grad_norm": 6.15251350402832,
      "learning_rate": 3.595644444444445e-05,
      "loss": 0.1913,
      "step": 27310
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.104523658752441,
      "learning_rate": 3.5954962962962965e-05,
      "loss": 0.1091,
      "step": 27320
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.698740005493164,
      "learning_rate": 3.595348148148148e-05,
      "loss": 0.126,
      "step": 27330
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.5095624923706055,
      "learning_rate": 3.5952000000000004e-05,
      "loss": 0.0865,
      "step": 27340
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.0350990295410156,
      "learning_rate": 3.595051851851852e-05,
      "loss": 0.0992,
      "step": 27350
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.230982780456543,
      "learning_rate": 3.594903703703704e-05,
      "loss": 0.0834,
      "step": 27360
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.406792640686035,
      "learning_rate": 3.594755555555556e-05,
      "loss": 0.0829,
      "step": 27370
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.7608156204223633,
      "learning_rate": 3.5946074074074075e-05,
      "loss": 0.0697,
      "step": 27380
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.490182399749756,
      "learning_rate": 3.59445925925926e-05,
      "loss": 0.0806,
      "step": 27390
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.3985698223114014,
      "learning_rate": 3.5943111111111114e-05,
      "loss": 0.102,
      "step": 27400
    },
    {
      "epoch": 3.05,
      "grad_norm": 7.463038444519043,
      "learning_rate": 3.594162962962963e-05,
      "loss": 0.0953,
      "step": 27410
    },
    {
      "epoch": 3.05,
      "grad_norm": 7.692519664764404,
      "learning_rate": 3.594014814814815e-05,
      "loss": 0.1088,
      "step": 27420
    },
    {
      "epoch": 3.05,
      "grad_norm": 7.326927661895752,
      "learning_rate": 3.593866666666667e-05,
      "loss": 0.1178,
      "step": 27430
    },
    {
      "epoch": 3.05,
      "grad_norm": 3.5606918334960938,
      "learning_rate": 3.5937185185185185e-05,
      "loss": 0.0897,
      "step": 27440
    },
    {
      "epoch": 3.05,
      "grad_norm": 2.4319725036621094,
      "learning_rate": 3.593570370370371e-05,
      "loss": 0.0971,
      "step": 27450
    },
    {
      "epoch": 3.05,
      "grad_norm": 1.2601134777069092,
      "learning_rate": 3.5934222222222223e-05,
      "loss": 0.1145,
      "step": 27460
    },
    {
      "epoch": 3.05,
      "grad_norm": 6.217947483062744,
      "learning_rate": 3.5932740740740746e-05,
      "loss": 0.1331,
      "step": 27470
    },
    {
      "epoch": 3.05,
      "grad_norm": 2.879202365875244,
      "learning_rate": 3.593125925925926e-05,
      "loss": 0.0818,
      "step": 27480
    },
    {
      "epoch": 3.05,
      "grad_norm": 3.846545457839966,
      "learning_rate": 3.592977777777778e-05,
      "loss": 0.0677,
      "step": 27490
    },
    {
      "epoch": 3.06,
      "grad_norm": 4.232955455780029,
      "learning_rate": 3.59282962962963e-05,
      "loss": 0.102,
      "step": 27500
    },
    {
      "epoch": 3.06,
      "grad_norm": 6.265649795532227,
      "learning_rate": 3.592681481481482e-05,
      "loss": 0.0918,
      "step": 27510
    },
    {
      "epoch": 3.06,
      "grad_norm": 5.396708011627197,
      "learning_rate": 3.592533333333333e-05,
      "loss": 0.0996,
      "step": 27520
    },
    {
      "epoch": 3.06,
      "grad_norm": 7.717989444732666,
      "learning_rate": 3.5923851851851856e-05,
      "loss": 0.1122,
      "step": 27530
    },
    {
      "epoch": 3.06,
      "grad_norm": 3.0112717151641846,
      "learning_rate": 3.592237037037037e-05,
      "loss": 0.0589,
      "step": 27540
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.8749566078186035,
      "learning_rate": 3.5920888888888895e-05,
      "loss": 0.1026,
      "step": 27550
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.5942434072494507,
      "learning_rate": 3.591940740740741e-05,
      "loss": 0.0893,
      "step": 27560
    },
    {
      "epoch": 3.06,
      "grad_norm": 12.79224681854248,
      "learning_rate": 3.591792592592593e-05,
      "loss": 0.0829,
      "step": 27570
    },
    {
      "epoch": 3.06,
      "grad_norm": 3.551340341567993,
      "learning_rate": 3.591644444444445e-05,
      "loss": 0.0925,
      "step": 27580
    },
    {
      "epoch": 3.07,
      "grad_norm": 1.9797260761260986,
      "learning_rate": 3.5914962962962966e-05,
      "loss": 0.1311,
      "step": 27590
    },
    {
      "epoch": 3.07,
      "grad_norm": 10.065987586975098,
      "learning_rate": 3.591348148148148e-05,
      "loss": 0.0819,
      "step": 27600
    },
    {
      "epoch": 3.07,
      "grad_norm": 6.314512252807617,
      "learning_rate": 3.5912000000000004e-05,
      "loss": 0.0537,
      "step": 27610
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.910076379776001,
      "learning_rate": 3.591051851851852e-05,
      "loss": 0.1563,
      "step": 27620
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.918229579925537,
      "learning_rate": 3.590903703703704e-05,
      "loss": 0.098,
      "step": 27630
    },
    {
      "epoch": 3.07,
      "grad_norm": 1.9992390871047974,
      "learning_rate": 3.590755555555556e-05,
      "loss": 0.073,
      "step": 27640
    },
    {
      "epoch": 3.07,
      "grad_norm": 5.214293003082275,
      "learning_rate": 3.5906074074074075e-05,
      "loss": 0.1204,
      "step": 27650
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.3330280780792236,
      "learning_rate": 3.59045925925926e-05,
      "loss": 0.1305,
      "step": 27660
    },
    {
      "epoch": 3.07,
      "grad_norm": 1.73373281955719,
      "learning_rate": 3.5903111111111114e-05,
      "loss": 0.0862,
      "step": 27670
    },
    {
      "epoch": 3.08,
      "grad_norm": 6.105330467224121,
      "learning_rate": 3.590162962962963e-05,
      "loss": 0.1165,
      "step": 27680
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.6821839809417725,
      "learning_rate": 3.590014814814815e-05,
      "loss": 0.1472,
      "step": 27690
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.8316149711608887,
      "learning_rate": 3.589866666666667e-05,
      "loss": 0.0887,
      "step": 27700
    },
    {
      "epoch": 3.08,
      "grad_norm": 5.313786506652832,
      "learning_rate": 3.5897185185185185e-05,
      "loss": 0.0934,
      "step": 27710
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.719634056091309,
      "learning_rate": 3.589570370370371e-05,
      "loss": 0.1922,
      "step": 27720
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.821203708648682,
      "learning_rate": 3.5894222222222224e-05,
      "loss": 0.0826,
      "step": 27730
    },
    {
      "epoch": 3.08,
      "grad_norm": 1.9194872379302979,
      "learning_rate": 3.589274074074075e-05,
      "loss": 0.0695,
      "step": 27740
    },
    {
      "epoch": 3.08,
      "grad_norm": 5.126215934753418,
      "learning_rate": 3.589125925925926e-05,
      "loss": 0.0987,
      "step": 27750
    },
    {
      "epoch": 3.08,
      "grad_norm": 10.271589279174805,
      "learning_rate": 3.588977777777778e-05,
      "loss": 0.1172,
      "step": 27760
    },
    {
      "epoch": 3.09,
      "grad_norm": 2.517796754837036,
      "learning_rate": 3.58882962962963e-05,
      "loss": 0.0915,
      "step": 27770
    },
    {
      "epoch": 3.09,
      "grad_norm": 7.35837984085083,
      "learning_rate": 3.588681481481482e-05,
      "loss": 0.1097,
      "step": 27780
    },
    {
      "epoch": 3.09,
      "grad_norm": 4.601481914520264,
      "learning_rate": 3.5885333333333334e-05,
      "loss": 0.119,
      "step": 27790
    },
    {
      "epoch": 3.09,
      "grad_norm": 5.1969380378723145,
      "learning_rate": 3.5883851851851856e-05,
      "loss": 0.0943,
      "step": 27800
    },
    {
      "epoch": 3.09,
      "grad_norm": 6.280503749847412,
      "learning_rate": 3.588237037037037e-05,
      "loss": 0.1018,
      "step": 27810
    },
    {
      "epoch": 3.09,
      "grad_norm": 2.856241464614868,
      "learning_rate": 3.5880888888888895e-05,
      "loss": 0.1382,
      "step": 27820
    },
    {
      "epoch": 3.09,
      "grad_norm": 3.877462863922119,
      "learning_rate": 3.587940740740741e-05,
      "loss": 0.0945,
      "step": 27830
    },
    {
      "epoch": 3.09,
      "grad_norm": 8.839371681213379,
      "learning_rate": 3.587792592592593e-05,
      "loss": 0.0825,
      "step": 27840
    },
    {
      "epoch": 3.09,
      "grad_norm": 4.64668083190918,
      "learning_rate": 3.587644444444445e-05,
      "loss": 0.1454,
      "step": 27850
    },
    {
      "epoch": 3.1,
      "grad_norm": 10.271867752075195,
      "learning_rate": 3.5874962962962966e-05,
      "loss": 0.1287,
      "step": 27860
    },
    {
      "epoch": 3.1,
      "grad_norm": 2.2133214473724365,
      "learning_rate": 3.587348148148148e-05,
      "loss": 0.0697,
      "step": 27870
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.056197166442871,
      "learning_rate": 3.5872000000000005e-05,
      "loss": 0.0988,
      "step": 27880
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.282158374786377,
      "learning_rate": 3.587051851851852e-05,
      "loss": 0.0767,
      "step": 27890
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.1739370822906494,
      "learning_rate": 3.586903703703704e-05,
      "loss": 0.095,
      "step": 27900
    },
    {
      "epoch": 3.1,
      "grad_norm": 10.452592849731445,
      "learning_rate": 3.586755555555556e-05,
      "loss": 0.0878,
      "step": 27910
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.8944013118743896,
      "learning_rate": 3.5866074074074076e-05,
      "loss": 0.1862,
      "step": 27920
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.666548252105713,
      "learning_rate": 3.58645925925926e-05,
      "loss": 0.0968,
      "step": 27930
    },
    {
      "epoch": 3.1,
      "grad_norm": 6.984294891357422,
      "learning_rate": 3.5863111111111115e-05,
      "loss": 0.0595,
      "step": 27940
    },
    {
      "epoch": 3.11,
      "grad_norm": 5.584505081176758,
      "learning_rate": 3.586162962962963e-05,
      "loss": 0.1274,
      "step": 27950
    },
    {
      "epoch": 3.11,
      "grad_norm": 5.667522430419922,
      "learning_rate": 3.586014814814815e-05,
      "loss": 0.0993,
      "step": 27960
    },
    {
      "epoch": 3.11,
      "grad_norm": 5.392989158630371,
      "learning_rate": 3.585866666666667e-05,
      "loss": 0.1123,
      "step": 27970
    },
    {
      "epoch": 3.11,
      "grad_norm": 5.811849594116211,
      "learning_rate": 3.5857185185185185e-05,
      "loss": 0.0847,
      "step": 27980
    },
    {
      "epoch": 3.11,
      "grad_norm": 5.099475383758545,
      "learning_rate": 3.585570370370371e-05,
      "loss": 0.1159,
      "step": 27990
    },
    {
      "epoch": 3.11,
      "grad_norm": 1.9351683855056763,
      "learning_rate": 3.5854222222222224e-05,
      "loss": 0.1132,
      "step": 28000
    },
    {
      "epoch": 3.11,
      "grad_norm": 6.610389709472656,
      "learning_rate": 3.585274074074074e-05,
      "loss": 0.1178,
      "step": 28010
    },
    {
      "epoch": 3.11,
      "grad_norm": 19.582061767578125,
      "learning_rate": 3.585125925925926e-05,
      "loss": 0.1565,
      "step": 28020
    },
    {
      "epoch": 3.11,
      "grad_norm": 4.253579616546631,
      "learning_rate": 3.584977777777778e-05,
      "loss": 0.1084,
      "step": 28030
    },
    {
      "epoch": 3.12,
      "grad_norm": 7.696225166320801,
      "learning_rate": 3.58482962962963e-05,
      "loss": 0.1121,
      "step": 28040
    },
    {
      "epoch": 3.12,
      "grad_norm": 4.639863014221191,
      "learning_rate": 3.584681481481482e-05,
      "loss": 0.1287,
      "step": 28050
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.699577808380127,
      "learning_rate": 3.5845333333333334e-05,
      "loss": 0.1482,
      "step": 28060
    },
    {
      "epoch": 3.12,
      "grad_norm": 4.6418538093566895,
      "learning_rate": 3.584385185185186e-05,
      "loss": 0.0632,
      "step": 28070
    },
    {
      "epoch": 3.12,
      "grad_norm": 5.704381465911865,
      "learning_rate": 3.584237037037037e-05,
      "loss": 0.1017,
      "step": 28080
    },
    {
      "epoch": 3.12,
      "grad_norm": 5.004666805267334,
      "learning_rate": 3.5840888888888896e-05,
      "loss": 0.112,
      "step": 28090
    },
    {
      "epoch": 3.12,
      "grad_norm": 3.280536413192749,
      "learning_rate": 3.583940740740741e-05,
      "loss": 0.0826,
      "step": 28100
    },
    {
      "epoch": 3.12,
      "grad_norm": 8.250555992126465,
      "learning_rate": 3.583792592592593e-05,
      "loss": 0.121,
      "step": 28110
    },
    {
      "epoch": 3.12,
      "grad_norm": 6.214605331420898,
      "learning_rate": 3.583644444444445e-05,
      "loss": 0.1647,
      "step": 28120
    },
    {
      "epoch": 3.13,
      "grad_norm": 4.983180046081543,
      "learning_rate": 3.5834962962962966e-05,
      "loss": 0.1016,
      "step": 28130
    },
    {
      "epoch": 3.13,
      "grad_norm": 1.5731663703918457,
      "learning_rate": 3.583348148148148e-05,
      "loss": 0.0614,
      "step": 28140
    },
    {
      "epoch": 3.13,
      "grad_norm": 4.8066325187683105,
      "learning_rate": 3.5832000000000005e-05,
      "loss": 0.091,
      "step": 28150
    },
    {
      "epoch": 3.13,
      "grad_norm": 6.156902313232422,
      "learning_rate": 3.583051851851852e-05,
      "loss": 0.0832,
      "step": 28160
    },
    {
      "epoch": 3.13,
      "grad_norm": 5.031578540802002,
      "learning_rate": 3.582903703703704e-05,
      "loss": 0.1103,
      "step": 28170
    },
    {
      "epoch": 3.13,
      "grad_norm": 1.895920753479004,
      "learning_rate": 3.582755555555556e-05,
      "loss": 0.0686,
      "step": 28180
    },
    {
      "epoch": 3.13,
      "grad_norm": 3.093310594558716,
      "learning_rate": 3.5826074074074076e-05,
      "loss": 0.0739,
      "step": 28190
    },
    {
      "epoch": 3.13,
      "grad_norm": 3.682504177093506,
      "learning_rate": 3.58245925925926e-05,
      "loss": 0.1991,
      "step": 28200
    },
    {
      "epoch": 3.13,
      "grad_norm": 7.376478672027588,
      "learning_rate": 3.5823111111111115e-05,
      "loss": 0.0966,
      "step": 28210
    },
    {
      "epoch": 3.14,
      "grad_norm": 5.11616849899292,
      "learning_rate": 3.582162962962963e-05,
      "loss": 0.147,
      "step": 28220
    },
    {
      "epoch": 3.14,
      "grad_norm": 4.050669193267822,
      "learning_rate": 3.5820148148148154e-05,
      "loss": 0.1696,
      "step": 28230
    },
    {
      "epoch": 3.14,
      "grad_norm": 6.779895782470703,
      "learning_rate": 3.581866666666667e-05,
      "loss": 0.1165,
      "step": 28240
    },
    {
      "epoch": 3.14,
      "grad_norm": 4.456605434417725,
      "learning_rate": 3.5817185185185186e-05,
      "loss": 0.062,
      "step": 28250
    },
    {
      "epoch": 3.14,
      "grad_norm": 6.818203449249268,
      "learning_rate": 3.581570370370371e-05,
      "loss": 0.1145,
      "step": 28260
    },
    {
      "epoch": 3.14,
      "grad_norm": 5.046623229980469,
      "learning_rate": 3.5814222222222225e-05,
      "loss": 0.0743,
      "step": 28270
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.7764415740966797,
      "learning_rate": 3.581274074074074e-05,
      "loss": 0.1069,
      "step": 28280
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.1645236015319824,
      "learning_rate": 3.5811259259259263e-05,
      "loss": 0.0582,
      "step": 28290
    },
    {
      "epoch": 3.14,
      "grad_norm": 4.38383150100708,
      "learning_rate": 3.580977777777778e-05,
      "loss": 0.1735,
      "step": 28300
    },
    {
      "epoch": 3.15,
      "grad_norm": 3.312309741973877,
      "learning_rate": 3.58082962962963e-05,
      "loss": 0.1408,
      "step": 28310
    },
    {
      "epoch": 3.15,
      "grad_norm": 2.6876583099365234,
      "learning_rate": 3.580681481481482e-05,
      "loss": 0.0858,
      "step": 28320
    },
    {
      "epoch": 3.15,
      "grad_norm": 6.84779167175293,
      "learning_rate": 3.5805333333333334e-05,
      "loss": 0.0764,
      "step": 28330
    },
    {
      "epoch": 3.15,
      "grad_norm": 1.242682933807373,
      "learning_rate": 3.580385185185186e-05,
      "loss": 0.1148,
      "step": 28340
    },
    {
      "epoch": 3.15,
      "grad_norm": 3.4076762199401855,
      "learning_rate": 3.580237037037037e-05,
      "loss": 0.091,
      "step": 28350
    },
    {
      "epoch": 3.15,
      "grad_norm": 6.586483478546143,
      "learning_rate": 3.5800888888888896e-05,
      "loss": 0.1047,
      "step": 28360
    },
    {
      "epoch": 3.15,
      "grad_norm": 3.559030532836914,
      "learning_rate": 3.579940740740741e-05,
      "loss": 0.1586,
      "step": 28370
    },
    {
      "epoch": 3.15,
      "grad_norm": 6.792522430419922,
      "learning_rate": 3.579792592592593e-05,
      "loss": 0.1328,
      "step": 28380
    },
    {
      "epoch": 3.15,
      "grad_norm": 5.305478096008301,
      "learning_rate": 3.5796444444444444e-05,
      "loss": 0.1005,
      "step": 28390
    },
    {
      "epoch": 3.16,
      "grad_norm": 8.917898178100586,
      "learning_rate": 3.579496296296297e-05,
      "loss": 0.1114,
      "step": 28400
    },
    {
      "epoch": 3.16,
      "grad_norm": 4.221600532531738,
      "learning_rate": 3.579348148148148e-05,
      "loss": 0.1063,
      "step": 28410
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.0775675773620605,
      "learning_rate": 3.5792000000000006e-05,
      "loss": 0.0945,
      "step": 28420
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.0569162368774414,
      "learning_rate": 3.579051851851852e-05,
      "loss": 0.1299,
      "step": 28430
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.4564667046070099,
      "learning_rate": 3.578903703703704e-05,
      "loss": 0.1415,
      "step": 28440
    },
    {
      "epoch": 3.16,
      "grad_norm": 7.106778144836426,
      "learning_rate": 3.578755555555556e-05,
      "loss": 0.1098,
      "step": 28450
    },
    {
      "epoch": 3.16,
      "grad_norm": 3.464292049407959,
      "learning_rate": 3.5786074074074076e-05,
      "loss": 0.1042,
      "step": 28460
    },
    {
      "epoch": 3.16,
      "grad_norm": 3.3695366382598877,
      "learning_rate": 3.57845925925926e-05,
      "loss": 0.0623,
      "step": 28470
    },
    {
      "epoch": 3.16,
      "grad_norm": 3.3171226978302,
      "learning_rate": 3.5783111111111115e-05,
      "loss": 0.0781,
      "step": 28480
    },
    {
      "epoch": 3.17,
      "grad_norm": 2.1158535480499268,
      "learning_rate": 3.578162962962963e-05,
      "loss": 0.0773,
      "step": 28490
    },
    {
      "epoch": 3.17,
      "grad_norm": 6.239696502685547,
      "learning_rate": 3.578014814814815e-05,
      "loss": 0.1338,
      "step": 28500
    },
    {
      "epoch": 3.17,
      "grad_norm": 1.892414927482605,
      "learning_rate": 3.577866666666667e-05,
      "loss": 0.0865,
      "step": 28510
    },
    {
      "epoch": 3.17,
      "grad_norm": 5.040903568267822,
      "learning_rate": 3.5777185185185186e-05,
      "loss": 0.127,
      "step": 28520
    },
    {
      "epoch": 3.17,
      "grad_norm": 4.468830585479736,
      "learning_rate": 3.577570370370371e-05,
      "loss": 0.077,
      "step": 28530
    },
    {
      "epoch": 3.17,
      "grad_norm": 6.097446441650391,
      "learning_rate": 3.5774222222222225e-05,
      "loss": 0.1068,
      "step": 28540
    },
    {
      "epoch": 3.17,
      "grad_norm": 3.3886935710906982,
      "learning_rate": 3.577274074074074e-05,
      "loss": 0.0853,
      "step": 28550
    },
    {
      "epoch": 3.17,
      "grad_norm": 5.611643314361572,
      "learning_rate": 3.5771259259259264e-05,
      "loss": 0.0867,
      "step": 28560
    },
    {
      "epoch": 3.17,
      "grad_norm": 5.807359218597412,
      "learning_rate": 3.576977777777778e-05,
      "loss": 0.1139,
      "step": 28570
    },
    {
      "epoch": 3.18,
      "grad_norm": 6.142245769500732,
      "learning_rate": 3.57682962962963e-05,
      "loss": 0.118,
      "step": 28580
    },
    {
      "epoch": 3.18,
      "grad_norm": 5.2992024421691895,
      "learning_rate": 3.576681481481482e-05,
      "loss": 0.0967,
      "step": 28590
    },
    {
      "epoch": 3.18,
      "grad_norm": 7.860994338989258,
      "learning_rate": 3.5765333333333335e-05,
      "loss": 0.1669,
      "step": 28600
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.7559494972229004,
      "learning_rate": 3.576385185185185e-05,
      "loss": 0.0757,
      "step": 28610
    },
    {
      "epoch": 3.18,
      "grad_norm": 5.012803077697754,
      "learning_rate": 3.5762370370370374e-05,
      "loss": 0.1156,
      "step": 28620
    },
    {
      "epoch": 3.18,
      "grad_norm": 2.987943172454834,
      "learning_rate": 3.5760888888888896e-05,
      "loss": 0.0961,
      "step": 28630
    },
    {
      "epoch": 3.18,
      "grad_norm": 4.762187480926514,
      "learning_rate": 3.575940740740741e-05,
      "loss": 0.1292,
      "step": 28640
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.8950672149658203,
      "learning_rate": 3.575792592592593e-05,
      "loss": 0.0805,
      "step": 28650
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.881354331970215,
      "learning_rate": 3.5756444444444444e-05,
      "loss": 0.081,
      "step": 28660
    },
    {
      "epoch": 3.19,
      "grad_norm": 6.298869609832764,
      "learning_rate": 3.575496296296297e-05,
      "loss": 0.1119,
      "step": 28670
    },
    {
      "epoch": 3.19,
      "grad_norm": 4.0736613273620605,
      "learning_rate": 3.575348148148148e-05,
      "loss": 0.0833,
      "step": 28680
    },
    {
      "epoch": 3.19,
      "grad_norm": 1.3985755443572998,
      "learning_rate": 3.5752000000000006e-05,
      "loss": 0.0921,
      "step": 28690
    },
    {
      "epoch": 3.19,
      "grad_norm": 3.3528449535369873,
      "learning_rate": 3.575051851851852e-05,
      "loss": 0.0762,
      "step": 28700
    },
    {
      "epoch": 3.19,
      "grad_norm": 2.4875059127807617,
      "learning_rate": 3.574903703703704e-05,
      "loss": 0.1359,
      "step": 28710
    },
    {
      "epoch": 3.19,
      "grad_norm": 8.86863899230957,
      "learning_rate": 3.574755555555556e-05,
      "loss": 0.1485,
      "step": 28720
    },
    {
      "epoch": 3.19,
      "grad_norm": 8.767598152160645,
      "learning_rate": 3.574607407407408e-05,
      "loss": 0.1199,
      "step": 28730
    },
    {
      "epoch": 3.19,
      "grad_norm": 4.077683448791504,
      "learning_rate": 3.57445925925926e-05,
      "loss": 0.1111,
      "step": 28740
    },
    {
      "epoch": 3.19,
      "grad_norm": 5.631331443786621,
      "learning_rate": 3.5743111111111116e-05,
      "loss": 0.0887,
      "step": 28750
    },
    {
      "epoch": 3.2,
      "grad_norm": 4.488420486450195,
      "learning_rate": 3.574162962962963e-05,
      "loss": 0.1046,
      "step": 28760
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.9925994873046875,
      "learning_rate": 3.574014814814815e-05,
      "loss": 0.13,
      "step": 28770
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.461646318435669,
      "learning_rate": 3.573866666666667e-05,
      "loss": 0.0618,
      "step": 28780
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.9541866779327393,
      "learning_rate": 3.573718518518519e-05,
      "loss": 0.1138,
      "step": 28790
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.7621676921844482,
      "learning_rate": 3.573570370370371e-05,
      "loss": 0.0656,
      "step": 28800
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.740281105041504,
      "learning_rate": 3.5734222222222225e-05,
      "loss": 0.106,
      "step": 28810
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.7920026779174805,
      "learning_rate": 3.573274074074074e-05,
      "loss": 0.1146,
      "step": 28820
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.657769203186035,
      "learning_rate": 3.5731259259259264e-05,
      "loss": 0.0831,
      "step": 28830
    },
    {
      "epoch": 3.2,
      "grad_norm": 4.037079334259033,
      "learning_rate": 3.572977777777778e-05,
      "loss": 0.1176,
      "step": 28840
    },
    {
      "epoch": 3.21,
      "grad_norm": 2.5640199184417725,
      "learning_rate": 3.57282962962963e-05,
      "loss": 0.085,
      "step": 28850
    },
    {
      "epoch": 3.21,
      "grad_norm": 3.0321037769317627,
      "learning_rate": 3.572681481481482e-05,
      "loss": 0.1182,
      "step": 28860
    },
    {
      "epoch": 3.21,
      "grad_norm": 1.8658491373062134,
      "learning_rate": 3.5725333333333335e-05,
      "loss": 0.0871,
      "step": 28870
    },
    {
      "epoch": 3.21,
      "grad_norm": 2.356600761413574,
      "learning_rate": 3.572385185185185e-05,
      "loss": 0.1134,
      "step": 28880
    },
    {
      "epoch": 3.21,
      "grad_norm": 6.6318511962890625,
      "learning_rate": 3.5722370370370374e-05,
      "loss": 0.1268,
      "step": 28890
    },
    {
      "epoch": 3.21,
      "grad_norm": 1.2677764892578125,
      "learning_rate": 3.57208888888889e-05,
      "loss": 0.0802,
      "step": 28900
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.656914234161377,
      "learning_rate": 3.571940740740741e-05,
      "loss": 0.0709,
      "step": 28910
    },
    {
      "epoch": 3.21,
      "grad_norm": 3.715205669403076,
      "learning_rate": 3.571792592592593e-05,
      "loss": 0.0885,
      "step": 28920
    },
    {
      "epoch": 3.21,
      "grad_norm": 5.0666117668151855,
      "learning_rate": 3.5716444444444445e-05,
      "loss": 0.113,
      "step": 28930
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.894505023956299,
      "learning_rate": 3.571496296296297e-05,
      "loss": 0.1184,
      "step": 28940
    },
    {
      "epoch": 3.22,
      "grad_norm": 12.092863082885742,
      "learning_rate": 3.5713481481481484e-05,
      "loss": 0.162,
      "step": 28950
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.864077091217041,
      "learning_rate": 3.5712000000000006e-05,
      "loss": 0.1377,
      "step": 28960
    },
    {
      "epoch": 3.22,
      "grad_norm": 6.393310546875,
      "learning_rate": 3.571051851851852e-05,
      "loss": 0.1122,
      "step": 28970
    },
    {
      "epoch": 3.22,
      "grad_norm": 6.299017906188965,
      "learning_rate": 3.570903703703704e-05,
      "loss": 0.0938,
      "step": 28980
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.041487693786621,
      "learning_rate": 3.5707555555555554e-05,
      "loss": 0.1131,
      "step": 28990
    },
    {
      "epoch": 3.22,
      "grad_norm": 3.845259666442871,
      "learning_rate": 3.570607407407408e-05,
      "loss": 0.0877,
      "step": 29000
    },
    {
      "epoch": 3.22,
      "grad_norm": 6.831221580505371,
      "learning_rate": 3.57045925925926e-05,
      "loss": 0.1264,
      "step": 29010
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.7626731395721436,
      "learning_rate": 3.5703111111111116e-05,
      "loss": 0.0909,
      "step": 29020
    },
    {
      "epoch": 3.23,
      "grad_norm": 12.15239429473877,
      "learning_rate": 3.570162962962963e-05,
      "loss": 0.1102,
      "step": 29030
    },
    {
      "epoch": 3.23,
      "grad_norm": 1.3130908012390137,
      "learning_rate": 3.570014814814815e-05,
      "loss": 0.152,
      "step": 29040
    },
    {
      "epoch": 3.23,
      "grad_norm": 6.4670610427856445,
      "learning_rate": 3.569866666666667e-05,
      "loss": 0.1068,
      "step": 29050
    },
    {
      "epoch": 3.23,
      "grad_norm": 2.278658390045166,
      "learning_rate": 3.569718518518519e-05,
      "loss": 0.1033,
      "step": 29060
    },
    {
      "epoch": 3.23,
      "grad_norm": 9.721874237060547,
      "learning_rate": 3.569570370370371e-05,
      "loss": 0.0847,
      "step": 29070
    },
    {
      "epoch": 3.23,
      "grad_norm": 1.3332172632217407,
      "learning_rate": 3.5694222222222226e-05,
      "loss": 0.0945,
      "step": 29080
    },
    {
      "epoch": 3.23,
      "grad_norm": 4.657268047332764,
      "learning_rate": 3.569274074074074e-05,
      "loss": 0.1069,
      "step": 29090
    },
    {
      "epoch": 3.23,
      "grad_norm": 4.147878170013428,
      "learning_rate": 3.569125925925926e-05,
      "loss": 0.0799,
      "step": 29100
    },
    {
      "epoch": 3.23,
      "grad_norm": 3.9931881427764893,
      "learning_rate": 3.568977777777778e-05,
      "loss": 0.0886,
      "step": 29110
    },
    {
      "epoch": 3.24,
      "grad_norm": 5.534543514251709,
      "learning_rate": 3.5688296296296303e-05,
      "loss": 0.1326,
      "step": 29120
    },
    {
      "epoch": 3.24,
      "grad_norm": 5.651610374450684,
      "learning_rate": 3.568681481481482e-05,
      "loss": 0.0895,
      "step": 29130
    },
    {
      "epoch": 3.24,
      "grad_norm": 4.050714015960693,
      "learning_rate": 3.5685333333333335e-05,
      "loss": 0.1028,
      "step": 29140
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.151916027069092,
      "learning_rate": 3.568385185185185e-05,
      "loss": 0.0729,
      "step": 29150
    },
    {
      "epoch": 3.24,
      "grad_norm": 4.32379674911499,
      "learning_rate": 3.5682370370370374e-05,
      "loss": 0.1023,
      "step": 29160
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.7407166957855225,
      "learning_rate": 3.56808888888889e-05,
      "loss": 0.1048,
      "step": 29170
    },
    {
      "epoch": 3.24,
      "grad_norm": 4.359139919281006,
      "learning_rate": 3.567940740740741e-05,
      "loss": 0.0876,
      "step": 29180
    },
    {
      "epoch": 3.24,
      "grad_norm": 1.5905991792678833,
      "learning_rate": 3.567792592592593e-05,
      "loss": 0.1148,
      "step": 29190
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.816298484802246,
      "learning_rate": 3.5676444444444445e-05,
      "loss": 0.0732,
      "step": 29200
    },
    {
      "epoch": 3.25,
      "grad_norm": 2.4857912063598633,
      "learning_rate": 3.567496296296297e-05,
      "loss": 0.0859,
      "step": 29210
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.045214891433716,
      "learning_rate": 3.5673481481481484e-05,
      "loss": 0.1378,
      "step": 29220
    },
    {
      "epoch": 3.25,
      "grad_norm": 9.774168968200684,
      "learning_rate": 3.567200000000001e-05,
      "loss": 0.121,
      "step": 29230
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.2529547214508057,
      "learning_rate": 3.567051851851852e-05,
      "loss": 0.0635,
      "step": 29240
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.5153861045837402,
      "learning_rate": 3.566903703703704e-05,
      "loss": 0.0798,
      "step": 29250
    },
    {
      "epoch": 3.25,
      "grad_norm": 11.095276832580566,
      "learning_rate": 3.5667555555555555e-05,
      "loss": 0.1427,
      "step": 29260
    },
    {
      "epoch": 3.25,
      "grad_norm": 1.5892696380615234,
      "learning_rate": 3.566607407407408e-05,
      "loss": 0.0788,
      "step": 29270
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.3143560886383057,
      "learning_rate": 3.56645925925926e-05,
      "loss": 0.1224,
      "step": 29280
    },
    {
      "epoch": 3.25,
      "grad_norm": 6.424800872802734,
      "learning_rate": 3.5663111111111116e-05,
      "loss": 0.1144,
      "step": 29290
    },
    {
      "epoch": 3.26,
      "grad_norm": 5.187564373016357,
      "learning_rate": 3.566162962962963e-05,
      "loss": 0.1086,
      "step": 29300
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.427679061889648,
      "learning_rate": 3.566014814814815e-05,
      "loss": 0.0693,
      "step": 29310
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.6143293380737305,
      "learning_rate": 3.565866666666667e-05,
      "loss": 0.0804,
      "step": 29320
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.9258995056152344,
      "learning_rate": 3.565718518518519e-05,
      "loss": 0.1164,
      "step": 29330
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.057994365692139,
      "learning_rate": 3.565570370370371e-05,
      "loss": 0.0666,
      "step": 29340
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.549534559249878,
      "learning_rate": 3.5654222222222226e-05,
      "loss": 0.095,
      "step": 29350
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.532272815704346,
      "learning_rate": 3.565274074074074e-05,
      "loss": 0.1455,
      "step": 29360
    },
    {
      "epoch": 3.26,
      "grad_norm": 7.890268325805664,
      "learning_rate": 3.565125925925926e-05,
      "loss": 0.1846,
      "step": 29370
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.698341131210327,
      "learning_rate": 3.564977777777778e-05,
      "loss": 0.1512,
      "step": 29380
    },
    {
      "epoch": 3.27,
      "grad_norm": 3.408552885055542,
      "learning_rate": 3.5648296296296304e-05,
      "loss": 0.1226,
      "step": 29390
    },
    {
      "epoch": 3.27,
      "grad_norm": 3.465601682662964,
      "learning_rate": 3.564681481481482e-05,
      "loss": 0.1671,
      "step": 29400
    },
    {
      "epoch": 3.27,
      "grad_norm": 3.9994964599609375,
      "learning_rate": 3.5645333333333336e-05,
      "loss": 0.1013,
      "step": 29410
    },
    {
      "epoch": 3.27,
      "grad_norm": 1.1919653415679932,
      "learning_rate": 3.564385185185185e-05,
      "loss": 0.1216,
      "step": 29420
    },
    {
      "epoch": 3.27,
      "grad_norm": 1.0332802534103394,
      "learning_rate": 3.5642370370370375e-05,
      "loss": 0.0947,
      "step": 29430
    },
    {
      "epoch": 3.27,
      "grad_norm": 1.9344011545181274,
      "learning_rate": 3.564088888888889e-05,
      "loss": 0.0595,
      "step": 29440
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.746540069580078,
      "learning_rate": 3.5639407407407413e-05,
      "loss": 0.0693,
      "step": 29450
    },
    {
      "epoch": 3.27,
      "grad_norm": 5.957732200622559,
      "learning_rate": 3.563792592592593e-05,
      "loss": 0.0963,
      "step": 29460
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.9840199947357178,
      "learning_rate": 3.5636444444444446e-05,
      "loss": 0.1569,
      "step": 29470
    },
    {
      "epoch": 3.28,
      "grad_norm": 2.201425790786743,
      "learning_rate": 3.563496296296296e-05,
      "loss": 0.0811,
      "step": 29480
    },
    {
      "epoch": 3.28,
      "grad_norm": 2.7810540199279785,
      "learning_rate": 3.5633481481481484e-05,
      "loss": 0.1063,
      "step": 29490
    },
    {
      "epoch": 3.28,
      "grad_norm": 10.791131019592285,
      "learning_rate": 3.563200000000001e-05,
      "loss": 0.0883,
      "step": 29500
    },
    {
      "epoch": 3.28,
      "grad_norm": 1.9330116510391235,
      "learning_rate": 3.563051851851852e-05,
      "loss": 0.1256,
      "step": 29510
    },
    {
      "epoch": 3.28,
      "grad_norm": 3.467177391052246,
      "learning_rate": 3.562903703703704e-05,
      "loss": 0.1055,
      "step": 29520
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.7268761396408081,
      "learning_rate": 3.5627555555555555e-05,
      "loss": 0.0703,
      "step": 29530
    },
    {
      "epoch": 3.28,
      "grad_norm": 7.600769519805908,
      "learning_rate": 3.562607407407408e-05,
      "loss": 0.0978,
      "step": 29540
    },
    {
      "epoch": 3.28,
      "grad_norm": 3.228671073913574,
      "learning_rate": 3.5624592592592594e-05,
      "loss": 0.0625,
      "step": 29550
    },
    {
      "epoch": 3.28,
      "grad_norm": 3.872410297393799,
      "learning_rate": 3.562311111111112e-05,
      "loss": 0.0717,
      "step": 29560
    },
    {
      "epoch": 3.29,
      "grad_norm": 3.577104330062866,
      "learning_rate": 3.562162962962963e-05,
      "loss": 0.1168,
      "step": 29570
    },
    {
      "epoch": 3.29,
      "grad_norm": 1.2931089401245117,
      "learning_rate": 3.562014814814815e-05,
      "loss": 0.1022,
      "step": 29580
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.6043550372123718,
      "learning_rate": 3.5618666666666665e-05,
      "loss": 0.1039,
      "step": 29590
    },
    {
      "epoch": 3.29,
      "grad_norm": 3.150731325149536,
      "learning_rate": 3.561718518518519e-05,
      "loss": 0.0718,
      "step": 29600
    },
    {
      "epoch": 3.29,
      "grad_norm": 6.236032485961914,
      "learning_rate": 3.561570370370371e-05,
      "loss": 0.0781,
      "step": 29610
    },
    {
      "epoch": 3.29,
      "grad_norm": 3.7375779151916504,
      "learning_rate": 3.5614222222222227e-05,
      "loss": 0.0926,
      "step": 29620
    },
    {
      "epoch": 3.29,
      "grad_norm": 5.863997936248779,
      "learning_rate": 3.561274074074074e-05,
      "loss": 0.129,
      "step": 29630
    },
    {
      "epoch": 3.29,
      "grad_norm": 2.787818193435669,
      "learning_rate": 3.561125925925926e-05,
      "loss": 0.1118,
      "step": 29640
    },
    {
      "epoch": 3.29,
      "grad_norm": 2.7244961261749268,
      "learning_rate": 3.560977777777778e-05,
      "loss": 0.0763,
      "step": 29650
    },
    {
      "epoch": 3.3,
      "grad_norm": 6.164427757263184,
      "learning_rate": 3.5608296296296304e-05,
      "loss": 0.0944,
      "step": 29660
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.9406619668006897,
      "learning_rate": 3.560681481481482e-05,
      "loss": 0.122,
      "step": 29670
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.4024367332458496,
      "learning_rate": 3.5605333333333336e-05,
      "loss": 0.1441,
      "step": 29680
    },
    {
      "epoch": 3.3,
      "grad_norm": 3.0231456756591797,
      "learning_rate": 3.560385185185185e-05,
      "loss": 0.1021,
      "step": 29690
    },
    {
      "epoch": 3.3,
      "grad_norm": 6.355120658874512,
      "learning_rate": 3.560237037037037e-05,
      "loss": 0.0752,
      "step": 29700
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.6708316802978516,
      "learning_rate": 3.560088888888889e-05,
      "loss": 0.0813,
      "step": 29710
    },
    {
      "epoch": 3.3,
      "grad_norm": 4.6773552894592285,
      "learning_rate": 3.5599407407407414e-05,
      "loss": 0.1088,
      "step": 29720
    },
    {
      "epoch": 3.3,
      "grad_norm": 4.070076942443848,
      "learning_rate": 3.559792592592593e-05,
      "loss": 0.1065,
      "step": 29730
    },
    {
      "epoch": 3.3,
      "grad_norm": 3.96976375579834,
      "learning_rate": 3.5596444444444446e-05,
      "loss": 0.1118,
      "step": 29740
    },
    {
      "epoch": 3.31,
      "grad_norm": 5.215542316436768,
      "learning_rate": 3.559496296296296e-05,
      "loss": 0.1105,
      "step": 29750
    },
    {
      "epoch": 3.31,
      "grad_norm": 8.959787368774414,
      "learning_rate": 3.5593481481481485e-05,
      "loss": 0.1501,
      "step": 29760
    },
    {
      "epoch": 3.31,
      "grad_norm": 5.015620708465576,
      "learning_rate": 3.559200000000001e-05,
      "loss": 0.1,
      "step": 29770
    },
    {
      "epoch": 3.31,
      "grad_norm": 5.323845386505127,
      "learning_rate": 3.5590518518518524e-05,
      "loss": 0.132,
      "step": 29780
    },
    {
      "epoch": 3.31,
      "grad_norm": 1.7675095796585083,
      "learning_rate": 3.558903703703704e-05,
      "loss": 0.1283,
      "step": 29790
    },
    {
      "epoch": 3.31,
      "grad_norm": 2.552295446395874,
      "learning_rate": 3.5587555555555556e-05,
      "loss": 0.1294,
      "step": 29800
    },
    {
      "epoch": 3.31,
      "grad_norm": 5.023264408111572,
      "learning_rate": 3.558607407407408e-05,
      "loss": 0.1213,
      "step": 29810
    },
    {
      "epoch": 3.31,
      "grad_norm": 5.800673007965088,
      "learning_rate": 3.5584592592592594e-05,
      "loss": 0.1096,
      "step": 29820
    },
    {
      "epoch": 3.31,
      "grad_norm": 4.432562828063965,
      "learning_rate": 3.558311111111112e-05,
      "loss": 0.1001,
      "step": 29830
    },
    {
      "epoch": 3.32,
      "grad_norm": 3.582750082015991,
      "learning_rate": 3.558162962962963e-05,
      "loss": 0.1033,
      "step": 29840
    },
    {
      "epoch": 3.32,
      "grad_norm": 5.112832546234131,
      "learning_rate": 3.558014814814815e-05,
      "loss": 0.1096,
      "step": 29850
    },
    {
      "epoch": 3.32,
      "grad_norm": 2.8246915340423584,
      "learning_rate": 3.5578666666666665e-05,
      "loss": 0.0677,
      "step": 29860
    },
    {
      "epoch": 3.32,
      "grad_norm": 2.0068366527557373,
      "learning_rate": 3.557718518518519e-05,
      "loss": 0.0826,
      "step": 29870
    },
    {
      "epoch": 3.32,
      "grad_norm": 8.539732933044434,
      "learning_rate": 3.557570370370371e-05,
      "loss": 0.0928,
      "step": 29880
    },
    {
      "epoch": 3.32,
      "grad_norm": 12.220762252807617,
      "learning_rate": 3.557422222222223e-05,
      "loss": 0.0786,
      "step": 29890
    },
    {
      "epoch": 3.32,
      "grad_norm": 4.805068016052246,
      "learning_rate": 3.557274074074074e-05,
      "loss": 0.0704,
      "step": 29900
    },
    {
      "epoch": 3.32,
      "grad_norm": 4.270802021026611,
      "learning_rate": 3.557125925925926e-05,
      "loss": 0.1481,
      "step": 29910
    },
    {
      "epoch": 3.32,
      "grad_norm": 4.074153900146484,
      "learning_rate": 3.556977777777778e-05,
      "loss": 0.0681,
      "step": 29920
    },
    {
      "epoch": 3.33,
      "grad_norm": 1.7183475494384766,
      "learning_rate": 3.55682962962963e-05,
      "loss": 0.0894,
      "step": 29930
    },
    {
      "epoch": 3.33,
      "grad_norm": 1.7054061889648438,
      "learning_rate": 3.556681481481482e-05,
      "loss": 0.0779,
      "step": 29940
    },
    {
      "epoch": 3.33,
      "grad_norm": 3.173970937728882,
      "learning_rate": 3.5565333333333337e-05,
      "loss": 0.1108,
      "step": 29950
    },
    {
      "epoch": 3.33,
      "grad_norm": 5.212510108947754,
      "learning_rate": 3.556385185185185e-05,
      "loss": 0.1325,
      "step": 29960
    },
    {
      "epoch": 3.33,
      "grad_norm": 3.8747096061706543,
      "learning_rate": 3.556237037037037e-05,
      "loss": 0.064,
      "step": 29970
    },
    {
      "epoch": 3.33,
      "grad_norm": 2.908470630645752,
      "learning_rate": 3.556088888888889e-05,
      "loss": 0.0635,
      "step": 29980
    },
    {
      "epoch": 3.33,
      "grad_norm": 7.373995780944824,
      "learning_rate": 3.5559407407407414e-05,
      "loss": 0.1724,
      "step": 29990
    },
    {
      "epoch": 3.33,
      "grad_norm": 7.541836738586426,
      "learning_rate": 3.555792592592593e-05,
      "loss": 0.072,
      "step": 30000
    },
    {
      "epoch": 3.33,
      "grad_norm": 5.216845989227295,
      "learning_rate": 3.5556444444444446e-05,
      "loss": 0.1141,
      "step": 30010
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.47093391418457,
      "learning_rate": 3.555496296296296e-05,
      "loss": 0.1145,
      "step": 30020
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.610460042953491,
      "learning_rate": 3.5553481481481485e-05,
      "loss": 0.1087,
      "step": 30030
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.3722925186157227,
      "learning_rate": 3.5552e-05,
      "loss": 0.1183,
      "step": 30040
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.453096866607666,
      "learning_rate": 3.5550518518518524e-05,
      "loss": 0.1181,
      "step": 30050
    },
    {
      "epoch": 3.34,
      "grad_norm": 7.640116214752197,
      "learning_rate": 3.554903703703704e-05,
      "loss": 0.1071,
      "step": 30060
    },
    {
      "epoch": 3.34,
      "grad_norm": 5.39073371887207,
      "learning_rate": 3.5547555555555556e-05,
      "loss": 0.1646,
      "step": 30070
    },
    {
      "epoch": 3.34,
      "grad_norm": 1.9435175657272339,
      "learning_rate": 3.554607407407407e-05,
      "loss": 0.0673,
      "step": 30080
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.410177707672119,
      "learning_rate": 3.5544592592592595e-05,
      "loss": 0.1278,
      "step": 30090
    },
    {
      "epoch": 3.34,
      "grad_norm": 1.5148099660873413,
      "learning_rate": 3.554311111111112e-05,
      "loss": 0.075,
      "step": 30100
    },
    {
      "epoch": 3.35,
      "grad_norm": 5.770481109619141,
      "learning_rate": 3.5541629629629634e-05,
      "loss": 0.0921,
      "step": 30110
    },
    {
      "epoch": 3.35,
      "grad_norm": 9.105049133300781,
      "learning_rate": 3.554014814814815e-05,
      "loss": 0.1346,
      "step": 30120
    },
    {
      "epoch": 3.35,
      "grad_norm": 4.849079608917236,
      "learning_rate": 3.5538666666666666e-05,
      "loss": 0.0833,
      "step": 30130
    },
    {
      "epoch": 3.35,
      "grad_norm": 2.8134138584136963,
      "learning_rate": 3.553718518518519e-05,
      "loss": 0.1167,
      "step": 30140
    },
    {
      "epoch": 3.35,
      "grad_norm": 3.989743947982788,
      "learning_rate": 3.5535703703703704e-05,
      "loss": 0.0868,
      "step": 30150
    },
    {
      "epoch": 3.35,
      "grad_norm": 3.1602721214294434,
      "learning_rate": 3.553422222222223e-05,
      "loss": 0.119,
      "step": 30160
    },
    {
      "epoch": 3.35,
      "grad_norm": 3.1793203353881836,
      "learning_rate": 3.553274074074074e-05,
      "loss": 0.1013,
      "step": 30170
    },
    {
      "epoch": 3.35,
      "grad_norm": 6.998600482940674,
      "learning_rate": 3.553125925925926e-05,
      "loss": 0.1321,
      "step": 30180
    },
    {
      "epoch": 3.35,
      "grad_norm": 2.3036270141601562,
      "learning_rate": 3.5529777777777775e-05,
      "loss": 0.0823,
      "step": 30190
    },
    {
      "epoch": 3.36,
      "grad_norm": 3.097299337387085,
      "learning_rate": 3.55282962962963e-05,
      "loss": 0.0811,
      "step": 30200
    },
    {
      "epoch": 3.36,
      "grad_norm": 4.766075134277344,
      "learning_rate": 3.552681481481482e-05,
      "loss": 0.0806,
      "step": 30210
    },
    {
      "epoch": 3.36,
      "grad_norm": 12.068882942199707,
      "learning_rate": 3.552533333333334e-05,
      "loss": 0.1088,
      "step": 30220
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.5646376609802246,
      "learning_rate": 3.552385185185185e-05,
      "loss": 0.0752,
      "step": 30230
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.3246443271636963,
      "learning_rate": 3.552237037037037e-05,
      "loss": 0.201,
      "step": 30240
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.5405054092407227,
      "learning_rate": 3.552088888888889e-05,
      "loss": 0.0657,
      "step": 30250
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.3204433917999268,
      "learning_rate": 3.5519407407407415e-05,
      "loss": 0.0918,
      "step": 30260
    },
    {
      "epoch": 3.36,
      "grad_norm": 6.088529586791992,
      "learning_rate": 3.551792592592593e-05,
      "loss": 0.135,
      "step": 30270
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.8345123529434204,
      "learning_rate": 3.551644444444445e-05,
      "loss": 0.1,
      "step": 30280
    },
    {
      "epoch": 3.37,
      "grad_norm": 4.141138076782227,
      "learning_rate": 3.551496296296296e-05,
      "loss": 0.0893,
      "step": 30290
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.957025408744812,
      "learning_rate": 3.5513481481481485e-05,
      "loss": 0.0692,
      "step": 30300
    },
    {
      "epoch": 3.37,
      "grad_norm": 2.07633376121521,
      "learning_rate": 3.5512e-05,
      "loss": 0.1415,
      "step": 30310
    },
    {
      "epoch": 3.37,
      "grad_norm": 1.5190694332122803,
      "learning_rate": 3.5510518518518524e-05,
      "loss": 0.0779,
      "step": 30320
    },
    {
      "epoch": 3.37,
      "grad_norm": 4.137959003448486,
      "learning_rate": 3.550903703703704e-05,
      "loss": 0.1312,
      "step": 30330
    },
    {
      "epoch": 3.37,
      "grad_norm": 4.233877658843994,
      "learning_rate": 3.5507555555555556e-05,
      "loss": 0.1423,
      "step": 30340
    },
    {
      "epoch": 3.37,
      "grad_norm": 9.66148567199707,
      "learning_rate": 3.550607407407407e-05,
      "loss": 0.1169,
      "step": 30350
    },
    {
      "epoch": 3.37,
      "grad_norm": 7.655543804168701,
      "learning_rate": 3.5504592592592595e-05,
      "loss": 0.1,
      "step": 30360
    },
    {
      "epoch": 3.37,
      "grad_norm": 1.2465542554855347,
      "learning_rate": 3.550311111111112e-05,
      "loss": 0.0609,
      "step": 30370
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.7003076076507568,
      "learning_rate": 3.5501629629629634e-05,
      "loss": 0.0828,
      "step": 30380
    },
    {
      "epoch": 3.38,
      "grad_norm": 6.8471245765686035,
      "learning_rate": 3.550014814814815e-05,
      "loss": 0.0821,
      "step": 30390
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.7336089611053467,
      "learning_rate": 3.5498666666666666e-05,
      "loss": 0.0967,
      "step": 30400
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.3984978199005127,
      "learning_rate": 3.549718518518519e-05,
      "loss": 0.0692,
      "step": 30410
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.413413166999817,
      "learning_rate": 3.5495703703703705e-05,
      "loss": 0.0617,
      "step": 30420
    },
    {
      "epoch": 3.38,
      "grad_norm": 8.883840560913086,
      "learning_rate": 3.549422222222223e-05,
      "loss": 0.081,
      "step": 30430
    },
    {
      "epoch": 3.38,
      "grad_norm": 3.2854902744293213,
      "learning_rate": 3.5492740740740744e-05,
      "loss": 0.1292,
      "step": 30440
    },
    {
      "epoch": 3.38,
      "grad_norm": 3.9591801166534424,
      "learning_rate": 3.549125925925926e-05,
      "loss": 0.1244,
      "step": 30450
    },
    {
      "epoch": 3.38,
      "grad_norm": 4.758001327514648,
      "learning_rate": 3.5489777777777776e-05,
      "loss": 0.0938,
      "step": 30460
    },
    {
      "epoch": 3.39,
      "grad_norm": 5.389327526092529,
      "learning_rate": 3.54882962962963e-05,
      "loss": 0.1036,
      "step": 30470
    },
    {
      "epoch": 3.39,
      "grad_norm": 2.647355556488037,
      "learning_rate": 3.548681481481482e-05,
      "loss": 0.116,
      "step": 30480
    },
    {
      "epoch": 3.39,
      "grad_norm": 2.999699354171753,
      "learning_rate": 3.548533333333334e-05,
      "loss": 0.0678,
      "step": 30490
    },
    {
      "epoch": 3.39,
      "grad_norm": 4.352945327758789,
      "learning_rate": 3.5483851851851853e-05,
      "loss": 0.0682,
      "step": 30500
    },
    {
      "epoch": 3.39,
      "grad_norm": 6.908661365509033,
      "learning_rate": 3.5482518518518524e-05,
      "loss": 0.1738,
      "step": 30510
    },
    {
      "epoch": 3.39,
      "grad_norm": 4.156158924102783,
      "learning_rate": 3.548103703703704e-05,
      "loss": 0.1178,
      "step": 30520
    },
    {
      "epoch": 3.39,
      "grad_norm": 3.911895275115967,
      "learning_rate": 3.547955555555556e-05,
      "loss": 0.0504,
      "step": 30530
    },
    {
      "epoch": 3.39,
      "grad_norm": 3.9385344982147217,
      "learning_rate": 3.547807407407408e-05,
      "loss": 0.066,
      "step": 30540
    },
    {
      "epoch": 3.39,
      "grad_norm": 2.7971463203430176,
      "learning_rate": 3.5476592592592595e-05,
      "loss": 0.0926,
      "step": 30550
    },
    {
      "epoch": 3.4,
      "grad_norm": 3.8396360874176025,
      "learning_rate": 3.547511111111111e-05,
      "loss": 0.113,
      "step": 30560
    },
    {
      "epoch": 3.4,
      "grad_norm": 4.302154064178467,
      "learning_rate": 3.5473629629629634e-05,
      "loss": 0.1498,
      "step": 30570
    },
    {
      "epoch": 3.4,
      "grad_norm": 3.5768370628356934,
      "learning_rate": 3.547214814814815e-05,
      "loss": 0.0877,
      "step": 30580
    },
    {
      "epoch": 3.4,
      "grad_norm": 4.964136123657227,
      "learning_rate": 3.547066666666667e-05,
      "loss": 0.0685,
      "step": 30590
    },
    {
      "epoch": 3.4,
      "grad_norm": 4.992021083831787,
      "learning_rate": 3.546918518518519e-05,
      "loss": 0.1424,
      "step": 30600
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.950010299682617,
      "learning_rate": 3.5467703703703704e-05,
      "loss": 0.1005,
      "step": 30610
    },
    {
      "epoch": 3.4,
      "grad_norm": 5.881022930145264,
      "learning_rate": 3.546622222222223e-05,
      "loss": 0.1535,
      "step": 30620
    },
    {
      "epoch": 3.4,
      "grad_norm": 8.512284278869629,
      "learning_rate": 3.546474074074074e-05,
      "loss": 0.1245,
      "step": 30630
    },
    {
      "epoch": 3.4,
      "grad_norm": 4.336479663848877,
      "learning_rate": 3.5463259259259266e-05,
      "loss": 0.0745,
      "step": 30640
    },
    {
      "epoch": 3.41,
      "grad_norm": 3.3754818439483643,
      "learning_rate": 3.546177777777778e-05,
      "loss": 0.0963,
      "step": 30650
    },
    {
      "epoch": 3.41,
      "grad_norm": 2.4597718715667725,
      "learning_rate": 3.54602962962963e-05,
      "loss": 0.1191,
      "step": 30660
    },
    {
      "epoch": 3.41,
      "grad_norm": 5.522956848144531,
      "learning_rate": 3.5458814814814814e-05,
      "loss": 0.1919,
      "step": 30670
    },
    {
      "epoch": 3.41,
      "grad_norm": 4.275769233703613,
      "learning_rate": 3.545733333333334e-05,
      "loss": 0.1484,
      "step": 30680
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.7629931569099426,
      "learning_rate": 3.545585185185186e-05,
      "loss": 0.1531,
      "step": 30690
    },
    {
      "epoch": 3.41,
      "grad_norm": 4.2881574630737305,
      "learning_rate": 3.5454370370370376e-05,
      "loss": 0.1203,
      "step": 30700
    },
    {
      "epoch": 3.41,
      "grad_norm": 4.862737655639648,
      "learning_rate": 3.545288888888889e-05,
      "loss": 0.0985,
      "step": 30710
    },
    {
      "epoch": 3.41,
      "grad_norm": 4.508910179138184,
      "learning_rate": 3.545140740740741e-05,
      "loss": 0.073,
      "step": 30720
    },
    {
      "epoch": 3.41,
      "grad_norm": 6.552762508392334,
      "learning_rate": 3.544992592592593e-05,
      "loss": 0.0708,
      "step": 30730
    },
    {
      "epoch": 3.42,
      "grad_norm": 6.073098182678223,
      "learning_rate": 3.544844444444445e-05,
      "loss": 0.1083,
      "step": 30740
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.1343798637390137,
      "learning_rate": 3.544696296296297e-05,
      "loss": 0.0795,
      "step": 30750
    },
    {
      "epoch": 3.42,
      "grad_norm": 4.462430000305176,
      "learning_rate": 3.5445481481481485e-05,
      "loss": 0.1451,
      "step": 30760
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.791940927505493,
      "learning_rate": 3.5444e-05,
      "loss": 0.0793,
      "step": 30770
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.8787010908126831,
      "learning_rate": 3.544251851851852e-05,
      "loss": 0.0718,
      "step": 30780
    },
    {
      "epoch": 3.42,
      "grad_norm": 6.046070575714111,
      "learning_rate": 3.544103703703704e-05,
      "loss": 0.1062,
      "step": 30790
    },
    {
      "epoch": 3.42,
      "grad_norm": 7.678452491760254,
      "learning_rate": 3.543955555555556e-05,
      "loss": 0.0991,
      "step": 30800
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.7364754676818848,
      "learning_rate": 3.543807407407408e-05,
      "loss": 0.084,
      "step": 30810
    },
    {
      "epoch": 3.42,
      "grad_norm": 4.248232364654541,
      "learning_rate": 3.5436592592592595e-05,
      "loss": 0.1028,
      "step": 30820
    },
    {
      "epoch": 3.43,
      "grad_norm": 5.199741363525391,
      "learning_rate": 3.543511111111111e-05,
      "loss": 0.0913,
      "step": 30830
    },
    {
      "epoch": 3.43,
      "grad_norm": 4.608431339263916,
      "learning_rate": 3.5433629629629634e-05,
      "loss": 0.0957,
      "step": 30840
    },
    {
      "epoch": 3.43,
      "grad_norm": 3.2862045764923096,
      "learning_rate": 3.543214814814815e-05,
      "loss": 0.0817,
      "step": 30850
    },
    {
      "epoch": 3.43,
      "grad_norm": 5.400891304016113,
      "learning_rate": 3.543066666666667e-05,
      "loss": 0.0862,
      "step": 30860
    },
    {
      "epoch": 3.43,
      "grad_norm": 1.9152336120605469,
      "learning_rate": 3.542918518518519e-05,
      "loss": 0.0721,
      "step": 30870
    },
    {
      "epoch": 3.43,
      "grad_norm": 2.109210252761841,
      "learning_rate": 3.5427703703703705e-05,
      "loss": 0.0792,
      "step": 30880
    },
    {
      "epoch": 3.43,
      "grad_norm": 3.917495012283325,
      "learning_rate": 3.542622222222222e-05,
      "loss": 0.1176,
      "step": 30890
    },
    {
      "epoch": 3.43,
      "grad_norm": 3.664642572402954,
      "learning_rate": 3.5424740740740744e-05,
      "loss": 0.1055,
      "step": 30900
    },
    {
      "epoch": 3.43,
      "grad_norm": 1.6183634996414185,
      "learning_rate": 3.5423259259259266e-05,
      "loss": 0.0646,
      "step": 30910
    },
    {
      "epoch": 3.44,
      "grad_norm": 5.083248138427734,
      "learning_rate": 3.542177777777778e-05,
      "loss": 0.0798,
      "step": 30920
    },
    {
      "epoch": 3.44,
      "grad_norm": 9.148115158081055,
      "learning_rate": 3.54202962962963e-05,
      "loss": 0.0817,
      "step": 30930
    },
    {
      "epoch": 3.44,
      "grad_norm": 6.839206218719482,
      "learning_rate": 3.5418814814814815e-05,
      "loss": 0.0981,
      "step": 30940
    },
    {
      "epoch": 3.44,
      "grad_norm": 8.937687873840332,
      "learning_rate": 3.541733333333334e-05,
      "loss": 0.0812,
      "step": 30950
    },
    {
      "epoch": 3.44,
      "grad_norm": 14.673872947692871,
      "learning_rate": 3.541585185185186e-05,
      "loss": 0.1172,
      "step": 30960
    },
    {
      "epoch": 3.44,
      "grad_norm": 4.731178283691406,
      "learning_rate": 3.5414370370370376e-05,
      "loss": 0.099,
      "step": 30970
    },
    {
      "epoch": 3.44,
      "grad_norm": 6.365437030792236,
      "learning_rate": 3.541288888888889e-05,
      "loss": 0.0978,
      "step": 30980
    },
    {
      "epoch": 3.44,
      "grad_norm": 5.017460346221924,
      "learning_rate": 3.541140740740741e-05,
      "loss": 0.0699,
      "step": 30990
    },
    {
      "epoch": 3.44,
      "grad_norm": 3.673478126525879,
      "learning_rate": 3.5409925925925924e-05,
      "loss": 0.0736,
      "step": 31000
    },
    {
      "epoch": 3.45,
      "grad_norm": 3.022561550140381,
      "learning_rate": 3.540844444444445e-05,
      "loss": 0.1023,
      "step": 31010
    },
    {
      "epoch": 3.45,
      "grad_norm": 5.673707962036133,
      "learning_rate": 3.540696296296297e-05,
      "loss": 0.1113,
      "step": 31020
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.384096145629883,
      "learning_rate": 3.5405481481481486e-05,
      "loss": 0.0822,
      "step": 31030
    },
    {
      "epoch": 3.45,
      "grad_norm": 4.257809638977051,
      "learning_rate": 3.5404e-05,
      "loss": 0.0686,
      "step": 31040
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.15640926361084,
      "learning_rate": 3.540251851851852e-05,
      "loss": 0.1139,
      "step": 31050
    },
    {
      "epoch": 3.45,
      "grad_norm": 12.302740097045898,
      "learning_rate": 3.540103703703704e-05,
      "loss": 0.0995,
      "step": 31060
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.6714861392974854,
      "learning_rate": 3.5399555555555563e-05,
      "loss": 0.1134,
      "step": 31070
    },
    {
      "epoch": 3.45,
      "grad_norm": 5.239035129547119,
      "learning_rate": 3.539807407407408e-05,
      "loss": 0.1033,
      "step": 31080
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.4475603103637695,
      "learning_rate": 3.5396592592592596e-05,
      "loss": 0.1036,
      "step": 31090
    },
    {
      "epoch": 3.46,
      "grad_norm": 7.276986598968506,
      "learning_rate": 3.539511111111111e-05,
      "loss": 0.0939,
      "step": 31100
    },
    {
      "epoch": 3.46,
      "grad_norm": 3.4795799255371094,
      "learning_rate": 3.5393629629629634e-05,
      "loss": 0.0925,
      "step": 31110
    },
    {
      "epoch": 3.46,
      "grad_norm": 4.714044094085693,
      "learning_rate": 3.539214814814815e-05,
      "loss": 0.077,
      "step": 31120
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.1315475702285767,
      "learning_rate": 3.539066666666667e-05,
      "loss": 0.0716,
      "step": 31130
    },
    {
      "epoch": 3.46,
      "grad_norm": 6.186585903167725,
      "learning_rate": 3.538918518518519e-05,
      "loss": 0.1072,
      "step": 31140
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.2262215614318848,
      "learning_rate": 3.5387703703703705e-05,
      "loss": 0.0593,
      "step": 31150
    },
    {
      "epoch": 3.46,
      "grad_norm": 3.5022525787353516,
      "learning_rate": 3.538622222222222e-05,
      "loss": 0.1034,
      "step": 31160
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.428884267807007,
      "learning_rate": 3.5384740740740744e-05,
      "loss": 0.1176,
      "step": 31170
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.5020689964294434,
      "learning_rate": 3.538325925925927e-05,
      "loss": 0.1084,
      "step": 31180
    },
    {
      "epoch": 3.47,
      "grad_norm": 3.6255667209625244,
      "learning_rate": 3.538177777777778e-05,
      "loss": 0.1247,
      "step": 31190
    },
    {
      "epoch": 3.47,
      "grad_norm": 6.436054706573486,
      "learning_rate": 3.53802962962963e-05,
      "loss": 0.0963,
      "step": 31200
    },
    {
      "epoch": 3.47,
      "grad_norm": 4.454982757568359,
      "learning_rate": 3.5378814814814815e-05,
      "loss": 0.0924,
      "step": 31210
    },
    {
      "epoch": 3.47,
      "grad_norm": 2.618584156036377,
      "learning_rate": 3.537733333333334e-05,
      "loss": 0.1061,
      "step": 31220
    },
    {
      "epoch": 3.47,
      "grad_norm": 13.028220176696777,
      "learning_rate": 3.5375851851851854e-05,
      "loss": 0.1324,
      "step": 31230
    },
    {
      "epoch": 3.47,
      "grad_norm": 2.3082492351531982,
      "learning_rate": 3.5374370370370377e-05,
      "loss": 0.1064,
      "step": 31240
    },
    {
      "epoch": 3.47,
      "grad_norm": 3.3702168464660645,
      "learning_rate": 3.537288888888889e-05,
      "loss": 0.1076,
      "step": 31250
    },
    {
      "epoch": 3.47,
      "grad_norm": 4.7804036140441895,
      "learning_rate": 3.537140740740741e-05,
      "loss": 0.0897,
      "step": 31260
    },
    {
      "epoch": 3.47,
      "grad_norm": 3.07096266746521,
      "learning_rate": 3.5369925925925925e-05,
      "loss": 0.1317,
      "step": 31270
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.0131897926330566,
      "learning_rate": 3.536844444444445e-05,
      "loss": 0.1768,
      "step": 31280
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.073726177215576,
      "learning_rate": 3.536696296296297e-05,
      "loss": 0.0875,
      "step": 31290
    },
    {
      "epoch": 3.48,
      "grad_norm": 8.775551795959473,
      "learning_rate": 3.5365481481481486e-05,
      "loss": 0.1615,
      "step": 31300
    },
    {
      "epoch": 3.48,
      "grad_norm": 11.085433006286621,
      "learning_rate": 3.5364e-05,
      "loss": 0.1247,
      "step": 31310
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.7322278022766113,
      "learning_rate": 3.536251851851852e-05,
      "loss": 0.0587,
      "step": 31320
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.2817471027374268,
      "learning_rate": 3.536103703703704e-05,
      "loss": 0.0981,
      "step": 31330
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.916346788406372,
      "learning_rate": 3.535955555555556e-05,
      "loss": 0.1593,
      "step": 31340
    },
    {
      "epoch": 3.48,
      "grad_norm": 4.963495254516602,
      "learning_rate": 3.535807407407408e-05,
      "loss": 0.108,
      "step": 31350
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.5188324451446533,
      "learning_rate": 3.5356592592592596e-05,
      "loss": 0.1241,
      "step": 31360
    },
    {
      "epoch": 3.49,
      "grad_norm": 3.3323240280151367,
      "learning_rate": 3.535511111111111e-05,
      "loss": 0.1926,
      "step": 31370
    },
    {
      "epoch": 3.49,
      "grad_norm": 1.9832583665847778,
      "learning_rate": 3.535362962962963e-05,
      "loss": 0.0961,
      "step": 31380
    },
    {
      "epoch": 3.49,
      "grad_norm": 3.899657726287842,
      "learning_rate": 3.535214814814815e-05,
      "loss": 0.0792,
      "step": 31390
    },
    {
      "epoch": 3.49,
      "grad_norm": 2.390641450881958,
      "learning_rate": 3.5350666666666674e-05,
      "loss": 0.0889,
      "step": 31400
    },
    {
      "epoch": 3.49,
      "grad_norm": 4.9541168212890625,
      "learning_rate": 3.534918518518519e-05,
      "loss": 0.1469,
      "step": 31410
    },
    {
      "epoch": 3.49,
      "grad_norm": 3.828989028930664,
      "learning_rate": 3.5347703703703706e-05,
      "loss": 0.1071,
      "step": 31420
    },
    {
      "epoch": 3.49,
      "grad_norm": 2.7718048095703125,
      "learning_rate": 3.534622222222222e-05,
      "loss": 0.0934,
      "step": 31430
    },
    {
      "epoch": 3.49,
      "grad_norm": 3.7941012382507324,
      "learning_rate": 3.5344740740740744e-05,
      "loss": 0.0595,
      "step": 31440
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.18128949403762817,
      "learning_rate": 3.534325925925926e-05,
      "loss": 0.0517,
      "step": 31450
    },
    {
      "epoch": 3.5,
      "grad_norm": 4.330667495727539,
      "learning_rate": 3.534177777777778e-05,
      "loss": 0.0907,
      "step": 31460
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.7240185737609863,
      "learning_rate": 3.53402962962963e-05,
      "loss": 0.0858,
      "step": 31470
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.87552809715271,
      "learning_rate": 3.5338814814814815e-05,
      "loss": 0.0663,
      "step": 31480
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.7408156394958496,
      "learning_rate": 3.533733333333333e-05,
      "loss": 0.1034,
      "step": 31490
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.7445966005325317,
      "learning_rate": 3.5335851851851854e-05,
      "loss": 0.0787,
      "step": 31500
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.589658498764038,
      "learning_rate": 3.533437037037038e-05,
      "loss": 0.0836,
      "step": 31510
    },
    {
      "epoch": 3.5,
      "grad_norm": 4.212850093841553,
      "learning_rate": 3.533288888888889e-05,
      "loss": 0.0893,
      "step": 31520
    },
    {
      "epoch": 3.5,
      "grad_norm": 9.532318115234375,
      "learning_rate": 3.533140740740741e-05,
      "loss": 0.1333,
      "step": 31530
    },
    {
      "epoch": 3.5,
      "grad_norm": 6.150717735290527,
      "learning_rate": 3.5329925925925925e-05,
      "loss": 0.1614,
      "step": 31540
    },
    {
      "epoch": 3.51,
      "grad_norm": 3.700483560562134,
      "learning_rate": 3.532844444444445e-05,
      "loss": 0.0922,
      "step": 31550
    },
    {
      "epoch": 3.51,
      "grad_norm": 5.0887837409973145,
      "learning_rate": 3.532696296296297e-05,
      "loss": 0.102,
      "step": 31560
    },
    {
      "epoch": 3.51,
      "grad_norm": 4.003568649291992,
      "learning_rate": 3.532548148148149e-05,
      "loss": 0.0716,
      "step": 31570
    },
    {
      "epoch": 3.51,
      "grad_norm": 2.818612575531006,
      "learning_rate": 3.5324e-05,
      "loss": 0.0925,
      "step": 31580
    },
    {
      "epoch": 3.51,
      "grad_norm": 4.0623698234558105,
      "learning_rate": 3.532251851851852e-05,
      "loss": 0.1153,
      "step": 31590
    },
    {
      "epoch": 3.51,
      "grad_norm": 2.347554922103882,
      "learning_rate": 3.532103703703704e-05,
      "loss": 0.1424,
      "step": 31600
    },
    {
      "epoch": 3.51,
      "grad_norm": 5.587997913360596,
      "learning_rate": 3.531955555555556e-05,
      "loss": 0.0759,
      "step": 31610
    },
    {
      "epoch": 3.51,
      "grad_norm": 4.056173324584961,
      "learning_rate": 3.531807407407408e-05,
      "loss": 0.0773,
      "step": 31620
    },
    {
      "epoch": 3.51,
      "grad_norm": 4.211554050445557,
      "learning_rate": 3.5316592592592596e-05,
      "loss": 0.0732,
      "step": 31630
    },
    {
      "epoch": 3.52,
      "grad_norm": 4.219667911529541,
      "learning_rate": 3.531511111111111e-05,
      "loss": 0.0823,
      "step": 31640
    },
    {
      "epoch": 3.52,
      "grad_norm": 5.161012172698975,
      "learning_rate": 3.531362962962963e-05,
      "loss": 0.1065,
      "step": 31650
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.8609890937805176,
      "learning_rate": 3.531214814814815e-05,
      "loss": 0.0762,
      "step": 31660
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.9919211864471436,
      "learning_rate": 3.5310666666666674e-05,
      "loss": 0.1029,
      "step": 31670
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.489027261734009,
      "learning_rate": 3.530918518518519e-05,
      "loss": 0.0654,
      "step": 31680
    },
    {
      "epoch": 3.52,
      "grad_norm": 4.893027305603027,
      "learning_rate": 3.5307703703703706e-05,
      "loss": 0.1786,
      "step": 31690
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.959918260574341,
      "learning_rate": 3.530622222222222e-05,
      "loss": 0.0696,
      "step": 31700
    },
    {
      "epoch": 3.52,
      "grad_norm": 13.926193237304688,
      "learning_rate": 3.5304740740740745e-05,
      "loss": 0.1124,
      "step": 31710
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.1335713863372803,
      "learning_rate": 3.530325925925926e-05,
      "loss": 0.0917,
      "step": 31720
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.9527095556259155,
      "learning_rate": 3.5301777777777784e-05,
      "loss": 0.1095,
      "step": 31730
    },
    {
      "epoch": 3.53,
      "grad_norm": 3.0722787380218506,
      "learning_rate": 3.53002962962963e-05,
      "loss": 0.1023,
      "step": 31740
    },
    {
      "epoch": 3.53,
      "grad_norm": 5.588274955749512,
      "learning_rate": 3.5298814814814816e-05,
      "loss": 0.1141,
      "step": 31750
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.2010642290115356,
      "learning_rate": 3.529733333333333e-05,
      "loss": 0.0547,
      "step": 31760
    },
    {
      "epoch": 3.53,
      "grad_norm": 3.3245749473571777,
      "learning_rate": 3.5295851851851855e-05,
      "loss": 0.0555,
      "step": 31770
    },
    {
      "epoch": 3.53,
      "grad_norm": 5.373080730438232,
      "learning_rate": 3.529437037037038e-05,
      "loss": 0.1598,
      "step": 31780
    },
    {
      "epoch": 3.53,
      "grad_norm": 4.494493007659912,
      "learning_rate": 3.529288888888889e-05,
      "loss": 0.0873,
      "step": 31790
    },
    {
      "epoch": 3.53,
      "grad_norm": 2.8301432132720947,
      "learning_rate": 3.529140740740741e-05,
      "loss": 0.1321,
      "step": 31800
    },
    {
      "epoch": 3.53,
      "grad_norm": 5.51155424118042,
      "learning_rate": 3.5289925925925925e-05,
      "loss": 0.1093,
      "step": 31810
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.105764389038086,
      "learning_rate": 3.528844444444445e-05,
      "loss": 0.0644,
      "step": 31820
    },
    {
      "epoch": 3.54,
      "grad_norm": 1.4263378381729126,
      "learning_rate": 3.5286962962962964e-05,
      "loss": 0.0953,
      "step": 31830
    },
    {
      "epoch": 3.54,
      "grad_norm": 4.404325485229492,
      "learning_rate": 3.528548148148149e-05,
      "loss": 0.1114,
      "step": 31840
    },
    {
      "epoch": 3.54,
      "grad_norm": 5.754574775695801,
      "learning_rate": 3.5284e-05,
      "loss": 0.1359,
      "step": 31850
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.1058461666107178,
      "learning_rate": 3.528251851851852e-05,
      "loss": 0.1467,
      "step": 31860
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.8893282413482666,
      "learning_rate": 3.5281037037037035e-05,
      "loss": 0.0819,
      "step": 31870
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.524731159210205,
      "learning_rate": 3.527955555555556e-05,
      "loss": 0.1138,
      "step": 31880
    },
    {
      "epoch": 3.54,
      "grad_norm": 4.221081256866455,
      "learning_rate": 3.527807407407408e-05,
      "loss": 0.0901,
      "step": 31890
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.2896482944488525,
      "learning_rate": 3.52765925925926e-05,
      "loss": 0.0714,
      "step": 31900
    },
    {
      "epoch": 3.55,
      "grad_norm": 5.710186004638672,
      "learning_rate": 3.527511111111111e-05,
      "loss": 0.0909,
      "step": 31910
    },
    {
      "epoch": 3.55,
      "grad_norm": 3.497410535812378,
      "learning_rate": 3.527362962962963e-05,
      "loss": 0.1009,
      "step": 31920
    },
    {
      "epoch": 3.55,
      "grad_norm": 3.824190378189087,
      "learning_rate": 3.527214814814815e-05,
      "loss": 0.0956,
      "step": 31930
    },
    {
      "epoch": 3.55,
      "grad_norm": 3.9718234539031982,
      "learning_rate": 3.527066666666667e-05,
      "loss": 0.0994,
      "step": 31940
    },
    {
      "epoch": 3.55,
      "grad_norm": 5.753085613250732,
      "learning_rate": 3.526918518518519e-05,
      "loss": 0.0675,
      "step": 31950
    },
    {
      "epoch": 3.55,
      "grad_norm": 10.05984878540039,
      "learning_rate": 3.5267703703703706e-05,
      "loss": 0.1822,
      "step": 31960
    },
    {
      "epoch": 3.55,
      "grad_norm": 5.102136611938477,
      "learning_rate": 3.526622222222222e-05,
      "loss": 0.1135,
      "step": 31970
    },
    {
      "epoch": 3.55,
      "grad_norm": 13.0059175491333,
      "learning_rate": 3.526474074074074e-05,
      "loss": 0.104,
      "step": 31980
    },
    {
      "epoch": 3.55,
      "grad_norm": 4.890838146209717,
      "learning_rate": 3.526325925925926e-05,
      "loss": 0.085,
      "step": 31990
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.2424698770046234,
      "learning_rate": 3.5261777777777784e-05,
      "loss": 0.0785,
      "step": 32000
    },
    {
      "epoch": 3.56,
      "eval_cer": 0.018296919869883105,
      "eval_loss": 0.2814083397388458,
      "eval_runtime": 1899.1456,
      "eval_samples_per_second": 4.212,
      "eval_steps_per_second": 0.527,
      "eval_wer": 0.04573811091256779,
      "step": 32000
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.933671712875366,
      "learning_rate": 3.52602962962963e-05,
      "loss": 0.0837,
      "step": 32010
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.0601816177368164,
      "learning_rate": 3.5258814814814816e-05,
      "loss": 0.0904,
      "step": 32020
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.408648729324341,
      "learning_rate": 3.525733333333333e-05,
      "loss": 0.0949,
      "step": 32030
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.791190505027771,
      "learning_rate": 3.5255851851851855e-05,
      "loss": 0.0973,
      "step": 32040
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.39477801322937,
      "learning_rate": 3.525437037037038e-05,
      "loss": 0.0684,
      "step": 32050
    },
    {
      "epoch": 3.56,
      "grad_norm": 4.401529788970947,
      "learning_rate": 3.5252888888888894e-05,
      "loss": 0.062,
      "step": 32060
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.281780481338501,
      "learning_rate": 3.525140740740741e-05,
      "loss": 0.0745,
      "step": 32070
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.474797248840332,
      "learning_rate": 3.5249925925925926e-05,
      "loss": 0.155,
      "step": 32080
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.7619004249572754,
      "learning_rate": 3.524844444444444e-05,
      "loss": 0.0816,
      "step": 32090
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.1201212406158447,
      "learning_rate": 3.5246962962962965e-05,
      "loss": 0.095,
      "step": 32100
    },
    {
      "epoch": 3.57,
      "grad_norm": 4.754909515380859,
      "learning_rate": 3.524548148148149e-05,
      "loss": 0.0787,
      "step": 32110
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.9448273181915283,
      "learning_rate": 3.5244000000000003e-05,
      "loss": 0.0887,
      "step": 32120
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.0705206394195557,
      "learning_rate": 3.524251851851852e-05,
      "loss": 0.1612,
      "step": 32130
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.849513292312622,
      "learning_rate": 3.5241037037037035e-05,
      "loss": 0.1794,
      "step": 32140
    },
    {
      "epoch": 3.57,
      "grad_norm": 2.2560577392578125,
      "learning_rate": 3.523955555555556e-05,
      "loss": 0.0966,
      "step": 32150
    },
    {
      "epoch": 3.57,
      "grad_norm": 11.56188678741455,
      "learning_rate": 3.523807407407408e-05,
      "loss": 0.1627,
      "step": 32160
    },
    {
      "epoch": 3.57,
      "grad_norm": 10.382347106933594,
      "learning_rate": 3.52365925925926e-05,
      "loss": 0.0904,
      "step": 32170
    },
    {
      "epoch": 3.58,
      "grad_norm": 3.0867505073547363,
      "learning_rate": 3.523511111111111e-05,
      "loss": 0.1065,
      "step": 32180
    },
    {
      "epoch": 3.58,
      "grad_norm": 6.829776287078857,
      "learning_rate": 3.523362962962963e-05,
      "loss": 0.1298,
      "step": 32190
    },
    {
      "epoch": 3.58,
      "grad_norm": 8.423569679260254,
      "learning_rate": 3.523214814814815e-05,
      "loss": 0.1147,
      "step": 32200
    },
    {
      "epoch": 3.58,
      "grad_norm": 4.506415843963623,
      "learning_rate": 3.523066666666667e-05,
      "loss": 0.0933,
      "step": 32210
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.3868277072906494,
      "learning_rate": 3.522918518518519e-05,
      "loss": 0.1029,
      "step": 32220
    },
    {
      "epoch": 3.58,
      "grad_norm": 2.3151063919067383,
      "learning_rate": 3.522770370370371e-05,
      "loss": 0.0955,
      "step": 32230
    },
    {
      "epoch": 3.58,
      "grad_norm": 3.637047290802002,
      "learning_rate": 3.522622222222222e-05,
      "loss": 0.1765,
      "step": 32240
    },
    {
      "epoch": 3.58,
      "grad_norm": 3.7750630378723145,
      "learning_rate": 3.522474074074074e-05,
      "loss": 0.0723,
      "step": 32250
    },
    {
      "epoch": 3.58,
      "grad_norm": 8.500439643859863,
      "learning_rate": 3.522325925925926e-05,
      "loss": 0.0946,
      "step": 32260
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.598728895187378,
      "learning_rate": 3.5221777777777784e-05,
      "loss": 0.0652,
      "step": 32270
    },
    {
      "epoch": 3.59,
      "grad_norm": 2.889634847640991,
      "learning_rate": 3.52202962962963e-05,
      "loss": 0.0706,
      "step": 32280
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.2159080505371094,
      "learning_rate": 3.5218814814814816e-05,
      "loss": 0.0791,
      "step": 32290
    },
    {
      "epoch": 3.59,
      "grad_norm": 4.188740253448486,
      "learning_rate": 3.521733333333333e-05,
      "loss": 0.0835,
      "step": 32300
    },
    {
      "epoch": 3.59,
      "grad_norm": 2.790760040283203,
      "learning_rate": 3.5215851851851855e-05,
      "loss": 0.0954,
      "step": 32310
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.286041021347046,
      "learning_rate": 3.521437037037037e-05,
      "loss": 0.0834,
      "step": 32320
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.4017064571380615,
      "learning_rate": 3.5212888888888894e-05,
      "loss": 0.0926,
      "step": 32330
    },
    {
      "epoch": 3.59,
      "grad_norm": 5.812433242797852,
      "learning_rate": 3.521140740740741e-05,
      "loss": 0.1143,
      "step": 32340
    },
    {
      "epoch": 3.59,
      "grad_norm": 1.3453028202056885,
      "learning_rate": 3.5209925925925926e-05,
      "loss": 0.0681,
      "step": 32350
    },
    {
      "epoch": 3.6,
      "grad_norm": 2.5816104412078857,
      "learning_rate": 3.520844444444445e-05,
      "loss": 0.0747,
      "step": 32360
    },
    {
      "epoch": 3.6,
      "grad_norm": 4.992176532745361,
      "learning_rate": 3.5206962962962965e-05,
      "loss": 0.154,
      "step": 32370
    },
    {
      "epoch": 3.6,
      "grad_norm": 4.539576530456543,
      "learning_rate": 3.520548148148149e-05,
      "loss": 0.1043,
      "step": 32380
    },
    {
      "epoch": 3.6,
      "grad_norm": 6.166762351989746,
      "learning_rate": 3.5204000000000004e-05,
      "loss": 0.1026,
      "step": 32390
    },
    {
      "epoch": 3.6,
      "grad_norm": 7.954926013946533,
      "learning_rate": 3.520251851851852e-05,
      "loss": 0.0893,
      "step": 32400
    },
    {
      "epoch": 3.6,
      "grad_norm": 5.55408239364624,
      "learning_rate": 3.5201037037037036e-05,
      "loss": 0.0816,
      "step": 32410
    },
    {
      "epoch": 3.6,
      "grad_norm": 4.145595550537109,
      "learning_rate": 3.519955555555556e-05,
      "loss": 0.1306,
      "step": 32420
    },
    {
      "epoch": 3.6,
      "grad_norm": 7.987072467803955,
      "learning_rate": 3.5198074074074075e-05,
      "loss": 0.1796,
      "step": 32430
    },
    {
      "epoch": 3.6,
      "grad_norm": 4.98196268081665,
      "learning_rate": 3.51965925925926e-05,
      "loss": 0.1357,
      "step": 32440
    },
    {
      "epoch": 3.61,
      "grad_norm": 6.354052543640137,
      "learning_rate": 3.5195111111111113e-05,
      "loss": 0.0864,
      "step": 32450
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.9044960737228394,
      "learning_rate": 3.519362962962963e-05,
      "loss": 0.0922,
      "step": 32460
    },
    {
      "epoch": 3.61,
      "grad_norm": 6.468061923980713,
      "learning_rate": 3.519214814814815e-05,
      "loss": 0.0974,
      "step": 32470
    },
    {
      "epoch": 3.61,
      "grad_norm": 3.8959789276123047,
      "learning_rate": 3.519066666666667e-05,
      "loss": 0.1227,
      "step": 32480
    },
    {
      "epoch": 3.61,
      "grad_norm": 5.064399242401123,
      "learning_rate": 3.518918518518519e-05,
      "loss": 0.1763,
      "step": 32490
    },
    {
      "epoch": 3.61,
      "grad_norm": 5.795170307159424,
      "learning_rate": 3.518770370370371e-05,
      "loss": 0.101,
      "step": 32500
    },
    {
      "epoch": 3.61,
      "grad_norm": 3.026610851287842,
      "learning_rate": 3.518622222222222e-05,
      "loss": 0.0855,
      "step": 32510
    },
    {
      "epoch": 3.61,
      "grad_norm": 2.3108928203582764,
      "learning_rate": 3.518474074074074e-05,
      "loss": 0.1196,
      "step": 32520
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.721426010131836,
      "learning_rate": 3.518325925925926e-05,
      "loss": 0.0594,
      "step": 32530
    },
    {
      "epoch": 3.62,
      "grad_norm": 3.4186251163482666,
      "learning_rate": 3.518177777777778e-05,
      "loss": 0.0807,
      "step": 32540
    },
    {
      "epoch": 3.62,
      "grad_norm": 7.605342388153076,
      "learning_rate": 3.51802962962963e-05,
      "loss": 0.0943,
      "step": 32550
    },
    {
      "epoch": 3.62,
      "grad_norm": 1.613309621810913,
      "learning_rate": 3.517881481481482e-05,
      "loss": 0.056,
      "step": 32560
    },
    {
      "epoch": 3.62,
      "grad_norm": 7.07057523727417,
      "learning_rate": 3.517733333333333e-05,
      "loss": 0.0896,
      "step": 32570
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.2289674282073975,
      "learning_rate": 3.5175851851851856e-05,
      "loss": 0.0742,
      "step": 32580
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.8100554943084717,
      "learning_rate": 3.517437037037037e-05,
      "loss": 0.1448,
      "step": 32590
    },
    {
      "epoch": 3.62,
      "grad_norm": 4.186968803405762,
      "learning_rate": 3.5172888888888894e-05,
      "loss": 0.1027,
      "step": 32600
    },
    {
      "epoch": 3.62,
      "grad_norm": 5.976280212402344,
      "learning_rate": 3.517140740740741e-05,
      "loss": 0.0821,
      "step": 32610
    },
    {
      "epoch": 3.62,
      "grad_norm": 5.866644859313965,
      "learning_rate": 3.5169925925925927e-05,
      "loss": 0.1815,
      "step": 32620
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.718505382537842,
      "learning_rate": 3.516844444444445e-05,
      "loss": 0.0659,
      "step": 32630
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.3850579261779785,
      "learning_rate": 3.5166962962962965e-05,
      "loss": 0.0873,
      "step": 32640
    },
    {
      "epoch": 3.63,
      "grad_norm": 8.628568649291992,
      "learning_rate": 3.516548148148149e-05,
      "loss": 0.1942,
      "step": 32650
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.682121992111206,
      "learning_rate": 3.5164000000000004e-05,
      "loss": 0.1413,
      "step": 32660
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.921875238418579,
      "learning_rate": 3.516251851851852e-05,
      "loss": 0.0829,
      "step": 32670
    },
    {
      "epoch": 3.63,
      "grad_norm": 5.877017498016357,
      "learning_rate": 3.5161037037037036e-05,
      "loss": 0.097,
      "step": 32680
    },
    {
      "epoch": 3.63,
      "grad_norm": 5.177579879760742,
      "learning_rate": 3.515955555555556e-05,
      "loss": 0.1572,
      "step": 32690
    },
    {
      "epoch": 3.63,
      "grad_norm": 3.3100173473358154,
      "learning_rate": 3.5158074074074075e-05,
      "loss": 0.0733,
      "step": 32700
    },
    {
      "epoch": 3.63,
      "grad_norm": 6.1079888343811035,
      "learning_rate": 3.51565925925926e-05,
      "loss": 0.0849,
      "step": 32710
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.1331697702407837,
      "learning_rate": 3.5155111111111114e-05,
      "loss": 0.1342,
      "step": 32720
    },
    {
      "epoch": 3.64,
      "grad_norm": 4.293539524078369,
      "learning_rate": 3.515362962962963e-05,
      "loss": 0.0803,
      "step": 32730
    },
    {
      "epoch": 3.64,
      "grad_norm": 6.329143524169922,
      "learning_rate": 3.515214814814815e-05,
      "loss": 0.0833,
      "step": 32740
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.5265687704086304,
      "learning_rate": 3.515066666666667e-05,
      "loss": 0.0948,
      "step": 32750
    },
    {
      "epoch": 3.64,
      "grad_norm": 4.112054824829102,
      "learning_rate": 3.514918518518519e-05,
      "loss": 0.0782,
      "step": 32760
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.5182387828826904,
      "learning_rate": 3.514770370370371e-05,
      "loss": 0.0639,
      "step": 32770
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.7843111753463745,
      "learning_rate": 3.5146222222222224e-05,
      "loss": 0.0823,
      "step": 32780
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.087860345840454,
      "learning_rate": 3.514474074074074e-05,
      "loss": 0.082,
      "step": 32790
    },
    {
      "epoch": 3.64,
      "grad_norm": 3.050759792327881,
      "learning_rate": 3.514325925925926e-05,
      "loss": 0.107,
      "step": 32800
    },
    {
      "epoch": 3.65,
      "grad_norm": 3.0090346336364746,
      "learning_rate": 3.514177777777778e-05,
      "loss": 0.0962,
      "step": 32810
    },
    {
      "epoch": 3.65,
      "grad_norm": 3.584026336669922,
      "learning_rate": 3.51402962962963e-05,
      "loss": 0.106,
      "step": 32820
    },
    {
      "epoch": 3.65,
      "grad_norm": 3.2529101371765137,
      "learning_rate": 3.513881481481482e-05,
      "loss": 0.0842,
      "step": 32830
    },
    {
      "epoch": 3.65,
      "grad_norm": 6.298541069030762,
      "learning_rate": 3.513733333333333e-05,
      "loss": 0.1098,
      "step": 32840
    },
    {
      "epoch": 3.65,
      "grad_norm": 3.0383546352386475,
      "learning_rate": 3.5135851851851856e-05,
      "loss": 0.0732,
      "step": 32850
    },
    {
      "epoch": 3.65,
      "grad_norm": 5.616189956665039,
      "learning_rate": 3.513437037037037e-05,
      "loss": 0.0929,
      "step": 32860
    },
    {
      "epoch": 3.65,
      "grad_norm": 2.5012292861938477,
      "learning_rate": 3.5132888888888895e-05,
      "loss": 0.0876,
      "step": 32870
    },
    {
      "epoch": 3.65,
      "grad_norm": 4.014462471008301,
      "learning_rate": 3.513140740740741e-05,
      "loss": 0.0879,
      "step": 32880
    },
    {
      "epoch": 3.65,
      "grad_norm": 1.8701303005218506,
      "learning_rate": 3.512992592592593e-05,
      "loss": 0.0749,
      "step": 32890
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.119591474533081,
      "learning_rate": 3.512844444444445e-05,
      "loss": 0.1029,
      "step": 32900
    },
    {
      "epoch": 3.66,
      "grad_norm": 1.2004815340042114,
      "learning_rate": 3.5126962962962966e-05,
      "loss": 0.0615,
      "step": 32910
    },
    {
      "epoch": 3.66,
      "grad_norm": 5.6829118728637695,
      "learning_rate": 3.512548148148148e-05,
      "loss": 0.1245,
      "step": 32920
    },
    {
      "epoch": 3.66,
      "grad_norm": 4.492824077606201,
      "learning_rate": 3.5124000000000005e-05,
      "loss": 0.0569,
      "step": 32930
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.772848129272461,
      "learning_rate": 3.512251851851852e-05,
      "loss": 0.1087,
      "step": 32940
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.578700065612793,
      "learning_rate": 3.5121037037037037e-05,
      "loss": 0.0747,
      "step": 32950
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.304234504699707,
      "learning_rate": 3.511955555555556e-05,
      "loss": 0.0857,
      "step": 32960
    },
    {
      "epoch": 3.66,
      "grad_norm": 11.09328842163086,
      "learning_rate": 3.5118074074074075e-05,
      "loss": 0.0866,
      "step": 32970
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.79321026802063,
      "learning_rate": 3.51165925925926e-05,
      "loss": 0.0858,
      "step": 32980
    },
    {
      "epoch": 3.67,
      "grad_norm": 12.226704597473145,
      "learning_rate": 3.5115111111111114e-05,
      "loss": 0.1239,
      "step": 32990
    },
    {
      "epoch": 3.67,
      "grad_norm": 4.499188423156738,
      "learning_rate": 3.511362962962963e-05,
      "loss": 0.0937,
      "step": 33000
    },
    {
      "epoch": 3.67,
      "grad_norm": 4.838826656341553,
      "learning_rate": 3.511214814814815e-05,
      "loss": 0.1006,
      "step": 33010
    },
    {
      "epoch": 3.67,
      "grad_norm": 7.768224239349365,
      "learning_rate": 3.511066666666667e-05,
      "loss": 0.1309,
      "step": 33020
    },
    {
      "epoch": 3.67,
      "grad_norm": 1.7883027791976929,
      "learning_rate": 3.5109185185185185e-05,
      "loss": 0.0611,
      "step": 33030
    },
    {
      "epoch": 3.67,
      "grad_norm": 7.029252529144287,
      "learning_rate": 3.510770370370371e-05,
      "loss": 0.1101,
      "step": 33040
    },
    {
      "epoch": 3.67,
      "grad_norm": 3.8764052391052246,
      "learning_rate": 3.5106222222222224e-05,
      "loss": 0.1786,
      "step": 33050
    },
    {
      "epoch": 3.67,
      "grad_norm": 3.223175287246704,
      "learning_rate": 3.510474074074074e-05,
      "loss": 0.1032,
      "step": 33060
    },
    {
      "epoch": 3.67,
      "grad_norm": 4.301307678222656,
      "learning_rate": 3.510325925925926e-05,
      "loss": 0.0943,
      "step": 33070
    },
    {
      "epoch": 3.68,
      "grad_norm": 4.932455062866211,
      "learning_rate": 3.510177777777778e-05,
      "loss": 0.1148,
      "step": 33080
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.434945285320282,
      "learning_rate": 3.51002962962963e-05,
      "loss": 0.0777,
      "step": 33090
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.004051685333252,
      "learning_rate": 3.509881481481482e-05,
      "loss": 0.0877,
      "step": 33100
    },
    {
      "epoch": 3.68,
      "grad_norm": 5.377744197845459,
      "learning_rate": 3.5097333333333334e-05,
      "loss": 0.0777,
      "step": 33110
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.9690667390823364,
      "learning_rate": 3.5095851851851856e-05,
      "loss": 0.0811,
      "step": 33120
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.0160255432128906,
      "learning_rate": 3.509437037037037e-05,
      "loss": 0.0863,
      "step": 33130
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.9674596786499023,
      "learning_rate": 3.5092888888888895e-05,
      "loss": 0.1286,
      "step": 33140
    },
    {
      "epoch": 3.68,
      "grad_norm": 2.0711820125579834,
      "learning_rate": 3.509140740740741e-05,
      "loss": 0.1067,
      "step": 33150
    },
    {
      "epoch": 3.68,
      "grad_norm": 2.6885087490081787,
      "learning_rate": 3.508992592592593e-05,
      "loss": 0.0955,
      "step": 33160
    },
    {
      "epoch": 3.69,
      "grad_norm": 6.991986274719238,
      "learning_rate": 3.508844444444445e-05,
      "loss": 0.0831,
      "step": 33170
    },
    {
      "epoch": 3.69,
      "grad_norm": 3.4044411182403564,
      "learning_rate": 3.5086962962962966e-05,
      "loss": 0.0763,
      "step": 33180
    },
    {
      "epoch": 3.69,
      "grad_norm": 3.9805638790130615,
      "learning_rate": 3.508548148148148e-05,
      "loss": 0.0978,
      "step": 33190
    },
    {
      "epoch": 3.69,
      "grad_norm": 3.3861186504364014,
      "learning_rate": 3.5084000000000005e-05,
      "loss": 0.0809,
      "step": 33200
    },
    {
      "epoch": 3.69,
      "grad_norm": 5.2341108322143555,
      "learning_rate": 3.508251851851852e-05,
      "loss": 0.1056,
      "step": 33210
    },
    {
      "epoch": 3.69,
      "grad_norm": 1.0660324096679688,
      "learning_rate": 3.508103703703704e-05,
      "loss": 0.0955,
      "step": 33220
    },
    {
      "epoch": 3.69,
      "grad_norm": 1.0172840356826782,
      "learning_rate": 3.507955555555556e-05,
      "loss": 0.0554,
      "step": 33230
    },
    {
      "epoch": 3.69,
      "grad_norm": 3.0931437015533447,
      "learning_rate": 3.5078074074074076e-05,
      "loss": 0.1031,
      "step": 33240
    },
    {
      "epoch": 3.69,
      "grad_norm": 4.851386547088623,
      "learning_rate": 3.50765925925926e-05,
      "loss": 0.0763,
      "step": 33250
    },
    {
      "epoch": 3.7,
      "grad_norm": 10.746617317199707,
      "learning_rate": 3.5075111111111115e-05,
      "loss": 0.1085,
      "step": 33260
    },
    {
      "epoch": 3.7,
      "grad_norm": 1.9303008317947388,
      "learning_rate": 3.507377777777778e-05,
      "loss": 0.1205,
      "step": 33270
    },
    {
      "epoch": 3.7,
      "grad_norm": 7.868214130401611,
      "learning_rate": 3.5072296296296294e-05,
      "loss": 0.1077,
      "step": 33280
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.9198572635650635,
      "learning_rate": 3.507081481481482e-05,
      "loss": 0.1018,
      "step": 33290
    },
    {
      "epoch": 3.7,
      "grad_norm": 5.270203590393066,
      "learning_rate": 3.506933333333334e-05,
      "loss": 0.1014,
      "step": 33300
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.0503439903259277,
      "learning_rate": 3.5067851851851856e-05,
      "loss": 0.1087,
      "step": 33310
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.2387497425079346,
      "learning_rate": 3.506637037037037e-05,
      "loss": 0.0813,
      "step": 33320
    },
    {
      "epoch": 3.7,
      "grad_norm": 11.11551570892334,
      "learning_rate": 3.506488888888889e-05,
      "loss": 0.1358,
      "step": 33330
    },
    {
      "epoch": 3.7,
      "grad_norm": 5.020590305328369,
      "learning_rate": 3.506340740740741e-05,
      "loss": 0.1714,
      "step": 33340
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.988662004470825,
      "learning_rate": 3.5061925925925934e-05,
      "loss": 0.0931,
      "step": 33350
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.9928479194641113,
      "learning_rate": 3.506044444444445e-05,
      "loss": 0.1017,
      "step": 33360
    },
    {
      "epoch": 3.71,
      "grad_norm": 5.865703105926514,
      "learning_rate": 3.5058962962962966e-05,
      "loss": 0.0942,
      "step": 33370
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.8230953216552734,
      "learning_rate": 3.505748148148148e-05,
      "loss": 0.079,
      "step": 33380
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.1489198207855225,
      "learning_rate": 3.5056e-05,
      "loss": 0.0688,
      "step": 33390
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.7013490200042725,
      "learning_rate": 3.505451851851852e-05,
      "loss": 0.1149,
      "step": 33400
    },
    {
      "epoch": 3.71,
      "grad_norm": 3.474734306335449,
      "learning_rate": 3.505303703703704e-05,
      "loss": 0.0595,
      "step": 33410
    },
    {
      "epoch": 3.71,
      "grad_norm": 4.177776336669922,
      "learning_rate": 3.505155555555556e-05,
      "loss": 0.125,
      "step": 33420
    },
    {
      "epoch": 3.71,
      "grad_norm": 5.4507622718811035,
      "learning_rate": 3.5050074074074075e-05,
      "loss": 0.0861,
      "step": 33430
    },
    {
      "epoch": 3.72,
      "grad_norm": 1.215424656867981,
      "learning_rate": 3.504859259259259e-05,
      "loss": 0.1329,
      "step": 33440
    },
    {
      "epoch": 3.72,
      "grad_norm": 2.1998839378356934,
      "learning_rate": 3.5047111111111114e-05,
      "loss": 0.0753,
      "step": 33450
    },
    {
      "epoch": 3.72,
      "grad_norm": 13.724189758300781,
      "learning_rate": 3.504562962962964e-05,
      "loss": 0.0964,
      "step": 33460
    },
    {
      "epoch": 3.72,
      "grad_norm": 6.729452610015869,
      "learning_rate": 3.504414814814815e-05,
      "loss": 0.0999,
      "step": 33470
    },
    {
      "epoch": 3.72,
      "grad_norm": 9.249485969543457,
      "learning_rate": 3.504266666666667e-05,
      "loss": 0.1005,
      "step": 33480
    },
    {
      "epoch": 3.72,
      "grad_norm": 4.632266521453857,
      "learning_rate": 3.5041185185185185e-05,
      "loss": 0.1128,
      "step": 33490
    },
    {
      "epoch": 3.72,
      "grad_norm": 7.577014446258545,
      "learning_rate": 3.503970370370371e-05,
      "loss": 0.1287,
      "step": 33500
    },
    {
      "epoch": 3.72,
      "grad_norm": 3.291534662246704,
      "learning_rate": 3.5038222222222224e-05,
      "loss": 0.0818,
      "step": 33510
    },
    {
      "epoch": 3.72,
      "grad_norm": 3.32690167427063,
      "learning_rate": 3.503674074074075e-05,
      "loss": 0.1059,
      "step": 33520
    },
    {
      "epoch": 3.73,
      "grad_norm": 4.216851234436035,
      "learning_rate": 3.503525925925926e-05,
      "loss": 0.0739,
      "step": 33530
    },
    {
      "epoch": 3.73,
      "grad_norm": 1.8274219036102295,
      "learning_rate": 3.503377777777778e-05,
      "loss": 0.0492,
      "step": 33540
    },
    {
      "epoch": 3.73,
      "grad_norm": 1.7680476903915405,
      "learning_rate": 3.5032296296296295e-05,
      "loss": 0.1199,
      "step": 33550
    },
    {
      "epoch": 3.73,
      "grad_norm": 7.371456146240234,
      "learning_rate": 3.503081481481482e-05,
      "loss": 0.0957,
      "step": 33560
    },
    {
      "epoch": 3.73,
      "grad_norm": 3.8866708278656006,
      "learning_rate": 3.502933333333334e-05,
      "loss": 0.1541,
      "step": 33570
    },
    {
      "epoch": 3.73,
      "grad_norm": 7.442952632904053,
      "learning_rate": 3.5027851851851856e-05,
      "loss": 0.0907,
      "step": 33580
    },
    {
      "epoch": 3.73,
      "grad_norm": 2.593064069747925,
      "learning_rate": 3.502637037037037e-05,
      "loss": 0.0674,
      "step": 33590
    },
    {
      "epoch": 3.73,
      "grad_norm": 3.757415771484375,
      "learning_rate": 3.502488888888889e-05,
      "loss": 0.0897,
      "step": 33600
    },
    {
      "epoch": 3.73,
      "grad_norm": 4.209708213806152,
      "learning_rate": 3.502340740740741e-05,
      "loss": 0.0372,
      "step": 33610
    },
    {
      "epoch": 3.74,
      "grad_norm": 3.1248862743377686,
      "learning_rate": 3.502192592592593e-05,
      "loss": 0.08,
      "step": 33620
    },
    {
      "epoch": 3.74,
      "grad_norm": 4.393179416656494,
      "learning_rate": 3.502044444444445e-05,
      "loss": 0.1034,
      "step": 33630
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.8697872161865234,
      "learning_rate": 3.5018962962962966e-05,
      "loss": 0.1187,
      "step": 33640
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.4317103326320648,
      "learning_rate": 3.501748148148148e-05,
      "loss": 0.0743,
      "step": 33650
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.256387710571289,
      "learning_rate": 3.5016e-05,
      "loss": 0.083,
      "step": 33660
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.9969536066055298,
      "learning_rate": 3.501451851851852e-05,
      "loss": 0.1203,
      "step": 33670
    },
    {
      "epoch": 3.74,
      "grad_norm": 5.432855129241943,
      "learning_rate": 3.5013037037037044e-05,
      "loss": 0.083,
      "step": 33680
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.0058183670043945,
      "learning_rate": 3.501155555555556e-05,
      "loss": 0.0578,
      "step": 33690
    },
    {
      "epoch": 3.74,
      "grad_norm": 5.819733619689941,
      "learning_rate": 3.5010074074074076e-05,
      "loss": 0.0871,
      "step": 33700
    },
    {
      "epoch": 3.75,
      "grad_norm": 5.191288471221924,
      "learning_rate": 3.500859259259259e-05,
      "loss": 0.0595,
      "step": 33710
    },
    {
      "epoch": 3.75,
      "grad_norm": 5.888176441192627,
      "learning_rate": 3.5007111111111115e-05,
      "loss": 0.0949,
      "step": 33720
    },
    {
      "epoch": 3.75,
      "grad_norm": 3.000591516494751,
      "learning_rate": 3.500562962962963e-05,
      "loss": 0.0922,
      "step": 33730
    },
    {
      "epoch": 3.75,
      "grad_norm": 7.078289031982422,
      "learning_rate": 3.5004148148148153e-05,
      "loss": 0.1297,
      "step": 33740
    },
    {
      "epoch": 3.75,
      "grad_norm": 3.287221908569336,
      "learning_rate": 3.500266666666667e-05,
      "loss": 0.0861,
      "step": 33750
    },
    {
      "epoch": 3.75,
      "grad_norm": 7.843649387359619,
      "learning_rate": 3.5001185185185185e-05,
      "loss": 0.1409,
      "step": 33760
    },
    {
      "epoch": 3.75,
      "grad_norm": 6.622467041015625,
      "learning_rate": 3.49997037037037e-05,
      "loss": 0.1193,
      "step": 33770
    },
    {
      "epoch": 3.75,
      "grad_norm": 6.114830017089844,
      "learning_rate": 3.4998222222222224e-05,
      "loss": 0.1099,
      "step": 33780
    },
    {
      "epoch": 3.75,
      "grad_norm": 4.064779281616211,
      "learning_rate": 3.499674074074075e-05,
      "loss": 0.1002,
      "step": 33790
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.4389090538024902,
      "learning_rate": 3.499525925925926e-05,
      "loss": 0.1182,
      "step": 33800
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.7817884683609009,
      "learning_rate": 3.499377777777778e-05,
      "loss": 0.0685,
      "step": 33810
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.5571887493133545,
      "learning_rate": 3.4992296296296295e-05,
      "loss": 0.0972,
      "step": 33820
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.414407730102539,
      "learning_rate": 3.499081481481482e-05,
      "loss": 0.0658,
      "step": 33830
    },
    {
      "epoch": 3.76,
      "grad_norm": 11.826498031616211,
      "learning_rate": 3.4989333333333334e-05,
      "loss": 0.1335,
      "step": 33840
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.889655351638794,
      "learning_rate": 3.498785185185186e-05,
      "loss": 0.0836,
      "step": 33850
    },
    {
      "epoch": 3.76,
      "grad_norm": 4.25313663482666,
      "learning_rate": 3.498637037037037e-05,
      "loss": 0.094,
      "step": 33860
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.864617347717285,
      "learning_rate": 3.498488888888889e-05,
      "loss": 0.0881,
      "step": 33870
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.39776068925857544,
      "learning_rate": 3.4983407407407405e-05,
      "loss": 0.0854,
      "step": 33880
    },
    {
      "epoch": 3.77,
      "grad_norm": 7.802690505981445,
      "learning_rate": 3.498192592592593e-05,
      "loss": 0.1049,
      "step": 33890
    },
    {
      "epoch": 3.77,
      "grad_norm": 2.334336996078491,
      "learning_rate": 3.498044444444445e-05,
      "loss": 0.1093,
      "step": 33900
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.8223843574523926,
      "learning_rate": 3.4978962962962966e-05,
      "loss": 0.0596,
      "step": 33910
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.5630669593811035,
      "learning_rate": 3.497748148148148e-05,
      "loss": 0.109,
      "step": 33920
    },
    {
      "epoch": 3.77,
      "grad_norm": 4.380012512207031,
      "learning_rate": 3.4976e-05,
      "loss": 0.0835,
      "step": 33930
    },
    {
      "epoch": 3.77,
      "grad_norm": 2.735537052154541,
      "learning_rate": 3.497451851851852e-05,
      "loss": 0.0688,
      "step": 33940
    },
    {
      "epoch": 3.77,
      "grad_norm": 3.787856340408325,
      "learning_rate": 3.4973037037037044e-05,
      "loss": 0.1064,
      "step": 33950
    },
    {
      "epoch": 3.77,
      "grad_norm": 5.670168876647949,
      "learning_rate": 3.497155555555556e-05,
      "loss": 0.0789,
      "step": 33960
    },
    {
      "epoch": 3.77,
      "grad_norm": 3.0089826583862305,
      "learning_rate": 3.4970074074074076e-05,
      "loss": 0.0922,
      "step": 33970
    },
    {
      "epoch": 3.78,
      "grad_norm": 6.780313491821289,
      "learning_rate": 3.496859259259259e-05,
      "loss": 0.1321,
      "step": 33980
    },
    {
      "epoch": 3.78,
      "grad_norm": 3.0373542308807373,
      "learning_rate": 3.4967111111111115e-05,
      "loss": 0.1097,
      "step": 33990
    },
    {
      "epoch": 3.78,
      "grad_norm": 1.828567624092102,
      "learning_rate": 3.496562962962963e-05,
      "loss": 0.0678,
      "step": 34000
    },
    {
      "epoch": 3.78,
      "grad_norm": 6.1108808517456055,
      "learning_rate": 3.4964148148148154e-05,
      "loss": 0.1098,
      "step": 34010
    },
    {
      "epoch": 3.78,
      "grad_norm": 5.819734573364258,
      "learning_rate": 3.496266666666667e-05,
      "loss": 0.0816,
      "step": 34020
    },
    {
      "epoch": 3.78,
      "grad_norm": 4.1200032234191895,
      "learning_rate": 3.4961185185185186e-05,
      "loss": 0.1687,
      "step": 34030
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.859506130218506,
      "learning_rate": 3.49597037037037e-05,
      "loss": 0.0718,
      "step": 34040
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.231226921081543,
      "learning_rate": 3.4958222222222225e-05,
      "loss": 0.0927,
      "step": 34050
    },
    {
      "epoch": 3.78,
      "grad_norm": 4.030051231384277,
      "learning_rate": 3.495674074074075e-05,
      "loss": 0.0855,
      "step": 34060
    },
    {
      "epoch": 3.79,
      "grad_norm": 3.9372878074645996,
      "learning_rate": 3.4955259259259263e-05,
      "loss": 0.0908,
      "step": 34070
    },
    {
      "epoch": 3.79,
      "grad_norm": 3.942793607711792,
      "learning_rate": 3.495377777777778e-05,
      "loss": 0.1184,
      "step": 34080
    },
    {
      "epoch": 3.79,
      "grad_norm": 4.6403679847717285,
      "learning_rate": 3.4952296296296296e-05,
      "loss": 0.1005,
      "step": 34090
    },
    {
      "epoch": 3.79,
      "grad_norm": 3.362192392349243,
      "learning_rate": 3.495081481481482e-05,
      "loss": 0.0916,
      "step": 34100
    },
    {
      "epoch": 3.79,
      "grad_norm": 1.2308168411254883,
      "learning_rate": 3.4949333333333334e-05,
      "loss": 0.0494,
      "step": 34110
    },
    {
      "epoch": 3.79,
      "grad_norm": 10.111486434936523,
      "learning_rate": 3.494785185185186e-05,
      "loss": 0.0909,
      "step": 34120
    },
    {
      "epoch": 3.79,
      "grad_norm": 4.03678560256958,
      "learning_rate": 3.494637037037037e-05,
      "loss": 0.1805,
      "step": 34130
    },
    {
      "epoch": 3.79,
      "grad_norm": 4.750489234924316,
      "learning_rate": 3.494488888888889e-05,
      "loss": 0.1057,
      "step": 34140
    },
    {
      "epoch": 3.79,
      "grad_norm": 6.477611541748047,
      "learning_rate": 3.4943407407407405e-05,
      "loss": 0.1527,
      "step": 34150
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.323549270629883,
      "learning_rate": 3.494192592592593e-05,
      "loss": 0.1483,
      "step": 34160
    },
    {
      "epoch": 3.8,
      "grad_norm": 170.66567993164062,
      "learning_rate": 3.49405925925926e-05,
      "loss": 0.438,
      "step": 34170
    },
    {
      "epoch": 3.8,
      "grad_norm": 9.49315071105957,
      "learning_rate": 3.4939111111111115e-05,
      "loss": 0.1038,
      "step": 34180
    },
    {
      "epoch": 3.8,
      "grad_norm": NaN,
      "learning_rate": 3.493777777777778e-05,
      "loss": 0.4258,
      "step": 34190
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.7108783721923828,
      "learning_rate": 3.49362962962963e-05,
      "loss": 0.2495,
      "step": 34200
    },
    {
      "epoch": 3.8,
      "grad_norm": 7.877134323120117,
      "learning_rate": 3.493481481481482e-05,
      "loss": 0.1259,
      "step": 34210
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.761199951171875,
      "learning_rate": 3.493333333333333e-05,
      "loss": 0.056,
      "step": 34220
    },
    {
      "epoch": 3.8,
      "grad_norm": 34.71015167236328,
      "learning_rate": 3.4931851851851856e-05,
      "loss": 0.4674,
      "step": 34230
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.239839553833008,
      "learning_rate": 3.493037037037037e-05,
      "loss": 0.0706,
      "step": 34240
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.3348805904388428,
      "learning_rate": 3.4928888888888895e-05,
      "loss": 0.1121,
      "step": 34250
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.091859817504883,
      "learning_rate": 3.492740740740741e-05,
      "loss": 0.1155,
      "step": 34260
    },
    {
      "epoch": 3.81,
      "grad_norm": 3.9658050537109375,
      "learning_rate": 3.492592592592593e-05,
      "loss": 0.0734,
      "step": 34270
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.93586802482605,
      "learning_rate": 3.492444444444444e-05,
      "loss": 0.1087,
      "step": 34280
    },
    {
      "epoch": 3.81,
      "grad_norm": 1.6777141094207764,
      "learning_rate": 3.4922962962962966e-05,
      "loss": 0.0849,
      "step": 34290
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.399035692214966,
      "learning_rate": 3.492148148148149e-05,
      "loss": 0.0949,
      "step": 34300
    },
    {
      "epoch": 3.81,
      "grad_norm": 3.0126655101776123,
      "learning_rate": 3.4920000000000004e-05,
      "loss": 0.0825,
      "step": 34310
    },
    {
      "epoch": 3.81,
      "grad_norm": 7.184364318847656,
      "learning_rate": 3.491851851851852e-05,
      "loss": 0.1053,
      "step": 34320
    },
    {
      "epoch": 3.81,
      "grad_norm": 1.9662784337997437,
      "learning_rate": 3.4917037037037037e-05,
      "loss": 0.0711,
      "step": 34330
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.8828437328338623,
      "learning_rate": 3.491555555555556e-05,
      "loss": 0.0713,
      "step": 34340
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.06286358833313,
      "learning_rate": 3.4914074074074075e-05,
      "loss": 0.0931,
      "step": 34350
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.1755642890930176,
      "learning_rate": 3.49125925925926e-05,
      "loss": 0.1081,
      "step": 34360
    },
    {
      "epoch": 3.82,
      "grad_norm": 5.494213581085205,
      "learning_rate": 3.4911111111111114e-05,
      "loss": 0.0858,
      "step": 34370
    },
    {
      "epoch": 3.82,
      "grad_norm": 7.049411773681641,
      "learning_rate": 3.490962962962963e-05,
      "loss": 0.1294,
      "step": 34380
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.407884359359741,
      "learning_rate": 3.4908148148148146e-05,
      "loss": 0.1272,
      "step": 34390
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.3371119499206543,
      "learning_rate": 3.490666666666667e-05,
      "loss": 0.1003,
      "step": 34400
    },
    {
      "epoch": 3.82,
      "grad_norm": 4.177926063537598,
      "learning_rate": 3.490518518518519e-05,
      "loss": 0.1044,
      "step": 34410
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.2044105529785156,
      "learning_rate": 3.490370370370371e-05,
      "loss": 0.0947,
      "step": 34420
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.1105860471725464,
      "learning_rate": 3.4902222222222224e-05,
      "loss": 0.0623,
      "step": 34430
    },
    {
      "epoch": 3.83,
      "grad_norm": 3.565493583679199,
      "learning_rate": 3.490074074074074e-05,
      "loss": 0.0876,
      "step": 34440
    },
    {
      "epoch": 3.83,
      "grad_norm": 2.782417058944702,
      "learning_rate": 3.489925925925926e-05,
      "loss": 0.0766,
      "step": 34450
    },
    {
      "epoch": 3.83,
      "grad_norm": 5.779515266418457,
      "learning_rate": 3.489777777777778e-05,
      "loss": 0.0611,
      "step": 34460
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.2483497858047485,
      "learning_rate": 3.48962962962963e-05,
      "loss": 0.0868,
      "step": 34470
    },
    {
      "epoch": 3.83,
      "grad_norm": 4.6498026847839355,
      "learning_rate": 3.489481481481482e-05,
      "loss": 0.0896,
      "step": 34480
    },
    {
      "epoch": 3.83,
      "grad_norm": 2.2492516040802,
      "learning_rate": 3.4893333333333334e-05,
      "loss": 0.0989,
      "step": 34490
    },
    {
      "epoch": 3.83,
      "grad_norm": 4.766262531280518,
      "learning_rate": 3.4891851851851856e-05,
      "loss": 0.1004,
      "step": 34500
    },
    {
      "epoch": 3.83,
      "grad_norm": 3.177286386489868,
      "learning_rate": 3.489037037037037e-05,
      "loss": 0.0893,
      "step": 34510
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.6054880619049072,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 0.0686,
      "step": 34520
    },
    {
      "epoch": 3.84,
      "grad_norm": 7.144611835479736,
      "learning_rate": 3.488740740740741e-05,
      "loss": 0.1052,
      "step": 34530
    },
    {
      "epoch": 3.84,
      "grad_norm": 8.486496925354004,
      "learning_rate": 3.488592592592593e-05,
      "loss": 0.133,
      "step": 34540
    },
    {
      "epoch": 3.84,
      "grad_norm": 10.075629234313965,
      "learning_rate": 3.488444444444444e-05,
      "loss": 0.1003,
      "step": 34550
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.253199577331543,
      "learning_rate": 3.4882962962962966e-05,
      "loss": 0.1062,
      "step": 34560
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.1502914428710938,
      "learning_rate": 3.488148148148148e-05,
      "loss": 0.0663,
      "step": 34570
    },
    {
      "epoch": 3.84,
      "grad_norm": 3.524667978286743,
      "learning_rate": 3.4880000000000005e-05,
      "loss": 0.1248,
      "step": 34580
    },
    {
      "epoch": 3.84,
      "grad_norm": 8.108343124389648,
      "learning_rate": 3.487851851851852e-05,
      "loss": 0.1339,
      "step": 34590
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.49866148829460144,
      "learning_rate": 3.487703703703704e-05,
      "loss": 0.0891,
      "step": 34600
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.9595189094543457,
      "learning_rate": 3.487555555555556e-05,
      "loss": 0.0817,
      "step": 34610
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.5661484599113464,
      "learning_rate": 3.4874074074074076e-05,
      "loss": 0.1259,
      "step": 34620
    },
    {
      "epoch": 3.85,
      "grad_norm": 10.805462837219238,
      "learning_rate": 3.48725925925926e-05,
      "loss": 0.1187,
      "step": 34630
    },
    {
      "epoch": 3.85,
      "grad_norm": 3.039602279663086,
      "learning_rate": 3.4871111111111115e-05,
      "loss": 0.0621,
      "step": 34640
    },
    {
      "epoch": 3.85,
      "grad_norm": 11.18207836151123,
      "learning_rate": 3.486962962962963e-05,
      "loss": 0.1077,
      "step": 34650
    },
    {
      "epoch": 3.85,
      "grad_norm": 6.536315441131592,
      "learning_rate": 3.486814814814815e-05,
      "loss": 0.0817,
      "step": 34660
    },
    {
      "epoch": 3.85,
      "grad_norm": 5.2464470863342285,
      "learning_rate": 3.486666666666667e-05,
      "loss": 0.0687,
      "step": 34670
    },
    {
      "epoch": 3.85,
      "grad_norm": 1.1640956401824951,
      "learning_rate": 3.4865185185185185e-05,
      "loss": 0.069,
      "step": 34680
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.4197990894317627,
      "learning_rate": 3.486370370370371e-05,
      "loss": 0.0586,
      "step": 34690
    },
    {
      "epoch": 3.86,
      "grad_norm": 4.299476623535156,
      "learning_rate": 3.4862222222222224e-05,
      "loss": 0.0811,
      "step": 34700
    },
    {
      "epoch": 3.86,
      "grad_norm": 3.0633344650268555,
      "learning_rate": 3.486074074074074e-05,
      "loss": 0.0911,
      "step": 34710
    },
    {
      "epoch": 3.86,
      "grad_norm": 1.6774418354034424,
      "learning_rate": 3.485925925925926e-05,
      "loss": 0.0855,
      "step": 34720
    },
    {
      "epoch": 3.86,
      "grad_norm": 5.338373184204102,
      "learning_rate": 3.485777777777778e-05,
      "loss": 0.0787,
      "step": 34730
    },
    {
      "epoch": 3.86,
      "grad_norm": 1.1993993520736694,
      "learning_rate": 3.48562962962963e-05,
      "loss": 0.0654,
      "step": 34740
    },
    {
      "epoch": 3.86,
      "grad_norm": 3.437121868133545,
      "learning_rate": 3.485481481481482e-05,
      "loss": 0.0786,
      "step": 34750
    },
    {
      "epoch": 3.86,
      "grad_norm": 5.032919406890869,
      "learning_rate": 3.4853333333333334e-05,
      "loss": 0.1317,
      "step": 34760
    },
    {
      "epoch": 3.86,
      "grad_norm": 1.2842689752578735,
      "learning_rate": 3.485185185185186e-05,
      "loss": 0.0636,
      "step": 34770
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.156111717224121,
      "learning_rate": 3.485037037037037e-05,
      "loss": 0.0713,
      "step": 34780
    },
    {
      "epoch": 3.87,
      "grad_norm": 9.147098541259766,
      "learning_rate": 3.484888888888889e-05,
      "loss": 0.1613,
      "step": 34790
    },
    {
      "epoch": 3.87,
      "grad_norm": 5.949478626251221,
      "learning_rate": 3.484740740740741e-05,
      "loss": 0.099,
      "step": 34800
    },
    {
      "epoch": 3.87,
      "grad_norm": 4.81600284576416,
      "learning_rate": 3.484592592592593e-05,
      "loss": 0.1383,
      "step": 34810
    },
    {
      "epoch": 3.87,
      "grad_norm": 6.085679054260254,
      "learning_rate": 3.4844444444444444e-05,
      "loss": 0.0909,
      "step": 34820
    },
    {
      "epoch": 3.87,
      "grad_norm": 4.026340007781982,
      "learning_rate": 3.4842962962962966e-05,
      "loss": 0.1056,
      "step": 34830
    },
    {
      "epoch": 3.87,
      "grad_norm": 3.1861703395843506,
      "learning_rate": 3.484148148148148e-05,
      "loss": 0.081,
      "step": 34840
    },
    {
      "epoch": 3.87,
      "grad_norm": 8.738141059875488,
      "learning_rate": 3.4840000000000005e-05,
      "loss": 0.1468,
      "step": 34850
    },
    {
      "epoch": 3.87,
      "grad_norm": 7.424221038818359,
      "learning_rate": 3.483851851851852e-05,
      "loss": 0.1217,
      "step": 34860
    },
    {
      "epoch": 3.87,
      "grad_norm": 6.681575775146484,
      "learning_rate": 3.483703703703704e-05,
      "loss": 0.066,
      "step": 34870
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.085127830505371,
      "learning_rate": 3.483555555555556e-05,
      "loss": 0.0512,
      "step": 34880
    },
    {
      "epoch": 3.88,
      "grad_norm": 8.236096382141113,
      "learning_rate": 3.4834074074074076e-05,
      "loss": 0.1002,
      "step": 34890
    },
    {
      "epoch": 3.88,
      "grad_norm": 3.140841245651245,
      "learning_rate": 3.48325925925926e-05,
      "loss": 0.0851,
      "step": 34900
    },
    {
      "epoch": 3.88,
      "grad_norm": 1.8294247388839722,
      "learning_rate": 3.4831111111111115e-05,
      "loss": 0.1079,
      "step": 34910
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.6739959716796875,
      "learning_rate": 3.482962962962963e-05,
      "loss": 0.0955,
      "step": 34920
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.9231770634651184,
      "learning_rate": 3.4828148148148154e-05,
      "loss": 0.1364,
      "step": 34930
    },
    {
      "epoch": 3.88,
      "grad_norm": 1.0541977882385254,
      "learning_rate": 3.482666666666667e-05,
      "loss": 0.1405,
      "step": 34940
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.400320053100586,
      "learning_rate": 3.4825185185185186e-05,
      "loss": 0.0819,
      "step": 34950
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.019879102706909,
      "learning_rate": 3.482370370370371e-05,
      "loss": 0.08,
      "step": 34960
    },
    {
      "epoch": 3.89,
      "grad_norm": 1.9944201707839966,
      "learning_rate": 3.4822222222222225e-05,
      "loss": 0.0872,
      "step": 34970
    },
    {
      "epoch": 3.89,
      "grad_norm": 7.842275142669678,
      "learning_rate": 3.482074074074074e-05,
      "loss": 0.0914,
      "step": 34980
    },
    {
      "epoch": 3.89,
      "grad_norm": 7.0358076095581055,
      "learning_rate": 3.4819259259259263e-05,
      "loss": 0.1041,
      "step": 34990
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.257631778717041,
      "learning_rate": 3.481777777777778e-05,
      "loss": 0.0733,
      "step": 35000
    },
    {
      "epoch": 3.89,
      "grad_norm": 26.285940170288086,
      "learning_rate": 3.48162962962963e-05,
      "loss": 0.1177,
      "step": 35010
    },
    {
      "epoch": 3.89,
      "grad_norm": 3.260770320892334,
      "learning_rate": 3.481481481481482e-05,
      "loss": 0.1234,
      "step": 35020
    },
    {
      "epoch": 3.89,
      "grad_norm": 1.1908135414123535,
      "learning_rate": 3.4813333333333334e-05,
      "loss": 0.0879,
      "step": 35030
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.136201858520508,
      "learning_rate": 3.481185185185186e-05,
      "loss": 0.0977,
      "step": 35040
    },
    {
      "epoch": 3.89,
      "grad_norm": 6.3311686515808105,
      "learning_rate": 3.481037037037037e-05,
      "loss": 0.0658,
      "step": 35050
    },
    {
      "epoch": 3.9,
      "grad_norm": 4.662032604217529,
      "learning_rate": 3.480888888888889e-05,
      "loss": 0.0951,
      "step": 35060
    },
    {
      "epoch": 3.9,
      "grad_norm": 4.255246162414551,
      "learning_rate": 3.480740740740741e-05,
      "loss": 0.0739,
      "step": 35070
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.614387035369873,
      "learning_rate": 3.480592592592593e-05,
      "loss": 0.0942,
      "step": 35080
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.859529733657837,
      "learning_rate": 3.4804444444444444e-05,
      "loss": 0.1128,
      "step": 35090
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.270707368850708,
      "learning_rate": 3.480296296296297e-05,
      "loss": 0.0605,
      "step": 35100
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.486008644104004,
      "learning_rate": 3.480148148148148e-05,
      "loss": 0.1199,
      "step": 35110
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.348215341567993,
      "learning_rate": 3.4800000000000006e-05,
      "loss": 0.0796,
      "step": 35120
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.109912872314453,
      "learning_rate": 3.479851851851852e-05,
      "loss": 0.0976,
      "step": 35130
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.6546247005462646,
      "learning_rate": 3.479703703703704e-05,
      "loss": 0.0668,
      "step": 35140
    },
    {
      "epoch": 3.91,
      "grad_norm": 2.75850772857666,
      "learning_rate": 3.479555555555556e-05,
      "loss": 0.0794,
      "step": 35150
    },
    {
      "epoch": 3.91,
      "grad_norm": 2.4301791191101074,
      "learning_rate": 3.4794074074074076e-05,
      "loss": 0.1513,
      "step": 35160
    },
    {
      "epoch": 3.91,
      "grad_norm": 6.097485542297363,
      "learning_rate": 3.479259259259259e-05,
      "loss": 0.096,
      "step": 35170
    },
    {
      "epoch": 3.91,
      "grad_norm": 7.728531360626221,
      "learning_rate": 3.4791111111111115e-05,
      "loss": 0.1161,
      "step": 35180
    },
    {
      "epoch": 3.91,
      "grad_norm": 3.5910167694091797,
      "learning_rate": 3.478962962962963e-05,
      "loss": 0.0551,
      "step": 35190
    },
    {
      "epoch": 3.91,
      "grad_norm": 5.483912944793701,
      "learning_rate": 3.4788148148148154e-05,
      "loss": 0.0716,
      "step": 35200
    },
    {
      "epoch": 3.91,
      "grad_norm": 3.4375457763671875,
      "learning_rate": 3.478666666666667e-05,
      "loss": 0.0986,
      "step": 35210
    },
    {
      "epoch": 3.91,
      "grad_norm": 3.7436375617980957,
      "learning_rate": 3.4785185185185186e-05,
      "loss": 0.0907,
      "step": 35220
    },
    {
      "epoch": 3.91,
      "grad_norm": 6.238242149353027,
      "learning_rate": 3.478370370370371e-05,
      "loss": 0.2105,
      "step": 35230
    },
    {
      "epoch": 3.92,
      "grad_norm": 5.042773723602295,
      "learning_rate": 3.4782222222222225e-05,
      "loss": 0.1054,
      "step": 35240
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.871804714202881,
      "learning_rate": 3.478074074074074e-05,
      "loss": 0.1133,
      "step": 35250
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.4761290550231934,
      "learning_rate": 3.4779259259259264e-05,
      "loss": 0.091,
      "step": 35260
    },
    {
      "epoch": 3.92,
      "grad_norm": 6.646767616271973,
      "learning_rate": 3.477777777777778e-05,
      "loss": 0.0917,
      "step": 35270
    },
    {
      "epoch": 3.92,
      "grad_norm": 4.7442426681518555,
      "learning_rate": 3.4776296296296296e-05,
      "loss": 0.1039,
      "step": 35280
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.709656000137329,
      "learning_rate": 3.477481481481482e-05,
      "loss": 0.1044,
      "step": 35290
    },
    {
      "epoch": 3.92,
      "grad_norm": 10.119019508361816,
      "learning_rate": 3.4773333333333335e-05,
      "loss": 0.0855,
      "step": 35300
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.8516745567321777,
      "learning_rate": 3.477185185185186e-05,
      "loss": 0.095,
      "step": 35310
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.2890875339508057,
      "learning_rate": 3.4770370370370374e-05,
      "loss": 0.0885,
      "step": 35320
    },
    {
      "epoch": 3.93,
      "grad_norm": 3.7874603271484375,
      "learning_rate": 3.476888888888889e-05,
      "loss": 0.0683,
      "step": 35330
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.6530634164810181,
      "learning_rate": 3.476740740740741e-05,
      "loss": 0.1026,
      "step": 35340
    },
    {
      "epoch": 3.93,
      "grad_norm": 2.6988325119018555,
      "learning_rate": 3.476592592592593e-05,
      "loss": 0.1104,
      "step": 35350
    },
    {
      "epoch": 3.93,
      "grad_norm": 2.816093921661377,
      "learning_rate": 3.4764444444444444e-05,
      "loss": 0.1111,
      "step": 35360
    },
    {
      "epoch": 3.93,
      "grad_norm": 3.551220655441284,
      "learning_rate": 3.476296296296297e-05,
      "loss": 0.0761,
      "step": 35370
    },
    {
      "epoch": 3.93,
      "grad_norm": 7.2108473777771,
      "learning_rate": 3.476148148148148e-05,
      "loss": 0.1321,
      "step": 35380
    },
    {
      "epoch": 3.93,
      "grad_norm": 1.897698163986206,
      "learning_rate": 3.4760000000000006e-05,
      "loss": 0.0687,
      "step": 35390
    },
    {
      "epoch": 3.93,
      "grad_norm": 3.2243573665618896,
      "learning_rate": 3.475851851851852e-05,
      "loss": 0.0743,
      "step": 35400
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.4011748731136322,
      "learning_rate": 3.475703703703704e-05,
      "loss": 0.0544,
      "step": 35410
    },
    {
      "epoch": 3.94,
      "grad_norm": 4.3577561378479,
      "learning_rate": 3.475555555555556e-05,
      "loss": 0.1286,
      "step": 35420
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.644826650619507,
      "learning_rate": 3.475407407407408e-05,
      "loss": 0.0976,
      "step": 35430
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.0923240184783936,
      "learning_rate": 3.475259259259259e-05,
      "loss": 0.0459,
      "step": 35440
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.827547073364258,
      "learning_rate": 3.4751111111111116e-05,
      "loss": 0.0367,
      "step": 35450
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.660290479660034,
      "learning_rate": 3.474962962962963e-05,
      "loss": 0.1161,
      "step": 35460
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.5968117713928223,
      "learning_rate": 3.4748148148148155e-05,
      "loss": 0.0864,
      "step": 35470
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.691406011581421,
      "learning_rate": 3.474666666666667e-05,
      "loss": 0.0537,
      "step": 35480
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.4206063747406006,
      "learning_rate": 3.4745185185185187e-05,
      "loss": 0.1008,
      "step": 35490
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.472221612930298,
      "learning_rate": 3.474370370370371e-05,
      "loss": 0.0976,
      "step": 35500
    },
    {
      "epoch": 3.95,
      "grad_norm": 3.410912275314331,
      "learning_rate": 3.4742222222222225e-05,
      "loss": 0.1348,
      "step": 35510
    },
    {
      "epoch": 3.95,
      "grad_norm": 1.4366024732589722,
      "learning_rate": 3.474074074074074e-05,
      "loss": 0.0982,
      "step": 35520
    },
    {
      "epoch": 3.95,
      "grad_norm": 15.657651901245117,
      "learning_rate": 3.4739259259259264e-05,
      "loss": 0.0786,
      "step": 35530
    },
    {
      "epoch": 3.95,
      "grad_norm": 1.639580249786377,
      "learning_rate": 3.473777777777778e-05,
      "loss": 0.1294,
      "step": 35540
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.3827474117279053,
      "learning_rate": 3.4736296296296296e-05,
      "loss": 0.0625,
      "step": 35550
    },
    {
      "epoch": 3.95,
      "grad_norm": 1.4461315870285034,
      "learning_rate": 3.473481481481482e-05,
      "loss": 0.0623,
      "step": 35560
    },
    {
      "epoch": 3.95,
      "grad_norm": 3.356090784072876,
      "learning_rate": 3.4733333333333335e-05,
      "loss": 0.0672,
      "step": 35570
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.788625955581665,
      "learning_rate": 3.473185185185186e-05,
      "loss": 0.0916,
      "step": 35580
    },
    {
      "epoch": 3.95,
      "grad_norm": 3.978055238723755,
      "learning_rate": 3.4730370370370374e-05,
      "loss": 0.098,
      "step": 35590
    },
    {
      "epoch": 3.96,
      "grad_norm": 8.436920166015625,
      "learning_rate": 3.472888888888889e-05,
      "loss": 0.0736,
      "step": 35600
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.8196306228637695,
      "learning_rate": 3.472740740740741e-05,
      "loss": 0.1313,
      "step": 35610
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.625715732574463,
      "learning_rate": 3.472592592592593e-05,
      "loss": 0.0773,
      "step": 35620
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.01535701751709,
      "learning_rate": 3.4724444444444445e-05,
      "loss": 0.0625,
      "step": 35630
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.015915393829346,
      "learning_rate": 3.472296296296297e-05,
      "loss": 0.0854,
      "step": 35640
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.423673152923584,
      "learning_rate": 3.4721481481481484e-05,
      "loss": 0.0883,
      "step": 35650
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.8246466517448425,
      "learning_rate": 3.472e-05,
      "loss": 0.0488,
      "step": 35660
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.015167236328125,
      "learning_rate": 3.471851851851852e-05,
      "loss": 0.0892,
      "step": 35670
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.125406503677368,
      "learning_rate": 3.471703703703704e-05,
      "loss": 0.0927,
      "step": 35680
    },
    {
      "epoch": 3.97,
      "grad_norm": 7.843455791473389,
      "learning_rate": 3.471555555555556e-05,
      "loss": 0.0937,
      "step": 35690
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.7952568531036377,
      "learning_rate": 3.471407407407408e-05,
      "loss": 0.1036,
      "step": 35700
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.4583475589752197,
      "learning_rate": 3.471259259259259e-05,
      "loss": 0.1214,
      "step": 35710
    },
    {
      "epoch": 3.97,
      "grad_norm": 8.9586763381958,
      "learning_rate": 3.4711111111111116e-05,
      "loss": 0.0717,
      "step": 35720
    },
    {
      "epoch": 3.97,
      "grad_norm": 4.7754693031311035,
      "learning_rate": 3.470962962962963e-05,
      "loss": 0.1169,
      "step": 35730
    },
    {
      "epoch": 3.97,
      "grad_norm": 3.824850559234619,
      "learning_rate": 3.4708148148148155e-05,
      "loss": 0.1272,
      "step": 35740
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.7998337745666504,
      "learning_rate": 3.470666666666667e-05,
      "loss": 0.1075,
      "step": 35750
    },
    {
      "epoch": 3.97,
      "grad_norm": 6.569159984588623,
      "learning_rate": 3.470518518518519e-05,
      "loss": 0.1226,
      "step": 35760
    },
    {
      "epoch": 3.97,
      "grad_norm": 3.3911194801330566,
      "learning_rate": 3.47037037037037e-05,
      "loss": 0.0663,
      "step": 35770
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.652345895767212,
      "learning_rate": 3.4702222222222226e-05,
      "loss": 0.133,
      "step": 35780
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.3044674396514893,
      "learning_rate": 3.470074074074074e-05,
      "loss": 0.1091,
      "step": 35790
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.9997317790985107,
      "learning_rate": 3.4699259259259265e-05,
      "loss": 0.0668,
      "step": 35800
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.890777826309204,
      "learning_rate": 3.469777777777778e-05,
      "loss": 0.0729,
      "step": 35810
    },
    {
      "epoch": 3.98,
      "grad_norm": 7.424187183380127,
      "learning_rate": 3.46962962962963e-05,
      "loss": 0.1076,
      "step": 35820
    },
    {
      "epoch": 3.98,
      "grad_norm": 7.051461219787598,
      "learning_rate": 3.469481481481482e-05,
      "loss": 0.1229,
      "step": 35830
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.940427780151367,
      "learning_rate": 3.4693333333333335e-05,
      "loss": 0.1062,
      "step": 35840
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.46177339553833,
      "learning_rate": 3.469185185185186e-05,
      "loss": 0.0925,
      "step": 35850
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.9703433513641357,
      "learning_rate": 3.4690370370370374e-05,
      "loss": 0.1464,
      "step": 35860
    },
    {
      "epoch": 3.99,
      "grad_norm": 2.8531086444854736,
      "learning_rate": 3.468888888888889e-05,
      "loss": 0.0741,
      "step": 35870
    },
    {
      "epoch": 3.99,
      "grad_norm": 3.197861671447754,
      "learning_rate": 3.4687407407407406e-05,
      "loss": 0.0873,
      "step": 35880
    },
    {
      "epoch": 3.99,
      "grad_norm": 3.853135108947754,
      "learning_rate": 3.468592592592593e-05,
      "loss": 0.1065,
      "step": 35890
    },
    {
      "epoch": 3.99,
      "grad_norm": 2.4409756660461426,
      "learning_rate": 3.468444444444445e-05,
      "loss": 0.095,
      "step": 35900
    },
    {
      "epoch": 3.99,
      "grad_norm": 1.7503314018249512,
      "learning_rate": 3.468296296296297e-05,
      "loss": 0.0723,
      "step": 35910
    },
    {
      "epoch": 3.99,
      "grad_norm": 5.691367149353027,
      "learning_rate": 3.4681481481481484e-05,
      "loss": 0.1177,
      "step": 35920
    },
    {
      "epoch": 3.99,
      "grad_norm": 3.6890225410461426,
      "learning_rate": 3.468e-05,
      "loss": 0.1056,
      "step": 35930
    },
    {
      "epoch": 3.99,
      "grad_norm": 2.3531641960144043,
      "learning_rate": 3.467851851851852e-05,
      "loss": 0.0665,
      "step": 35940
    },
    {
      "epoch": 3.99,
      "grad_norm": 2.5645079612731934,
      "learning_rate": 3.467703703703704e-05,
      "loss": 0.0633,
      "step": 35950
    },
    {
      "epoch": 4.0,
      "grad_norm": 9.307022094726562,
      "learning_rate": 3.467555555555556e-05,
      "loss": 0.072,
      "step": 35960
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.5532218217849731,
      "learning_rate": 3.467407407407408e-05,
      "loss": 0.1278,
      "step": 35970
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.7298059463500977,
      "learning_rate": 3.4672592592592594e-05,
      "loss": 0.1083,
      "step": 35980
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.8470500707626343,
      "learning_rate": 3.4671111111111116e-05,
      "loss": 0.0771,
      "step": 35990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.0797557830810547,
      "learning_rate": 3.466962962962963e-05,
      "loss": 0.0844,
      "step": 36000
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.3275818824768066,
      "learning_rate": 3.4668148148148155e-05,
      "loss": 0.0289,
      "step": 36010
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.542481541633606,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.1654,
      "step": 36020
    },
    {
      "epoch": 4.0,
      "grad_norm": 7.476986408233643,
      "learning_rate": 3.466518518518519e-05,
      "loss": 0.0877,
      "step": 36030
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.6555588245391846,
      "learning_rate": 3.46637037037037e-05,
      "loss": 0.0604,
      "step": 36040
    },
    {
      "epoch": 4.01,
      "grad_norm": 1.70940363407135,
      "learning_rate": 3.4662222222222226e-05,
      "loss": 0.0771,
      "step": 36050
    },
    {
      "epoch": 4.01,
      "grad_norm": 9.658073425292969,
      "learning_rate": 3.466074074074074e-05,
      "loss": 0.0893,
      "step": 36060
    },
    {
      "epoch": 4.01,
      "grad_norm": 1.9392342567443848,
      "learning_rate": 3.4659259259259265e-05,
      "loss": 0.0801,
      "step": 36070
    },
    {
      "epoch": 4.01,
      "grad_norm": 1.404383659362793,
      "learning_rate": 3.465777777777778e-05,
      "loss": 0.0599,
      "step": 36080
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.5712984800338745,
      "learning_rate": 3.46562962962963e-05,
      "loss": 0.0523,
      "step": 36090
    },
    {
      "epoch": 4.01,
      "grad_norm": 5.882256031036377,
      "learning_rate": 3.465481481481482e-05,
      "loss": 0.0801,
      "step": 36100
    },
    {
      "epoch": 4.01,
      "grad_norm": 7.182994365692139,
      "learning_rate": 3.4653333333333336e-05,
      "loss": 0.0524,
      "step": 36110
    },
    {
      "epoch": 4.01,
      "grad_norm": 6.634760856628418,
      "learning_rate": 3.465185185185186e-05,
      "loss": 0.0844,
      "step": 36120
    },
    {
      "epoch": 4.01,
      "grad_norm": 2.8158202171325684,
      "learning_rate": 3.4650370370370375e-05,
      "loss": 0.0753,
      "step": 36130
    },
    {
      "epoch": 4.02,
      "grad_norm": 4.284470081329346,
      "learning_rate": 3.464888888888889e-05,
      "loss": 0.106,
      "step": 36140
    },
    {
      "epoch": 4.02,
      "grad_norm": 6.080912113189697,
      "learning_rate": 3.464740740740741e-05,
      "loss": 0.0834,
      "step": 36150
    },
    {
      "epoch": 4.02,
      "grad_norm": 6.3911261558532715,
      "learning_rate": 3.464592592592593e-05,
      "loss": 0.0607,
      "step": 36160
    },
    {
      "epoch": 4.02,
      "grad_norm": 11.871145248413086,
      "learning_rate": 3.464444444444445e-05,
      "loss": 0.0741,
      "step": 36170
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.5599496364593506,
      "learning_rate": 3.464296296296297e-05,
      "loss": 0.0687,
      "step": 36180
    },
    {
      "epoch": 4.02,
      "grad_norm": 4.976343631744385,
      "learning_rate": 3.4641481481481484e-05,
      "loss": 0.085,
      "step": 36190
    },
    {
      "epoch": 4.02,
      "grad_norm": 2.0009875297546387,
      "learning_rate": 3.464e-05,
      "loss": 0.0584,
      "step": 36200
    },
    {
      "epoch": 4.02,
      "grad_norm": 2.533247947692871,
      "learning_rate": 3.463851851851852e-05,
      "loss": 0.0573,
      "step": 36210
    },
    {
      "epoch": 4.02,
      "grad_norm": 2.3817434310913086,
      "learning_rate": 3.463703703703704e-05,
      "loss": 0.0487,
      "step": 36220
    },
    {
      "epoch": 4.03,
      "grad_norm": 4.971839427947998,
      "learning_rate": 3.463555555555556e-05,
      "loss": 0.0553,
      "step": 36230
    },
    {
      "epoch": 4.03,
      "grad_norm": 6.514794826507568,
      "learning_rate": 3.463407407407408e-05,
      "loss": 0.0479,
      "step": 36240
    },
    {
      "epoch": 4.03,
      "grad_norm": 4.8540520668029785,
      "learning_rate": 3.4632592592592594e-05,
      "loss": 0.0773,
      "step": 36250
    },
    {
      "epoch": 4.03,
      "grad_norm": 4.670306205749512,
      "learning_rate": 3.463111111111111e-05,
      "loss": 0.1767,
      "step": 36260
    },
    {
      "epoch": 4.03,
      "grad_norm": 6.7617034912109375,
      "learning_rate": 3.462962962962963e-05,
      "loss": 0.0896,
      "step": 36270
    },
    {
      "epoch": 4.03,
      "grad_norm": 2.429771900177002,
      "learning_rate": 3.4628148148148156e-05,
      "loss": 0.0701,
      "step": 36280
    },
    {
      "epoch": 4.03,
      "grad_norm": 7.243430137634277,
      "learning_rate": 3.462666666666667e-05,
      "loss": 0.0828,
      "step": 36290
    },
    {
      "epoch": 4.03,
      "grad_norm": 4.267267227172852,
      "learning_rate": 3.462518518518519e-05,
      "loss": 0.1203,
      "step": 36300
    },
    {
      "epoch": 4.03,
      "grad_norm": 12.480996131896973,
      "learning_rate": 3.4623703703703704e-05,
      "loss": 0.0612,
      "step": 36310
    },
    {
      "epoch": 4.04,
      "grad_norm": 4.428744316101074,
      "learning_rate": 3.4622222222222227e-05,
      "loss": 0.0653,
      "step": 36320
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.330507755279541,
      "learning_rate": 3.462074074074074e-05,
      "loss": 0.064,
      "step": 36330
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.2645790576934814,
      "learning_rate": 3.4619259259259265e-05,
      "loss": 0.0668,
      "step": 36340
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.7867767810821533,
      "learning_rate": 3.461777777777778e-05,
      "loss": 0.0561,
      "step": 36350
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.7665222883224487,
      "learning_rate": 3.46162962962963e-05,
      "loss": 0.0422,
      "step": 36360
    },
    {
      "epoch": 4.04,
      "grad_norm": 5.941287517547607,
      "learning_rate": 3.4614814814814813e-05,
      "loss": 0.0969,
      "step": 36370
    },
    {
      "epoch": 4.04,
      "grad_norm": 6.872321605682373,
      "learning_rate": 3.4613333333333336e-05,
      "loss": 0.0534,
      "step": 36380
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.8388280868530273,
      "learning_rate": 3.461185185185186e-05,
      "loss": 0.075,
      "step": 36390
    },
    {
      "epoch": 4.04,
      "grad_norm": 3.286242961883545,
      "learning_rate": 3.4610370370370375e-05,
      "loss": 0.0701,
      "step": 36400
    },
    {
      "epoch": 4.05,
      "grad_norm": 5.432011604309082,
      "learning_rate": 3.460888888888889e-05,
      "loss": 0.0744,
      "step": 36410
    },
    {
      "epoch": 4.05,
      "grad_norm": 1.1686383485794067,
      "learning_rate": 3.460740740740741e-05,
      "loss": 0.081,
      "step": 36420
    },
    {
      "epoch": 4.05,
      "grad_norm": 2.9726366996765137,
      "learning_rate": 3.460592592592593e-05,
      "loss": 0.0897,
      "step": 36430
    },
    {
      "epoch": 4.05,
      "grad_norm": 4.137170314788818,
      "learning_rate": 3.460444444444445e-05,
      "loss": 0.0809,
      "step": 36440
    },
    {
      "epoch": 4.05,
      "grad_norm": 3.5497500896453857,
      "learning_rate": 3.460296296296297e-05,
      "loss": 0.1207,
      "step": 36450
    },
    {
      "epoch": 4.05,
      "grad_norm": 7.621305465698242,
      "learning_rate": 3.4601481481481485e-05,
      "loss": 0.0697,
      "step": 36460
    },
    {
      "epoch": 4.05,
      "grad_norm": 2.61340594291687,
      "learning_rate": 3.46e-05,
      "loss": 0.1007,
      "step": 36470
    },
    {
      "epoch": 4.05,
      "grad_norm": 3.1362171173095703,
      "learning_rate": 3.459851851851852e-05,
      "loss": 0.0634,
      "step": 36480
    },
    {
      "epoch": 4.05,
      "grad_norm": 5.7789530754089355,
      "learning_rate": 3.459703703703704e-05,
      "loss": 0.0785,
      "step": 36490
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.5363696217536926,
      "learning_rate": 3.459555555555556e-05,
      "loss": 0.0541,
      "step": 36500
    },
    {
      "epoch": 4.06,
      "grad_norm": 13.115157127380371,
      "learning_rate": 3.459407407407408e-05,
      "loss": 0.0694,
      "step": 36510
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.7331304550170898,
      "learning_rate": 3.4592592592592594e-05,
      "loss": 0.0639,
      "step": 36520
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.7702059745788574,
      "learning_rate": 3.459111111111111e-05,
      "loss": 0.0622,
      "step": 36530
    },
    {
      "epoch": 4.06,
      "grad_norm": 3.4480013847351074,
      "learning_rate": 3.458962962962963e-05,
      "loss": 0.055,
      "step": 36540
    },
    {
      "epoch": 4.06,
      "grad_norm": 5.142148017883301,
      "learning_rate": 3.4588148148148156e-05,
      "loss": 0.0599,
      "step": 36550
    },
    {
      "epoch": 4.06,
      "grad_norm": 5.5246148109436035,
      "learning_rate": 3.458666666666667e-05,
      "loss": 0.0603,
      "step": 36560
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.5659319162368774,
      "learning_rate": 3.458518518518519e-05,
      "loss": 0.0724,
      "step": 36570
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.7058087587356567,
      "learning_rate": 3.4583703703703704e-05,
      "loss": 0.0846,
      "step": 36580
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.9135133028030396,
      "learning_rate": 3.458222222222223e-05,
      "loss": 0.0728,
      "step": 36590
    },
    {
      "epoch": 4.07,
      "grad_norm": 7.411935806274414,
      "learning_rate": 3.458074074074074e-05,
      "loss": 0.1061,
      "step": 36600
    },
    {
      "epoch": 4.07,
      "grad_norm": 5.192842960357666,
      "learning_rate": 3.4579259259259266e-05,
      "loss": 0.0435,
      "step": 36610
    },
    {
      "epoch": 4.07,
      "grad_norm": 4.83470344543457,
      "learning_rate": 3.457777777777778e-05,
      "loss": 0.1325,
      "step": 36620
    },
    {
      "epoch": 4.07,
      "grad_norm": 2.960399866104126,
      "learning_rate": 3.45762962962963e-05,
      "loss": 0.0676,
      "step": 36630
    },
    {
      "epoch": 4.07,
      "grad_norm": 2.6779987812042236,
      "learning_rate": 3.4574814814814814e-05,
      "loss": 0.0883,
      "step": 36640
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.2737290561199188,
      "learning_rate": 3.4573333333333337e-05,
      "loss": 0.1277,
      "step": 36650
    },
    {
      "epoch": 4.07,
      "grad_norm": 1.955596923828125,
      "learning_rate": 3.457185185185186e-05,
      "loss": 0.06,
      "step": 36660
    },
    {
      "epoch": 4.07,
      "grad_norm": 4.370821952819824,
      "learning_rate": 3.4570370370370375e-05,
      "loss": 0.0445,
      "step": 36670
    },
    {
      "epoch": 4.08,
      "grad_norm": 5.316725254058838,
      "learning_rate": 3.456888888888889e-05,
      "loss": 0.0866,
      "step": 36680
    },
    {
      "epoch": 4.08,
      "grad_norm": 6.146301746368408,
      "learning_rate": 3.456740740740741e-05,
      "loss": 0.1285,
      "step": 36690
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.5228195190429688,
      "learning_rate": 3.456592592592593e-05,
      "loss": 0.0878,
      "step": 36700
    },
    {
      "epoch": 4.08,
      "grad_norm": 10.249577522277832,
      "learning_rate": 3.4564444444444446e-05,
      "loss": 0.1228,
      "step": 36710
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.144407033920288,
      "learning_rate": 3.456296296296297e-05,
      "loss": 0.0945,
      "step": 36720
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.496767997741699,
      "learning_rate": 3.4561481481481485e-05,
      "loss": 0.0963,
      "step": 36730
    },
    {
      "epoch": 4.08,
      "grad_norm": 4.301875591278076,
      "learning_rate": 3.456e-05,
      "loss": 0.075,
      "step": 36740
    },
    {
      "epoch": 4.08,
      "grad_norm": 1.7579251527786255,
      "learning_rate": 3.455851851851852e-05,
      "loss": 0.0566,
      "step": 36750
    },
    {
      "epoch": 4.08,
      "grad_norm": 3.0367162227630615,
      "learning_rate": 3.455703703703704e-05,
      "loss": 0.0857,
      "step": 36760
    },
    {
      "epoch": 4.09,
      "grad_norm": 9.161321640014648,
      "learning_rate": 3.455555555555556e-05,
      "loss": 0.0761,
      "step": 36770
    },
    {
      "epoch": 4.09,
      "grad_norm": 4.12951135635376,
      "learning_rate": 3.455407407407408e-05,
      "loss": 0.0798,
      "step": 36780
    },
    {
      "epoch": 4.09,
      "grad_norm": 3.828813076019287,
      "learning_rate": 3.4552592592592595e-05,
      "loss": 0.0928,
      "step": 36790
    },
    {
      "epoch": 4.09,
      "grad_norm": 2.533818483352661,
      "learning_rate": 3.455111111111111e-05,
      "loss": 0.0915,
      "step": 36800
    },
    {
      "epoch": 4.09,
      "grad_norm": 4.271940231323242,
      "learning_rate": 3.4549629629629634e-05,
      "loss": 0.0782,
      "step": 36810
    },
    {
      "epoch": 4.09,
      "grad_norm": 2.0269763469696045,
      "learning_rate": 3.454814814814815e-05,
      "loss": 0.0442,
      "step": 36820
    },
    {
      "epoch": 4.09,
      "grad_norm": 3.5586631298065186,
      "learning_rate": 3.454666666666667e-05,
      "loss": 0.0513,
      "step": 36830
    },
    {
      "epoch": 4.09,
      "grad_norm": 8.533714294433594,
      "learning_rate": 3.454518518518519e-05,
      "loss": 0.0853,
      "step": 36840
    },
    {
      "epoch": 4.09,
      "grad_norm": 2.392510175704956,
      "learning_rate": 3.4543703703703705e-05,
      "loss": 0.1126,
      "step": 36850
    },
    {
      "epoch": 4.1,
      "grad_norm": 2.6734330654144287,
      "learning_rate": 3.454222222222222e-05,
      "loss": 0.0611,
      "step": 36860
    },
    {
      "epoch": 4.1,
      "grad_norm": 2.8043341636657715,
      "learning_rate": 3.454074074074074e-05,
      "loss": 0.0903,
      "step": 36870
    },
    {
      "epoch": 4.1,
      "grad_norm": 1.5845385789871216,
      "learning_rate": 3.4539259259259266e-05,
      "loss": 0.0543,
      "step": 36880
    },
    {
      "epoch": 4.1,
      "grad_norm": 1.7482002973556519,
      "learning_rate": 3.453777777777778e-05,
      "loss": 0.0631,
      "step": 36890
    },
    {
      "epoch": 4.1,
      "grad_norm": 2.335909843444824,
      "learning_rate": 3.45362962962963e-05,
      "loss": 0.1389,
      "step": 36900
    },
    {
      "epoch": 4.1,
      "grad_norm": 2.4569294452667236,
      "learning_rate": 3.4534814814814814e-05,
      "loss": 0.0697,
      "step": 36910
    },
    {
      "epoch": 4.1,
      "grad_norm": 1.7330552339553833,
      "learning_rate": 3.453333333333334e-05,
      "loss": 0.0523,
      "step": 36920
    },
    {
      "epoch": 4.1,
      "grad_norm": 4.315672874450684,
      "learning_rate": 3.453185185185185e-05,
      "loss": 0.0739,
      "step": 36930
    },
    {
      "epoch": 4.1,
      "grad_norm": 6.538266181945801,
      "learning_rate": 3.4530370370370376e-05,
      "loss": 0.0744,
      "step": 36940
    },
    {
      "epoch": 4.11,
      "grad_norm": 3.620196580886841,
      "learning_rate": 3.452888888888889e-05,
      "loss": 0.0586,
      "step": 36950
    },
    {
      "epoch": 4.11,
      "grad_norm": 2.5068957805633545,
      "learning_rate": 3.452740740740741e-05,
      "loss": 0.0451,
      "step": 36960
    },
    {
      "epoch": 4.11,
      "grad_norm": 2.886399984359741,
      "learning_rate": 3.4525925925925924e-05,
      "loss": 0.0792,
      "step": 36970
    },
    {
      "epoch": 4.11,
      "grad_norm": 2.796251058578491,
      "learning_rate": 3.452444444444445e-05,
      "loss": 0.0776,
      "step": 36980
    },
    {
      "epoch": 4.11,
      "grad_norm": 5.083879470825195,
      "learning_rate": 3.452296296296297e-05,
      "loss": 0.0993,
      "step": 36990
    },
    {
      "epoch": 4.11,
      "grad_norm": 3.9252359867095947,
      "learning_rate": 3.4521481481481486e-05,
      "loss": 0.0756,
      "step": 37000
    },
    {
      "epoch": 4.11,
      "grad_norm": 2.2961533069610596,
      "learning_rate": 3.452e-05,
      "loss": 0.0713,
      "step": 37010
    },
    {
      "epoch": 4.11,
      "grad_norm": 1.4397966861724854,
      "learning_rate": 3.451851851851852e-05,
      "loss": 0.053,
      "step": 37020
    },
    {
      "epoch": 4.11,
      "grad_norm": 3.4825022220611572,
      "learning_rate": 3.451703703703704e-05,
      "loss": 0.0558,
      "step": 37030
    },
    {
      "epoch": 4.12,
      "grad_norm": 2.447416067123413,
      "learning_rate": 3.451555555555556e-05,
      "loss": 0.1038,
      "step": 37040
    },
    {
      "epoch": 4.12,
      "grad_norm": 4.201240062713623,
      "learning_rate": 3.451407407407408e-05,
      "loss": 0.0797,
      "step": 37050
    },
    {
      "epoch": 4.12,
      "grad_norm": 4.5232696533203125,
      "learning_rate": 3.4512592592592595e-05,
      "loss": 0.065,
      "step": 37060
    },
    {
      "epoch": 4.12,
      "grad_norm": 3.1599340438842773,
      "learning_rate": 3.451111111111111e-05,
      "loss": 0.0497,
      "step": 37070
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.7822171449661255,
      "learning_rate": 3.4509629629629634e-05,
      "loss": 0.0839,
      "step": 37080
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.1694539785385132,
      "learning_rate": 3.450814814814815e-05,
      "loss": 0.0417,
      "step": 37090
    },
    {
      "epoch": 4.12,
      "grad_norm": 3.407379150390625,
      "learning_rate": 3.450666666666667e-05,
      "loss": 0.0577,
      "step": 37100
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.1169072389602661,
      "learning_rate": 3.450518518518519e-05,
      "loss": 0.081,
      "step": 37110
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.342966079711914,
      "learning_rate": 3.4503703703703705e-05,
      "loss": 0.0359,
      "step": 37120
    },
    {
      "epoch": 4.13,
      "grad_norm": 4.034575939178467,
      "learning_rate": 3.450222222222222e-05,
      "loss": 0.079,
      "step": 37130
    },
    {
      "epoch": 4.13,
      "grad_norm": 1.9485565423965454,
      "learning_rate": 3.4500740740740744e-05,
      "loss": 0.0931,
      "step": 37140
    },
    {
      "epoch": 4.13,
      "grad_norm": 2.3967742919921875,
      "learning_rate": 3.4499259259259267e-05,
      "loss": 0.0764,
      "step": 37150
    },
    {
      "epoch": 4.13,
      "grad_norm": 3.5782623291015625,
      "learning_rate": 3.449777777777778e-05,
      "loss": 0.0613,
      "step": 37160
    },
    {
      "epoch": 4.13,
      "grad_norm": 3.455364227294922,
      "learning_rate": 3.44962962962963e-05,
      "loss": 0.0845,
      "step": 37170
    },
    {
      "epoch": 4.13,
      "grad_norm": 2.5497093200683594,
      "learning_rate": 3.4494814814814815e-05,
      "loss": 0.0879,
      "step": 37180
    },
    {
      "epoch": 4.13,
      "grad_norm": 5.537567138671875,
      "learning_rate": 3.449333333333334e-05,
      "loss": 0.1012,
      "step": 37190
    },
    {
      "epoch": 4.13,
      "grad_norm": 3.2014474868774414,
      "learning_rate": 3.4491851851851853e-05,
      "loss": 0.105,
      "step": 37200
    },
    {
      "epoch": 4.13,
      "grad_norm": 3.080613613128662,
      "learning_rate": 3.4490370370370376e-05,
      "loss": 0.102,
      "step": 37210
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.7869350910186768,
      "learning_rate": 3.448888888888889e-05,
      "loss": 0.0608,
      "step": 37220
    },
    {
      "epoch": 4.14,
      "grad_norm": 5.057989120483398,
      "learning_rate": 3.448740740740741e-05,
      "loss": 0.1065,
      "step": 37230
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.0941638946533203,
      "learning_rate": 3.4485925925925924e-05,
      "loss": 0.0577,
      "step": 37240
    },
    {
      "epoch": 4.14,
      "grad_norm": 3.062720775604248,
      "learning_rate": 3.448444444444445e-05,
      "loss": 0.0459,
      "step": 37250
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.1478395462036133,
      "learning_rate": 3.448296296296297e-05,
      "loss": 0.0858,
      "step": 37260
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.3328981399536133,
      "learning_rate": 3.4481481481481486e-05,
      "loss": 0.0557,
      "step": 37270
    },
    {
      "epoch": 4.14,
      "grad_norm": 7.8282084465026855,
      "learning_rate": 3.448e-05,
      "loss": 0.1108,
      "step": 37280
    },
    {
      "epoch": 4.14,
      "grad_norm": 3.0263214111328125,
      "learning_rate": 3.447851851851852e-05,
      "loss": 0.1028,
      "step": 37290
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.4539642333984375,
      "learning_rate": 3.447703703703704e-05,
      "loss": 0.0896,
      "step": 37300
    },
    {
      "epoch": 4.15,
      "grad_norm": 4.355320930480957,
      "learning_rate": 3.447555555555556e-05,
      "loss": 0.0859,
      "step": 37310
    },
    {
      "epoch": 4.15,
      "grad_norm": 5.344089984893799,
      "learning_rate": 3.447407407407408e-05,
      "loss": 0.0837,
      "step": 37320
    },
    {
      "epoch": 4.15,
      "grad_norm": 2.4872052669525146,
      "learning_rate": 3.4472592592592596e-05,
      "loss": 0.0762,
      "step": 37330
    },
    {
      "epoch": 4.15,
      "grad_norm": 5.295590400695801,
      "learning_rate": 3.447111111111111e-05,
      "loss": 0.0445,
      "step": 37340
    },
    {
      "epoch": 4.15,
      "grad_norm": 8.798553466796875,
      "learning_rate": 3.446962962962963e-05,
      "loss": 0.1036,
      "step": 37350
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.6443209648132324,
      "learning_rate": 3.446814814814815e-05,
      "loss": 0.0578,
      "step": 37360
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.42691847681999207,
      "learning_rate": 3.446666666666667e-05,
      "loss": 0.0988,
      "step": 37370
    },
    {
      "epoch": 4.15,
      "grad_norm": 4.199733734130859,
      "learning_rate": 3.446518518518519e-05,
      "loss": 0.0836,
      "step": 37380
    },
    {
      "epoch": 4.15,
      "grad_norm": 4.7795000076293945,
      "learning_rate": 3.4463703703703705e-05,
      "loss": 0.0411,
      "step": 37390
    },
    {
      "epoch": 4.16,
      "grad_norm": 3.4334123134613037,
      "learning_rate": 3.446222222222222e-05,
      "loss": 0.0797,
      "step": 37400
    },
    {
      "epoch": 4.16,
      "grad_norm": 4.768252372741699,
      "learning_rate": 3.4460740740740744e-05,
      "loss": 0.1178,
      "step": 37410
    },
    {
      "epoch": 4.16,
      "grad_norm": 3.2807276248931885,
      "learning_rate": 3.445925925925926e-05,
      "loss": 0.1207,
      "step": 37420
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.8594659566879272,
      "learning_rate": 3.445777777777778e-05,
      "loss": 0.0841,
      "step": 37430
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.290781021118164,
      "learning_rate": 3.44562962962963e-05,
      "loss": 0.098,
      "step": 37440
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.3560855388641357,
      "learning_rate": 3.4454814814814815e-05,
      "loss": 0.0703,
      "step": 37450
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.890713691711426,
      "learning_rate": 3.445333333333333e-05,
      "loss": 0.0586,
      "step": 37460
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.5964388847351074,
      "learning_rate": 3.4451851851851854e-05,
      "loss": 0.09,
      "step": 37470
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.8999650478363037,
      "learning_rate": 3.4450370370370377e-05,
      "loss": 0.0655,
      "step": 37480
    },
    {
      "epoch": 4.17,
      "grad_norm": 5.311600685119629,
      "learning_rate": 3.444888888888889e-05,
      "loss": 0.0835,
      "step": 37490
    },
    {
      "epoch": 4.17,
      "grad_norm": 6.9371795654296875,
      "learning_rate": 3.444740740740741e-05,
      "loss": 0.0715,
      "step": 37500
    },
    {
      "epoch": 4.17,
      "grad_norm": 1.0374433994293213,
      "learning_rate": 3.4445925925925925e-05,
      "loss": 0.0507,
      "step": 37510
    },
    {
      "epoch": 4.17,
      "grad_norm": 1.826503038406372,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0737,
      "step": 37520
    },
    {
      "epoch": 4.17,
      "grad_norm": 2.9710707664489746,
      "learning_rate": 3.444296296296297e-05,
      "loss": 0.0662,
      "step": 37530
    },
    {
      "epoch": 4.17,
      "grad_norm": 3.099628210067749,
      "learning_rate": 3.4441481481481486e-05,
      "loss": 0.0891,
      "step": 37540
    },
    {
      "epoch": 4.17,
      "grad_norm": 8.604962348937988,
      "learning_rate": 3.444e-05,
      "loss": 0.1086,
      "step": 37550
    },
    {
      "epoch": 4.17,
      "grad_norm": 4.270572185516357,
      "learning_rate": 3.443851851851852e-05,
      "loss": 0.0549,
      "step": 37560
    },
    {
      "epoch": 4.17,
      "grad_norm": 5.511541366577148,
      "learning_rate": 3.4437037037037034e-05,
      "loss": 0.1028,
      "step": 37570
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.6198267936706543,
      "learning_rate": 3.443555555555556e-05,
      "loss": 0.0967,
      "step": 37580
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.571747064590454,
      "learning_rate": 3.443407407407408e-05,
      "loss": 0.061,
      "step": 37590
    },
    {
      "epoch": 4.18,
      "grad_norm": 5.057005405426025,
      "learning_rate": 3.4432592592592596e-05,
      "loss": 0.0734,
      "step": 37600
    },
    {
      "epoch": 4.18,
      "grad_norm": 3.5819599628448486,
      "learning_rate": 3.443111111111111e-05,
      "loss": 0.0614,
      "step": 37610
    },
    {
      "epoch": 4.18,
      "grad_norm": 3.6521074771881104,
      "learning_rate": 3.442962962962963e-05,
      "loss": 0.0852,
      "step": 37620
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.5759958028793335,
      "learning_rate": 3.442814814814815e-05,
      "loss": 0.0634,
      "step": 37630
    },
    {
      "epoch": 4.18,
      "grad_norm": 3.3953440189361572,
      "learning_rate": 3.4426666666666674e-05,
      "loss": 0.054,
      "step": 37640
    },
    {
      "epoch": 4.18,
      "grad_norm": 1.950829029083252,
      "learning_rate": 3.442518518518519e-05,
      "loss": 0.0796,
      "step": 37650
    },
    {
      "epoch": 4.18,
      "grad_norm": 5.983396530151367,
      "learning_rate": 3.4423703703703706e-05,
      "loss": 0.099,
      "step": 37660
    },
    {
      "epoch": 4.19,
      "grad_norm": 6.538952827453613,
      "learning_rate": 3.442222222222222e-05,
      "loss": 0.0634,
      "step": 37670
    },
    {
      "epoch": 4.19,
      "grad_norm": 4.414525985717773,
      "learning_rate": 3.4420740740740744e-05,
      "loss": 0.0543,
      "step": 37680
    },
    {
      "epoch": 4.19,
      "grad_norm": 6.592028617858887,
      "learning_rate": 3.441925925925926e-05,
      "loss": 0.0488,
      "step": 37690
    },
    {
      "epoch": 4.19,
      "grad_norm": 6.7615966796875,
      "learning_rate": 3.441777777777778e-05,
      "loss": 0.084,
      "step": 37700
    },
    {
      "epoch": 4.19,
      "grad_norm": 2.0706660747528076,
      "learning_rate": 3.44162962962963e-05,
      "loss": 0.0531,
      "step": 37710
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.626562237739563,
      "learning_rate": 3.4414814814814815e-05,
      "loss": 0.0431,
      "step": 37720
    },
    {
      "epoch": 4.19,
      "grad_norm": 7.442575931549072,
      "learning_rate": 3.441333333333333e-05,
      "loss": 0.0978,
      "step": 37730
    },
    {
      "epoch": 4.19,
      "grad_norm": 6.720751762390137,
      "learning_rate": 3.4411851851851854e-05,
      "loss": 0.0992,
      "step": 37740
    },
    {
      "epoch": 4.19,
      "grad_norm": 3.4448769092559814,
      "learning_rate": 3.441037037037038e-05,
      "loss": 0.073,
      "step": 37750
    },
    {
      "epoch": 4.2,
      "grad_norm": 3.6855273246765137,
      "learning_rate": 3.440888888888889e-05,
      "loss": 0.0734,
      "step": 37760
    },
    {
      "epoch": 4.2,
      "grad_norm": 10.124601364135742,
      "learning_rate": 3.440740740740741e-05,
      "loss": 0.1015,
      "step": 37770
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.0784361362457275,
      "learning_rate": 3.4405925925925925e-05,
      "loss": 0.0757,
      "step": 37780
    },
    {
      "epoch": 4.2,
      "grad_norm": 4.066205024719238,
      "learning_rate": 3.440444444444445e-05,
      "loss": 0.0953,
      "step": 37790
    },
    {
      "epoch": 4.2,
      "grad_norm": 4.001591205596924,
      "learning_rate": 3.4402962962962964e-05,
      "loss": 0.0665,
      "step": 37800
    },
    {
      "epoch": 4.2,
      "grad_norm": 4.138743877410889,
      "learning_rate": 3.440148148148149e-05,
      "loss": 0.0833,
      "step": 37810
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.5712536573410034,
      "learning_rate": 3.44e-05,
      "loss": 0.0552,
      "step": 37820
    },
    {
      "epoch": 4.2,
      "grad_norm": 3.4298040866851807,
      "learning_rate": 3.439851851851852e-05,
      "loss": 0.0758,
      "step": 37830
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.435671329498291,
      "learning_rate": 3.4397037037037035e-05,
      "loss": 0.0801,
      "step": 37840
    },
    {
      "epoch": 4.21,
      "grad_norm": 4.515292167663574,
      "learning_rate": 3.439555555555556e-05,
      "loss": 0.0744,
      "step": 37850
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.4399055242538452,
      "learning_rate": 3.439407407407408e-05,
      "loss": 0.0919,
      "step": 37860
    },
    {
      "epoch": 4.21,
      "grad_norm": 3.019535779953003,
      "learning_rate": 3.4392592592592596e-05,
      "loss": 0.0504,
      "step": 37870
    },
    {
      "epoch": 4.21,
      "grad_norm": 2.728612184524536,
      "learning_rate": 3.439111111111111e-05,
      "loss": 0.0385,
      "step": 37880
    },
    {
      "epoch": 4.21,
      "grad_norm": 1.4028977155685425,
      "learning_rate": 3.438962962962963e-05,
      "loss": 0.0914,
      "step": 37890
    },
    {
      "epoch": 4.21,
      "grad_norm": 13.092791557312012,
      "learning_rate": 3.438814814814815e-05,
      "loss": 0.0751,
      "step": 37900
    },
    {
      "epoch": 4.21,
      "grad_norm": 5.245734691619873,
      "learning_rate": 3.438666666666667e-05,
      "loss": 0.1159,
      "step": 37910
    },
    {
      "epoch": 4.21,
      "grad_norm": 4.728877067565918,
      "learning_rate": 3.438518518518519e-05,
      "loss": 0.0638,
      "step": 37920
    },
    {
      "epoch": 4.21,
      "grad_norm": 2.859177827835083,
      "learning_rate": 3.4383703703703706e-05,
      "loss": 0.0704,
      "step": 37930
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.669619560241699,
      "learning_rate": 3.438222222222222e-05,
      "loss": 0.0357,
      "step": 37940
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.7516239285469055,
      "learning_rate": 3.4380740740740745e-05,
      "loss": 0.0644,
      "step": 37950
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.1458096504211426,
      "learning_rate": 3.437925925925926e-05,
      "loss": 0.072,
      "step": 37960
    },
    {
      "epoch": 4.22,
      "grad_norm": 7.269416332244873,
      "learning_rate": 3.4377777777777784e-05,
      "loss": 0.0591,
      "step": 37970
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.9608781337738037,
      "learning_rate": 3.43762962962963e-05,
      "loss": 0.0429,
      "step": 37980
    },
    {
      "epoch": 4.22,
      "grad_norm": 12.414480209350586,
      "learning_rate": 3.4374814814814816e-05,
      "loss": 0.1206,
      "step": 37990
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.0500831604003906,
      "learning_rate": 3.437333333333333e-05,
      "loss": 0.1101,
      "step": 38000
    },
    {
      "epoch": 4.22,
      "grad_norm": 4.7481489181518555,
      "learning_rate": 3.4371851851851855e-05,
      "loss": 0.0817,
      "step": 38010
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.2639122009277344,
      "learning_rate": 3.437037037037037e-05,
      "loss": 0.0845,
      "step": 38020
    },
    {
      "epoch": 4.23,
      "grad_norm": 2.2654991149902344,
      "learning_rate": 3.436888888888889e-05,
      "loss": 0.0814,
      "step": 38030
    },
    {
      "epoch": 4.23,
      "grad_norm": 6.651828289031982,
      "learning_rate": 3.436740740740741e-05,
      "loss": 0.0639,
      "step": 38040
    },
    {
      "epoch": 4.23,
      "grad_norm": 4.533054351806641,
      "learning_rate": 3.4365925925925925e-05,
      "loss": 0.1125,
      "step": 38050
    },
    {
      "epoch": 4.23,
      "grad_norm": 1.461628794670105,
      "learning_rate": 3.436444444444445e-05,
      "loss": 0.0656,
      "step": 38060
    },
    {
      "epoch": 4.23,
      "grad_norm": 3.9826889038085938,
      "learning_rate": 3.4362962962962964e-05,
      "loss": 0.0585,
      "step": 38070
    },
    {
      "epoch": 4.23,
      "grad_norm": 6.416123867034912,
      "learning_rate": 3.436148148148149e-05,
      "loss": 0.0811,
      "step": 38080
    },
    {
      "epoch": 4.23,
      "grad_norm": 2.023893117904663,
      "learning_rate": 3.436e-05,
      "loss": 0.0629,
      "step": 38090
    },
    {
      "epoch": 4.23,
      "grad_norm": 5.055387020111084,
      "learning_rate": 3.435851851851852e-05,
      "loss": 0.0793,
      "step": 38100
    },
    {
      "epoch": 4.23,
      "grad_norm": 4.598764419555664,
      "learning_rate": 3.4357037037037035e-05,
      "loss": 0.0852,
      "step": 38110
    },
    {
      "epoch": 4.24,
      "grad_norm": 3.8592677116394043,
      "learning_rate": 3.435555555555556e-05,
      "loss": 0.0818,
      "step": 38120
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.9787876605987549,
      "learning_rate": 3.435407407407408e-05,
      "loss": 0.0518,
      "step": 38130
    },
    {
      "epoch": 4.24,
      "grad_norm": 7.489261150360107,
      "learning_rate": 3.43525925925926e-05,
      "loss": 0.0583,
      "step": 38140
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.017914056777954,
      "learning_rate": 3.435111111111111e-05,
      "loss": 0.0494,
      "step": 38150
    },
    {
      "epoch": 4.24,
      "grad_norm": 6.1240763664245605,
      "learning_rate": 3.434962962962963e-05,
      "loss": 0.0916,
      "step": 38160
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.6734118461608887,
      "learning_rate": 3.434814814814815e-05,
      "loss": 0.0612,
      "step": 38170
    },
    {
      "epoch": 4.24,
      "grad_norm": 4.700789928436279,
      "learning_rate": 3.434666666666667e-05,
      "loss": 0.0402,
      "step": 38180
    },
    {
      "epoch": 4.24,
      "grad_norm": 3.7422733306884766,
      "learning_rate": 3.434518518518519e-05,
      "loss": 0.075,
      "step": 38190
    },
    {
      "epoch": 4.24,
      "grad_norm": 6.62976598739624,
      "learning_rate": 3.4343703703703706e-05,
      "loss": 0.0907,
      "step": 38200
    },
    {
      "epoch": 4.25,
      "grad_norm": 2.691596508026123,
      "learning_rate": 3.434222222222222e-05,
      "loss": 0.1311,
      "step": 38210
    },
    {
      "epoch": 4.25,
      "grad_norm": 7.785464286804199,
      "learning_rate": 3.4340740740740745e-05,
      "loss": 0.0726,
      "step": 38220
    },
    {
      "epoch": 4.25,
      "grad_norm": 1.031024694442749,
      "learning_rate": 3.433925925925926e-05,
      "loss": 0.0872,
      "step": 38230
    },
    {
      "epoch": 4.25,
      "grad_norm": 27.731985092163086,
      "learning_rate": 3.4337777777777784e-05,
      "loss": 0.0776,
      "step": 38240
    },
    {
      "epoch": 4.25,
      "grad_norm": 4.010685443878174,
      "learning_rate": 3.43362962962963e-05,
      "loss": 0.0908,
      "step": 38250
    },
    {
      "epoch": 4.25,
      "grad_norm": 4.3528594970703125,
      "learning_rate": 3.4334814814814816e-05,
      "loss": 0.0325,
      "step": 38260
    },
    {
      "epoch": 4.25,
      "grad_norm": 6.079835414886475,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.0749,
      "step": 38270
    },
    {
      "epoch": 4.25,
      "grad_norm": 1.6854610443115234,
      "learning_rate": 3.4331851851851855e-05,
      "loss": 0.064,
      "step": 38280
    },
    {
      "epoch": 4.25,
      "grad_norm": 5.436627388000488,
      "learning_rate": 3.433037037037037e-05,
      "loss": 0.0895,
      "step": 38290
    },
    {
      "epoch": 4.26,
      "grad_norm": 13.315023422241211,
      "learning_rate": 3.4328888888888894e-05,
      "loss": 0.0526,
      "step": 38300
    },
    {
      "epoch": 4.26,
      "grad_norm": 7.160554885864258,
      "learning_rate": 3.432740740740741e-05,
      "loss": 0.1006,
      "step": 38310
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.9470139741897583,
      "learning_rate": 3.4325925925925926e-05,
      "loss": 0.0632,
      "step": 38320
    },
    {
      "epoch": 4.26,
      "grad_norm": 5.819299697875977,
      "learning_rate": 3.432444444444445e-05,
      "loss": 0.0784,
      "step": 38330
    },
    {
      "epoch": 4.26,
      "grad_norm": 6.736128330230713,
      "learning_rate": 3.4322962962962965e-05,
      "loss": 0.1035,
      "step": 38340
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.6936651468276978,
      "learning_rate": 3.432148148148149e-05,
      "loss": 0.0503,
      "step": 38350
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.3708305358886719,
      "learning_rate": 3.4320000000000003e-05,
      "loss": 0.1175,
      "step": 38360
    },
    {
      "epoch": 4.26,
      "grad_norm": 11.242833137512207,
      "learning_rate": 3.431851851851852e-05,
      "loss": 0.0866,
      "step": 38370
    },
    {
      "epoch": 4.26,
      "grad_norm": 3.3231594562530518,
      "learning_rate": 3.431703703703704e-05,
      "loss": 0.0676,
      "step": 38380
    },
    {
      "epoch": 4.27,
      "grad_norm": 2.5975306034088135,
      "learning_rate": 3.431555555555556e-05,
      "loss": 0.0671,
      "step": 38390
    },
    {
      "epoch": 4.27,
      "grad_norm": 3.471133232116699,
      "learning_rate": 3.4314074074074074e-05,
      "loss": 0.0569,
      "step": 38400
    },
    {
      "epoch": 4.27,
      "grad_norm": 3.6583917140960693,
      "learning_rate": 3.43125925925926e-05,
      "loss": 0.1052,
      "step": 38410
    },
    {
      "epoch": 4.27,
      "grad_norm": 3.6189064979553223,
      "learning_rate": 3.431111111111111e-05,
      "loss": 0.0594,
      "step": 38420
    },
    {
      "epoch": 4.27,
      "grad_norm": 4.922661781311035,
      "learning_rate": 3.430962962962963e-05,
      "loss": 0.0662,
      "step": 38430
    },
    {
      "epoch": 4.27,
      "grad_norm": 5.462798595428467,
      "learning_rate": 3.430814814814815e-05,
      "loss": 0.0772,
      "step": 38440
    },
    {
      "epoch": 4.27,
      "grad_norm": 5.162343978881836,
      "learning_rate": 3.430666666666667e-05,
      "loss": 0.1099,
      "step": 38450
    },
    {
      "epoch": 4.27,
      "grad_norm": 2.391662120819092,
      "learning_rate": 3.430518518518519e-05,
      "loss": 0.0739,
      "step": 38460
    },
    {
      "epoch": 4.27,
      "grad_norm": 4.849626064300537,
      "learning_rate": 3.430370370370371e-05,
      "loss": 0.0593,
      "step": 38470
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.7767730951309204,
      "learning_rate": 3.430222222222222e-05,
      "loss": 0.0487,
      "step": 38480
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.7108830213546753,
      "learning_rate": 3.4300740740740746e-05,
      "loss": 0.0873,
      "step": 38490
    },
    {
      "epoch": 4.28,
      "grad_norm": 5.684605121612549,
      "learning_rate": 3.429925925925926e-05,
      "loss": 0.062,
      "step": 38500
    },
    {
      "epoch": 4.28,
      "grad_norm": 6.267323970794678,
      "learning_rate": 3.429777777777778e-05,
      "loss": 0.0351,
      "step": 38510
    },
    {
      "epoch": 4.28,
      "grad_norm": 4.391561508178711,
      "learning_rate": 3.42962962962963e-05,
      "loss": 0.0711,
      "step": 38520
    },
    {
      "epoch": 4.28,
      "grad_norm": 3.963298797607422,
      "learning_rate": 3.4294814814814816e-05,
      "loss": 0.0979,
      "step": 38530
    },
    {
      "epoch": 4.28,
      "grad_norm": 2.6257705688476562,
      "learning_rate": 3.429333333333333e-05,
      "loss": 0.0323,
      "step": 38540
    },
    {
      "epoch": 4.28,
      "grad_norm": 4.503907680511475,
      "learning_rate": 3.4291851851851855e-05,
      "loss": 0.0861,
      "step": 38550
    },
    {
      "epoch": 4.28,
      "grad_norm": 2.057837724685669,
      "learning_rate": 3.429037037037037e-05,
      "loss": 0.082,
      "step": 38560
    },
    {
      "epoch": 4.29,
      "grad_norm": 4.761709690093994,
      "learning_rate": 3.4288888888888894e-05,
      "loss": 0.0796,
      "step": 38570
    },
    {
      "epoch": 4.29,
      "grad_norm": 3.3113620281219482,
      "learning_rate": 3.428740740740741e-05,
      "loss": 0.0441,
      "step": 38580
    },
    {
      "epoch": 4.29,
      "grad_norm": 2.5460402965545654,
      "learning_rate": 3.4285925925925926e-05,
      "loss": 0.1358,
      "step": 38590
    },
    {
      "epoch": 4.29,
      "grad_norm": 8.828392028808594,
      "learning_rate": 3.428444444444445e-05,
      "loss": 0.1638,
      "step": 38600
    },
    {
      "epoch": 4.29,
      "grad_norm": 5.296968936920166,
      "learning_rate": 3.4282962962962965e-05,
      "loss": 0.0736,
      "step": 38610
    },
    {
      "epoch": 4.29,
      "grad_norm": 3.772594451904297,
      "learning_rate": 3.428148148148149e-05,
      "loss": 0.1195,
      "step": 38620
    },
    {
      "epoch": 4.29,
      "grad_norm": 1.8415039777755737,
      "learning_rate": 3.4280000000000004e-05,
      "loss": 0.0688,
      "step": 38630
    },
    {
      "epoch": 4.29,
      "grad_norm": 8.562686920166016,
      "learning_rate": 3.427851851851852e-05,
      "loss": 0.1185,
      "step": 38640
    },
    {
      "epoch": 4.29,
      "grad_norm": 1.548802137374878,
      "learning_rate": 3.427703703703704e-05,
      "loss": 0.0744,
      "step": 38650
    },
    {
      "epoch": 4.3,
      "grad_norm": 2.2127256393432617,
      "learning_rate": 3.427555555555556e-05,
      "loss": 0.0738,
      "step": 38660
    },
    {
      "epoch": 4.3,
      "grad_norm": 2.6296334266662598,
      "learning_rate": 3.4274074074074075e-05,
      "loss": 0.0706,
      "step": 38670
    },
    {
      "epoch": 4.3,
      "grad_norm": 5.01693868637085,
      "learning_rate": 3.42725925925926e-05,
      "loss": 0.0685,
      "step": 38680
    },
    {
      "epoch": 4.3,
      "grad_norm": 3.6646575927734375,
      "learning_rate": 3.4271111111111114e-05,
      "loss": 0.0835,
      "step": 38690
    },
    {
      "epoch": 4.3,
      "grad_norm": 5.087342739105225,
      "learning_rate": 3.426962962962963e-05,
      "loss": 0.0724,
      "step": 38700
    },
    {
      "epoch": 4.3,
      "grad_norm": 2.638920307159424,
      "learning_rate": 3.426814814814815e-05,
      "loss": 0.065,
      "step": 38710
    },
    {
      "epoch": 4.3,
      "grad_norm": 6.045899391174316,
      "learning_rate": 3.426666666666667e-05,
      "loss": 0.0812,
      "step": 38720
    },
    {
      "epoch": 4.3,
      "grad_norm": 7.958293437957764,
      "learning_rate": 3.426518518518519e-05,
      "loss": 0.1084,
      "step": 38730
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.8117119073867798,
      "learning_rate": 3.426370370370371e-05,
      "loss": 0.0704,
      "step": 38740
    },
    {
      "epoch": 4.31,
      "grad_norm": 3.571383476257324,
      "learning_rate": 3.426222222222222e-05,
      "loss": 0.0724,
      "step": 38750
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.18186654150485992,
      "learning_rate": 3.4260740740740746e-05,
      "loss": 0.0501,
      "step": 38760
    },
    {
      "epoch": 4.31,
      "grad_norm": 3.300947904586792,
      "learning_rate": 3.425925925925926e-05,
      "loss": 0.0846,
      "step": 38770
    },
    {
      "epoch": 4.31,
      "grad_norm": 4.516732215881348,
      "learning_rate": 3.425777777777778e-05,
      "loss": 0.1149,
      "step": 38780
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.6458470225334167,
      "learning_rate": 3.42562962962963e-05,
      "loss": 0.0908,
      "step": 38790
    },
    {
      "epoch": 4.31,
      "grad_norm": 1.8802870512008667,
      "learning_rate": 3.425481481481482e-05,
      "loss": 0.0795,
      "step": 38800
    },
    {
      "epoch": 4.31,
      "grad_norm": 4.853740215301514,
      "learning_rate": 3.425333333333333e-05,
      "loss": 0.0709,
      "step": 38810
    },
    {
      "epoch": 4.31,
      "grad_norm": 7.263363361358643,
      "learning_rate": 3.4251851851851856e-05,
      "loss": 0.1136,
      "step": 38820
    },
    {
      "epoch": 4.31,
      "grad_norm": 1.4802683591842651,
      "learning_rate": 3.425037037037037e-05,
      "loss": 0.0815,
      "step": 38830
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.6122100353240967,
      "learning_rate": 3.4248888888888895e-05,
      "loss": 0.0335,
      "step": 38840
    },
    {
      "epoch": 4.32,
      "grad_norm": 4.3157267570495605,
      "learning_rate": 3.424740740740741e-05,
      "loss": 0.0436,
      "step": 38850
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.6441370844841003,
      "learning_rate": 3.4245925925925927e-05,
      "loss": 0.0924,
      "step": 38860
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.0660622119903564,
      "learning_rate": 3.424444444444445e-05,
      "loss": 0.0902,
      "step": 38870
    },
    {
      "epoch": 4.32,
      "grad_norm": 4.365388870239258,
      "learning_rate": 3.4242962962962965e-05,
      "loss": 0.0654,
      "step": 38880
    },
    {
      "epoch": 4.32,
      "grad_norm": 3.1633763313293457,
      "learning_rate": 3.424148148148148e-05,
      "loss": 0.1195,
      "step": 38890
    },
    {
      "epoch": 4.32,
      "grad_norm": 7.530106544494629,
      "learning_rate": 3.4240000000000004e-05,
      "loss": 0.1045,
      "step": 38900
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.304985761642456,
      "learning_rate": 3.423851851851852e-05,
      "loss": 0.0948,
      "step": 38910
    },
    {
      "epoch": 4.32,
      "grad_norm": 3.4632039070129395,
      "learning_rate": 3.423703703703704e-05,
      "loss": 0.0831,
      "step": 38920
    },
    {
      "epoch": 4.33,
      "grad_norm": 9.044598579406738,
      "learning_rate": 3.423555555555556e-05,
      "loss": 0.1099,
      "step": 38930
    },
    {
      "epoch": 4.33,
      "grad_norm": 3.1627354621887207,
      "learning_rate": 3.4234074074074075e-05,
      "loss": 0.1144,
      "step": 38940
    },
    {
      "epoch": 4.33,
      "grad_norm": 4.434257507324219,
      "learning_rate": 3.42325925925926e-05,
      "loss": 0.0492,
      "step": 38950
    },
    {
      "epoch": 4.33,
      "grad_norm": 12.039647102355957,
      "learning_rate": 3.4231111111111114e-05,
      "loss": 0.0602,
      "step": 38960
    },
    {
      "epoch": 4.33,
      "grad_norm": 4.173794746398926,
      "learning_rate": 3.422962962962963e-05,
      "loss": 0.0723,
      "step": 38970
    },
    {
      "epoch": 4.33,
      "grad_norm": 2.7817156314849854,
      "learning_rate": 3.422814814814815e-05,
      "loss": 0.0756,
      "step": 38980
    },
    {
      "epoch": 4.33,
      "grad_norm": 6.448019504547119,
      "learning_rate": 3.422666666666667e-05,
      "loss": 0.0925,
      "step": 38990
    },
    {
      "epoch": 4.33,
      "grad_norm": 1.4040776491165161,
      "learning_rate": 3.4225185185185185e-05,
      "loss": 0.0591,
      "step": 39000
    },
    {
      "epoch": 4.33,
      "grad_norm": 22.530372619628906,
      "learning_rate": 3.422370370370371e-05,
      "loss": 0.096,
      "step": 39010
    },
    {
      "epoch": 4.34,
      "grad_norm": 5.7161946296691895,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.0856,
      "step": 39020
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.9419713020324707,
      "learning_rate": 3.4220740740740746e-05,
      "loss": 0.0517,
      "step": 39030
    },
    {
      "epoch": 4.34,
      "grad_norm": 1.523228406906128,
      "learning_rate": 3.421925925925926e-05,
      "loss": 0.0492,
      "step": 39040
    },
    {
      "epoch": 4.34,
      "grad_norm": 6.3661885261535645,
      "learning_rate": 3.421777777777778e-05,
      "loss": 0.1116,
      "step": 39050
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.2583541870117188,
      "learning_rate": 3.42162962962963e-05,
      "loss": 0.0435,
      "step": 39060
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.5037569999694824,
      "learning_rate": 3.421481481481482e-05,
      "loss": 0.0654,
      "step": 39070
    },
    {
      "epoch": 4.34,
      "grad_norm": 4.53108024597168,
      "learning_rate": 3.421333333333333e-05,
      "loss": 0.0732,
      "step": 39080
    },
    {
      "epoch": 4.34,
      "grad_norm": 1.212430715560913,
      "learning_rate": 3.4211851851851856e-05,
      "loss": 0.0564,
      "step": 39090
    },
    {
      "epoch": 4.34,
      "grad_norm": 3.098184823989868,
      "learning_rate": 3.421037037037037e-05,
      "loss": 0.1106,
      "step": 39100
    },
    {
      "epoch": 4.35,
      "grad_norm": 2.9964046478271484,
      "learning_rate": 3.420888888888889e-05,
      "loss": 0.0432,
      "step": 39110
    },
    {
      "epoch": 4.35,
      "grad_norm": 1.3102127313613892,
      "learning_rate": 3.420740740740741e-05,
      "loss": 0.0355,
      "step": 39120
    },
    {
      "epoch": 4.35,
      "grad_norm": 4.588359355926514,
      "learning_rate": 3.420592592592593e-05,
      "loss": 0.065,
      "step": 39130
    },
    {
      "epoch": 4.35,
      "grad_norm": 5.708898067474365,
      "learning_rate": 3.420444444444445e-05,
      "loss": 0.0993,
      "step": 39140
    },
    {
      "epoch": 4.35,
      "grad_norm": 3.402346611022949,
      "learning_rate": 3.4202962962962966e-05,
      "loss": 0.0829,
      "step": 39150
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.8573051691055298,
      "learning_rate": 3.420148148148148e-05,
      "loss": 0.0751,
      "step": 39160
    },
    {
      "epoch": 4.35,
      "grad_norm": 1.461751103401184,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.0624,
      "step": 39170
    },
    {
      "epoch": 4.35,
      "grad_norm": 2.6754860877990723,
      "learning_rate": 3.419851851851852e-05,
      "loss": 0.0803,
      "step": 39180
    },
    {
      "epoch": 4.35,
      "grad_norm": 4.045355319976807,
      "learning_rate": 3.4197037037037043e-05,
      "loss": 0.1058,
      "step": 39190
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.7467242479324341,
      "learning_rate": 3.419555555555556e-05,
      "loss": 0.0844,
      "step": 39200
    },
    {
      "epoch": 4.36,
      "grad_norm": 4.362709999084473,
      "learning_rate": 3.4194074074074075e-05,
      "loss": 0.0273,
      "step": 39210
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.578473687171936,
      "learning_rate": 3.41925925925926e-05,
      "loss": 0.0834,
      "step": 39220
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.9445856809616089,
      "learning_rate": 3.4191111111111114e-05,
      "loss": 0.0384,
      "step": 39230
    },
    {
      "epoch": 4.36,
      "grad_norm": 11.479421615600586,
      "learning_rate": 3.418962962962963e-05,
      "loss": 0.0941,
      "step": 39240
    },
    {
      "epoch": 4.36,
      "grad_norm": 5.767307281494141,
      "learning_rate": 3.418814814814815e-05,
      "loss": 0.0631,
      "step": 39250
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.7445618510246277,
      "learning_rate": 3.418666666666667e-05,
      "loss": 0.0668,
      "step": 39260
    },
    {
      "epoch": 4.36,
      "grad_norm": 7.267444133758545,
      "learning_rate": 3.4185185185185185e-05,
      "loss": 0.0823,
      "step": 39270
    },
    {
      "epoch": 4.36,
      "grad_norm": 5.984036922454834,
      "learning_rate": 3.418370370370371e-05,
      "loss": 0.0675,
      "step": 39280
    },
    {
      "epoch": 4.37,
      "grad_norm": 2.9360873699188232,
      "learning_rate": 3.4182222222222224e-05,
      "loss": 0.0657,
      "step": 39290
    },
    {
      "epoch": 4.37,
      "grad_norm": 6.468185901641846,
      "learning_rate": 3.418074074074075e-05,
      "loss": 0.1127,
      "step": 39300
    },
    {
      "epoch": 4.37,
      "grad_norm": 2.102254629135132,
      "learning_rate": 3.417925925925926e-05,
      "loss": 0.0818,
      "step": 39310
    },
    {
      "epoch": 4.37,
      "grad_norm": 4.784058570861816,
      "learning_rate": 3.417777777777778e-05,
      "loss": 0.0709,
      "step": 39320
    },
    {
      "epoch": 4.37,
      "grad_norm": 2.2875285148620605,
      "learning_rate": 3.41762962962963e-05,
      "loss": 0.0891,
      "step": 39330
    },
    {
      "epoch": 4.37,
      "grad_norm": 7.477487087249756,
      "learning_rate": 3.417481481481482e-05,
      "loss": 0.0913,
      "step": 39340
    },
    {
      "epoch": 4.37,
      "grad_norm": 1.647816777229309,
      "learning_rate": 3.4173333333333334e-05,
      "loss": 0.0422,
      "step": 39350
    },
    {
      "epoch": 4.37,
      "grad_norm": 6.075915336608887,
      "learning_rate": 3.4171851851851856e-05,
      "loss": 0.0814,
      "step": 39360
    },
    {
      "epoch": 4.37,
      "grad_norm": 3.5142409801483154,
      "learning_rate": 3.417037037037037e-05,
      "loss": 0.1394,
      "step": 39370
    },
    {
      "epoch": 4.38,
      "grad_norm": 3.3911004066467285,
      "learning_rate": 3.416888888888889e-05,
      "loss": 0.0719,
      "step": 39380
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.947298526763916,
      "learning_rate": 3.416740740740741e-05,
      "loss": 0.0783,
      "step": 39390
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.3587613105773926,
      "learning_rate": 3.416592592592593e-05,
      "loss": 0.0647,
      "step": 39400
    },
    {
      "epoch": 4.38,
      "grad_norm": 3.9950501918792725,
      "learning_rate": 3.416444444444445e-05,
      "loss": 0.0734,
      "step": 39410
    },
    {
      "epoch": 4.38,
      "grad_norm": 3.8174798488616943,
      "learning_rate": 3.4162962962962966e-05,
      "loss": 0.0566,
      "step": 39420
    },
    {
      "epoch": 4.38,
      "grad_norm": 10.710909843444824,
      "learning_rate": 3.416148148148148e-05,
      "loss": 0.1076,
      "step": 39430
    },
    {
      "epoch": 4.38,
      "grad_norm": 6.175958633422852,
      "learning_rate": 3.4160000000000005e-05,
      "loss": 0.0841,
      "step": 39440
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.5736773014068604,
      "learning_rate": 3.415851851851852e-05,
      "loss": 0.0905,
      "step": 39450
    },
    {
      "epoch": 4.38,
      "grad_norm": 4.3384857177734375,
      "learning_rate": 3.4157037037037044e-05,
      "loss": 0.0591,
      "step": 39460
    },
    {
      "epoch": 4.39,
      "grad_norm": 5.149857521057129,
      "learning_rate": 3.415555555555556e-05,
      "loss": 0.068,
      "step": 39470
    },
    {
      "epoch": 4.39,
      "grad_norm": 4.615443229675293,
      "learning_rate": 3.4154074074074076e-05,
      "loss": 0.0588,
      "step": 39480
    },
    {
      "epoch": 4.39,
      "grad_norm": 3.0629539489746094,
      "learning_rate": 3.415259259259259e-05,
      "loss": 0.0745,
      "step": 39490
    },
    {
      "epoch": 4.39,
      "grad_norm": 2.763908863067627,
      "learning_rate": 3.4151111111111115e-05,
      "loss": 0.0983,
      "step": 39500
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.5777307152748108,
      "learning_rate": 3.414962962962963e-05,
      "loss": 0.0578,
      "step": 39510
    },
    {
      "epoch": 4.39,
      "grad_norm": 3.798038959503174,
      "learning_rate": 3.4148148148148153e-05,
      "loss": 0.0818,
      "step": 39520
    },
    {
      "epoch": 4.39,
      "grad_norm": 9.814682960510254,
      "learning_rate": 3.414666666666667e-05,
      "loss": 0.0933,
      "step": 39530
    },
    {
      "epoch": 4.39,
      "grad_norm": 3.5487961769104004,
      "learning_rate": 3.4145185185185186e-05,
      "loss": 0.1153,
      "step": 39540
    },
    {
      "epoch": 4.39,
      "grad_norm": 1.9312012195587158,
      "learning_rate": 3.414370370370371e-05,
      "loss": 0.0907,
      "step": 39550
    },
    {
      "epoch": 4.4,
      "grad_norm": 5.49130392074585,
      "learning_rate": 3.4142222222222224e-05,
      "loss": 0.0541,
      "step": 39560
    },
    {
      "epoch": 4.4,
      "grad_norm": 5.40796422958374,
      "learning_rate": 3.414074074074075e-05,
      "loss": 0.1487,
      "step": 39570
    },
    {
      "epoch": 4.4,
      "grad_norm": 3.6514294147491455,
      "learning_rate": 3.413925925925926e-05,
      "loss": 0.0609,
      "step": 39580
    },
    {
      "epoch": 4.4,
      "grad_norm": 3.956564426422119,
      "learning_rate": 3.413777777777778e-05,
      "loss": 0.0861,
      "step": 39590
    },
    {
      "epoch": 4.4,
      "grad_norm": 4.032271862030029,
      "learning_rate": 3.4136296296296295e-05,
      "loss": 0.0913,
      "step": 39600
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.6832163333892822,
      "learning_rate": 3.413481481481482e-05,
      "loss": 0.0857,
      "step": 39610
    },
    {
      "epoch": 4.4,
      "grad_norm": 4.548360347747803,
      "learning_rate": 3.413333333333334e-05,
      "loss": 0.0719,
      "step": 39620
    },
    {
      "epoch": 4.4,
      "grad_norm": 17.52791976928711,
      "learning_rate": 3.413185185185186e-05,
      "loss": 0.0441,
      "step": 39630
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.959216833114624,
      "learning_rate": 3.413037037037037e-05,
      "loss": 0.0638,
      "step": 39640
    },
    {
      "epoch": 4.41,
      "grad_norm": 3.2710678577423096,
      "learning_rate": 3.412888888888889e-05,
      "loss": 0.0512,
      "step": 39650
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.9062380194664001,
      "learning_rate": 3.412740740740741e-05,
      "loss": 0.1,
      "step": 39660
    },
    {
      "epoch": 4.41,
      "grad_norm": 2.8716936111450195,
      "learning_rate": 3.412592592592593e-05,
      "loss": 0.0899,
      "step": 39670
    },
    {
      "epoch": 4.41,
      "grad_norm": 5.867396354675293,
      "learning_rate": 3.412444444444445e-05,
      "loss": 0.0726,
      "step": 39680
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.7331448793411255,
      "learning_rate": 3.4122962962962967e-05,
      "loss": 0.0668,
      "step": 39690
    },
    {
      "epoch": 4.41,
      "grad_norm": 3.128664493560791,
      "learning_rate": 3.412148148148148e-05,
      "loss": 0.0996,
      "step": 39700
    },
    {
      "epoch": 4.41,
      "grad_norm": 4.555644989013672,
      "learning_rate": 3.4120000000000005e-05,
      "loss": 0.0733,
      "step": 39710
    },
    {
      "epoch": 4.41,
      "grad_norm": 2.1240198612213135,
      "learning_rate": 3.411851851851852e-05,
      "loss": 0.066,
      "step": 39720
    },
    {
      "epoch": 4.41,
      "grad_norm": 1.2187983989715576,
      "learning_rate": 3.4117037037037044e-05,
      "loss": 0.0549,
      "step": 39730
    },
    {
      "epoch": 4.42,
      "grad_norm": 4.049063205718994,
      "learning_rate": 3.411555555555556e-05,
      "loss": 0.083,
      "step": 39740
    },
    {
      "epoch": 4.42,
      "grad_norm": 4.042941093444824,
      "learning_rate": 3.4114074074074076e-05,
      "loss": 0.0666,
      "step": 39750
    },
    {
      "epoch": 4.42,
      "grad_norm": 4.731443881988525,
      "learning_rate": 3.411259259259259e-05,
      "loss": 0.0846,
      "step": 39760
    },
    {
      "epoch": 4.42,
      "grad_norm": 3.4018571376800537,
      "learning_rate": 3.4111111111111115e-05,
      "loss": 0.1116,
      "step": 39770
    },
    {
      "epoch": 4.42,
      "grad_norm": 3.291891098022461,
      "learning_rate": 3.410962962962963e-05,
      "loss": 0.0887,
      "step": 39780
    },
    {
      "epoch": 4.42,
      "grad_norm": 24.426542282104492,
      "learning_rate": 3.4108148148148154e-05,
      "loss": 0.0732,
      "step": 39790
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.734469413757324,
      "learning_rate": 3.410666666666667e-05,
      "loss": 0.1662,
      "step": 39800
    },
    {
      "epoch": 4.42,
      "grad_norm": 1.7197011709213257,
      "learning_rate": 3.4105185185185186e-05,
      "loss": 0.0709,
      "step": 39810
    },
    {
      "epoch": 4.42,
      "grad_norm": 1.3356459140777588,
      "learning_rate": 3.410370370370371e-05,
      "loss": 0.073,
      "step": 39820
    },
    {
      "epoch": 4.43,
      "grad_norm": 1.4219813346862793,
      "learning_rate": 3.4102222222222225e-05,
      "loss": 0.0772,
      "step": 39830
    },
    {
      "epoch": 4.43,
      "grad_norm": 1.379493236541748,
      "learning_rate": 3.410074074074075e-05,
      "loss": 0.0571,
      "step": 39840
    },
    {
      "epoch": 4.43,
      "grad_norm": 4.826963424682617,
      "learning_rate": 3.4099259259259264e-05,
      "loss": 0.0672,
      "step": 39850
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.7025226950645447,
      "learning_rate": 3.409777777777778e-05,
      "loss": 0.0761,
      "step": 39860
    },
    {
      "epoch": 4.43,
      "grad_norm": 2.5798416137695312,
      "learning_rate": 3.4096296296296296e-05,
      "loss": 0.1179,
      "step": 39870
    },
    {
      "epoch": 4.43,
      "grad_norm": 11.835823059082031,
      "learning_rate": 3.409481481481482e-05,
      "loss": 0.2,
      "step": 39880
    },
    {
      "epoch": 4.43,
      "grad_norm": 8.167604446411133,
      "learning_rate": 3.409333333333334e-05,
      "loss": 0.051,
      "step": 39890
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.4605901837348938,
      "learning_rate": 3.409185185185186e-05,
      "loss": 0.1127,
      "step": 39900
    },
    {
      "epoch": 4.43,
      "grad_norm": 1.94560968875885,
      "learning_rate": 3.409037037037037e-05,
      "loss": 0.1118,
      "step": 39910
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.703207492828369,
      "learning_rate": 3.408888888888889e-05,
      "loss": 0.0725,
      "step": 39920
    },
    {
      "epoch": 4.44,
      "grad_norm": 4.275900363922119,
      "learning_rate": 3.408740740740741e-05,
      "loss": 0.0845,
      "step": 39930
    },
    {
      "epoch": 4.44,
      "grad_norm": 6.763244152069092,
      "learning_rate": 3.408592592592593e-05,
      "loss": 0.0645,
      "step": 39940
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.424679756164551,
      "learning_rate": 3.408444444444445e-05,
      "loss": 0.0941,
      "step": 39950
    },
    {
      "epoch": 4.44,
      "grad_norm": 5.323887825012207,
      "learning_rate": 3.408296296296297e-05,
      "loss": 0.1204,
      "step": 39960
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.1400303840637207,
      "learning_rate": 3.408148148148148e-05,
      "loss": 0.07,
      "step": 39970
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.3881025314331055,
      "learning_rate": 3.408e-05,
      "loss": 0.0372,
      "step": 39980
    },
    {
      "epoch": 4.44,
      "grad_norm": 6.707710266113281,
      "learning_rate": 3.407851851851852e-05,
      "loss": 0.079,
      "step": 39990
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.9396862983703613,
      "learning_rate": 3.4077037037037045e-05,
      "loss": 0.0701,
      "step": 40000
    },
    {
      "epoch": 4.44,
      "eval_cer": 0.014881043886781083,
      "eval_loss": 0.17818088829517365,
      "eval_runtime": 1931.8578,
      "eval_samples_per_second": 4.141,
      "eval_steps_per_second": 0.518,
      "eval_wer": 0.03763440860215054,
      "step": 40000
    },
    {
      "epoch": 4.45,
      "grad_norm": 3.721642017364502,
      "learning_rate": 3.407555555555556e-05,
      "loss": 0.0774,
      "step": 40010
    },
    {
      "epoch": 4.45,
      "grad_norm": 6.11239767074585,
      "learning_rate": 3.4074074074074077e-05,
      "loss": 0.0799,
      "step": 40020
    },
    {
      "epoch": 4.45,
      "grad_norm": 1.0802953243255615,
      "learning_rate": 3.407259259259259e-05,
      "loss": 0.0747,
      "step": 40030
    },
    {
      "epoch": 4.45,
      "grad_norm": 1.9777642488479614,
      "learning_rate": 3.4071111111111115e-05,
      "loss": 0.0537,
      "step": 40040
    },
    {
      "epoch": 4.45,
      "grad_norm": 1.488938808441162,
      "learning_rate": 3.406962962962963e-05,
      "loss": 0.0943,
      "step": 40050
    },
    {
      "epoch": 4.45,
      "grad_norm": 2.932661294937134,
      "learning_rate": 3.4068148148148154e-05,
      "loss": 0.087,
      "step": 40060
    },
    {
      "epoch": 4.45,
      "grad_norm": 3.138575315475464,
      "learning_rate": 3.406666666666667e-05,
      "loss": 0.0528,
      "step": 40070
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.6786758303642273,
      "learning_rate": 3.4065185185185186e-05,
      "loss": 0.06,
      "step": 40080
    },
    {
      "epoch": 4.45,
      "grad_norm": 17.644323348999023,
      "learning_rate": 3.40637037037037e-05,
      "loss": 0.0399,
      "step": 40090
    },
    {
      "epoch": 4.46,
      "grad_norm": 3.8898491859436035,
      "learning_rate": 3.406251851851852e-05,
      "loss": 0.105,
      "step": 40100
    },
    {
      "epoch": 4.46,
      "grad_norm": 3.9408721923828125,
      "learning_rate": 3.4061037037037037e-05,
      "loss": 0.0575,
      "step": 40110
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.5362462997436523,
      "learning_rate": 3.405955555555556e-05,
      "loss": 0.1043,
      "step": 40120
    },
    {
      "epoch": 4.46,
      "grad_norm": 16.542390823364258,
      "learning_rate": 3.405807407407408e-05,
      "loss": 0.0816,
      "step": 40130
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.75211238861084,
      "learning_rate": 3.40565925925926e-05,
      "loss": 0.0609,
      "step": 40140
    },
    {
      "epoch": 4.46,
      "grad_norm": 3.7585525512695312,
      "learning_rate": 3.4055111111111114e-05,
      "loss": 0.1003,
      "step": 40150
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.87385892868042,
      "learning_rate": 3.405362962962963e-05,
      "loss": 0.0962,
      "step": 40160
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.8904433250427246,
      "learning_rate": 3.405214814814815e-05,
      "loss": 0.0499,
      "step": 40170
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.0108213424682617,
      "learning_rate": 3.405066666666667e-05,
      "loss": 0.0365,
      "step": 40180
    },
    {
      "epoch": 4.47,
      "grad_norm": 1.4714215993881226,
      "learning_rate": 3.404918518518519e-05,
      "loss": 0.0601,
      "step": 40190
    },
    {
      "epoch": 4.47,
      "grad_norm": 1.839767336845398,
      "learning_rate": 3.404770370370371e-05,
      "loss": 0.0767,
      "step": 40200
    },
    {
      "epoch": 4.47,
      "grad_norm": 5.891022682189941,
      "learning_rate": 3.4046222222222224e-05,
      "loss": 0.1133,
      "step": 40210
    },
    {
      "epoch": 4.47,
      "grad_norm": 2.2491278648376465,
      "learning_rate": 3.404474074074074e-05,
      "loss": 0.0795,
      "step": 40220
    },
    {
      "epoch": 4.47,
      "grad_norm": 1.6592841148376465,
      "learning_rate": 3.404325925925926e-05,
      "loss": 0.0488,
      "step": 40230
    },
    {
      "epoch": 4.47,
      "grad_norm": 2.397145986557007,
      "learning_rate": 3.4041777777777786e-05,
      "loss": 0.0571,
      "step": 40240
    },
    {
      "epoch": 4.47,
      "grad_norm": 10.419404029846191,
      "learning_rate": 3.40402962962963e-05,
      "loss": 0.0975,
      "step": 40250
    },
    {
      "epoch": 4.47,
      "grad_norm": 1.7121493816375732,
      "learning_rate": 3.403881481481482e-05,
      "loss": 0.0476,
      "step": 40260
    },
    {
      "epoch": 4.47,
      "grad_norm": 6.460731029510498,
      "learning_rate": 3.4037333333333334e-05,
      "loss": 0.1074,
      "step": 40270
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.4046908617019653,
      "learning_rate": 3.4035851851851856e-05,
      "loss": 0.0728,
      "step": 40280
    },
    {
      "epoch": 4.48,
      "grad_norm": 2.384800434112549,
      "learning_rate": 3.403437037037037e-05,
      "loss": 0.0696,
      "step": 40290
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.0449647903442383,
      "learning_rate": 3.4032888888888895e-05,
      "loss": 0.0924,
      "step": 40300
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.186429262161255,
      "learning_rate": 3.403140740740741e-05,
      "loss": 0.0356,
      "step": 40310
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.4688305854797363,
      "learning_rate": 3.402992592592593e-05,
      "loss": 0.0531,
      "step": 40320
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.3919081687927246,
      "learning_rate": 3.402844444444444e-05,
      "loss": 0.0664,
      "step": 40330
    },
    {
      "epoch": 4.48,
      "grad_norm": 4.423938751220703,
      "learning_rate": 3.4026962962962966e-05,
      "loss": 0.0715,
      "step": 40340
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.1826398372650146,
      "learning_rate": 3.402548148148149e-05,
      "loss": 0.0518,
      "step": 40350
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.9991573095321655,
      "learning_rate": 3.4024000000000005e-05,
      "loss": 0.0477,
      "step": 40360
    },
    {
      "epoch": 4.49,
      "grad_norm": 3.179342746734619,
      "learning_rate": 3.402251851851852e-05,
      "loss": 0.0407,
      "step": 40370
    },
    {
      "epoch": 4.49,
      "grad_norm": 5.027198314666748,
      "learning_rate": 3.402103703703704e-05,
      "loss": 0.0459,
      "step": 40380
    },
    {
      "epoch": 4.49,
      "grad_norm": 2.5914690494537354,
      "learning_rate": 3.401955555555556e-05,
      "loss": 0.0486,
      "step": 40390
    },
    {
      "epoch": 4.49,
      "grad_norm": 2.8762097358703613,
      "learning_rate": 3.4018074074074076e-05,
      "loss": 0.0815,
      "step": 40400
    },
    {
      "epoch": 4.49,
      "grad_norm": 3.5483956336975098,
      "learning_rate": 3.40165925925926e-05,
      "loss": 0.0866,
      "step": 40410
    },
    {
      "epoch": 4.49,
      "grad_norm": 6.8742995262146,
      "learning_rate": 3.4015111111111115e-05,
      "loss": 0.0748,
      "step": 40420
    },
    {
      "epoch": 4.49,
      "grad_norm": 2.3454513549804688,
      "learning_rate": 3.401362962962963e-05,
      "loss": 0.069,
      "step": 40430
    },
    {
      "epoch": 4.49,
      "grad_norm": 2.7039546966552734,
      "learning_rate": 3.401214814814815e-05,
      "loss": 0.0743,
      "step": 40440
    },
    {
      "epoch": 4.49,
      "grad_norm": 2.3233957290649414,
      "learning_rate": 3.401066666666667e-05,
      "loss": 0.0902,
      "step": 40450
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.732975721359253,
      "learning_rate": 3.400918518518519e-05,
      "loss": 0.1474,
      "step": 40460
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.9616639614105225,
      "learning_rate": 3.400770370370371e-05,
      "loss": 0.0527,
      "step": 40470
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.264620065689087,
      "learning_rate": 3.4006222222222224e-05,
      "loss": 0.078,
      "step": 40480
    },
    {
      "epoch": 4.5,
      "grad_norm": 6.855259895324707,
      "learning_rate": 3.400474074074074e-05,
      "loss": 0.1034,
      "step": 40490
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.8101770877838135,
      "learning_rate": 3.400325925925926e-05,
      "loss": 0.0614,
      "step": 40500
    },
    {
      "epoch": 4.5,
      "grad_norm": 6.214545249938965,
      "learning_rate": 3.400177777777778e-05,
      "loss": 0.0895,
      "step": 40510
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.473661184310913,
      "learning_rate": 3.40002962962963e-05,
      "loss": 0.0765,
      "step": 40520
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.1928168535232544,
      "learning_rate": 3.399881481481482e-05,
      "loss": 0.0807,
      "step": 40530
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.6393952369689941,
      "learning_rate": 3.3997333333333334e-05,
      "loss": 0.0501,
      "step": 40540
    },
    {
      "epoch": 4.51,
      "grad_norm": 3.410524845123291,
      "learning_rate": 3.399585185185185e-05,
      "loss": 0.0591,
      "step": 40550
    },
    {
      "epoch": 4.51,
      "grad_norm": 3.1672322750091553,
      "learning_rate": 3.399437037037037e-05,
      "loss": 0.0759,
      "step": 40560
    },
    {
      "epoch": 4.51,
      "grad_norm": 4.250060558319092,
      "learning_rate": 3.3992888888888896e-05,
      "loss": 0.064,
      "step": 40570
    },
    {
      "epoch": 4.51,
      "grad_norm": 3.1103434562683105,
      "learning_rate": 3.399140740740741e-05,
      "loss": 0.0642,
      "step": 40580
    },
    {
      "epoch": 4.51,
      "grad_norm": 3.5822532176971436,
      "learning_rate": 3.398992592592593e-05,
      "loss": 0.0652,
      "step": 40590
    },
    {
      "epoch": 4.51,
      "grad_norm": 1.0358961820602417,
      "learning_rate": 3.3988444444444444e-05,
      "loss": 0.1056,
      "step": 40600
    },
    {
      "epoch": 4.51,
      "grad_norm": 5.869477272033691,
      "learning_rate": 3.3986962962962966e-05,
      "loss": 0.053,
      "step": 40610
    },
    {
      "epoch": 4.51,
      "grad_norm": 2.1943130493164062,
      "learning_rate": 3.398548148148149e-05,
      "loss": 0.0559,
      "step": 40620
    },
    {
      "epoch": 4.51,
      "grad_norm": 1.637150764465332,
      "learning_rate": 3.3984000000000005e-05,
      "loss": 0.0574,
      "step": 40630
    },
    {
      "epoch": 4.52,
      "grad_norm": 3.4708621501922607,
      "learning_rate": 3.398251851851852e-05,
      "loss": 0.0529,
      "step": 40640
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.0974509716033936,
      "learning_rate": 3.398103703703704e-05,
      "loss": 0.0596,
      "step": 40650
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.61284339427948,
      "learning_rate": 3.397955555555555e-05,
      "loss": 0.0617,
      "step": 40660
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.7241703867912292,
      "learning_rate": 3.3978074074074076e-05,
      "loss": 0.0377,
      "step": 40670
    },
    {
      "epoch": 4.52,
      "grad_norm": 2.1003870964050293,
      "learning_rate": 3.39765925925926e-05,
      "loss": 0.0868,
      "step": 40680
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.7214224338531494,
      "learning_rate": 3.3975111111111115e-05,
      "loss": 0.0692,
      "step": 40690
    },
    {
      "epoch": 4.52,
      "grad_norm": 8.75354290008545,
      "learning_rate": 3.397362962962963e-05,
      "loss": 0.0701,
      "step": 40700
    },
    {
      "epoch": 4.52,
      "grad_norm": 2.6414172649383545,
      "learning_rate": 3.397214814814815e-05,
      "loss": 0.0607,
      "step": 40710
    },
    {
      "epoch": 4.52,
      "grad_norm": 7.9206342697143555,
      "learning_rate": 3.397066666666667e-05,
      "loss": 0.097,
      "step": 40720
    },
    {
      "epoch": 4.53,
      "grad_norm": 2.439615488052368,
      "learning_rate": 3.396918518518519e-05,
      "loss": 0.0826,
      "step": 40730
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.5429800748825073,
      "learning_rate": 3.396770370370371e-05,
      "loss": 0.0823,
      "step": 40740
    },
    {
      "epoch": 4.53,
      "grad_norm": 2.544154167175293,
      "learning_rate": 3.3966222222222225e-05,
      "loss": 0.0336,
      "step": 40750
    },
    {
      "epoch": 4.53,
      "grad_norm": 3.325634717941284,
      "learning_rate": 3.396474074074074e-05,
      "loss": 0.093,
      "step": 40760
    },
    {
      "epoch": 4.53,
      "grad_norm": 2.9874038696289062,
      "learning_rate": 3.3963259259259264e-05,
      "loss": 0.0788,
      "step": 40770
    },
    {
      "epoch": 4.53,
      "grad_norm": 3.599513053894043,
      "learning_rate": 3.396177777777778e-05,
      "loss": 0.1069,
      "step": 40780
    },
    {
      "epoch": 4.53,
      "grad_norm": 3.817092180252075,
      "learning_rate": 3.39602962962963e-05,
      "loss": 0.0363,
      "step": 40790
    },
    {
      "epoch": 4.53,
      "grad_norm": 5.725604057312012,
      "learning_rate": 3.395881481481482e-05,
      "loss": 0.052,
      "step": 40800
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.6676756143569946,
      "learning_rate": 3.3957333333333334e-05,
      "loss": 0.079,
      "step": 40810
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.8357269763946533,
      "learning_rate": 3.395585185185185e-05,
      "loss": 0.0743,
      "step": 40820
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.5740890502929688,
      "learning_rate": 3.395437037037037e-05,
      "loss": 0.0646,
      "step": 40830
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.8043339252471924,
      "learning_rate": 3.3952888888888896e-05,
      "loss": 0.0635,
      "step": 40840
    },
    {
      "epoch": 4.54,
      "grad_norm": 3.598010540008545,
      "learning_rate": 3.395140740740741e-05,
      "loss": 0.0766,
      "step": 40850
    },
    {
      "epoch": 4.54,
      "grad_norm": 1.88265860080719,
      "learning_rate": 3.394992592592593e-05,
      "loss": 0.0346,
      "step": 40860
    },
    {
      "epoch": 4.54,
      "grad_norm": 4.275219440460205,
      "learning_rate": 3.3948444444444444e-05,
      "loss": 0.0846,
      "step": 40870
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.3087165355682373,
      "learning_rate": 3.394696296296297e-05,
      "loss": 0.0926,
      "step": 40880
    },
    {
      "epoch": 4.54,
      "grad_norm": 6.379135608673096,
      "learning_rate": 3.394548148148148e-05,
      "loss": 0.0925,
      "step": 40890
    },
    {
      "epoch": 4.54,
      "grad_norm": 3.7011241912841797,
      "learning_rate": 3.3944000000000006e-05,
      "loss": 0.0915,
      "step": 40900
    },
    {
      "epoch": 4.55,
      "grad_norm": 2.9163639545440674,
      "learning_rate": 3.394251851851852e-05,
      "loss": 0.0532,
      "step": 40910
    },
    {
      "epoch": 4.55,
      "grad_norm": 3.966285228729248,
      "learning_rate": 3.394103703703704e-05,
      "loss": 0.0951,
      "step": 40920
    },
    {
      "epoch": 4.55,
      "grad_norm": 2.475257396697998,
      "learning_rate": 3.3939555555555554e-05,
      "loss": 0.0754,
      "step": 40930
    },
    {
      "epoch": 4.55,
      "grad_norm": 8.543126106262207,
      "learning_rate": 3.3938074074074077e-05,
      "loss": 0.0835,
      "step": 40940
    },
    {
      "epoch": 4.55,
      "grad_norm": 18.311912536621094,
      "learning_rate": 3.39365925925926e-05,
      "loss": 0.0758,
      "step": 40950
    },
    {
      "epoch": 4.55,
      "grad_norm": 13.55013656616211,
      "learning_rate": 3.3935111111111115e-05,
      "loss": 0.0576,
      "step": 40960
    },
    {
      "epoch": 4.55,
      "grad_norm": 2.656569004058838,
      "learning_rate": 3.393362962962963e-05,
      "loss": 0.0862,
      "step": 40970
    },
    {
      "epoch": 4.55,
      "grad_norm": 3.0337953567504883,
      "learning_rate": 3.393214814814815e-05,
      "loss": 0.0678,
      "step": 40980
    },
    {
      "epoch": 4.55,
      "grad_norm": 3.973144054412842,
      "learning_rate": 3.393066666666667e-05,
      "loss": 0.0818,
      "step": 40990
    },
    {
      "epoch": 4.56,
      "grad_norm": 7.729520320892334,
      "learning_rate": 3.3929185185185186e-05,
      "loss": 0.1223,
      "step": 41000
    },
    {
      "epoch": 4.56,
      "grad_norm": 3.3492660522460938,
      "learning_rate": 3.392770370370371e-05,
      "loss": 0.0695,
      "step": 41010
    },
    {
      "epoch": 4.56,
      "grad_norm": 2.0875144004821777,
      "learning_rate": 3.3926222222222225e-05,
      "loss": 0.0492,
      "step": 41020
    },
    {
      "epoch": 4.56,
      "grad_norm": 4.823132038116455,
      "learning_rate": 3.392474074074074e-05,
      "loss": 0.0656,
      "step": 41030
    },
    {
      "epoch": 4.56,
      "grad_norm": 7.950719833374023,
      "learning_rate": 3.392325925925926e-05,
      "loss": 0.0851,
      "step": 41040
    },
    {
      "epoch": 4.56,
      "grad_norm": 5.347289085388184,
      "learning_rate": 3.392177777777778e-05,
      "loss": 0.0825,
      "step": 41050
    },
    {
      "epoch": 4.56,
      "grad_norm": 4.460666179656982,
      "learning_rate": 3.39202962962963e-05,
      "loss": 0.0817,
      "step": 41060
    },
    {
      "epoch": 4.56,
      "grad_norm": 12.735978126525879,
      "learning_rate": 3.391881481481482e-05,
      "loss": 0.1056,
      "step": 41070
    },
    {
      "epoch": 4.56,
      "grad_norm": 1.7939739227294922,
      "learning_rate": 3.3917333333333335e-05,
      "loss": 0.1044,
      "step": 41080
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.9104591608047485,
      "learning_rate": 3.391585185185185e-05,
      "loss": 0.0377,
      "step": 41090
    },
    {
      "epoch": 4.57,
      "grad_norm": 4.40938663482666,
      "learning_rate": 3.3914370370370374e-05,
      "loss": 0.0434,
      "step": 41100
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.634890079498291,
      "learning_rate": 3.391288888888889e-05,
      "loss": 0.0361,
      "step": 41110
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.8538644313812256,
      "learning_rate": 3.391140740740741e-05,
      "loss": 0.0596,
      "step": 41120
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.680445671081543,
      "learning_rate": 3.390992592592593e-05,
      "loss": 0.097,
      "step": 41130
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.9600512981414795,
      "learning_rate": 3.3908444444444444e-05,
      "loss": 0.0585,
      "step": 41140
    },
    {
      "epoch": 4.57,
      "grad_norm": 6.726297378540039,
      "learning_rate": 3.390696296296296e-05,
      "loss": 0.1174,
      "step": 41150
    },
    {
      "epoch": 4.57,
      "grad_norm": 3.935793161392212,
      "learning_rate": 3.390548148148148e-05,
      "loss": 0.0883,
      "step": 41160
    },
    {
      "epoch": 4.57,
      "grad_norm": 3.1844074726104736,
      "learning_rate": 3.3904000000000006e-05,
      "loss": 0.1378,
      "step": 41170
    },
    {
      "epoch": 4.58,
      "grad_norm": 3.0193676948547363,
      "learning_rate": 3.390251851851852e-05,
      "loss": 0.0391,
      "step": 41180
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.43727970123291,
      "learning_rate": 3.390103703703704e-05,
      "loss": 0.0438,
      "step": 41190
    },
    {
      "epoch": 4.58,
      "grad_norm": 4.345363140106201,
      "learning_rate": 3.3899555555555554e-05,
      "loss": 0.0513,
      "step": 41200
    },
    {
      "epoch": 4.58,
      "grad_norm": 4.267477035522461,
      "learning_rate": 3.389807407407408e-05,
      "loss": 0.0957,
      "step": 41210
    },
    {
      "epoch": 4.58,
      "grad_norm": 5.1858134269714355,
      "learning_rate": 3.38965925925926e-05,
      "loss": 0.0741,
      "step": 41220
    },
    {
      "epoch": 4.58,
      "grad_norm": 3.447176456451416,
      "learning_rate": 3.3895111111111116e-05,
      "loss": 0.0803,
      "step": 41230
    },
    {
      "epoch": 4.58,
      "grad_norm": 8.493871688842773,
      "learning_rate": 3.389362962962963e-05,
      "loss": 0.0743,
      "step": 41240
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.214182138442993,
      "learning_rate": 3.389214814814815e-05,
      "loss": 0.07,
      "step": 41250
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.1314730644226074,
      "learning_rate": 3.389066666666667e-05,
      "loss": 0.0712,
      "step": 41260
    },
    {
      "epoch": 4.59,
      "grad_norm": 4.559423923492432,
      "learning_rate": 3.388918518518519e-05,
      "loss": 0.0453,
      "step": 41270
    },
    {
      "epoch": 4.59,
      "grad_norm": 3.6907155513763428,
      "learning_rate": 3.388770370370371e-05,
      "loss": 0.0858,
      "step": 41280
    },
    {
      "epoch": 4.59,
      "grad_norm": 4.242140293121338,
      "learning_rate": 3.3886222222222225e-05,
      "loss": 0.048,
      "step": 41290
    },
    {
      "epoch": 4.59,
      "grad_norm": 5.075408935546875,
      "learning_rate": 3.388474074074074e-05,
      "loss": 0.0959,
      "step": 41300
    },
    {
      "epoch": 4.59,
      "grad_norm": 2.411461353302002,
      "learning_rate": 3.388325925925926e-05,
      "loss": 0.0782,
      "step": 41310
    },
    {
      "epoch": 4.59,
      "grad_norm": 3.3612442016601562,
      "learning_rate": 3.388177777777778e-05,
      "loss": 0.0694,
      "step": 41320
    },
    {
      "epoch": 4.59,
      "grad_norm": 7.127426624298096,
      "learning_rate": 3.38802962962963e-05,
      "loss": 0.0732,
      "step": 41330
    },
    {
      "epoch": 4.59,
      "grad_norm": 2.383890151977539,
      "learning_rate": 3.387881481481482e-05,
      "loss": 0.1226,
      "step": 41340
    },
    {
      "epoch": 4.59,
      "grad_norm": 4.061460018157959,
      "learning_rate": 3.3877333333333335e-05,
      "loss": 0.1058,
      "step": 41350
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.03259539604187,
      "learning_rate": 3.387585185185185e-05,
      "loss": 0.0453,
      "step": 41360
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.4497397243976593,
      "learning_rate": 3.3874370370370374e-05,
      "loss": 0.0489,
      "step": 41370
    },
    {
      "epoch": 4.6,
      "grad_norm": 1.3079043626785278,
      "learning_rate": 3.387288888888889e-05,
      "loss": 0.0652,
      "step": 41380
    },
    {
      "epoch": 4.6,
      "grad_norm": 4.05423641204834,
      "learning_rate": 3.387140740740741e-05,
      "loss": 0.0864,
      "step": 41390
    },
    {
      "epoch": 4.6,
      "grad_norm": 3.3642311096191406,
      "learning_rate": 3.3870074074074077e-05,
      "loss": 0.0898,
      "step": 41400
    },
    {
      "epoch": 4.6,
      "grad_norm": 3.169196367263794,
      "learning_rate": 3.386859259259259e-05,
      "loss": 0.0536,
      "step": 41410
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.56947922706604,
      "learning_rate": 3.3867111111111115e-05,
      "loss": 0.0597,
      "step": 41420
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.8799378871917725,
      "learning_rate": 3.386562962962963e-05,
      "loss": 0.0831,
      "step": 41430
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.2249526977539062,
      "learning_rate": 3.3864148148148154e-05,
      "loss": 0.0628,
      "step": 41440
    },
    {
      "epoch": 4.61,
      "grad_norm": 1.0509889125823975,
      "learning_rate": 3.386266666666667e-05,
      "loss": 0.0545,
      "step": 41450
    },
    {
      "epoch": 4.61,
      "grad_norm": 3.2739884853363037,
      "learning_rate": 3.3861185185185186e-05,
      "loss": 0.0759,
      "step": 41460
    },
    {
      "epoch": 4.61,
      "grad_norm": 7.581596374511719,
      "learning_rate": 3.385970370370371e-05,
      "loss": 0.0532,
      "step": 41470
    },
    {
      "epoch": 4.61,
      "grad_norm": 6.650616645812988,
      "learning_rate": 3.3858222222222225e-05,
      "loss": 0.0721,
      "step": 41480
    },
    {
      "epoch": 4.61,
      "grad_norm": 1.9588098526000977,
      "learning_rate": 3.385674074074075e-05,
      "loss": 0.0524,
      "step": 41490
    },
    {
      "epoch": 4.61,
      "grad_norm": 4.609376907348633,
      "learning_rate": 3.3855259259259264e-05,
      "loss": 0.0664,
      "step": 41500
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.2553658187389374,
      "learning_rate": 3.385377777777778e-05,
      "loss": 0.0643,
      "step": 41510
    },
    {
      "epoch": 4.61,
      "grad_norm": 6.736942768096924,
      "learning_rate": 3.3852296296296296e-05,
      "loss": 0.0911,
      "step": 41520
    },
    {
      "epoch": 4.61,
      "grad_norm": 4.182652473449707,
      "learning_rate": 3.385081481481482e-05,
      "loss": 0.1107,
      "step": 41530
    },
    {
      "epoch": 4.62,
      "grad_norm": 2.882171869277954,
      "learning_rate": 3.3849333333333335e-05,
      "loss": 0.0641,
      "step": 41540
    },
    {
      "epoch": 4.62,
      "grad_norm": 4.715262413024902,
      "learning_rate": 3.384785185185186e-05,
      "loss": 0.0875,
      "step": 41550
    },
    {
      "epoch": 4.62,
      "grad_norm": 3.1512179374694824,
      "learning_rate": 3.3846370370370374e-05,
      "loss": 0.0596,
      "step": 41560
    },
    {
      "epoch": 4.62,
      "grad_norm": 3.198746919631958,
      "learning_rate": 3.384488888888889e-05,
      "loss": 0.0888,
      "step": 41570
    },
    {
      "epoch": 4.62,
      "grad_norm": 2.1317801475524902,
      "learning_rate": 3.384340740740741e-05,
      "loss": 0.0509,
      "step": 41580
    },
    {
      "epoch": 4.62,
      "grad_norm": 1.8177953958511353,
      "learning_rate": 3.384192592592593e-05,
      "loss": 0.0618,
      "step": 41590
    },
    {
      "epoch": 4.62,
      "grad_norm": 4.590898036956787,
      "learning_rate": 3.384044444444445e-05,
      "loss": 0.0933,
      "step": 41600
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.3991924226284027,
      "learning_rate": 3.383896296296297e-05,
      "loss": 0.05,
      "step": 41610
    },
    {
      "epoch": 4.62,
      "grad_norm": 3.8547825813293457,
      "learning_rate": 3.383748148148148e-05,
      "loss": 0.097,
      "step": 41620
    },
    {
      "epoch": 4.63,
      "grad_norm": 2.267507791519165,
      "learning_rate": 3.3836e-05,
      "loss": 0.058,
      "step": 41630
    },
    {
      "epoch": 4.63,
      "grad_norm": 2.433835744857788,
      "learning_rate": 3.383451851851852e-05,
      "loss": 0.0317,
      "step": 41640
    },
    {
      "epoch": 4.63,
      "grad_norm": 1.2219629287719727,
      "learning_rate": 3.3833037037037045e-05,
      "loss": 0.0401,
      "step": 41650
    },
    {
      "epoch": 4.63,
      "grad_norm": 1.7135982513427734,
      "learning_rate": 3.383155555555556e-05,
      "loss": 0.0614,
      "step": 41660
    },
    {
      "epoch": 4.63,
      "grad_norm": 4.671035289764404,
      "learning_rate": 3.383007407407408e-05,
      "loss": 0.0778,
      "step": 41670
    },
    {
      "epoch": 4.63,
      "grad_norm": 8.707383155822754,
      "learning_rate": 3.382859259259259e-05,
      "loss": 0.0524,
      "step": 41680
    },
    {
      "epoch": 4.63,
      "grad_norm": 2.6185731887817383,
      "learning_rate": 3.3827111111111116e-05,
      "loss": 0.0572,
      "step": 41690
    },
    {
      "epoch": 4.63,
      "grad_norm": 2.1513772010803223,
      "learning_rate": 3.382562962962963e-05,
      "loss": 0.0773,
      "step": 41700
    },
    {
      "epoch": 4.63,
      "grad_norm": 3.062786102294922,
      "learning_rate": 3.3824148148148155e-05,
      "loss": 0.1176,
      "step": 41710
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.9933052659034729,
      "learning_rate": 3.382266666666667e-05,
      "loss": 0.1187,
      "step": 41720
    },
    {
      "epoch": 4.64,
      "grad_norm": 4.279785633087158,
      "learning_rate": 3.3821185185185187e-05,
      "loss": 0.0644,
      "step": 41730
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.6835407614707947,
      "learning_rate": 3.38197037037037e-05,
      "loss": 0.0523,
      "step": 41740
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.8610622882843018,
      "learning_rate": 3.3818222222222225e-05,
      "loss": 0.1066,
      "step": 41750
    },
    {
      "epoch": 4.64,
      "grad_norm": 6.678393363952637,
      "learning_rate": 3.381674074074075e-05,
      "loss": 0.035,
      "step": 41760
    },
    {
      "epoch": 4.64,
      "grad_norm": 7.222301483154297,
      "learning_rate": 3.3815259259259264e-05,
      "loss": 0.1368,
      "step": 41770
    },
    {
      "epoch": 4.64,
      "grad_norm": 9.658738136291504,
      "learning_rate": 3.381377777777778e-05,
      "loss": 0.067,
      "step": 41780
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.329603910446167,
      "learning_rate": 3.3812296296296296e-05,
      "loss": 0.0675,
      "step": 41790
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.1380386352539062,
      "learning_rate": 3.381081481481482e-05,
      "loss": 0.0514,
      "step": 41800
    },
    {
      "epoch": 4.65,
      "grad_norm": 2.5867066383361816,
      "learning_rate": 3.3809333333333335e-05,
      "loss": 0.0709,
      "step": 41810
    },
    {
      "epoch": 4.65,
      "grad_norm": 6.757940769195557,
      "learning_rate": 3.380785185185186e-05,
      "loss": 0.072,
      "step": 41820
    },
    {
      "epoch": 4.65,
      "grad_norm": 4.535849094390869,
      "learning_rate": 3.3806370370370374e-05,
      "loss": 0.0996,
      "step": 41830
    },
    {
      "epoch": 4.65,
      "grad_norm": 34.51969909667969,
      "learning_rate": 3.380488888888889e-05,
      "loss": 0.0483,
      "step": 41840
    },
    {
      "epoch": 4.65,
      "grad_norm": 13.344138145446777,
      "learning_rate": 3.3803407407407406e-05,
      "loss": 0.0657,
      "step": 41850
    },
    {
      "epoch": 4.65,
      "grad_norm": 5.129302978515625,
      "learning_rate": 3.380192592592593e-05,
      "loss": 0.0959,
      "step": 41860
    },
    {
      "epoch": 4.65,
      "grad_norm": 3.2087714672088623,
      "learning_rate": 3.380044444444445e-05,
      "loss": 0.096,
      "step": 41870
    },
    {
      "epoch": 4.65,
      "grad_norm": 13.056631088256836,
      "learning_rate": 3.379896296296297e-05,
      "loss": 0.0573,
      "step": 41880
    },
    {
      "epoch": 4.65,
      "grad_norm": 3.1095149517059326,
      "learning_rate": 3.3797481481481484e-05,
      "loss": 0.1336,
      "step": 41890
    },
    {
      "epoch": 4.66,
      "grad_norm": 4.088332653045654,
      "learning_rate": 3.3796e-05,
      "loss": 0.0523,
      "step": 41900
    },
    {
      "epoch": 4.66,
      "grad_norm": 6.099287509918213,
      "learning_rate": 3.379451851851852e-05,
      "loss": 0.0885,
      "step": 41910
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.652071714401245,
      "learning_rate": 3.3793037037037045e-05,
      "loss": 0.0547,
      "step": 41920
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.1213455200195312,
      "learning_rate": 3.379155555555556e-05,
      "loss": 0.0612,
      "step": 41930
    },
    {
      "epoch": 4.66,
      "grad_norm": 4.010937213897705,
      "learning_rate": 3.379007407407408e-05,
      "loss": 0.0745,
      "step": 41940
    },
    {
      "epoch": 4.66,
      "grad_norm": 5.361849784851074,
      "learning_rate": 3.378859259259259e-05,
      "loss": 0.0657,
      "step": 41950
    },
    {
      "epoch": 4.66,
      "grad_norm": 3.5237982273101807,
      "learning_rate": 3.3787111111111116e-05,
      "loss": 0.0751,
      "step": 41960
    },
    {
      "epoch": 4.66,
      "grad_norm": 6.432455062866211,
      "learning_rate": 3.378562962962963e-05,
      "loss": 0.1424,
      "step": 41970
    },
    {
      "epoch": 4.66,
      "grad_norm": 3.0950982570648193,
      "learning_rate": 3.3784148148148155e-05,
      "loss": 0.0514,
      "step": 41980
    },
    {
      "epoch": 4.67,
      "grad_norm": 4.661796569824219,
      "learning_rate": 3.378266666666667e-05,
      "loss": 0.0704,
      "step": 41990
    },
    {
      "epoch": 4.67,
      "grad_norm": 2.5136091709136963,
      "learning_rate": 3.378118518518519e-05,
      "loss": 0.0643,
      "step": 42000
    },
    {
      "epoch": 4.67,
      "grad_norm": 2.600841999053955,
      "learning_rate": 3.37797037037037e-05,
      "loss": 0.0678,
      "step": 42010
    },
    {
      "epoch": 4.67,
      "grad_norm": 5.991963863372803,
      "learning_rate": 3.3778222222222226e-05,
      "loss": 0.0842,
      "step": 42020
    },
    {
      "epoch": 4.67,
      "grad_norm": 2.7164175510406494,
      "learning_rate": 3.377674074074075e-05,
      "loss": 0.042,
      "step": 42030
    },
    {
      "epoch": 4.67,
      "grad_norm": 6.099792003631592,
      "learning_rate": 3.3775259259259265e-05,
      "loss": 0.0689,
      "step": 42040
    },
    {
      "epoch": 4.67,
      "grad_norm": 1.8908332586288452,
      "learning_rate": 3.377377777777778e-05,
      "loss": 0.074,
      "step": 42050
    },
    {
      "epoch": 4.67,
      "grad_norm": 8.736241340637207,
      "learning_rate": 3.37722962962963e-05,
      "loss": 0.0672,
      "step": 42060
    },
    {
      "epoch": 4.67,
      "grad_norm": 4.870484352111816,
      "learning_rate": 3.377081481481482e-05,
      "loss": 0.069,
      "step": 42070
    },
    {
      "epoch": 4.68,
      "grad_norm": 2.8395771980285645,
      "learning_rate": 3.3769333333333335e-05,
      "loss": 0.0785,
      "step": 42080
    },
    {
      "epoch": 4.68,
      "grad_norm": 5.067650318145752,
      "learning_rate": 3.376785185185186e-05,
      "loss": 0.0493,
      "step": 42090
    },
    {
      "epoch": 4.68,
      "grad_norm": 6.177677154541016,
      "learning_rate": 3.3766370370370374e-05,
      "loss": 0.06,
      "step": 42100
    },
    {
      "epoch": 4.68,
      "grad_norm": 6.973058700561523,
      "learning_rate": 3.376488888888889e-05,
      "loss": 0.0639,
      "step": 42110
    },
    {
      "epoch": 4.68,
      "grad_norm": 10.801713943481445,
      "learning_rate": 3.3763407407407406e-05,
      "loss": 0.0612,
      "step": 42120
    },
    {
      "epoch": 4.68,
      "grad_norm": 6.793081283569336,
      "learning_rate": 3.376192592592593e-05,
      "loss": 0.066,
      "step": 42130
    },
    {
      "epoch": 4.68,
      "grad_norm": 3.270559072494507,
      "learning_rate": 3.376044444444445e-05,
      "loss": 0.059,
      "step": 42140
    },
    {
      "epoch": 4.68,
      "grad_norm": 11.604242324829102,
      "learning_rate": 3.375896296296297e-05,
      "loss": 0.0588,
      "step": 42150
    },
    {
      "epoch": 4.68,
      "grad_norm": 1.0556565523147583,
      "learning_rate": 3.3757481481481484e-05,
      "loss": 0.0655,
      "step": 42160
    },
    {
      "epoch": 4.69,
      "grad_norm": 4.242036819458008,
      "learning_rate": 3.3756e-05,
      "loss": 0.0549,
      "step": 42170
    },
    {
      "epoch": 4.69,
      "grad_norm": 1.420620322227478,
      "learning_rate": 3.375451851851852e-05,
      "loss": 0.0678,
      "step": 42180
    },
    {
      "epoch": 4.69,
      "grad_norm": 15.606534004211426,
      "learning_rate": 3.375303703703704e-05,
      "loss": 0.0518,
      "step": 42190
    },
    {
      "epoch": 4.69,
      "grad_norm": 2.4775328636169434,
      "learning_rate": 3.375155555555556e-05,
      "loss": 0.1094,
      "step": 42200
    },
    {
      "epoch": 4.69,
      "grad_norm": 1.8694283962249756,
      "learning_rate": 3.375007407407408e-05,
      "loss": 0.0558,
      "step": 42210
    },
    {
      "epoch": 4.69,
      "grad_norm": 5.460415840148926,
      "learning_rate": 3.3748592592592594e-05,
      "loss": 0.069,
      "step": 42220
    },
    {
      "epoch": 4.69,
      "grad_norm": 2.2280795574188232,
      "learning_rate": 3.374711111111111e-05,
      "loss": 0.0527,
      "step": 42230
    },
    {
      "epoch": 4.69,
      "grad_norm": 7.787528991699219,
      "learning_rate": 3.374562962962963e-05,
      "loss": 0.0887,
      "step": 42240
    },
    {
      "epoch": 4.69,
      "grad_norm": 1.788337230682373,
      "learning_rate": 3.3744148148148155e-05,
      "loss": 0.0733,
      "step": 42250
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.6552844047546387,
      "learning_rate": 3.374266666666667e-05,
      "loss": 0.0686,
      "step": 42260
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.7042841911315918,
      "learning_rate": 3.374118518518519e-05,
      "loss": 0.0727,
      "step": 42270
    },
    {
      "epoch": 4.7,
      "grad_norm": 4.290401458740234,
      "learning_rate": 3.3739703703703703e-05,
      "loss": 0.1288,
      "step": 42280
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.4807151556015015,
      "learning_rate": 3.3738222222222226e-05,
      "loss": 0.0866,
      "step": 42290
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.5642050504684448,
      "learning_rate": 3.373674074074074e-05,
      "loss": 0.115,
      "step": 42300
    },
    {
      "epoch": 4.7,
      "grad_norm": 3.0233893394470215,
      "learning_rate": 3.3735259259259265e-05,
      "loss": 0.0889,
      "step": 42310
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.8084218502044678,
      "learning_rate": 3.373377777777778e-05,
      "loss": 0.0917,
      "step": 42320
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.2273855209350586,
      "learning_rate": 3.37322962962963e-05,
      "loss": 0.0745,
      "step": 42330
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.8205783367156982,
      "learning_rate": 3.373081481481481e-05,
      "loss": 0.0603,
      "step": 42340
    },
    {
      "epoch": 4.71,
      "grad_norm": 6.7249956130981445,
      "learning_rate": 3.3729333333333336e-05,
      "loss": 0.0834,
      "step": 42350
    },
    {
      "epoch": 4.71,
      "grad_norm": 1.9617633819580078,
      "learning_rate": 3.372785185185186e-05,
      "loss": 0.0747,
      "step": 42360
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.26581209897994995,
      "learning_rate": 3.3726370370370375e-05,
      "loss": 0.0574,
      "step": 42370
    },
    {
      "epoch": 4.71,
      "grad_norm": 5.8265509605407715,
      "learning_rate": 3.372488888888889e-05,
      "loss": 0.1013,
      "step": 42380
    },
    {
      "epoch": 4.71,
      "grad_norm": 10.7752046585083,
      "learning_rate": 3.372340740740741e-05,
      "loss": 0.066,
      "step": 42390
    },
    {
      "epoch": 4.71,
      "grad_norm": 2.82061767578125,
      "learning_rate": 3.372192592592593e-05,
      "loss": 0.057,
      "step": 42400
    },
    {
      "epoch": 4.71,
      "grad_norm": 4.344501972198486,
      "learning_rate": 3.372044444444445e-05,
      "loss": 0.05,
      "step": 42410
    },
    {
      "epoch": 4.71,
      "grad_norm": 3.992500066757202,
      "learning_rate": 3.371896296296297e-05,
      "loss": 0.0655,
      "step": 42420
    },
    {
      "epoch": 4.71,
      "grad_norm": 2.060312509536743,
      "learning_rate": 3.3717481481481484e-05,
      "loss": 0.065,
      "step": 42430
    },
    {
      "epoch": 4.72,
      "grad_norm": 5.510054588317871,
      "learning_rate": 3.3716e-05,
      "loss": 0.0829,
      "step": 42440
    },
    {
      "epoch": 4.72,
      "grad_norm": 7.428066253662109,
      "learning_rate": 3.3714518518518516e-05,
      "loss": 0.1146,
      "step": 42450
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.4888699054718018,
      "learning_rate": 3.371303703703704e-05,
      "loss": 0.133,
      "step": 42460
    },
    {
      "epoch": 4.72,
      "grad_norm": 4.975855827331543,
      "learning_rate": 3.371155555555556e-05,
      "loss": 0.0504,
      "step": 42470
    },
    {
      "epoch": 4.72,
      "grad_norm": 2.9758691787719727,
      "learning_rate": 3.371007407407408e-05,
      "loss": 0.0627,
      "step": 42480
    },
    {
      "epoch": 4.72,
      "grad_norm": 4.860839366912842,
      "learning_rate": 3.3708592592592594e-05,
      "loss": 0.0577,
      "step": 42490
    },
    {
      "epoch": 4.72,
      "grad_norm": 2.39029598236084,
      "learning_rate": 3.370711111111111e-05,
      "loss": 0.0509,
      "step": 42500
    },
    {
      "epoch": 4.72,
      "grad_norm": 6.088208198547363,
      "learning_rate": 3.370562962962963e-05,
      "loss": 0.0844,
      "step": 42510
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.0779387950897217,
      "learning_rate": 3.3704148148148156e-05,
      "loss": 0.0367,
      "step": 42520
    },
    {
      "epoch": 4.73,
      "grad_norm": 7.113622188568115,
      "learning_rate": 3.370266666666667e-05,
      "loss": 0.0789,
      "step": 42530
    },
    {
      "epoch": 4.73,
      "grad_norm": 2.7601895332336426,
      "learning_rate": 3.370118518518519e-05,
      "loss": 0.0843,
      "step": 42540
    },
    {
      "epoch": 4.73,
      "grad_norm": 2.468968391418457,
      "learning_rate": 3.3699703703703704e-05,
      "loss": 0.0912,
      "step": 42550
    },
    {
      "epoch": 4.73,
      "grad_norm": 1.5192625522613525,
      "learning_rate": 3.3698222222222227e-05,
      "loss": 0.0391,
      "step": 42560
    },
    {
      "epoch": 4.73,
      "grad_norm": 3.662611722946167,
      "learning_rate": 3.369674074074074e-05,
      "loss": 0.0505,
      "step": 42570
    },
    {
      "epoch": 4.73,
      "grad_norm": 3.38537335395813,
      "learning_rate": 3.3695259259259265e-05,
      "loss": 0.0445,
      "step": 42580
    },
    {
      "epoch": 4.73,
      "grad_norm": 5.632629871368408,
      "learning_rate": 3.369377777777778e-05,
      "loss": 0.0653,
      "step": 42590
    },
    {
      "epoch": 4.73,
      "grad_norm": 2.3502955436706543,
      "learning_rate": 3.36922962962963e-05,
      "loss": 0.0505,
      "step": 42600
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.5546333193778992,
      "learning_rate": 3.3690814814814813e-05,
      "loss": 0.0617,
      "step": 42610
    },
    {
      "epoch": 4.74,
      "grad_norm": 4.205912113189697,
      "learning_rate": 3.3689333333333336e-05,
      "loss": 0.0791,
      "step": 42620
    },
    {
      "epoch": 4.74,
      "grad_norm": 3.525299072265625,
      "learning_rate": 3.368785185185186e-05,
      "loss": 0.099,
      "step": 42630
    },
    {
      "epoch": 4.74,
      "grad_norm": 6.2863030433654785,
      "learning_rate": 3.3686370370370375e-05,
      "loss": 0.0662,
      "step": 42640
    },
    {
      "epoch": 4.74,
      "grad_norm": 3.4970340728759766,
      "learning_rate": 3.368488888888889e-05,
      "loss": 0.051,
      "step": 42650
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.938279390335083,
      "learning_rate": 3.368340740740741e-05,
      "loss": 0.0617,
      "step": 42660
    },
    {
      "epoch": 4.74,
      "grad_norm": 5.126352310180664,
      "learning_rate": 3.368192592592593e-05,
      "loss": 0.0584,
      "step": 42670
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.98801851272583,
      "learning_rate": 3.3680444444444446e-05,
      "loss": 0.0712,
      "step": 42680
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.339561939239502,
      "learning_rate": 3.367896296296297e-05,
      "loss": 0.054,
      "step": 42690
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.219853162765503,
      "learning_rate": 3.3677481481481485e-05,
      "loss": 0.0468,
      "step": 42700
    },
    {
      "epoch": 4.75,
      "grad_norm": 3.9269964694976807,
      "learning_rate": 3.3676e-05,
      "loss": 0.0651,
      "step": 42710
    },
    {
      "epoch": 4.75,
      "grad_norm": 3.750215530395508,
      "learning_rate": 3.367451851851852e-05,
      "loss": 0.0589,
      "step": 42720
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.9560329914093018,
      "learning_rate": 3.367303703703704e-05,
      "loss": 0.1078,
      "step": 42730
    },
    {
      "epoch": 4.75,
      "grad_norm": 3.7857825756073,
      "learning_rate": 3.367155555555556e-05,
      "loss": 0.0555,
      "step": 42740
    },
    {
      "epoch": 4.75,
      "grad_norm": 2.034416675567627,
      "learning_rate": 3.367007407407408e-05,
      "loss": 0.0571,
      "step": 42750
    },
    {
      "epoch": 4.75,
      "grad_norm": 1.1549170017242432,
      "learning_rate": 3.3668592592592594e-05,
      "loss": 0.0777,
      "step": 42760
    },
    {
      "epoch": 4.75,
      "grad_norm": 3.0243492126464844,
      "learning_rate": 3.366711111111111e-05,
      "loss": 0.0424,
      "step": 42770
    },
    {
      "epoch": 4.75,
      "grad_norm": 1.0129649639129639,
      "learning_rate": 3.366562962962963e-05,
      "loss": 0.0965,
      "step": 42780
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.7984659075737,
      "learning_rate": 3.366414814814815e-05,
      "loss": 0.0566,
      "step": 42790
    },
    {
      "epoch": 4.76,
      "grad_norm": 4.088674068450928,
      "learning_rate": 3.366266666666667e-05,
      "loss": 0.2187,
      "step": 42800
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.7774765491485596,
      "learning_rate": 3.366118518518519e-05,
      "loss": 0.0877,
      "step": 42810
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.15971025824546814,
      "learning_rate": 3.3659703703703704e-05,
      "loss": 0.0259,
      "step": 42820
    },
    {
      "epoch": 4.76,
      "grad_norm": 3.5785973072052,
      "learning_rate": 3.365822222222222e-05,
      "loss": 0.0281,
      "step": 42830
    },
    {
      "epoch": 4.76,
      "grad_norm": 6.632829666137695,
      "learning_rate": 3.365674074074074e-05,
      "loss": 0.0665,
      "step": 42840
    },
    {
      "epoch": 4.76,
      "grad_norm": 6.002777576446533,
      "learning_rate": 3.3655259259259266e-05,
      "loss": 0.0996,
      "step": 42850
    },
    {
      "epoch": 4.76,
      "grad_norm": 2.498417615890503,
      "learning_rate": 3.365377777777778e-05,
      "loss": 0.0806,
      "step": 42860
    },
    {
      "epoch": 4.76,
      "grad_norm": 2.1605353355407715,
      "learning_rate": 3.36522962962963e-05,
      "loss": 0.0674,
      "step": 42870
    },
    {
      "epoch": 4.76,
      "grad_norm": 5.766443252563477,
      "learning_rate": 3.3650814814814814e-05,
      "loss": 0.0997,
      "step": 42880
    },
    {
      "epoch": 4.77,
      "grad_norm": 3.1701486110687256,
      "learning_rate": 3.364933333333334e-05,
      "loss": 0.0707,
      "step": 42890
    },
    {
      "epoch": 4.77,
      "grad_norm": 4.319159030914307,
      "learning_rate": 3.364785185185185e-05,
      "loss": 0.0494,
      "step": 42900
    },
    {
      "epoch": 4.77,
      "grad_norm": 3.773660659790039,
      "learning_rate": 3.3646370370370375e-05,
      "loss": 0.0646,
      "step": 42910
    },
    {
      "epoch": 4.77,
      "grad_norm": 4.691162586212158,
      "learning_rate": 3.364488888888889e-05,
      "loss": 0.0546,
      "step": 42920
    },
    {
      "epoch": 4.77,
      "grad_norm": 6.419181823730469,
      "learning_rate": 3.364340740740741e-05,
      "loss": 0.1202,
      "step": 42930
    },
    {
      "epoch": 4.77,
      "grad_norm": 11.537459373474121,
      "learning_rate": 3.3641925925925924e-05,
      "loss": 0.1066,
      "step": 42940
    },
    {
      "epoch": 4.77,
      "grad_norm": 1.8333230018615723,
      "learning_rate": 3.3640444444444446e-05,
      "loss": 0.1213,
      "step": 42950
    },
    {
      "epoch": 4.77,
      "grad_norm": 4.577528476715088,
      "learning_rate": 3.363896296296297e-05,
      "loss": 0.0562,
      "step": 42960
    },
    {
      "epoch": 4.77,
      "grad_norm": 4.035919666290283,
      "learning_rate": 3.3637481481481485e-05,
      "loss": 0.0892,
      "step": 42970
    },
    {
      "epoch": 4.78,
      "grad_norm": 1.453471302986145,
      "learning_rate": 3.3636e-05,
      "loss": 0.0583,
      "step": 42980
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.5276710987091064,
      "learning_rate": 3.363451851851852e-05,
      "loss": 0.0565,
      "step": 42990
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.559757709503174,
      "learning_rate": 3.363303703703704e-05,
      "loss": 0.047,
      "step": 43000
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.8428354263305664,
      "learning_rate": 3.363155555555556e-05,
      "loss": 0.0856,
      "step": 43010
    },
    {
      "epoch": 4.78,
      "grad_norm": 6.30822229385376,
      "learning_rate": 3.363007407407408e-05,
      "loss": 0.1007,
      "step": 43020
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.019329786300659,
      "learning_rate": 3.3628592592592595e-05,
      "loss": 0.0968,
      "step": 43030
    },
    {
      "epoch": 4.78,
      "grad_norm": 1.2041082382202148,
      "learning_rate": 3.362711111111111e-05,
      "loss": 0.1492,
      "step": 43040
    },
    {
      "epoch": 4.78,
      "grad_norm": 5.748122215270996,
      "learning_rate": 3.3625629629629634e-05,
      "loss": 0.0569,
      "step": 43050
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.342820882797241,
      "learning_rate": 3.362414814814815e-05,
      "loss": 0.0576,
      "step": 43060
    },
    {
      "epoch": 4.79,
      "grad_norm": 3.144658088684082,
      "learning_rate": 3.362266666666667e-05,
      "loss": 0.1086,
      "step": 43070
    },
    {
      "epoch": 4.79,
      "grad_norm": 1.8675724267959595,
      "learning_rate": 3.362118518518519e-05,
      "loss": 0.0369,
      "step": 43080
    },
    {
      "epoch": 4.79,
      "grad_norm": 2.7868833541870117,
      "learning_rate": 3.3619703703703705e-05,
      "loss": 0.126,
      "step": 43090
    },
    {
      "epoch": 4.79,
      "grad_norm": 3.0316507816314697,
      "learning_rate": 3.361822222222222e-05,
      "loss": 0.0488,
      "step": 43100
    },
    {
      "epoch": 4.79,
      "grad_norm": 2.5074827671051025,
      "learning_rate": 3.361674074074074e-05,
      "loss": 0.0739,
      "step": 43110
    },
    {
      "epoch": 4.79,
      "grad_norm": 4.320302486419678,
      "learning_rate": 3.3615259259259266e-05,
      "loss": 0.0807,
      "step": 43120
    },
    {
      "epoch": 4.79,
      "grad_norm": 1.7225090265274048,
      "learning_rate": 3.361377777777778e-05,
      "loss": 0.0422,
      "step": 43130
    },
    {
      "epoch": 4.79,
      "grad_norm": 1.7586848735809326,
      "learning_rate": 3.36122962962963e-05,
      "loss": 0.0755,
      "step": 43140
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.9290823936462402,
      "learning_rate": 3.3610814814814814e-05,
      "loss": 0.0873,
      "step": 43150
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.9501004219055176,
      "learning_rate": 3.360933333333334e-05,
      "loss": 0.1297,
      "step": 43160
    },
    {
      "epoch": 4.8,
      "grad_norm": 6.193797588348389,
      "learning_rate": 3.360785185185185e-05,
      "loss": 0.0564,
      "step": 43170
    },
    {
      "epoch": 4.8,
      "grad_norm": 7.787376403808594,
      "learning_rate": 3.3606370370370376e-05,
      "loss": 0.0747,
      "step": 43180
    },
    {
      "epoch": 4.8,
      "grad_norm": 3.874055862426758,
      "learning_rate": 3.360488888888889e-05,
      "loss": 0.0475,
      "step": 43190
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.6415250301361084,
      "learning_rate": 3.360340740740741e-05,
      "loss": 0.0645,
      "step": 43200
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.2589720487594604,
      "learning_rate": 3.3601925925925924e-05,
      "loss": 0.0809,
      "step": 43210
    },
    {
      "epoch": 4.8,
      "grad_norm": 2.799118757247925,
      "learning_rate": 3.360044444444445e-05,
      "loss": 0.1078,
      "step": 43220
    },
    {
      "epoch": 4.8,
      "grad_norm": 3.473222017288208,
      "learning_rate": 3.359896296296297e-05,
      "loss": 0.0815,
      "step": 43230
    },
    {
      "epoch": 4.8,
      "grad_norm": 2.5135140419006348,
      "learning_rate": 3.3597481481481486e-05,
      "loss": 0.067,
      "step": 43240
    },
    {
      "epoch": 4.81,
      "grad_norm": 3.7696239948272705,
      "learning_rate": 3.3596e-05,
      "loss": 0.067,
      "step": 43250
    },
    {
      "epoch": 4.81,
      "grad_norm": 3.7950758934020996,
      "learning_rate": 3.359451851851852e-05,
      "loss": 0.0615,
      "step": 43260
    },
    {
      "epoch": 4.81,
      "grad_norm": 0.47443312406539917,
      "learning_rate": 3.359303703703704e-05,
      "loss": 0.0361,
      "step": 43270
    },
    {
      "epoch": 4.81,
      "grad_norm": 3.80721116065979,
      "learning_rate": 3.3591555555555556e-05,
      "loss": 0.0311,
      "step": 43280
    },
    {
      "epoch": 4.81,
      "grad_norm": 12.129228591918945,
      "learning_rate": 3.359007407407408e-05,
      "loss": 0.1073,
      "step": 43290
    },
    {
      "epoch": 4.81,
      "grad_norm": 10.029147148132324,
      "learning_rate": 3.3588592592592595e-05,
      "loss": 0.08,
      "step": 43300
    },
    {
      "epoch": 4.81,
      "grad_norm": 3.7522778511047363,
      "learning_rate": 3.358711111111111e-05,
      "loss": 0.0633,
      "step": 43310
    },
    {
      "epoch": 4.81,
      "grad_norm": 7.7555060386657715,
      "learning_rate": 3.358562962962963e-05,
      "loss": 0.052,
      "step": 43320
    },
    {
      "epoch": 4.81,
      "grad_norm": 2.1474013328552246,
      "learning_rate": 3.358414814814815e-05,
      "loss": 0.066,
      "step": 43330
    },
    {
      "epoch": 4.82,
      "grad_norm": 4.589950084686279,
      "learning_rate": 3.358266666666667e-05,
      "loss": 0.0852,
      "step": 43340
    },
    {
      "epoch": 4.82,
      "grad_norm": 3.3171277046203613,
      "learning_rate": 3.358118518518519e-05,
      "loss": 0.0497,
      "step": 43350
    },
    {
      "epoch": 4.82,
      "grad_norm": 3.167276620864868,
      "learning_rate": 3.3579703703703705e-05,
      "loss": 0.0563,
      "step": 43360
    },
    {
      "epoch": 4.82,
      "grad_norm": 2.843432664871216,
      "learning_rate": 3.357822222222222e-05,
      "loss": 0.0556,
      "step": 43370
    },
    {
      "epoch": 4.82,
      "grad_norm": 2.5733792781829834,
      "learning_rate": 3.3576740740740744e-05,
      "loss": 0.0488,
      "step": 43380
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.373370885848999,
      "learning_rate": 3.357525925925926e-05,
      "loss": 0.0314,
      "step": 43390
    },
    {
      "epoch": 4.82,
      "grad_norm": 6.099342346191406,
      "learning_rate": 3.357377777777778e-05,
      "loss": 0.0856,
      "step": 43400
    },
    {
      "epoch": 4.82,
      "grad_norm": 14.780962944030762,
      "learning_rate": 3.35722962962963e-05,
      "loss": 0.0963,
      "step": 43410
    },
    {
      "epoch": 4.82,
      "grad_norm": 3.689607620239258,
      "learning_rate": 3.3570814814814815e-05,
      "loss": 0.0819,
      "step": 43420
    },
    {
      "epoch": 4.83,
      "grad_norm": 2.3651936054229736,
      "learning_rate": 3.356933333333334e-05,
      "loss": 0.0743,
      "step": 43430
    },
    {
      "epoch": 4.83,
      "grad_norm": 4.9151129722595215,
      "learning_rate": 3.3567851851851853e-05,
      "loss": 0.0968,
      "step": 43440
    },
    {
      "epoch": 4.83,
      "grad_norm": 2.887784242630005,
      "learning_rate": 3.3566370370370376e-05,
      "loss": 0.0411,
      "step": 43450
    },
    {
      "epoch": 4.83,
      "grad_norm": 10.04184341430664,
      "learning_rate": 3.356488888888889e-05,
      "loss": 0.0678,
      "step": 43460
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.3029855787754059,
      "learning_rate": 3.356340740740741e-05,
      "loss": 0.055,
      "step": 43470
    },
    {
      "epoch": 4.83,
      "grad_norm": 9.741653442382812,
      "learning_rate": 3.3561925925925924e-05,
      "loss": 0.0992,
      "step": 43480
    },
    {
      "epoch": 4.83,
      "grad_norm": 3.5266573429107666,
      "learning_rate": 3.356044444444445e-05,
      "loss": 0.0375,
      "step": 43490
    },
    {
      "epoch": 4.83,
      "grad_norm": 3.3318450450897217,
      "learning_rate": 3.355896296296297e-05,
      "loss": 0.0434,
      "step": 43500
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.6137754321098328,
      "learning_rate": 3.3557481481481486e-05,
      "loss": 0.0811,
      "step": 43510
    },
    {
      "epoch": 4.84,
      "grad_norm": 3.7379186153411865,
      "learning_rate": 3.3556e-05,
      "loss": 0.0619,
      "step": 43520
    },
    {
      "epoch": 4.84,
      "grad_norm": 4.844531059265137,
      "learning_rate": 3.355451851851852e-05,
      "loss": 0.097,
      "step": 43530
    },
    {
      "epoch": 4.84,
      "grad_norm": 1.334714412689209,
      "learning_rate": 3.355303703703704e-05,
      "loss": 0.0994,
      "step": 43540
    },
    {
      "epoch": 4.84,
      "grad_norm": 3.5415332317352295,
      "learning_rate": 3.355155555555556e-05,
      "loss": 0.0905,
      "step": 43550
    },
    {
      "epoch": 4.84,
      "grad_norm": 2.379610776901245,
      "learning_rate": 3.355007407407408e-05,
      "loss": 0.071,
      "step": 43560
    },
    {
      "epoch": 4.84,
      "grad_norm": 2.603134870529175,
      "learning_rate": 3.3548592592592596e-05,
      "loss": 0.0499,
      "step": 43570
    },
    {
      "epoch": 4.84,
      "grad_norm": 2.905571699142456,
      "learning_rate": 3.354711111111111e-05,
      "loss": 0.0751,
      "step": 43580
    },
    {
      "epoch": 4.84,
      "grad_norm": 5.141642093658447,
      "learning_rate": 3.354562962962963e-05,
      "loss": 0.0989,
      "step": 43590
    },
    {
      "epoch": 4.84,
      "grad_norm": 3.69439959526062,
      "learning_rate": 3.354414814814815e-05,
      "loss": 0.0903,
      "step": 43600
    },
    {
      "epoch": 4.85,
      "grad_norm": 4.359939098358154,
      "learning_rate": 3.354266666666667e-05,
      "loss": 0.0753,
      "step": 43610
    },
    {
      "epoch": 4.85,
      "grad_norm": 3.970960855484009,
      "learning_rate": 3.354118518518519e-05,
      "loss": 0.0565,
      "step": 43620
    },
    {
      "epoch": 4.85,
      "grad_norm": 4.876255989074707,
      "learning_rate": 3.3539703703703705e-05,
      "loss": 0.0658,
      "step": 43630
    },
    {
      "epoch": 4.85,
      "grad_norm": 4.714385986328125,
      "learning_rate": 3.353822222222222e-05,
      "loss": 0.0758,
      "step": 43640
    },
    {
      "epoch": 4.85,
      "grad_norm": 4.3425726890563965,
      "learning_rate": 3.3536740740740744e-05,
      "loss": 0.073,
      "step": 43650
    },
    {
      "epoch": 4.85,
      "grad_norm": 3.454850435256958,
      "learning_rate": 3.353525925925926e-05,
      "loss": 0.0679,
      "step": 43660
    },
    {
      "epoch": 4.85,
      "grad_norm": 6.486518859863281,
      "learning_rate": 3.353377777777778e-05,
      "loss": 0.0808,
      "step": 43670
    },
    {
      "epoch": 4.85,
      "grad_norm": 6.909809112548828,
      "learning_rate": 3.35322962962963e-05,
      "loss": 0.1047,
      "step": 43680
    },
    {
      "epoch": 4.85,
      "grad_norm": 2.5001776218414307,
      "learning_rate": 3.3530814814814815e-05,
      "loss": 0.0721,
      "step": 43690
    },
    {
      "epoch": 4.86,
      "grad_norm": 1.6291536092758179,
      "learning_rate": 3.352933333333334e-05,
      "loss": 0.0514,
      "step": 43700
    },
    {
      "epoch": 4.86,
      "grad_norm": 4.763537883758545,
      "learning_rate": 3.3527851851851854e-05,
      "loss": 0.0834,
      "step": 43710
    },
    {
      "epoch": 4.86,
      "grad_norm": 7.7468061447143555,
      "learning_rate": 3.352637037037038e-05,
      "loss": 0.0562,
      "step": 43720
    },
    {
      "epoch": 4.86,
      "grad_norm": 2.464202880859375,
      "learning_rate": 3.352488888888889e-05,
      "loss": 0.0725,
      "step": 43730
    },
    {
      "epoch": 4.86,
      "grad_norm": 6.3498616218566895,
      "learning_rate": 3.352340740740741e-05,
      "loss": 0.1069,
      "step": 43740
    },
    {
      "epoch": 4.86,
      "grad_norm": 2.850792407989502,
      "learning_rate": 3.3521925925925925e-05,
      "loss": 0.0681,
      "step": 43750
    },
    {
      "epoch": 4.86,
      "grad_norm": 8.122386932373047,
      "learning_rate": 3.352044444444445e-05,
      "loss": 0.0668,
      "step": 43760
    },
    {
      "epoch": 4.86,
      "grad_norm": 3.6938061714172363,
      "learning_rate": 3.3518962962962964e-05,
      "loss": 0.1009,
      "step": 43770
    },
    {
      "epoch": 4.86,
      "grad_norm": 2.343517303466797,
      "learning_rate": 3.3517481481481486e-05,
      "loss": 0.0486,
      "step": 43780
    },
    {
      "epoch": 4.87,
      "grad_norm": 2.8255257606506348,
      "learning_rate": 3.3516e-05,
      "loss": 0.0524,
      "step": 43790
    },
    {
      "epoch": 4.87,
      "grad_norm": 8.436674118041992,
      "learning_rate": 3.351451851851852e-05,
      "loss": 0.0904,
      "step": 43800
    },
    {
      "epoch": 4.87,
      "grad_norm": 2.6841015815734863,
      "learning_rate": 3.351303703703704e-05,
      "loss": 0.0736,
      "step": 43810
    },
    {
      "epoch": 4.87,
      "grad_norm": 2.4292659759521484,
      "learning_rate": 3.351155555555556e-05,
      "loss": 0.0853,
      "step": 43820
    },
    {
      "epoch": 4.87,
      "grad_norm": 1.3035292625427246,
      "learning_rate": 3.351007407407408e-05,
      "loss": 0.0496,
      "step": 43830
    },
    {
      "epoch": 4.87,
      "grad_norm": 2.8394436836242676,
      "learning_rate": 3.3508592592592596e-05,
      "loss": 0.0416,
      "step": 43840
    },
    {
      "epoch": 4.87,
      "grad_norm": 3.615408420562744,
      "learning_rate": 3.350711111111111e-05,
      "loss": 0.0533,
      "step": 43850
    },
    {
      "epoch": 4.87,
      "grad_norm": 1.6261154413223267,
      "learning_rate": 3.350562962962963e-05,
      "loss": 0.0656,
      "step": 43860
    },
    {
      "epoch": 4.87,
      "grad_norm": 4.363127708435059,
      "learning_rate": 3.350414814814815e-05,
      "loss": 0.0593,
      "step": 43870
    },
    {
      "epoch": 4.88,
      "grad_norm": 4.055850028991699,
      "learning_rate": 3.350266666666667e-05,
      "loss": 0.0889,
      "step": 43880
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.997866153717041,
      "learning_rate": 3.350118518518519e-05,
      "loss": 0.0469,
      "step": 43890
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.23665237426757812,
      "learning_rate": 3.3499703703703706e-05,
      "loss": 0.045,
      "step": 43900
    },
    {
      "epoch": 4.88,
      "grad_norm": 17.64334487915039,
      "learning_rate": 3.349822222222222e-05,
      "loss": 0.1047,
      "step": 43910
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.0781242847442627,
      "learning_rate": 3.3496740740740745e-05,
      "loss": 0.0642,
      "step": 43920
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.2168593406677246,
      "learning_rate": 3.349525925925926e-05,
      "loss": 0.0807,
      "step": 43930
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.3091354370117188,
      "learning_rate": 3.349377777777778e-05,
      "loss": 0.0892,
      "step": 43940
    },
    {
      "epoch": 4.88,
      "grad_norm": 4.504302978515625,
      "learning_rate": 3.34922962962963e-05,
      "loss": 0.061,
      "step": 43950
    },
    {
      "epoch": 4.88,
      "grad_norm": 5.315037250518799,
      "learning_rate": 3.3490814814814815e-05,
      "loss": 0.0795,
      "step": 43960
    },
    {
      "epoch": 4.89,
      "grad_norm": 9.423467636108398,
      "learning_rate": 3.348933333333334e-05,
      "loss": 0.0562,
      "step": 43970
    },
    {
      "epoch": 4.89,
      "grad_norm": 2.5462770462036133,
      "learning_rate": 3.3487851851851854e-05,
      "loss": 0.0824,
      "step": 43980
    },
    {
      "epoch": 4.89,
      "grad_norm": 5.555482864379883,
      "learning_rate": 3.348637037037037e-05,
      "loss": 0.0688,
      "step": 43990
    },
    {
      "epoch": 4.89,
      "grad_norm": 4.613125324249268,
      "learning_rate": 3.348488888888889e-05,
      "loss": 0.0516,
      "step": 44000
    },
    {
      "epoch": 4.89,
      "grad_norm": 3.2638449668884277,
      "learning_rate": 3.348340740740741e-05,
      "loss": 0.093,
      "step": 44010
    },
    {
      "epoch": 4.89,
      "grad_norm": 3.682330846786499,
      "learning_rate": 3.3481925925925925e-05,
      "loss": 0.0717,
      "step": 44020
    },
    {
      "epoch": 4.89,
      "grad_norm": 17.34070587158203,
      "learning_rate": 3.348044444444445e-05,
      "loss": 0.0631,
      "step": 44030
    },
    {
      "epoch": 4.89,
      "grad_norm": 4.18987512588501,
      "learning_rate": 3.3478962962962964e-05,
      "loss": 0.0496,
      "step": 44040
    },
    {
      "epoch": 4.89,
      "grad_norm": 2.229506015777588,
      "learning_rate": 3.347748148148149e-05,
      "loss": 0.0558,
      "step": 44050
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.534958600997925,
      "learning_rate": 3.3476e-05,
      "loss": 0.0912,
      "step": 44060
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.855912446975708,
      "learning_rate": 3.347451851851852e-05,
      "loss": 0.0763,
      "step": 44070
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.4657695293426514,
      "learning_rate": 3.347303703703704e-05,
      "loss": 0.0651,
      "step": 44080
    },
    {
      "epoch": 4.9,
      "grad_norm": 1.8685439825057983,
      "learning_rate": 3.347155555555556e-05,
      "loss": 0.0593,
      "step": 44090
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.9637932777404785,
      "learning_rate": 3.347007407407408e-05,
      "loss": 0.0509,
      "step": 44100
    },
    {
      "epoch": 4.9,
      "grad_norm": 1.4827972650527954,
      "learning_rate": 3.3468592592592596e-05,
      "loss": 0.0808,
      "step": 44110
    },
    {
      "epoch": 4.9,
      "grad_norm": 3.63883900642395,
      "learning_rate": 3.346711111111111e-05,
      "loss": 0.0704,
      "step": 44120
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.7956278324127197,
      "learning_rate": 3.3465629629629635e-05,
      "loss": 0.0698,
      "step": 44130
    },
    {
      "epoch": 4.9,
      "grad_norm": 4.489651203155518,
      "learning_rate": 3.346414814814815e-05,
      "loss": 0.0738,
      "step": 44140
    },
    {
      "epoch": 4.91,
      "grad_norm": 2.762078046798706,
      "learning_rate": 3.346266666666667e-05,
      "loss": 0.0698,
      "step": 44150
    },
    {
      "epoch": 4.91,
      "grad_norm": 2.5649619102478027,
      "learning_rate": 3.346118518518519e-05,
      "loss": 0.0604,
      "step": 44160
    },
    {
      "epoch": 4.91,
      "grad_norm": 13.558859825134277,
      "learning_rate": 3.3459703703703706e-05,
      "loss": 0.0526,
      "step": 44170
    },
    {
      "epoch": 4.91,
      "grad_norm": 10.244405746459961,
      "learning_rate": 3.345822222222222e-05,
      "loss": 0.062,
      "step": 44180
    },
    {
      "epoch": 4.91,
      "grad_norm": 2.091797351837158,
      "learning_rate": 3.3456740740740745e-05,
      "loss": 0.0496,
      "step": 44190
    },
    {
      "epoch": 4.91,
      "grad_norm": 5.561651706695557,
      "learning_rate": 3.345525925925926e-05,
      "loss": 0.038,
      "step": 44200
    },
    {
      "epoch": 4.91,
      "grad_norm": 3.803818941116333,
      "learning_rate": 3.3453777777777784e-05,
      "loss": 0.0694,
      "step": 44210
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.1912717968225479,
      "learning_rate": 3.34522962962963e-05,
      "loss": 0.0715,
      "step": 44220
    },
    {
      "epoch": 4.91,
      "grad_norm": 3.4172587394714355,
      "learning_rate": 3.3450814814814816e-05,
      "loss": 0.0684,
      "step": 44230
    },
    {
      "epoch": 4.92,
      "grad_norm": 5.377902507781982,
      "learning_rate": 3.344933333333334e-05,
      "loss": 0.0525,
      "step": 44240
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.1805968284606934,
      "learning_rate": 3.3447851851851855e-05,
      "loss": 0.0404,
      "step": 44250
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.643212080001831,
      "learning_rate": 3.344637037037037e-05,
      "loss": 0.047,
      "step": 44260
    },
    {
      "epoch": 4.92,
      "grad_norm": 3.272961378097534,
      "learning_rate": 3.3444888888888893e-05,
      "loss": 0.0761,
      "step": 44270
    },
    {
      "epoch": 4.92,
      "grad_norm": 3.17568039894104,
      "learning_rate": 3.344340740740741e-05,
      "loss": 0.072,
      "step": 44280
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.118907928466797,
      "learning_rate": 3.3441925925925925e-05,
      "loss": 0.077,
      "step": 44290
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.341010570526123,
      "learning_rate": 3.344044444444445e-05,
      "loss": 0.079,
      "step": 44300
    },
    {
      "epoch": 4.92,
      "grad_norm": 5.088111877441406,
      "learning_rate": 3.3438962962962964e-05,
      "loss": 0.0622,
      "step": 44310
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.559718132019043,
      "learning_rate": 3.343748148148149e-05,
      "loss": 0.0609,
      "step": 44320
    },
    {
      "epoch": 4.93,
      "grad_norm": 2.100896120071411,
      "learning_rate": 3.3436e-05,
      "loss": 0.0937,
      "step": 44330
    },
    {
      "epoch": 4.93,
      "grad_norm": 4.033049583435059,
      "learning_rate": 3.343451851851852e-05,
      "loss": 0.08,
      "step": 44340
    },
    {
      "epoch": 4.93,
      "grad_norm": 4.264538764953613,
      "learning_rate": 3.343303703703704e-05,
      "loss": 0.0481,
      "step": 44350
    },
    {
      "epoch": 4.93,
      "grad_norm": 4.319780349731445,
      "learning_rate": 3.343155555555556e-05,
      "loss": 0.0339,
      "step": 44360
    },
    {
      "epoch": 4.93,
      "grad_norm": 6.857564449310303,
      "learning_rate": 3.3430074074074074e-05,
      "loss": 0.0369,
      "step": 44370
    },
    {
      "epoch": 4.93,
      "grad_norm": 4.412975788116455,
      "learning_rate": 3.3428740740740744e-05,
      "loss": 0.0684,
      "step": 44380
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.42992737889289856,
      "learning_rate": 3.342725925925926e-05,
      "loss": 0.041,
      "step": 44390
    },
    {
      "epoch": 4.93,
      "grad_norm": 5.752057075500488,
      "learning_rate": 3.3425777777777777e-05,
      "loss": 0.139,
      "step": 44400
    },
    {
      "epoch": 4.93,
      "grad_norm": 3.3526453971862793,
      "learning_rate": 3.34242962962963e-05,
      "loss": 0.0379,
      "step": 44410
    },
    {
      "epoch": 4.94,
      "grad_norm": 3.5531551837921143,
      "learning_rate": 3.342281481481482e-05,
      "loss": 0.0886,
      "step": 44420
    },
    {
      "epoch": 4.94,
      "grad_norm": 7.112370014190674,
      "learning_rate": 3.342133333333334e-05,
      "loss": 0.1535,
      "step": 44430
    },
    {
      "epoch": 4.94,
      "grad_norm": 3.2586512565612793,
      "learning_rate": 3.3419851851851854e-05,
      "loss": 0.0578,
      "step": 44440
    },
    {
      "epoch": 4.94,
      "grad_norm": 3.770925283432007,
      "learning_rate": 3.341837037037037e-05,
      "loss": 0.0795,
      "step": 44450
    },
    {
      "epoch": 4.94,
      "grad_norm": 2.4257795810699463,
      "learning_rate": 3.341688888888889e-05,
      "loss": 0.052,
      "step": 44460
    },
    {
      "epoch": 4.94,
      "grad_norm": 2.195119619369507,
      "learning_rate": 3.341540740740741e-05,
      "loss": 0.0589,
      "step": 44470
    },
    {
      "epoch": 4.94,
      "grad_norm": 3.06838059425354,
      "learning_rate": 3.341392592592593e-05,
      "loss": 0.0728,
      "step": 44480
    },
    {
      "epoch": 4.94,
      "grad_norm": 8.896289825439453,
      "learning_rate": 3.341244444444445e-05,
      "loss": 0.0425,
      "step": 44490
    },
    {
      "epoch": 4.94,
      "grad_norm": 3.77001690864563,
      "learning_rate": 3.3410962962962964e-05,
      "loss": 0.067,
      "step": 44500
    },
    {
      "epoch": 4.95,
      "grad_norm": 1.0969761610031128,
      "learning_rate": 3.340948148148148e-05,
      "loss": 0.0541,
      "step": 44510
    },
    {
      "epoch": 4.95,
      "grad_norm": 2.911350965499878,
      "learning_rate": 3.3408e-05,
      "loss": 0.0502,
      "step": 44520
    },
    {
      "epoch": 4.95,
      "grad_norm": 4.550980567932129,
      "learning_rate": 3.3406518518518525e-05,
      "loss": 0.0694,
      "step": 44530
    },
    {
      "epoch": 4.95,
      "grad_norm": 2.7867515087127686,
      "learning_rate": 3.340503703703704e-05,
      "loss": 0.046,
      "step": 44540
    },
    {
      "epoch": 4.95,
      "grad_norm": 4.64628267288208,
      "learning_rate": 3.340355555555556e-05,
      "loss": 0.1084,
      "step": 44550
    },
    {
      "epoch": 4.95,
      "grad_norm": 3.879930257797241,
      "learning_rate": 3.3402074074074074e-05,
      "loss": 0.0581,
      "step": 44560
    },
    {
      "epoch": 4.95,
      "grad_norm": 5.568060874938965,
      "learning_rate": 3.3400592592592596e-05,
      "loss": 0.0628,
      "step": 44570
    },
    {
      "epoch": 4.95,
      "grad_norm": 5.49631404876709,
      "learning_rate": 3.339911111111111e-05,
      "loss": 0.0668,
      "step": 44580
    },
    {
      "epoch": 4.95,
      "grad_norm": 12.129053115844727,
      "learning_rate": 3.3397629629629635e-05,
      "loss": 0.0943,
      "step": 44590
    },
    {
      "epoch": 4.96,
      "grad_norm": 7.195597171783447,
      "learning_rate": 3.339614814814815e-05,
      "loss": 0.0669,
      "step": 44600
    },
    {
      "epoch": 4.96,
      "grad_norm": 3.9426305294036865,
      "learning_rate": 3.339466666666667e-05,
      "loss": 0.0898,
      "step": 44610
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.172712564468384,
      "learning_rate": 3.339318518518518e-05,
      "loss": 0.0578,
      "step": 44620
    },
    {
      "epoch": 4.96,
      "grad_norm": 3.412240505218506,
      "learning_rate": 3.3391703703703706e-05,
      "loss": 0.0536,
      "step": 44630
    },
    {
      "epoch": 4.96,
      "grad_norm": 8.4696683883667,
      "learning_rate": 3.339022222222223e-05,
      "loss": 0.0802,
      "step": 44640
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.9239493608474731,
      "learning_rate": 3.3388740740740745e-05,
      "loss": 0.0498,
      "step": 44650
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.6590492725372314,
      "learning_rate": 3.338725925925926e-05,
      "loss": 0.0382,
      "step": 44660
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.518049716949463,
      "learning_rate": 3.338592592592593e-05,
      "loss": 0.0517,
      "step": 44670
    },
    {
      "epoch": 4.96,
      "grad_norm": 4.1461262702941895,
      "learning_rate": 3.338444444444445e-05,
      "loss": 0.0866,
      "step": 44680
    },
    {
      "epoch": 4.97,
      "grad_norm": 7.568112850189209,
      "learning_rate": 3.3382962962962963e-05,
      "loss": 0.0746,
      "step": 44690
    },
    {
      "epoch": 4.97,
      "grad_norm": 2.696263313293457,
      "learning_rate": 3.3381481481481486e-05,
      "loss": 0.0685,
      "step": 44700
    },
    {
      "epoch": 4.97,
      "grad_norm": 2.6723854541778564,
      "learning_rate": 3.338e-05,
      "loss": 0.0581,
      "step": 44710
    },
    {
      "epoch": 4.97,
      "grad_norm": 5.954126834869385,
      "learning_rate": 3.337851851851852e-05,
      "loss": 0.0616,
      "step": 44720
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.3302030861377716,
      "learning_rate": 3.337703703703704e-05,
      "loss": 0.0601,
      "step": 44730
    },
    {
      "epoch": 4.97,
      "grad_norm": 2.3623363971710205,
      "learning_rate": 3.337555555555556e-05,
      "loss": 0.0559,
      "step": 44740
    },
    {
      "epoch": 4.97,
      "grad_norm": 7.046534538269043,
      "learning_rate": 3.337407407407408e-05,
      "loss": 0.1351,
      "step": 44750
    },
    {
      "epoch": 4.97,
      "grad_norm": 2.526702642440796,
      "learning_rate": 3.3372592592592596e-05,
      "loss": 0.0847,
      "step": 44760
    },
    {
      "epoch": 4.97,
      "grad_norm": 2.3963418006896973,
      "learning_rate": 3.337111111111111e-05,
      "loss": 0.0516,
      "step": 44770
    },
    {
      "epoch": 4.98,
      "grad_norm": 5.105483531951904,
      "learning_rate": 3.3369629629629635e-05,
      "loss": 0.1192,
      "step": 44780
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.8027966618537903,
      "learning_rate": 3.336814814814815e-05,
      "loss": 0.0866,
      "step": 44790
    },
    {
      "epoch": 4.98,
      "grad_norm": 5.488290786743164,
      "learning_rate": 3.336666666666667e-05,
      "loss": 0.107,
      "step": 44800
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.9236115217208862,
      "learning_rate": 3.336518518518519e-05,
      "loss": 0.084,
      "step": 44810
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.336672782897949,
      "learning_rate": 3.3363703703703706e-05,
      "loss": 0.079,
      "step": 44820
    },
    {
      "epoch": 4.98,
      "grad_norm": 4.797979831695557,
      "learning_rate": 3.336222222222222e-05,
      "loss": 0.0942,
      "step": 44830
    },
    {
      "epoch": 4.98,
      "grad_norm": 3.811121940612793,
      "learning_rate": 3.3360740740740744e-05,
      "loss": 0.0471,
      "step": 44840
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.3696461915969849,
      "learning_rate": 3.335925925925926e-05,
      "loss": 0.0543,
      "step": 44850
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.8670313358306885,
      "learning_rate": 3.335777777777778e-05,
      "loss": 0.0496,
      "step": 44860
    },
    {
      "epoch": 4.99,
      "grad_norm": 2.886951208114624,
      "learning_rate": 3.33562962962963e-05,
      "loss": 0.0939,
      "step": 44870
    },
    {
      "epoch": 4.99,
      "grad_norm": 5.019588470458984,
      "learning_rate": 3.3354814814814815e-05,
      "loss": 0.0516,
      "step": 44880
    },
    {
      "epoch": 4.99,
      "grad_norm": 4.570547103881836,
      "learning_rate": 3.335333333333334e-05,
      "loss": 0.0921,
      "step": 44890
    },
    {
      "epoch": 4.99,
      "grad_norm": 2.0960185527801514,
      "learning_rate": 3.3351851851851854e-05,
      "loss": 0.0394,
      "step": 44900
    },
    {
      "epoch": 4.99,
      "grad_norm": 10.714692115783691,
      "learning_rate": 3.335037037037038e-05,
      "loss": 0.0789,
      "step": 44910
    },
    {
      "epoch": 4.99,
      "grad_norm": 1.3086310625076294,
      "learning_rate": 3.334888888888889e-05,
      "loss": 0.1013,
      "step": 44920
    },
    {
      "epoch": 4.99,
      "grad_norm": 2.431260347366333,
      "learning_rate": 3.334740740740741e-05,
      "loss": 0.0505,
      "step": 44930
    },
    {
      "epoch": 4.99,
      "grad_norm": 4.879149436950684,
      "learning_rate": 3.3345925925925925e-05,
      "loss": 0.0801,
      "step": 44940
    },
    {
      "epoch": 4.99,
      "grad_norm": 1.673707365989685,
      "learning_rate": 3.334444444444445e-05,
      "loss": 0.0848,
      "step": 44950
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.752364158630371,
      "learning_rate": 3.3342962962962964e-05,
      "loss": 0.1039,
      "step": 44960
    },
    {
      "epoch": 5.0,
      "grad_norm": 12.28481674194336,
      "learning_rate": 3.334148148148149e-05,
      "loss": 0.0582,
      "step": 44970
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.7043451070785522,
      "learning_rate": 3.334e-05,
      "loss": 0.0694,
      "step": 44980
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.0141689777374268,
      "learning_rate": 3.333851851851852e-05,
      "loss": 0.0451,
      "step": 44990
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.7698655128479004,
      "learning_rate": 3.333703703703704e-05,
      "loss": 0.058,
      "step": 45000
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.080660104751587,
      "learning_rate": 3.333555555555556e-05,
      "loss": 0.0404,
      "step": 45010
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.5314096212387085,
      "learning_rate": 3.333407407407408e-05,
      "loss": 0.0446,
      "step": 45020
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.23701900243759155,
      "learning_rate": 3.3332592592592596e-05,
      "loss": 0.0956,
      "step": 45030
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.4134135246276855,
      "learning_rate": 3.333111111111111e-05,
      "loss": 0.0481,
      "step": 45040
    },
    {
      "epoch": 5.01,
      "grad_norm": 3.3111748695373535,
      "learning_rate": 3.3329629629629635e-05,
      "loss": 0.0376,
      "step": 45050
    },
    {
      "epoch": 5.01,
      "grad_norm": 3.1588449478149414,
      "learning_rate": 3.332814814814815e-05,
      "loss": 0.0268,
      "step": 45060
    },
    {
      "epoch": 5.01,
      "grad_norm": 5.120781421661377,
      "learning_rate": 3.3326666666666674e-05,
      "loss": 0.0531,
      "step": 45070
    },
    {
      "epoch": 5.01,
      "grad_norm": 1.5773571729660034,
      "learning_rate": 3.332518518518519e-05,
      "loss": 0.0903,
      "step": 45080
    },
    {
      "epoch": 5.01,
      "grad_norm": 8.855321884155273,
      "learning_rate": 3.3323703703703706e-05,
      "loss": 0.0402,
      "step": 45090
    },
    {
      "epoch": 5.01,
      "grad_norm": 2.9484078884124756,
      "learning_rate": 3.332222222222222e-05,
      "loss": 0.081,
      "step": 45100
    },
    {
      "epoch": 5.01,
      "grad_norm": 2.2953407764434814,
      "learning_rate": 3.3320740740740745e-05,
      "loss": 0.0569,
      "step": 45110
    },
    {
      "epoch": 5.01,
      "grad_norm": 3.253221035003662,
      "learning_rate": 3.331925925925926e-05,
      "loss": 0.0674,
      "step": 45120
    },
    {
      "epoch": 5.01,
      "grad_norm": 3.8445842266082764,
      "learning_rate": 3.3317777777777784e-05,
      "loss": 0.0537,
      "step": 45130
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.2649049758911133,
      "learning_rate": 3.33162962962963e-05,
      "loss": 0.0261,
      "step": 45140
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.9846203923225403,
      "learning_rate": 3.3314814814814816e-05,
      "loss": 0.0609,
      "step": 45150
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.4472192525863647,
      "learning_rate": 3.331333333333334e-05,
      "loss": 0.0524,
      "step": 45160
    },
    {
      "epoch": 5.02,
      "grad_norm": 3.9678189754486084,
      "learning_rate": 3.3311851851851855e-05,
      "loss": 0.0592,
      "step": 45170
    },
    {
      "epoch": 5.02,
      "grad_norm": 9.454130172729492,
      "learning_rate": 3.331037037037038e-05,
      "loss": 0.0586,
      "step": 45180
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.5164353251457214,
      "learning_rate": 3.330888888888889e-05,
      "loss": 0.074,
      "step": 45190
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.126211166381836,
      "learning_rate": 3.330740740740741e-05,
      "loss": 0.0691,
      "step": 45200
    },
    {
      "epoch": 5.02,
      "grad_norm": 3.6778664588928223,
      "learning_rate": 3.3305925925925925e-05,
      "loss": 0.0481,
      "step": 45210
    },
    {
      "epoch": 5.02,
      "grad_norm": 2.761500835418701,
      "learning_rate": 3.330444444444445e-05,
      "loss": 0.0487,
      "step": 45220
    },
    {
      "epoch": 5.03,
      "grad_norm": 2.582625150680542,
      "learning_rate": 3.3302962962962964e-05,
      "loss": 0.0685,
      "step": 45230
    },
    {
      "epoch": 5.03,
      "grad_norm": 2.1795594692230225,
      "learning_rate": 3.330148148148149e-05,
      "loss": 0.0521,
      "step": 45240
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.765483021736145,
      "learning_rate": 3.33e-05,
      "loss": 0.0339,
      "step": 45250
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.801155924797058,
      "learning_rate": 3.329851851851852e-05,
      "loss": 0.0938,
      "step": 45260
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.6604173183441162,
      "learning_rate": 3.329703703703704e-05,
      "loss": 0.0426,
      "step": 45270
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.0243302583694458,
      "learning_rate": 3.329555555555556e-05,
      "loss": 0.0287,
      "step": 45280
    },
    {
      "epoch": 5.03,
      "grad_norm": 4.241954803466797,
      "learning_rate": 3.329407407407408e-05,
      "loss": 0.0649,
      "step": 45290
    },
    {
      "epoch": 5.03,
      "grad_norm": 2.000164031982422,
      "learning_rate": 3.32925925925926e-05,
      "loss": 0.0573,
      "step": 45300
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.7004384994506836,
      "learning_rate": 3.329111111111111e-05,
      "loss": 0.065,
      "step": 45310
    },
    {
      "epoch": 5.04,
      "grad_norm": 13.198190689086914,
      "learning_rate": 3.328962962962963e-05,
      "loss": 0.0534,
      "step": 45320
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.218459129333496,
      "learning_rate": 3.328814814814815e-05,
      "loss": 0.0758,
      "step": 45330
    },
    {
      "epoch": 5.04,
      "grad_norm": 2.4797844886779785,
      "learning_rate": 3.3286666666666674e-05,
      "loss": 0.0442,
      "step": 45340
    },
    {
      "epoch": 5.04,
      "grad_norm": 5.30884313583374,
      "learning_rate": 3.328518518518519e-05,
      "loss": 0.0648,
      "step": 45350
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.37534940242767334,
      "learning_rate": 3.3283703703703706e-05,
      "loss": 0.0637,
      "step": 45360
    },
    {
      "epoch": 5.04,
      "grad_norm": 3.867136240005493,
      "learning_rate": 3.328222222222222e-05,
      "loss": 0.0768,
      "step": 45370
    },
    {
      "epoch": 5.04,
      "grad_norm": 2.2010812759399414,
      "learning_rate": 3.3280740740740745e-05,
      "loss": 0.0724,
      "step": 45380
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.8751144409179688,
      "learning_rate": 3.327925925925926e-05,
      "loss": 0.0286,
      "step": 45390
    },
    {
      "epoch": 5.04,
      "grad_norm": 3.737757444381714,
      "learning_rate": 3.3277777777777784e-05,
      "loss": 0.0599,
      "step": 45400
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.43126535415649414,
      "learning_rate": 3.32762962962963e-05,
      "loss": 0.0416,
      "step": 45410
    },
    {
      "epoch": 5.05,
      "grad_norm": 4.5520710945129395,
      "learning_rate": 3.3274814814814816e-05,
      "loss": 0.058,
      "step": 45420
    },
    {
      "epoch": 5.05,
      "grad_norm": 1.576663851737976,
      "learning_rate": 3.327333333333333e-05,
      "loss": 0.0755,
      "step": 45430
    },
    {
      "epoch": 5.05,
      "grad_norm": 4.469228267669678,
      "learning_rate": 3.3271851851851855e-05,
      "loss": 0.0709,
      "step": 45440
    },
    {
      "epoch": 5.05,
      "grad_norm": 1.3159700632095337,
      "learning_rate": 3.327037037037038e-05,
      "loss": 0.0351,
      "step": 45450
    },
    {
      "epoch": 5.05,
      "grad_norm": 6.655332565307617,
      "learning_rate": 3.3268888888888894e-05,
      "loss": 0.0639,
      "step": 45460
    },
    {
      "epoch": 5.05,
      "grad_norm": 3.138127565383911,
      "learning_rate": 3.326740740740741e-05,
      "loss": 0.062,
      "step": 45470
    },
    {
      "epoch": 5.05,
      "grad_norm": 3.2074687480926514,
      "learning_rate": 3.3265925925925926e-05,
      "loss": 0.0992,
      "step": 45480
    },
    {
      "epoch": 5.05,
      "grad_norm": 2.8700761795043945,
      "learning_rate": 3.326444444444445e-05,
      "loss": 0.0296,
      "step": 45490
    },
    {
      "epoch": 5.06,
      "grad_norm": 2.576411485671997,
      "learning_rate": 3.3262962962962965e-05,
      "loss": 0.0703,
      "step": 45500
    },
    {
      "epoch": 5.06,
      "grad_norm": 3.863715171813965,
      "learning_rate": 3.326148148148149e-05,
      "loss": 0.0802,
      "step": 45510
    },
    {
      "epoch": 5.06,
      "grad_norm": 3.3407208919525146,
      "learning_rate": 3.3260000000000003e-05,
      "loss": 0.0362,
      "step": 45520
    },
    {
      "epoch": 5.06,
      "grad_norm": 3.6322360038757324,
      "learning_rate": 3.325851851851852e-05,
      "loss": 0.0485,
      "step": 45530
    },
    {
      "epoch": 5.06,
      "grad_norm": 2.8435378074645996,
      "learning_rate": 3.3257037037037035e-05,
      "loss": 0.0928,
      "step": 45540
    },
    {
      "epoch": 5.06,
      "grad_norm": 2.2154154777526855,
      "learning_rate": 3.325555555555556e-05,
      "loss": 0.0617,
      "step": 45550
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.0953747034072876,
      "learning_rate": 3.325407407407408e-05,
      "loss": 0.0573,
      "step": 45560
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.3318551778793335,
      "learning_rate": 3.32525925925926e-05,
      "loss": 0.0486,
      "step": 45570
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.9390212297439575,
      "learning_rate": 3.325111111111111e-05,
      "loss": 0.0325,
      "step": 45580
    },
    {
      "epoch": 5.07,
      "grad_norm": 2.8758976459503174,
      "learning_rate": 3.324962962962963e-05,
      "loss": 0.0684,
      "step": 45590
    },
    {
      "epoch": 5.07,
      "grad_norm": 0.12634840607643127,
      "learning_rate": 3.324814814814815e-05,
      "loss": 0.0523,
      "step": 45600
    },
    {
      "epoch": 5.07,
      "grad_norm": 0.3952218294143677,
      "learning_rate": 3.3246666666666675e-05,
      "loss": 0.0317,
      "step": 45610
    },
    {
      "epoch": 5.07,
      "grad_norm": 3.107700824737549,
      "learning_rate": 3.324518518518519e-05,
      "loss": 0.0499,
      "step": 45620
    },
    {
      "epoch": 5.07,
      "grad_norm": 2.889326810836792,
      "learning_rate": 3.324370370370371e-05,
      "loss": 0.075,
      "step": 45630
    },
    {
      "epoch": 5.07,
      "grad_norm": 1.152726650238037,
      "learning_rate": 3.324222222222222e-05,
      "loss": 0.0583,
      "step": 45640
    },
    {
      "epoch": 5.07,
      "grad_norm": 3.7778689861297607,
      "learning_rate": 3.3240740740740746e-05,
      "loss": 0.0739,
      "step": 45650
    },
    {
      "epoch": 5.07,
      "grad_norm": 5.584857940673828,
      "learning_rate": 3.323925925925926e-05,
      "loss": 0.0705,
      "step": 45660
    },
    {
      "epoch": 5.07,
      "grad_norm": 6.363152503967285,
      "learning_rate": 3.3237777777777784e-05,
      "loss": 0.0776,
      "step": 45670
    },
    {
      "epoch": 5.08,
      "grad_norm": 2.659302234649658,
      "learning_rate": 3.32362962962963e-05,
      "loss": 0.0443,
      "step": 45680
    },
    {
      "epoch": 5.08,
      "grad_norm": 6.062387466430664,
      "learning_rate": 3.3234814814814816e-05,
      "loss": 0.047,
      "step": 45690
    },
    {
      "epoch": 5.08,
      "grad_norm": 4.28743839263916,
      "learning_rate": 3.323333333333333e-05,
      "loss": 0.0412,
      "step": 45700
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.6471612453460693,
      "learning_rate": 3.3231851851851855e-05,
      "loss": 0.0884,
      "step": 45710
    },
    {
      "epoch": 5.08,
      "grad_norm": 4.8903913497924805,
      "learning_rate": 3.323037037037038e-05,
      "loss": 0.0388,
      "step": 45720
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.0701910257339478,
      "learning_rate": 3.3228888888888894e-05,
      "loss": 0.0248,
      "step": 45730
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.6537390947341919,
      "learning_rate": 3.322740740740741e-05,
      "loss": 0.0432,
      "step": 45740
    },
    {
      "epoch": 5.08,
      "grad_norm": 4.147399425506592,
      "learning_rate": 3.3225925925925926e-05,
      "loss": 0.0593,
      "step": 45750
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.8058493137359619,
      "learning_rate": 3.322444444444445e-05,
      "loss": 0.11,
      "step": 45760
    },
    {
      "epoch": 5.09,
      "grad_norm": 1.0959910154342651,
      "learning_rate": 3.3222962962962965e-05,
      "loss": 0.0404,
      "step": 45770
    },
    {
      "epoch": 5.09,
      "grad_norm": 1.8283183574676514,
      "learning_rate": 3.322148148148149e-05,
      "loss": 0.072,
      "step": 45780
    },
    {
      "epoch": 5.09,
      "grad_norm": 5.302414894104004,
      "learning_rate": 3.3220000000000004e-05,
      "loss": 0.059,
      "step": 45790
    },
    {
      "epoch": 5.09,
      "grad_norm": 2.9258649349212646,
      "learning_rate": 3.321851851851852e-05,
      "loss": 0.0482,
      "step": 45800
    },
    {
      "epoch": 5.09,
      "grad_norm": 4.018308162689209,
      "learning_rate": 3.3217037037037036e-05,
      "loss": 0.0798,
      "step": 45810
    },
    {
      "epoch": 5.09,
      "grad_norm": 9.27467155456543,
      "learning_rate": 3.321555555555556e-05,
      "loss": 0.0984,
      "step": 45820
    },
    {
      "epoch": 5.09,
      "grad_norm": 2.643847942352295,
      "learning_rate": 3.321407407407408e-05,
      "loss": 0.0616,
      "step": 45830
    },
    {
      "epoch": 5.09,
      "grad_norm": 1.8243414163589478,
      "learning_rate": 3.32125925925926e-05,
      "loss": 0.0805,
      "step": 45840
    },
    {
      "epoch": 5.09,
      "grad_norm": 5.5013532638549805,
      "learning_rate": 3.3211111111111114e-05,
      "loss": 0.0663,
      "step": 45850
    },
    {
      "epoch": 5.1,
      "grad_norm": 7.871593952178955,
      "learning_rate": 3.320962962962963e-05,
      "loss": 0.0716,
      "step": 45860
    },
    {
      "epoch": 5.1,
      "grad_norm": 5.3246612548828125,
      "learning_rate": 3.320814814814815e-05,
      "loss": 0.0939,
      "step": 45870
    },
    {
      "epoch": 5.1,
      "grad_norm": 6.123587131500244,
      "learning_rate": 3.320666666666667e-05,
      "loss": 0.1453,
      "step": 45880
    },
    {
      "epoch": 5.1,
      "grad_norm": 2.9976463317871094,
      "learning_rate": 3.320518518518519e-05,
      "loss": 0.1143,
      "step": 45890
    },
    {
      "epoch": 5.1,
      "grad_norm": 5.968732833862305,
      "learning_rate": 3.320370370370371e-05,
      "loss": 0.0775,
      "step": 45900
    },
    {
      "epoch": 5.1,
      "grad_norm": 2.212923049926758,
      "learning_rate": 3.320222222222222e-05,
      "loss": 0.1516,
      "step": 45910
    },
    {
      "epoch": 5.1,
      "grad_norm": 3.02382230758667,
      "learning_rate": 3.320074074074074e-05,
      "loss": 0.1489,
      "step": 45920
    },
    {
      "epoch": 5.1,
      "grad_norm": 3.9234211444854736,
      "learning_rate": 3.319925925925926e-05,
      "loss": 0.1085,
      "step": 45930
    },
    {
      "epoch": 5.1,
      "grad_norm": 5.557750225067139,
      "learning_rate": 3.3197777777777785e-05,
      "loss": 0.0692,
      "step": 45940
    },
    {
      "epoch": 5.11,
      "grad_norm": 1.8321083784103394,
      "learning_rate": 3.31962962962963e-05,
      "loss": 0.0576,
      "step": 45950
    },
    {
      "epoch": 5.11,
      "grad_norm": 0.21120475232601166,
      "learning_rate": 3.319481481481482e-05,
      "loss": 0.043,
      "step": 45960
    },
    {
      "epoch": 5.11,
      "grad_norm": 2.7427852153778076,
      "learning_rate": 3.319333333333333e-05,
      "loss": 0.0683,
      "step": 45970
    },
    {
      "epoch": 5.11,
      "grad_norm": 3.166886329650879,
      "learning_rate": 3.3191851851851856e-05,
      "loss": 0.0488,
      "step": 45980
    },
    {
      "epoch": 5.11,
      "grad_norm": 2.8231139183044434,
      "learning_rate": 3.319037037037037e-05,
      "loss": 0.042,
      "step": 45990
    },
    {
      "epoch": 5.11,
      "grad_norm": 1.5571494102478027,
      "learning_rate": 3.3188888888888895e-05,
      "loss": 0.0494,
      "step": 46000
    },
    {
      "epoch": 5.11,
      "grad_norm": 2.9316246509552,
      "learning_rate": 3.318740740740741e-05,
      "loss": 0.0371,
      "step": 46010
    },
    {
      "epoch": 5.11,
      "grad_norm": 2.5961227416992188,
      "learning_rate": 3.3185925925925927e-05,
      "loss": 0.077,
      "step": 46020
    },
    {
      "epoch": 5.11,
      "grad_norm": 4.267338275909424,
      "learning_rate": 3.318444444444444e-05,
      "loss": 0.0462,
      "step": 46030
    },
    {
      "epoch": 5.12,
      "grad_norm": 4.12477445602417,
      "learning_rate": 3.3182962962962965e-05,
      "loss": 0.0519,
      "step": 46040
    },
    {
      "epoch": 5.12,
      "grad_norm": 4.866983890533447,
      "learning_rate": 3.318148148148149e-05,
      "loss": 0.0713,
      "step": 46050
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.5839782357215881,
      "learning_rate": 3.3180000000000004e-05,
      "loss": 0.0827,
      "step": 46060
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.31777849793434143,
      "learning_rate": 3.317851851851852e-05,
      "loss": 0.07,
      "step": 46070
    },
    {
      "epoch": 5.12,
      "grad_norm": 3.8570950031280518,
      "learning_rate": 3.3177037037037036e-05,
      "loss": 0.0785,
      "step": 46080
    },
    {
      "epoch": 5.12,
      "grad_norm": 3.474506378173828,
      "learning_rate": 3.317555555555556e-05,
      "loss": 0.0667,
      "step": 46090
    },
    {
      "epoch": 5.12,
      "grad_norm": 2.623072624206543,
      "learning_rate": 3.317407407407408e-05,
      "loss": 0.0835,
      "step": 46100
    },
    {
      "epoch": 5.12,
      "grad_norm": 2.2440972328186035,
      "learning_rate": 3.31725925925926e-05,
      "loss": 0.0617,
      "step": 46110
    },
    {
      "epoch": 5.12,
      "grad_norm": 2.673595666885376,
      "learning_rate": 3.3171111111111114e-05,
      "loss": 0.0438,
      "step": 46120
    },
    {
      "epoch": 5.13,
      "grad_norm": 3.665658473968506,
      "learning_rate": 3.316962962962963e-05,
      "loss": 0.0883,
      "step": 46130
    },
    {
      "epoch": 5.13,
      "grad_norm": 1.3685508966445923,
      "learning_rate": 3.3168148148148146e-05,
      "loss": 0.0431,
      "step": 46140
    },
    {
      "epoch": 5.13,
      "grad_norm": 4.409319877624512,
      "learning_rate": 3.316666666666667e-05,
      "loss": 0.0527,
      "step": 46150
    },
    {
      "epoch": 5.13,
      "grad_norm": 1.0680475234985352,
      "learning_rate": 3.316518518518519e-05,
      "loss": 0.0462,
      "step": 46160
    },
    {
      "epoch": 5.13,
      "grad_norm": 3.749023914337158,
      "learning_rate": 3.316370370370371e-05,
      "loss": 0.0568,
      "step": 46170
    },
    {
      "epoch": 5.13,
      "grad_norm": 4.8924760818481445,
      "learning_rate": 3.3162222222222224e-05,
      "loss": 0.0755,
      "step": 46180
    },
    {
      "epoch": 5.13,
      "grad_norm": 0.5480320453643799,
      "learning_rate": 3.316074074074074e-05,
      "loss": 0.0299,
      "step": 46190
    },
    {
      "epoch": 5.13,
      "grad_norm": 4.551098346710205,
      "learning_rate": 3.315925925925926e-05,
      "loss": 0.0553,
      "step": 46200
    },
    {
      "epoch": 5.13,
      "grad_norm": 3.22316312789917,
      "learning_rate": 3.3157777777777785e-05,
      "loss": 0.0585,
      "step": 46210
    },
    {
      "epoch": 5.14,
      "grad_norm": 2.1575496196746826,
      "learning_rate": 3.31562962962963e-05,
      "loss": 0.0827,
      "step": 46220
    },
    {
      "epoch": 5.14,
      "grad_norm": 4.380944728851318,
      "learning_rate": 3.315481481481482e-05,
      "loss": 0.0706,
      "step": 46230
    },
    {
      "epoch": 5.14,
      "grad_norm": 3.9512245655059814,
      "learning_rate": 3.315333333333333e-05,
      "loss": 0.0632,
      "step": 46240
    },
    {
      "epoch": 5.14,
      "grad_norm": 2.7273550033569336,
      "learning_rate": 3.3151851851851856e-05,
      "loss": 0.1013,
      "step": 46250
    },
    {
      "epoch": 5.14,
      "grad_norm": 4.716024875640869,
      "learning_rate": 3.315037037037037e-05,
      "loss": 0.0625,
      "step": 46260
    },
    {
      "epoch": 5.14,
      "grad_norm": 3.3637583255767822,
      "learning_rate": 3.3148888888888895e-05,
      "loss": 0.0569,
      "step": 46270
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.5277868509292603,
      "learning_rate": 3.314740740740741e-05,
      "loss": 0.0502,
      "step": 46280
    },
    {
      "epoch": 5.14,
      "grad_norm": 2.660519599914551,
      "learning_rate": 3.314592592592593e-05,
      "loss": 0.0612,
      "step": 46290
    },
    {
      "epoch": 5.14,
      "grad_norm": 11.495158195495605,
      "learning_rate": 3.314444444444444e-05,
      "loss": 0.1007,
      "step": 46300
    },
    {
      "epoch": 5.15,
      "grad_norm": 3.269087553024292,
      "learning_rate": 3.3142962962962966e-05,
      "loss": 0.0421,
      "step": 46310
    },
    {
      "epoch": 5.15,
      "grad_norm": 2.2015111446380615,
      "learning_rate": 3.314148148148149e-05,
      "loss": 0.0382,
      "step": 46320
    },
    {
      "epoch": 5.15,
      "grad_norm": 2.3662211894989014,
      "learning_rate": 3.3140000000000005e-05,
      "loss": 0.0548,
      "step": 46330
    },
    {
      "epoch": 5.15,
      "grad_norm": 3.8160207271575928,
      "learning_rate": 3.313851851851852e-05,
      "loss": 0.0367,
      "step": 46340
    },
    {
      "epoch": 5.15,
      "grad_norm": 2.1287970542907715,
      "learning_rate": 3.313703703703704e-05,
      "loss": 0.067,
      "step": 46350
    },
    {
      "epoch": 5.15,
      "grad_norm": 4.664666175842285,
      "learning_rate": 3.313555555555556e-05,
      "loss": 0.0475,
      "step": 46360
    },
    {
      "epoch": 5.15,
      "grad_norm": 3.6437106132507324,
      "learning_rate": 3.3134074074074075e-05,
      "loss": 0.0903,
      "step": 46370
    },
    {
      "epoch": 5.15,
      "grad_norm": 4.338266849517822,
      "learning_rate": 3.31325925925926e-05,
      "loss": 0.0713,
      "step": 46380
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.23978684842586517,
      "learning_rate": 3.3131111111111114e-05,
      "loss": 0.0355,
      "step": 46390
    },
    {
      "epoch": 5.16,
      "grad_norm": 4.208438873291016,
      "learning_rate": 3.312962962962963e-05,
      "loss": 0.0355,
      "step": 46400
    },
    {
      "epoch": 5.16,
      "grad_norm": 7.43214750289917,
      "learning_rate": 3.3128148148148146e-05,
      "loss": 0.1154,
      "step": 46410
    },
    {
      "epoch": 5.16,
      "grad_norm": 3.9213154315948486,
      "learning_rate": 3.312666666666667e-05,
      "loss": 0.0647,
      "step": 46420
    },
    {
      "epoch": 5.16,
      "grad_norm": 14.888216018676758,
      "learning_rate": 3.312518518518519e-05,
      "loss": 0.054,
      "step": 46430
    },
    {
      "epoch": 5.16,
      "grad_norm": 7.826723575592041,
      "learning_rate": 3.312370370370371e-05,
      "loss": 0.0756,
      "step": 46440
    },
    {
      "epoch": 5.16,
      "grad_norm": 5.441619873046875,
      "learning_rate": 3.3122222222222224e-05,
      "loss": 0.0407,
      "step": 46450
    },
    {
      "epoch": 5.16,
      "grad_norm": 5.695779800415039,
      "learning_rate": 3.312074074074074e-05,
      "loss": 0.0577,
      "step": 46460
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.237952709197998,
      "learning_rate": 3.311925925925926e-05,
      "loss": 0.0399,
      "step": 46470
    },
    {
      "epoch": 5.16,
      "grad_norm": 3.34295654296875,
      "learning_rate": 3.311777777777778e-05,
      "loss": 0.0765,
      "step": 46480
    },
    {
      "epoch": 5.17,
      "grad_norm": 2.0138120651245117,
      "learning_rate": 3.31162962962963e-05,
      "loss": 0.055,
      "step": 46490
    },
    {
      "epoch": 5.17,
      "grad_norm": 5.447288513183594,
      "learning_rate": 3.311481481481482e-05,
      "loss": 0.042,
      "step": 46500
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.5186805129051208,
      "learning_rate": 3.3113333333333334e-05,
      "loss": 0.1181,
      "step": 46510
    },
    {
      "epoch": 5.17,
      "grad_norm": 2.8982226848602295,
      "learning_rate": 3.311185185185185e-05,
      "loss": 0.0331,
      "step": 46520
    },
    {
      "epoch": 5.17,
      "grad_norm": 1.8060364723205566,
      "learning_rate": 3.311037037037037e-05,
      "loss": 0.0752,
      "step": 46530
    },
    {
      "epoch": 5.17,
      "grad_norm": 1.2891417741775513,
      "learning_rate": 3.3108888888888895e-05,
      "loss": 0.0568,
      "step": 46540
    },
    {
      "epoch": 5.17,
      "grad_norm": 8.480770111083984,
      "learning_rate": 3.310740740740741e-05,
      "loss": 0.0514,
      "step": 46550
    },
    {
      "epoch": 5.17,
      "grad_norm": 4.489897727966309,
      "learning_rate": 3.310592592592593e-05,
      "loss": 0.0632,
      "step": 46560
    },
    {
      "epoch": 5.17,
      "grad_norm": 2.409872531890869,
      "learning_rate": 3.310444444444444e-05,
      "loss": 0.0975,
      "step": 46570
    },
    {
      "epoch": 5.18,
      "grad_norm": 4.195532321929932,
      "learning_rate": 3.3102962962962966e-05,
      "loss": 0.0631,
      "step": 46580
    },
    {
      "epoch": 5.18,
      "grad_norm": 3.302506685256958,
      "learning_rate": 3.310148148148148e-05,
      "loss": 0.0399,
      "step": 46590
    },
    {
      "epoch": 5.18,
      "grad_norm": 6.5682477951049805,
      "learning_rate": 3.3100000000000005e-05,
      "loss": 0.0564,
      "step": 46600
    },
    {
      "epoch": 5.18,
      "grad_norm": 10.016088485717773,
      "learning_rate": 3.309851851851852e-05,
      "loss": 0.0966,
      "step": 46610
    },
    {
      "epoch": 5.18,
      "grad_norm": 7.5080461502075195,
      "learning_rate": 3.309703703703704e-05,
      "loss": 0.0909,
      "step": 46620
    },
    {
      "epoch": 5.18,
      "grad_norm": 4.127501964569092,
      "learning_rate": 3.309555555555555e-05,
      "loss": 0.0319,
      "step": 46630
    },
    {
      "epoch": 5.18,
      "grad_norm": 2.4545302391052246,
      "learning_rate": 3.3094074074074076e-05,
      "loss": 0.0413,
      "step": 46640
    },
    {
      "epoch": 5.18,
      "grad_norm": 2.538090467453003,
      "learning_rate": 3.30925925925926e-05,
      "loss": 0.0746,
      "step": 46650
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.30198290944099426,
      "learning_rate": 3.3091111111111115e-05,
      "loss": 0.0768,
      "step": 46660
    },
    {
      "epoch": 5.19,
      "grad_norm": 4.69238805770874,
      "learning_rate": 3.308962962962963e-05,
      "loss": 0.0513,
      "step": 46670
    },
    {
      "epoch": 5.19,
      "grad_norm": 2.975513219833374,
      "learning_rate": 3.308814814814815e-05,
      "loss": 0.0406,
      "step": 46680
    },
    {
      "epoch": 5.19,
      "grad_norm": 2.5020246505737305,
      "learning_rate": 3.308666666666667e-05,
      "loss": 0.0667,
      "step": 46690
    },
    {
      "epoch": 5.19,
      "grad_norm": 1.001298427581787,
      "learning_rate": 3.308518518518519e-05,
      "loss": 0.0546,
      "step": 46700
    },
    {
      "epoch": 5.19,
      "grad_norm": 3.6355011463165283,
      "learning_rate": 3.308370370370371e-05,
      "loss": 0.0374,
      "step": 46710
    },
    {
      "epoch": 5.19,
      "grad_norm": 8.4984130859375,
      "learning_rate": 3.3082222222222224e-05,
      "loss": 0.0746,
      "step": 46720
    },
    {
      "epoch": 5.19,
      "grad_norm": 3.7934272289276123,
      "learning_rate": 3.308074074074074e-05,
      "loss": 0.0585,
      "step": 46730
    },
    {
      "epoch": 5.19,
      "grad_norm": 3.5685172080993652,
      "learning_rate": 3.307925925925926e-05,
      "loss": 0.0261,
      "step": 46740
    },
    {
      "epoch": 5.19,
      "grad_norm": 1.6197779178619385,
      "learning_rate": 3.307777777777778e-05,
      "loss": 0.0229,
      "step": 46750
    },
    {
      "epoch": 5.2,
      "grad_norm": 37.6229133605957,
      "learning_rate": 3.30762962962963e-05,
      "loss": 0.0685,
      "step": 46760
    },
    {
      "epoch": 5.2,
      "grad_norm": 2.405910015106201,
      "learning_rate": 3.307481481481482e-05,
      "loss": 0.0541,
      "step": 46770
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.0048842430114746,
      "learning_rate": 3.3073333333333334e-05,
      "loss": 0.0518,
      "step": 46780
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.554469585418701,
      "learning_rate": 3.307185185185185e-05,
      "loss": 0.0551,
      "step": 46790
    },
    {
      "epoch": 5.2,
      "grad_norm": 2.4720277786254883,
      "learning_rate": 3.307037037037037e-05,
      "loss": 0.0665,
      "step": 46800
    },
    {
      "epoch": 5.2,
      "grad_norm": 7.728160381317139,
      "learning_rate": 3.3068888888888896e-05,
      "loss": 0.0381,
      "step": 46810
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.8682963848114014,
      "learning_rate": 3.306740740740741e-05,
      "loss": 0.0382,
      "step": 46820
    },
    {
      "epoch": 5.2,
      "grad_norm": 5.581731796264648,
      "learning_rate": 3.306592592592593e-05,
      "loss": 0.078,
      "step": 46830
    },
    {
      "epoch": 5.2,
      "grad_norm": 2.878800868988037,
      "learning_rate": 3.3064444444444444e-05,
      "loss": 0.0485,
      "step": 46840
    },
    {
      "epoch": 5.21,
      "grad_norm": 2.8941662311553955,
      "learning_rate": 3.3062962962962967e-05,
      "loss": 0.1108,
      "step": 46850
    },
    {
      "epoch": 5.21,
      "grad_norm": 4.10120964050293,
      "learning_rate": 3.306148148148148e-05,
      "loss": 0.0722,
      "step": 46860
    },
    {
      "epoch": 5.21,
      "grad_norm": 2.2184431552886963,
      "learning_rate": 3.3060000000000005e-05,
      "loss": 0.0855,
      "step": 46870
    },
    {
      "epoch": 5.21,
      "grad_norm": 6.925820827484131,
      "learning_rate": 3.305851851851852e-05,
      "loss": 0.0722,
      "step": 46880
    },
    {
      "epoch": 5.21,
      "grad_norm": 2.8006365299224854,
      "learning_rate": 3.305703703703704e-05,
      "loss": 0.054,
      "step": 46890
    },
    {
      "epoch": 5.21,
      "grad_norm": 2.9103477001190186,
      "learning_rate": 3.3055555555555553e-05,
      "loss": 0.0422,
      "step": 46900
    },
    {
      "epoch": 5.21,
      "grad_norm": 0.9650659561157227,
      "learning_rate": 3.3054074074074076e-05,
      "loss": 0.0745,
      "step": 46910
    },
    {
      "epoch": 5.21,
      "grad_norm": 5.71962833404541,
      "learning_rate": 3.30525925925926e-05,
      "loss": 0.0506,
      "step": 46920
    },
    {
      "epoch": 5.21,
      "grad_norm": 1.3870311975479126,
      "learning_rate": 3.3051111111111115e-05,
      "loss": 0.0318,
      "step": 46930
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.573864221572876,
      "learning_rate": 3.304962962962963e-05,
      "loss": 0.0543,
      "step": 46940
    },
    {
      "epoch": 5.22,
      "grad_norm": 12.323637008666992,
      "learning_rate": 3.304814814814815e-05,
      "loss": 0.0557,
      "step": 46950
    },
    {
      "epoch": 5.22,
      "grad_norm": 3.2182657718658447,
      "learning_rate": 3.304666666666667e-05,
      "loss": 0.0697,
      "step": 46960
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.8081722259521484,
      "learning_rate": 3.3045185185185186e-05,
      "loss": 0.0249,
      "step": 46970
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.015775203704834,
      "learning_rate": 3.304370370370371e-05,
      "loss": 0.0346,
      "step": 46980
    },
    {
      "epoch": 5.22,
      "grad_norm": 3.902712106704712,
      "learning_rate": 3.3042222222222225e-05,
      "loss": 0.0453,
      "step": 46990
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.723651170730591,
      "learning_rate": 3.304074074074074e-05,
      "loss": 0.0505,
      "step": 47000
    },
    {
      "epoch": 5.22,
      "grad_norm": 4.026878833770752,
      "learning_rate": 3.303925925925926e-05,
      "loss": 0.0806,
      "step": 47010
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.17934513092041,
      "learning_rate": 3.303777777777778e-05,
      "loss": 0.0834,
      "step": 47020
    },
    {
      "epoch": 5.23,
      "grad_norm": 2.6668875217437744,
      "learning_rate": 3.30362962962963e-05,
      "loss": 0.0441,
      "step": 47030
    },
    {
      "epoch": 5.23,
      "grad_norm": 2.5546929836273193,
      "learning_rate": 3.3034962962962966e-05,
      "loss": 0.2201,
      "step": 47040
    },
    {
      "epoch": 5.23,
      "grad_norm": 4.657364845275879,
      "learning_rate": 3.303348148148148e-05,
      "loss": 0.1078,
      "step": 47050
    },
    {
      "epoch": 5.23,
      "grad_norm": 3.9375531673431396,
      "learning_rate": 3.3032000000000005e-05,
      "loss": 0.1203,
      "step": 47060
    },
    {
      "epoch": 5.23,
      "grad_norm": 1.8553035259246826,
      "learning_rate": 3.303051851851852e-05,
      "loss": 0.0575,
      "step": 47070
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.5386939644813538,
      "learning_rate": 3.3029037037037044e-05,
      "loss": 0.0352,
      "step": 47080
    },
    {
      "epoch": 5.23,
      "grad_norm": 2.2547528743743896,
      "learning_rate": 3.302755555555556e-05,
      "loss": 0.0931,
      "step": 47090
    },
    {
      "epoch": 5.23,
      "grad_norm": 4.62692928314209,
      "learning_rate": 3.3026074074074076e-05,
      "loss": 0.0481,
      "step": 47100
    },
    {
      "epoch": 5.23,
      "grad_norm": 1.8079025745391846,
      "learning_rate": 3.302459259259259e-05,
      "loss": 0.048,
      "step": 47110
    },
    {
      "epoch": 5.24,
      "grad_norm": 8.57645320892334,
      "learning_rate": 3.3023111111111115e-05,
      "loss": 0.0942,
      "step": 47120
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.9466392993927002,
      "learning_rate": 3.302162962962963e-05,
      "loss": 0.0381,
      "step": 47130
    },
    {
      "epoch": 5.24,
      "grad_norm": 2.2505075931549072,
      "learning_rate": 3.3020148148148153e-05,
      "loss": 0.0585,
      "step": 47140
    },
    {
      "epoch": 5.24,
      "grad_norm": 11.476030349731445,
      "learning_rate": 3.301866666666667e-05,
      "loss": 0.0545,
      "step": 47150
    },
    {
      "epoch": 5.24,
      "grad_norm": 2.5306341648101807,
      "learning_rate": 3.3017185185185185e-05,
      "loss": 0.0702,
      "step": 47160
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.46558877825737,
      "learning_rate": 3.301570370370371e-05,
      "loss": 0.052,
      "step": 47170
    },
    {
      "epoch": 5.24,
      "grad_norm": 2.5191423892974854,
      "learning_rate": 3.3014222222222224e-05,
      "loss": 0.0893,
      "step": 47180
    },
    {
      "epoch": 5.24,
      "grad_norm": 3.5869410037994385,
      "learning_rate": 3.301274074074075e-05,
      "loss": 0.0817,
      "step": 47190
    },
    {
      "epoch": 5.24,
      "grad_norm": 1.7699023485183716,
      "learning_rate": 3.301125925925926e-05,
      "loss": 0.0311,
      "step": 47200
    },
    {
      "epoch": 5.25,
      "grad_norm": 3.3940436840057373,
      "learning_rate": 3.300977777777778e-05,
      "loss": 0.0629,
      "step": 47210
    },
    {
      "epoch": 5.25,
      "grad_norm": 5.426249980926514,
      "learning_rate": 3.3008296296296295e-05,
      "loss": 0.059,
      "step": 47220
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.7090994715690613,
      "learning_rate": 3.300681481481482e-05,
      "loss": 0.0973,
      "step": 47230
    },
    {
      "epoch": 5.25,
      "grad_norm": 1.7850555181503296,
      "learning_rate": 3.300533333333334e-05,
      "loss": 0.0713,
      "step": 47240
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.489106684923172,
      "learning_rate": 3.300385185185186e-05,
      "loss": 0.0594,
      "step": 47250
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.4810376763343811,
      "learning_rate": 3.300237037037037e-05,
      "loss": 0.0608,
      "step": 47260
    },
    {
      "epoch": 5.25,
      "grad_norm": 3.266986846923828,
      "learning_rate": 3.300088888888889e-05,
      "loss": 0.0496,
      "step": 47270
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.6093620657920837,
      "learning_rate": 3.299940740740741e-05,
      "loss": 0.0378,
      "step": 47280
    },
    {
      "epoch": 5.25,
      "grad_norm": 3.1721389293670654,
      "learning_rate": 3.299792592592593e-05,
      "loss": 0.0506,
      "step": 47290
    },
    {
      "epoch": 5.26,
      "grad_norm": 6.206668853759766,
      "learning_rate": 3.299644444444445e-05,
      "loss": 0.0715,
      "step": 47300
    },
    {
      "epoch": 5.26,
      "grad_norm": 4.8968825340271,
      "learning_rate": 3.2994962962962966e-05,
      "loss": 0.04,
      "step": 47310
    },
    {
      "epoch": 5.26,
      "grad_norm": 3.1834471225738525,
      "learning_rate": 3.299348148148148e-05,
      "loss": 0.0464,
      "step": 47320
    },
    {
      "epoch": 5.26,
      "grad_norm": 3.5986015796661377,
      "learning_rate": 3.2992e-05,
      "loss": 0.1266,
      "step": 47330
    },
    {
      "epoch": 5.26,
      "grad_norm": 7.611372947692871,
      "learning_rate": 3.299051851851852e-05,
      "loss": 0.063,
      "step": 47340
    },
    {
      "epoch": 5.26,
      "grad_norm": 3.893019199371338,
      "learning_rate": 3.2989037037037044e-05,
      "loss": 0.058,
      "step": 47350
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.1073241233825684,
      "learning_rate": 3.298755555555556e-05,
      "loss": 0.023,
      "step": 47360
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.37645450234413147,
      "learning_rate": 3.2986074074074076e-05,
      "loss": 0.0394,
      "step": 47370
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.5541715621948242,
      "learning_rate": 3.298459259259259e-05,
      "loss": 0.0519,
      "step": 47380
    },
    {
      "epoch": 5.27,
      "grad_norm": 4.308438777923584,
      "learning_rate": 3.2983111111111115e-05,
      "loss": 0.054,
      "step": 47390
    },
    {
      "epoch": 5.27,
      "grad_norm": 3.8237578868865967,
      "learning_rate": 3.298162962962963e-05,
      "loss": 0.0433,
      "step": 47400
    },
    {
      "epoch": 5.27,
      "grad_norm": 1.0478935241699219,
      "learning_rate": 3.2980148148148154e-05,
      "loss": 0.0523,
      "step": 47410
    },
    {
      "epoch": 5.27,
      "grad_norm": 4.185564994812012,
      "learning_rate": 3.297866666666667e-05,
      "loss": 0.0497,
      "step": 47420
    },
    {
      "epoch": 5.27,
      "grad_norm": 1.256878137588501,
      "learning_rate": 3.2977185185185186e-05,
      "loss": 0.0671,
      "step": 47430
    },
    {
      "epoch": 5.27,
      "grad_norm": 2.450096368789673,
      "learning_rate": 3.297570370370371e-05,
      "loss": 0.1075,
      "step": 47440
    },
    {
      "epoch": 5.27,
      "grad_norm": 5.996199607849121,
      "learning_rate": 3.2974222222222225e-05,
      "loss": 0.0518,
      "step": 47450
    },
    {
      "epoch": 5.27,
      "grad_norm": 3.1536567211151123,
      "learning_rate": 3.297274074074075e-05,
      "loss": 0.0595,
      "step": 47460
    },
    {
      "epoch": 5.27,
      "grad_norm": 5.788474082946777,
      "learning_rate": 3.2971259259259264e-05,
      "loss": 0.0723,
      "step": 47470
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.3407136797904968,
      "learning_rate": 3.296977777777778e-05,
      "loss": 0.0736,
      "step": 47480
    },
    {
      "epoch": 5.28,
      "grad_norm": 4.032467365264893,
      "learning_rate": 3.2968296296296296e-05,
      "loss": 0.052,
      "step": 47490
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.6122876405715942,
      "learning_rate": 3.296681481481482e-05,
      "loss": 0.0384,
      "step": 47500
    },
    {
      "epoch": 5.28,
      "grad_norm": 4.970973014831543,
      "learning_rate": 3.296533333333334e-05,
      "loss": 0.1327,
      "step": 47510
    },
    {
      "epoch": 5.28,
      "grad_norm": 3.150405168533325,
      "learning_rate": 3.296385185185186e-05,
      "loss": 0.052,
      "step": 47520
    },
    {
      "epoch": 5.28,
      "grad_norm": 2.8729124069213867,
      "learning_rate": 3.296237037037037e-05,
      "loss": 0.0365,
      "step": 47530
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.224012017250061,
      "learning_rate": 3.296088888888889e-05,
      "loss": 0.079,
      "step": 47540
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.4260978698730469,
      "learning_rate": 3.295940740740741e-05,
      "loss": 0.1058,
      "step": 47550
    },
    {
      "epoch": 5.28,
      "grad_norm": 4.030488014221191,
      "learning_rate": 3.295792592592593e-05,
      "loss": 0.0625,
      "step": 47560
    },
    {
      "epoch": 5.29,
      "grad_norm": 2.8990185260772705,
      "learning_rate": 3.295644444444445e-05,
      "loss": 0.0498,
      "step": 47570
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.3742837607860565,
      "learning_rate": 3.295496296296297e-05,
      "loss": 0.0551,
      "step": 47580
    },
    {
      "epoch": 5.29,
      "grad_norm": 4.757289409637451,
      "learning_rate": 3.295348148148148e-05,
      "loss": 0.0695,
      "step": 47590
    },
    {
      "epoch": 5.29,
      "grad_norm": 3.3992221355438232,
      "learning_rate": 3.2952e-05,
      "loss": 0.0567,
      "step": 47600
    },
    {
      "epoch": 5.29,
      "grad_norm": 7.248395919799805,
      "learning_rate": 3.295051851851852e-05,
      "loss": 0.0723,
      "step": 47610
    },
    {
      "epoch": 5.29,
      "grad_norm": 2.369232416152954,
      "learning_rate": 3.2949037037037045e-05,
      "loss": 0.0289,
      "step": 47620
    },
    {
      "epoch": 5.29,
      "grad_norm": 2.483745813369751,
      "learning_rate": 3.294755555555556e-05,
      "loss": 0.0468,
      "step": 47630
    },
    {
      "epoch": 5.29,
      "grad_norm": 1.0298151969909668,
      "learning_rate": 3.2946074074074077e-05,
      "loss": 0.0744,
      "step": 47640
    },
    {
      "epoch": 5.29,
      "grad_norm": 4.8066229820251465,
      "learning_rate": 3.294459259259259e-05,
      "loss": 0.0388,
      "step": 47650
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.930350124835968,
      "learning_rate": 3.2943111111111115e-05,
      "loss": 0.0223,
      "step": 47660
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.3706729412078857,
      "learning_rate": 3.294162962962963e-05,
      "loss": 0.0424,
      "step": 47670
    },
    {
      "epoch": 5.3,
      "grad_norm": 3.953707218170166,
      "learning_rate": 3.2940148148148154e-05,
      "loss": 0.0313,
      "step": 47680
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.6073439121246338,
      "learning_rate": 3.293866666666667e-05,
      "loss": 0.036,
      "step": 47690
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.9692885279655457,
      "learning_rate": 3.2937185185185186e-05,
      "loss": 0.0393,
      "step": 47700
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.8394489288330078,
      "learning_rate": 3.29357037037037e-05,
      "loss": 0.0497,
      "step": 47710
    },
    {
      "epoch": 5.3,
      "grad_norm": 9.91759967803955,
      "learning_rate": 3.2934222222222225e-05,
      "loss": 0.057,
      "step": 47720
    },
    {
      "epoch": 5.3,
      "grad_norm": 3.5955421924591064,
      "learning_rate": 3.293274074074075e-05,
      "loss": 0.0359,
      "step": 47730
    },
    {
      "epoch": 5.3,
      "grad_norm": 4.160653114318848,
      "learning_rate": 3.2931259259259264e-05,
      "loss": 0.0505,
      "step": 47740
    },
    {
      "epoch": 5.31,
      "grad_norm": 2.8755455017089844,
      "learning_rate": 3.292977777777778e-05,
      "loss": 0.0708,
      "step": 47750
    },
    {
      "epoch": 5.31,
      "grad_norm": 2.8498947620391846,
      "learning_rate": 3.2928296296296296e-05,
      "loss": 0.0613,
      "step": 47760
    },
    {
      "epoch": 5.31,
      "grad_norm": 3.841844320297241,
      "learning_rate": 3.292681481481482e-05,
      "loss": 0.1078,
      "step": 47770
    },
    {
      "epoch": 5.31,
      "grad_norm": 2.011206865310669,
      "learning_rate": 3.2925333333333335e-05,
      "loss": 0.0753,
      "step": 47780
    },
    {
      "epoch": 5.31,
      "grad_norm": 4.344559669494629,
      "learning_rate": 3.292385185185186e-05,
      "loss": 0.0454,
      "step": 47790
    },
    {
      "epoch": 5.31,
      "grad_norm": 0.4920351207256317,
      "learning_rate": 3.2922370370370374e-05,
      "loss": 0.0622,
      "step": 47800
    },
    {
      "epoch": 5.31,
      "grad_norm": 1.7838274240493774,
      "learning_rate": 3.292088888888889e-05,
      "loss": 0.188,
      "step": 47810
    },
    {
      "epoch": 5.31,
      "grad_norm": 1.4854698181152344,
      "learning_rate": 3.2919407407407406e-05,
      "loss": 0.0417,
      "step": 47820
    },
    {
      "epoch": 5.31,
      "grad_norm": 6.307490825653076,
      "learning_rate": 3.291792592592593e-05,
      "loss": 0.0584,
      "step": 47830
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.3867385387420654,
      "learning_rate": 3.291644444444445e-05,
      "loss": 0.0489,
      "step": 47840
    },
    {
      "epoch": 5.32,
      "grad_norm": 4.282111167907715,
      "learning_rate": 3.291496296296297e-05,
      "loss": 0.0709,
      "step": 47850
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.0688939094543457,
      "learning_rate": 3.291348148148148e-05,
      "loss": 0.1052,
      "step": 47860
    },
    {
      "epoch": 5.32,
      "grad_norm": 3.6851158142089844,
      "learning_rate": 3.2912e-05,
      "loss": 0.0696,
      "step": 47870
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.849590301513672,
      "learning_rate": 3.291051851851852e-05,
      "loss": 0.071,
      "step": 47880
    },
    {
      "epoch": 5.32,
      "grad_norm": 4.370015621185303,
      "learning_rate": 3.2909037037037045e-05,
      "loss": 0.1059,
      "step": 47890
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.938646674156189,
      "learning_rate": 3.290755555555556e-05,
      "loss": 0.0661,
      "step": 47900
    },
    {
      "epoch": 5.32,
      "grad_norm": 7.78483247756958,
      "learning_rate": 3.290607407407408e-05,
      "loss": 0.0703,
      "step": 47910
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.1937642097473145,
      "learning_rate": 3.290459259259259e-05,
      "loss": 0.0539,
      "step": 47920
    },
    {
      "epoch": 5.33,
      "grad_norm": 0.2915263772010803,
      "learning_rate": 3.290311111111111e-05,
      "loss": 0.0669,
      "step": 47930
    },
    {
      "epoch": 5.33,
      "grad_norm": 3.448812246322632,
      "learning_rate": 3.290162962962963e-05,
      "loss": 0.0639,
      "step": 47940
    },
    {
      "epoch": 5.33,
      "grad_norm": 2.0450901985168457,
      "learning_rate": 3.2900148148148155e-05,
      "loss": 0.0755,
      "step": 47950
    },
    {
      "epoch": 5.33,
      "grad_norm": 5.111329078674316,
      "learning_rate": 3.289866666666667e-05,
      "loss": 0.0454,
      "step": 47960
    },
    {
      "epoch": 5.33,
      "grad_norm": 2.01462459564209,
      "learning_rate": 3.289718518518519e-05,
      "loss": 0.0254,
      "step": 47970
    },
    {
      "epoch": 5.33,
      "grad_norm": 7.791852951049805,
      "learning_rate": 3.28957037037037e-05,
      "loss": 0.051,
      "step": 47980
    },
    {
      "epoch": 5.33,
      "grad_norm": 3.315688371658325,
      "learning_rate": 3.2894222222222225e-05,
      "loss": 0.0581,
      "step": 47990
    },
    {
      "epoch": 5.33,
      "grad_norm": 1.0507303476333618,
      "learning_rate": 3.289274074074075e-05,
      "loss": 0.0471,
      "step": 48000
    },
    {
      "epoch": 5.33,
      "eval_cer": 0.01098860554780074,
      "eval_loss": 0.28242027759552,
      "eval_runtime": 2030.8379,
      "eval_samples_per_second": 3.939,
      "eval_steps_per_second": 0.492,
      "eval_wer": 0.02924856578576131,
      "step": 48000
    },
    {
      "epoch": 5.33,
      "grad_norm": 5.837801933288574,
      "learning_rate": 3.2891259259259264e-05,
      "loss": 0.0533,
      "step": 48010
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.6096837520599365,
      "learning_rate": 3.288977777777778e-05,
      "loss": 0.0897,
      "step": 48020
    },
    {
      "epoch": 5.34,
      "grad_norm": 3.4568090438842773,
      "learning_rate": 3.2888296296296296e-05,
      "loss": 0.0292,
      "step": 48030
    },
    {
      "epoch": 5.34,
      "grad_norm": 4.075625419616699,
      "learning_rate": 3.288681481481482e-05,
      "loss": 0.0573,
      "step": 48040
    },
    {
      "epoch": 5.34,
      "grad_norm": 6.359731197357178,
      "learning_rate": 3.2885333333333335e-05,
      "loss": 0.0654,
      "step": 48050
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.0113991498947144,
      "learning_rate": 3.288385185185186e-05,
      "loss": 0.0681,
      "step": 48060
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.3983938694000244,
      "learning_rate": 3.2882370370370374e-05,
      "loss": 0.0656,
      "step": 48070
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.2656657695770264,
      "learning_rate": 3.288088888888889e-05,
      "loss": 0.0399,
      "step": 48080
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.920840263366699,
      "learning_rate": 3.2879407407407406e-05,
      "loss": 0.0515,
      "step": 48090
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.388355255126953,
      "learning_rate": 3.287792592592593e-05,
      "loss": 0.0507,
      "step": 48100
    },
    {
      "epoch": 5.35,
      "grad_norm": 2.7798917293548584,
      "learning_rate": 3.287659259259259e-05,
      "loss": 0.0518,
      "step": 48110
    },
    {
      "epoch": 5.35,
      "grad_norm": 1.741039514541626,
      "learning_rate": 3.2875111111111115e-05,
      "loss": 0.082,
      "step": 48120
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.24979916214942932,
      "learning_rate": 3.287362962962963e-05,
      "loss": 0.0517,
      "step": 48130
    },
    {
      "epoch": 5.35,
      "grad_norm": 3.266073226928711,
      "learning_rate": 3.2872148148148154e-05,
      "loss": 0.0301,
      "step": 48140
    },
    {
      "epoch": 5.35,
      "grad_norm": 4.317760944366455,
      "learning_rate": 3.287066666666667e-05,
      "loss": 0.1083,
      "step": 48150
    },
    {
      "epoch": 5.35,
      "grad_norm": 2.3699307441711426,
      "learning_rate": 3.2869333333333334e-05,
      "loss": 0.1096,
      "step": 48160
    },
    {
      "epoch": 5.35,
      "grad_norm": 3.130727529525757,
      "learning_rate": 3.286785185185185e-05,
      "loss": 0.0728,
      "step": 48170
    },
    {
      "epoch": 5.35,
      "grad_norm": 1.087768316268921,
      "learning_rate": 3.286637037037037e-05,
      "loss": 0.0559,
      "step": 48180
    },
    {
      "epoch": 5.35,
      "grad_norm": 1.6914418935775757,
      "learning_rate": 3.2864888888888896e-05,
      "loss": 0.073,
      "step": 48190
    },
    {
      "epoch": 5.36,
      "grad_norm": 6.205083847045898,
      "learning_rate": 3.286340740740741e-05,
      "loss": 0.0658,
      "step": 48200
    },
    {
      "epoch": 5.36,
      "grad_norm": 3.2315661907196045,
      "learning_rate": 3.286192592592593e-05,
      "loss": 0.0915,
      "step": 48210
    },
    {
      "epoch": 5.36,
      "grad_norm": 5.075651168823242,
      "learning_rate": 3.2860444444444444e-05,
      "loss": 0.0343,
      "step": 48220
    },
    {
      "epoch": 5.36,
      "grad_norm": 1.4185975790023804,
      "learning_rate": 3.2858962962962966e-05,
      "loss": 0.0686,
      "step": 48230
    },
    {
      "epoch": 5.36,
      "grad_norm": 3.1471965312957764,
      "learning_rate": 3.285748148148148e-05,
      "loss": 0.1239,
      "step": 48240
    },
    {
      "epoch": 5.36,
      "grad_norm": 2.9595022201538086,
      "learning_rate": 3.2856000000000005e-05,
      "loss": 0.0818,
      "step": 48250
    },
    {
      "epoch": 5.36,
      "grad_norm": 4.54170036315918,
      "learning_rate": 3.285451851851852e-05,
      "loss": 0.0665,
      "step": 48260
    },
    {
      "epoch": 5.36,
      "grad_norm": 6.734840393066406,
      "learning_rate": 3.285303703703704e-05,
      "loss": 0.0772,
      "step": 48270
    },
    {
      "epoch": 5.36,
      "grad_norm": 2.2503442764282227,
      "learning_rate": 3.285155555555555e-05,
      "loss": 0.0621,
      "step": 48280
    },
    {
      "epoch": 5.37,
      "grad_norm": 4.8834357261657715,
      "learning_rate": 3.2850074074074076e-05,
      "loss": 0.0694,
      "step": 48290
    },
    {
      "epoch": 5.37,
      "grad_norm": 2.2384426593780518,
      "learning_rate": 3.28485925925926e-05,
      "loss": 0.0528,
      "step": 48300
    },
    {
      "epoch": 5.37,
      "grad_norm": 3.5188100337982178,
      "learning_rate": 3.2847111111111115e-05,
      "loss": 0.0297,
      "step": 48310
    },
    {
      "epoch": 5.37,
      "grad_norm": 6.23359489440918,
      "learning_rate": 3.284562962962963e-05,
      "loss": 0.0516,
      "step": 48320
    },
    {
      "epoch": 5.37,
      "grad_norm": 2.9765496253967285,
      "learning_rate": 3.284414814814815e-05,
      "loss": 0.0458,
      "step": 48330
    },
    {
      "epoch": 5.37,
      "grad_norm": 3.216613292694092,
      "learning_rate": 3.284266666666667e-05,
      "loss": 0.0521,
      "step": 48340
    },
    {
      "epoch": 5.37,
      "grad_norm": 4.190840721130371,
      "learning_rate": 3.284118518518519e-05,
      "loss": 0.0424,
      "step": 48350
    },
    {
      "epoch": 5.37,
      "grad_norm": 13.359463691711426,
      "learning_rate": 3.283970370370371e-05,
      "loss": 0.0789,
      "step": 48360
    },
    {
      "epoch": 5.37,
      "grad_norm": 2.6388657093048096,
      "learning_rate": 3.2838222222222225e-05,
      "loss": 0.07,
      "step": 48370
    },
    {
      "epoch": 5.38,
      "grad_norm": 2.4257895946502686,
      "learning_rate": 3.283674074074074e-05,
      "loss": 0.0496,
      "step": 48380
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.749540090560913,
      "learning_rate": 3.283525925925926e-05,
      "loss": 0.069,
      "step": 48390
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.3777198791503906,
      "learning_rate": 3.283377777777778e-05,
      "loss": 0.0506,
      "step": 48400
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.956403970718384,
      "learning_rate": 3.28322962962963e-05,
      "loss": 0.0673,
      "step": 48410
    },
    {
      "epoch": 5.38,
      "grad_norm": 6.329170227050781,
      "learning_rate": 3.283081481481482e-05,
      "loss": 0.0667,
      "step": 48420
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.2887961864471436,
      "learning_rate": 3.2829333333333334e-05,
      "loss": 0.0771,
      "step": 48430
    },
    {
      "epoch": 5.38,
      "grad_norm": 5.202338695526123,
      "learning_rate": 3.282785185185185e-05,
      "loss": 0.0791,
      "step": 48440
    },
    {
      "epoch": 5.38,
      "grad_norm": 2.7214715480804443,
      "learning_rate": 3.282637037037037e-05,
      "loss": 0.0364,
      "step": 48450
    },
    {
      "epoch": 5.38,
      "grad_norm": 4.120067596435547,
      "learning_rate": 3.2824888888888896e-05,
      "loss": 0.0564,
      "step": 48460
    },
    {
      "epoch": 5.39,
      "grad_norm": 2.654803514480591,
      "learning_rate": 3.282340740740741e-05,
      "loss": 0.0407,
      "step": 48470
    },
    {
      "epoch": 5.39,
      "grad_norm": 4.119006633758545,
      "learning_rate": 3.282192592592593e-05,
      "loss": 0.0895,
      "step": 48480
    },
    {
      "epoch": 5.39,
      "grad_norm": 3.152486562728882,
      "learning_rate": 3.2820444444444444e-05,
      "loss": 0.0683,
      "step": 48490
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.9635640978813171,
      "learning_rate": 3.281896296296297e-05,
      "loss": 0.0488,
      "step": 48500
    },
    {
      "epoch": 5.39,
      "grad_norm": 5.548121929168701,
      "learning_rate": 3.281748148148148e-05,
      "loss": 0.0664,
      "step": 48510
    },
    {
      "epoch": 5.39,
      "grad_norm": 2.324134588241577,
      "learning_rate": 3.2816000000000006e-05,
      "loss": 0.0705,
      "step": 48520
    },
    {
      "epoch": 5.39,
      "grad_norm": 4.419208526611328,
      "learning_rate": 3.281451851851852e-05,
      "loss": 0.0614,
      "step": 48530
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.8033635020256042,
      "learning_rate": 3.281303703703704e-05,
      "loss": 0.0351,
      "step": 48540
    },
    {
      "epoch": 5.39,
      "grad_norm": 2.2202911376953125,
      "learning_rate": 3.2811555555555554e-05,
      "loss": 0.0964,
      "step": 48550
    },
    {
      "epoch": 5.4,
      "grad_norm": 5.3802385330200195,
      "learning_rate": 3.2810074074074077e-05,
      "loss": 0.0487,
      "step": 48560
    },
    {
      "epoch": 5.4,
      "grad_norm": 4.3307318687438965,
      "learning_rate": 3.28085925925926e-05,
      "loss": 0.0536,
      "step": 48570
    },
    {
      "epoch": 5.4,
      "grad_norm": 5.7907867431640625,
      "learning_rate": 3.2807111111111115e-05,
      "loss": 0.0469,
      "step": 48580
    },
    {
      "epoch": 5.4,
      "grad_norm": 5.008203029632568,
      "learning_rate": 3.280562962962963e-05,
      "loss": 0.0715,
      "step": 48590
    },
    {
      "epoch": 5.4,
      "grad_norm": 10.719152450561523,
      "learning_rate": 3.280414814814815e-05,
      "loss": 0.0635,
      "step": 48600
    },
    {
      "epoch": 5.4,
      "grad_norm": 2.7264745235443115,
      "learning_rate": 3.280266666666667e-05,
      "loss": 0.0545,
      "step": 48610
    },
    {
      "epoch": 5.4,
      "grad_norm": 7.201093673706055,
      "learning_rate": 3.2801185185185186e-05,
      "loss": 0.0677,
      "step": 48620
    },
    {
      "epoch": 5.4,
      "grad_norm": 5.847363471984863,
      "learning_rate": 3.279970370370371e-05,
      "loss": 0.0884,
      "step": 48630
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.9216378927230835,
      "learning_rate": 3.2798222222222225e-05,
      "loss": 0.1437,
      "step": 48640
    },
    {
      "epoch": 5.41,
      "grad_norm": 1.3333526849746704,
      "learning_rate": 3.279674074074074e-05,
      "loss": 0.1064,
      "step": 48650
    },
    {
      "epoch": 5.41,
      "grad_norm": 1.0737134218215942,
      "learning_rate": 3.279525925925926e-05,
      "loss": 0.0457,
      "step": 48660
    },
    {
      "epoch": 5.41,
      "grad_norm": 0.7880334854125977,
      "learning_rate": 3.279377777777778e-05,
      "loss": 0.0398,
      "step": 48670
    },
    {
      "epoch": 5.41,
      "grad_norm": 3.3528077602386475,
      "learning_rate": 3.27922962962963e-05,
      "loss": 0.0799,
      "step": 48680
    },
    {
      "epoch": 5.41,
      "grad_norm": 3.356154441833496,
      "learning_rate": 3.279081481481482e-05,
      "loss": 0.0768,
      "step": 48690
    },
    {
      "epoch": 5.41,
      "grad_norm": 1.3386051654815674,
      "learning_rate": 3.2789333333333335e-05,
      "loss": 0.0323,
      "step": 48700
    },
    {
      "epoch": 5.41,
      "grad_norm": 1.243003010749817,
      "learning_rate": 3.278785185185185e-05,
      "loss": 0.0533,
      "step": 48710
    },
    {
      "epoch": 5.41,
      "grad_norm": 3.8974387645721436,
      "learning_rate": 3.2786370370370374e-05,
      "loss": 0.1105,
      "step": 48720
    },
    {
      "epoch": 5.41,
      "grad_norm": 3.8075828552246094,
      "learning_rate": 3.278488888888889e-05,
      "loss": 0.0413,
      "step": 48730
    },
    {
      "epoch": 5.42,
      "grad_norm": 9.519586563110352,
      "learning_rate": 3.278340740740741e-05,
      "loss": 0.1061,
      "step": 48740
    },
    {
      "epoch": 5.42,
      "grad_norm": 3.581022024154663,
      "learning_rate": 3.278192592592593e-05,
      "loss": 0.0828,
      "step": 48750
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.2726001739501953,
      "learning_rate": 3.2780444444444444e-05,
      "loss": 0.0865,
      "step": 48760
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.0301225185394287,
      "learning_rate": 3.277896296296296e-05,
      "loss": 0.0463,
      "step": 48770
    },
    {
      "epoch": 5.42,
      "grad_norm": 5.1984100341796875,
      "learning_rate": 3.277748148148148e-05,
      "loss": 0.0483,
      "step": 48780
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.4946413040161133,
      "learning_rate": 3.2776000000000006e-05,
      "loss": 0.0444,
      "step": 48790
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.0637826919555664,
      "learning_rate": 3.277451851851852e-05,
      "loss": 0.0617,
      "step": 48800
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.6073456406593323,
      "learning_rate": 3.277303703703704e-05,
      "loss": 0.0621,
      "step": 48810
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.2112401723861694,
      "learning_rate": 3.2771555555555554e-05,
      "loss": 0.0564,
      "step": 48820
    },
    {
      "epoch": 5.43,
      "grad_norm": 4.746169567108154,
      "learning_rate": 3.277007407407408e-05,
      "loss": 0.0782,
      "step": 48830
    },
    {
      "epoch": 5.43,
      "grad_norm": 4.7941083908081055,
      "learning_rate": 3.276859259259259e-05,
      "loss": 0.0678,
      "step": 48840
    },
    {
      "epoch": 5.43,
      "grad_norm": 3.6563940048217773,
      "learning_rate": 3.2767111111111116e-05,
      "loss": 0.0633,
      "step": 48850
    },
    {
      "epoch": 5.43,
      "grad_norm": 5.605388164520264,
      "learning_rate": 3.276562962962963e-05,
      "loss": 0.0726,
      "step": 48860
    },
    {
      "epoch": 5.43,
      "grad_norm": 2.1717262268066406,
      "learning_rate": 3.276414814814815e-05,
      "loss": 0.0406,
      "step": 48870
    },
    {
      "epoch": 5.43,
      "grad_norm": 4.068389415740967,
      "learning_rate": 3.276266666666667e-05,
      "loss": 0.0741,
      "step": 48880
    },
    {
      "epoch": 5.43,
      "grad_norm": 3.4040369987487793,
      "learning_rate": 3.2761185185185187e-05,
      "loss": 0.0636,
      "step": 48890
    },
    {
      "epoch": 5.43,
      "grad_norm": 3.679776191711426,
      "learning_rate": 3.275970370370371e-05,
      "loss": 0.0438,
      "step": 48900
    },
    {
      "epoch": 5.43,
      "grad_norm": 4.015875816345215,
      "learning_rate": 3.2758222222222225e-05,
      "loss": 0.0541,
      "step": 48910
    },
    {
      "epoch": 5.44,
      "grad_norm": 4.5092291831970215,
      "learning_rate": 3.275674074074074e-05,
      "loss": 0.065,
      "step": 48920
    },
    {
      "epoch": 5.44,
      "grad_norm": 5.446528434753418,
      "learning_rate": 3.275525925925926e-05,
      "loss": 0.0674,
      "step": 48930
    },
    {
      "epoch": 5.44,
      "grad_norm": 8.174345016479492,
      "learning_rate": 3.275377777777778e-05,
      "loss": 0.076,
      "step": 48940
    },
    {
      "epoch": 5.44,
      "grad_norm": 3.3768560886383057,
      "learning_rate": 3.27522962962963e-05,
      "loss": 0.0602,
      "step": 48950
    },
    {
      "epoch": 5.44,
      "grad_norm": 5.408716678619385,
      "learning_rate": 3.275081481481482e-05,
      "loss": 0.0503,
      "step": 48960
    },
    {
      "epoch": 5.44,
      "grad_norm": 6.294994831085205,
      "learning_rate": 3.2749333333333335e-05,
      "loss": 0.139,
      "step": 48970
    },
    {
      "epoch": 5.44,
      "grad_norm": 6.408283710479736,
      "learning_rate": 3.274785185185185e-05,
      "loss": 0.0636,
      "step": 48980
    },
    {
      "epoch": 5.44,
      "grad_norm": 5.554441928863525,
      "learning_rate": 3.2746370370370374e-05,
      "loss": 0.1262,
      "step": 48990
    },
    {
      "epoch": 5.44,
      "grad_norm": 3.6509737968444824,
      "learning_rate": 3.274488888888889e-05,
      "loss": 0.0538,
      "step": 49000
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.9274523258209229,
      "learning_rate": 3.274340740740741e-05,
      "loss": 0.0404,
      "step": 49010
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.9998369216918945,
      "learning_rate": 3.274192592592593e-05,
      "loss": 0.0332,
      "step": 49020
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.3492840826511383,
      "learning_rate": 3.2740444444444445e-05,
      "loss": 0.0304,
      "step": 49030
    },
    {
      "epoch": 5.45,
      "grad_norm": 4.055743217468262,
      "learning_rate": 3.273896296296296e-05,
      "loss": 0.0717,
      "step": 49040
    },
    {
      "epoch": 5.45,
      "grad_norm": 3.2014551162719727,
      "learning_rate": 3.2737481481481484e-05,
      "loss": 0.0489,
      "step": 49050
    },
    {
      "epoch": 5.45,
      "grad_norm": 3.215386390686035,
      "learning_rate": 3.2736000000000006e-05,
      "loss": 0.06,
      "step": 49060
    },
    {
      "epoch": 5.45,
      "grad_norm": 1.905806064605713,
      "learning_rate": 3.273451851851852e-05,
      "loss": 0.0582,
      "step": 49070
    },
    {
      "epoch": 5.45,
      "grad_norm": 4.825428009033203,
      "learning_rate": 3.273303703703704e-05,
      "loss": 0.0587,
      "step": 49080
    },
    {
      "epoch": 5.45,
      "grad_norm": 14.06007194519043,
      "learning_rate": 3.2731555555555554e-05,
      "loss": 0.0685,
      "step": 49090
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.4859180450439453,
      "learning_rate": 3.273007407407408e-05,
      "loss": 0.0418,
      "step": 49100
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.981011152267456,
      "learning_rate": 3.272859259259259e-05,
      "loss": 0.0557,
      "step": 49110
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.5096544027328491,
      "learning_rate": 3.2727111111111116e-05,
      "loss": 0.0426,
      "step": 49120
    },
    {
      "epoch": 5.46,
      "grad_norm": 8.31177806854248,
      "learning_rate": 3.272562962962963e-05,
      "loss": 0.0642,
      "step": 49130
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.5131391882896423,
      "learning_rate": 3.272414814814815e-05,
      "loss": 0.089,
      "step": 49140
    },
    {
      "epoch": 5.46,
      "grad_norm": 3.288294792175293,
      "learning_rate": 3.272266666666667e-05,
      "loss": 0.0513,
      "step": 49150
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.10166335105896,
      "learning_rate": 3.272118518518519e-05,
      "loss": 0.0464,
      "step": 49160
    },
    {
      "epoch": 5.46,
      "grad_norm": 6.109760284423828,
      "learning_rate": 3.271970370370371e-05,
      "loss": 0.0549,
      "step": 49170
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.5250779390335083,
      "learning_rate": 3.2718222222222226e-05,
      "loss": 0.0502,
      "step": 49180
    },
    {
      "epoch": 5.47,
      "grad_norm": 5.0217180252075195,
      "learning_rate": 3.271674074074074e-05,
      "loss": 0.0453,
      "step": 49190
    },
    {
      "epoch": 5.47,
      "grad_norm": 3.947321653366089,
      "learning_rate": 3.271525925925926e-05,
      "loss": 0.1096,
      "step": 49200
    },
    {
      "epoch": 5.47,
      "grad_norm": 4.237592697143555,
      "learning_rate": 3.271377777777778e-05,
      "loss": 0.1121,
      "step": 49210
    },
    {
      "epoch": 5.47,
      "grad_norm": 1.213204264640808,
      "learning_rate": 3.27122962962963e-05,
      "loss": 0.0677,
      "step": 49220
    },
    {
      "epoch": 5.47,
      "grad_norm": 2.1647770404815674,
      "learning_rate": 3.271081481481482e-05,
      "loss": 0.0663,
      "step": 49230
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.6330654621124268,
      "learning_rate": 3.2709333333333335e-05,
      "loss": 0.0612,
      "step": 49240
    },
    {
      "epoch": 5.47,
      "grad_norm": 3.76326847076416,
      "learning_rate": 3.270785185185185e-05,
      "loss": 0.0599,
      "step": 49250
    },
    {
      "epoch": 5.47,
      "grad_norm": 2.011395215988159,
      "learning_rate": 3.2706370370370374e-05,
      "loss": 0.0434,
      "step": 49260
    },
    {
      "epoch": 5.47,
      "grad_norm": 3.2221033573150635,
      "learning_rate": 3.270488888888889e-05,
      "loss": 0.0654,
      "step": 49270
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.4617987871170044,
      "learning_rate": 3.270340740740741e-05,
      "loss": 0.0299,
      "step": 49280
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.449813723564148,
      "learning_rate": 3.270192592592593e-05,
      "loss": 0.0622,
      "step": 49290
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.7305262088775635,
      "learning_rate": 3.2700444444444445e-05,
      "loss": 0.0404,
      "step": 49300
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.4548243284225464,
      "learning_rate": 3.269896296296296e-05,
      "loss": 0.0753,
      "step": 49310
    },
    {
      "epoch": 5.48,
      "grad_norm": 2.427159309387207,
      "learning_rate": 3.2697481481481484e-05,
      "loss": 0.0363,
      "step": 49320
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.5940003395080566,
      "learning_rate": 3.2696e-05,
      "loss": 0.0359,
      "step": 49330
    },
    {
      "epoch": 5.48,
      "grad_norm": 2.0967023372650146,
      "learning_rate": 3.269451851851852e-05,
      "loss": 0.091,
      "step": 49340
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.0658451318740845,
      "learning_rate": 3.269303703703704e-05,
      "loss": 0.0596,
      "step": 49350
    },
    {
      "epoch": 5.48,
      "grad_norm": 5.420596599578857,
      "learning_rate": 3.2691555555555555e-05,
      "loss": 0.091,
      "step": 49360
    },
    {
      "epoch": 5.49,
      "grad_norm": 1.0605546236038208,
      "learning_rate": 3.269007407407408e-05,
      "loss": 0.021,
      "step": 49370
    },
    {
      "epoch": 5.49,
      "grad_norm": 2.345536231994629,
      "learning_rate": 3.2688592592592594e-05,
      "loss": 0.0867,
      "step": 49380
    },
    {
      "epoch": 5.49,
      "grad_norm": 6.5269060134887695,
      "learning_rate": 3.2687111111111116e-05,
      "loss": 0.0625,
      "step": 49390
    },
    {
      "epoch": 5.49,
      "grad_norm": 1.2922130823135376,
      "learning_rate": 3.268562962962963e-05,
      "loss": 0.0619,
      "step": 49400
    },
    {
      "epoch": 5.49,
      "grad_norm": 2.4411213397979736,
      "learning_rate": 3.268414814814815e-05,
      "loss": 0.1137,
      "step": 49410
    },
    {
      "epoch": 5.49,
      "grad_norm": 2.9149701595306396,
      "learning_rate": 3.268266666666667e-05,
      "loss": 0.0433,
      "step": 49420
    },
    {
      "epoch": 5.49,
      "grad_norm": 0.9134950637817383,
      "learning_rate": 3.268118518518519e-05,
      "loss": 0.0993,
      "step": 49430
    },
    {
      "epoch": 5.49,
      "grad_norm": 2.4963393211364746,
      "learning_rate": 3.267970370370371e-05,
      "loss": 0.0632,
      "step": 49440
    },
    {
      "epoch": 5.49,
      "grad_norm": 1.7638723850250244,
      "learning_rate": 3.2678222222222226e-05,
      "loss": 0.0553,
      "step": 49450
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.1328017711639404,
      "learning_rate": 3.267674074074074e-05,
      "loss": 0.0288,
      "step": 49460
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.3532189130783081,
      "learning_rate": 3.267525925925926e-05,
      "loss": 0.0627,
      "step": 49470
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.4017326831817627,
      "learning_rate": 3.267377777777778e-05,
      "loss": 0.0558,
      "step": 49480
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.46600157022476196,
      "learning_rate": 3.26722962962963e-05,
      "loss": 0.0443,
      "step": 49490
    },
    {
      "epoch": 5.5,
      "grad_norm": 6.240547180175781,
      "learning_rate": 3.267081481481482e-05,
      "loss": 0.0438,
      "step": 49500
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.512850284576416,
      "learning_rate": 3.2669333333333336e-05,
      "loss": 0.0575,
      "step": 49510
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.964124083518982,
      "learning_rate": 3.266785185185185e-05,
      "loss": 0.0432,
      "step": 49520
    },
    {
      "epoch": 5.5,
      "grad_norm": 6.217191696166992,
      "learning_rate": 3.2666370370370375e-05,
      "loss": 0.0756,
      "step": 49530
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.0286307334899902,
      "learning_rate": 3.266488888888889e-05,
      "loss": 0.0459,
      "step": 49540
    },
    {
      "epoch": 5.51,
      "grad_norm": 2.889068126678467,
      "learning_rate": 3.2663407407407414e-05,
      "loss": 0.0767,
      "step": 49550
    },
    {
      "epoch": 5.51,
      "grad_norm": 4.185914993286133,
      "learning_rate": 3.266192592592593e-05,
      "loss": 0.0836,
      "step": 49560
    },
    {
      "epoch": 5.51,
      "grad_norm": 2.190548896789551,
      "learning_rate": 3.2660444444444446e-05,
      "loss": 0.0446,
      "step": 49570
    },
    {
      "epoch": 5.51,
      "grad_norm": 2.260364294052124,
      "learning_rate": 3.265896296296296e-05,
      "loss": 0.0996,
      "step": 49580
    },
    {
      "epoch": 5.51,
      "grad_norm": 3.2720768451690674,
      "learning_rate": 3.2657481481481484e-05,
      "loss": 0.0692,
      "step": 49590
    },
    {
      "epoch": 5.51,
      "grad_norm": 2.8483784198760986,
      "learning_rate": 3.2656e-05,
      "loss": 0.0869,
      "step": 49600
    },
    {
      "epoch": 5.51,
      "grad_norm": 5.777606964111328,
      "learning_rate": 3.265451851851852e-05,
      "loss": 0.0611,
      "step": 49610
    },
    {
      "epoch": 5.51,
      "grad_norm": 3.536104440689087,
      "learning_rate": 3.265303703703704e-05,
      "loss": 0.0461,
      "step": 49620
    },
    {
      "epoch": 5.51,
      "grad_norm": 1.7578465938568115,
      "learning_rate": 3.2651555555555555e-05,
      "loss": 0.0749,
      "step": 49630
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.0649579763412476,
      "learning_rate": 3.265007407407408e-05,
      "loss": 0.0213,
      "step": 49640
    },
    {
      "epoch": 5.52,
      "grad_norm": 7.9019036293029785,
      "learning_rate": 3.2648592592592594e-05,
      "loss": 0.0634,
      "step": 49650
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.9252762794494629,
      "learning_rate": 3.264711111111112e-05,
      "loss": 0.0331,
      "step": 49660
    },
    {
      "epoch": 5.52,
      "grad_norm": 8.636724472045898,
      "learning_rate": 3.264562962962963e-05,
      "loss": 0.0622,
      "step": 49670
    },
    {
      "epoch": 5.52,
      "grad_norm": 6.66623592376709,
      "learning_rate": 3.264414814814815e-05,
      "loss": 0.1157,
      "step": 49680
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.578506588935852,
      "learning_rate": 3.264266666666667e-05,
      "loss": 0.0337,
      "step": 49690
    },
    {
      "epoch": 5.52,
      "grad_norm": 17.002614974975586,
      "learning_rate": 3.264118518518519e-05,
      "loss": 0.1088,
      "step": 49700
    },
    {
      "epoch": 5.52,
      "grad_norm": 3.930263042449951,
      "learning_rate": 3.2639703703703704e-05,
      "loss": 0.0626,
      "step": 49710
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.9332672357559204,
      "learning_rate": 3.2638222222222227e-05,
      "loss": 0.0462,
      "step": 49720
    },
    {
      "epoch": 5.53,
      "grad_norm": 2.2448253631591797,
      "learning_rate": 3.263688888888889e-05,
      "loss": 0.2623,
      "step": 49730
    },
    {
      "epoch": 5.53,
      "grad_norm": 2.293041467666626,
      "learning_rate": 3.2635407407407406e-05,
      "loss": 0.0425,
      "step": 49740
    },
    {
      "epoch": 5.53,
      "grad_norm": 6.289446830749512,
      "learning_rate": 3.263392592592593e-05,
      "loss": 0.0845,
      "step": 49750
    },
    {
      "epoch": 5.53,
      "grad_norm": 9.401753425598145,
      "learning_rate": 3.263244444444445e-05,
      "loss": 0.0479,
      "step": 49760
    },
    {
      "epoch": 5.53,
      "grad_norm": 10.867669105529785,
      "learning_rate": 3.263096296296297e-05,
      "loss": 0.0362,
      "step": 49770
    },
    {
      "epoch": 5.53,
      "grad_norm": 3.874030828475952,
      "learning_rate": 3.2629481481481484e-05,
      "loss": 0.1544,
      "step": 49780
    },
    {
      "epoch": 5.53,
      "grad_norm": 4.031452178955078,
      "learning_rate": 3.2628e-05,
      "loss": 0.0712,
      "step": 49790
    },
    {
      "epoch": 5.53,
      "grad_norm": 3.3400721549987793,
      "learning_rate": 3.262651851851852e-05,
      "loss": 0.09,
      "step": 49800
    },
    {
      "epoch": 5.53,
      "grad_norm": 2.9245307445526123,
      "learning_rate": 3.262503703703704e-05,
      "loss": 0.0851,
      "step": 49810
    },
    {
      "epoch": 5.54,
      "grad_norm": 4.424587726593018,
      "learning_rate": 3.262355555555556e-05,
      "loss": 0.0934,
      "step": 49820
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.394693374633789,
      "learning_rate": 3.262207407407408e-05,
      "loss": 0.0419,
      "step": 49830
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.17792989313602448,
      "learning_rate": 3.2620592592592594e-05,
      "loss": 0.0318,
      "step": 49840
    },
    {
      "epoch": 5.54,
      "grad_norm": 13.140189170837402,
      "learning_rate": 3.261911111111111e-05,
      "loss": 0.0897,
      "step": 49850
    },
    {
      "epoch": 5.54,
      "grad_norm": 3.265972137451172,
      "learning_rate": 3.261762962962963e-05,
      "loss": 0.0366,
      "step": 49860
    },
    {
      "epoch": 5.54,
      "grad_norm": 1.633429765701294,
      "learning_rate": 3.2616148148148155e-05,
      "loss": 0.0359,
      "step": 49870
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.7576606273651123,
      "learning_rate": 3.261466666666667e-05,
      "loss": 0.0487,
      "step": 49880
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.345067262649536,
      "learning_rate": 3.261318518518519e-05,
      "loss": 0.0829,
      "step": 49890
    },
    {
      "epoch": 5.54,
      "grad_norm": 3.0141706466674805,
      "learning_rate": 3.26117037037037e-05,
      "loss": 0.0828,
      "step": 49900
    },
    {
      "epoch": 5.55,
      "grad_norm": 2.7620437145233154,
      "learning_rate": 3.2610222222222226e-05,
      "loss": 0.0488,
      "step": 49910
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.4463274478912354,
      "learning_rate": 3.260874074074074e-05,
      "loss": 0.0562,
      "step": 49920
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.3425403833389282,
      "learning_rate": 3.2607259259259265e-05,
      "loss": 0.0744,
      "step": 49930
    },
    {
      "epoch": 5.55,
      "grad_norm": 2.2240169048309326,
      "learning_rate": 3.260577777777778e-05,
      "loss": 0.0383,
      "step": 49940
    },
    {
      "epoch": 5.55,
      "grad_norm": 4.120499134063721,
      "learning_rate": 3.26042962962963e-05,
      "loss": 0.0569,
      "step": 49950
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.8180663585662842,
      "learning_rate": 3.260281481481481e-05,
      "loss": 0.0449,
      "step": 49960
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.2722145318984985,
      "learning_rate": 3.2601333333333336e-05,
      "loss": 0.0476,
      "step": 49970
    },
    {
      "epoch": 5.55,
      "grad_norm": 6.509855270385742,
      "learning_rate": 3.259985185185186e-05,
      "loss": 0.077,
      "step": 49980
    },
    {
      "epoch": 5.55,
      "grad_norm": 4.720386981964111,
      "learning_rate": 3.2598370370370375e-05,
      "loss": 0.0342,
      "step": 49990
    },
    {
      "epoch": 5.56,
      "grad_norm": 3.011540412902832,
      "learning_rate": 3.259688888888889e-05,
      "loss": 0.0418,
      "step": 50000
    },
    {
      "epoch": 5.56,
      "grad_norm": 3.131089687347412,
      "learning_rate": 3.259540740740741e-05,
      "loss": 0.05,
      "step": 50010
    },
    {
      "epoch": 5.56,
      "grad_norm": 9.812215805053711,
      "learning_rate": 3.259392592592593e-05,
      "loss": 0.0715,
      "step": 50020
    },
    {
      "epoch": 5.56,
      "grad_norm": 4.019695281982422,
      "learning_rate": 3.2592444444444446e-05,
      "loss": 0.0654,
      "step": 50030
    },
    {
      "epoch": 5.56,
      "grad_norm": 2.0418879985809326,
      "learning_rate": 3.259096296296297e-05,
      "loss": 0.0679,
      "step": 50040
    },
    {
      "epoch": 5.56,
      "grad_norm": 1.3412072658538818,
      "learning_rate": 3.2589481481481484e-05,
      "loss": 0.0586,
      "step": 50050
    },
    {
      "epoch": 5.56,
      "grad_norm": 3.051694631576538,
      "learning_rate": 3.2588e-05,
      "loss": 0.0576,
      "step": 50060
    },
    {
      "epoch": 5.56,
      "grad_norm": 8.741789817810059,
      "learning_rate": 3.2586518518518516e-05,
      "loss": 0.046,
      "step": 50070
    },
    {
      "epoch": 5.56,
      "grad_norm": 6.548033237457275,
      "learning_rate": 3.258503703703704e-05,
      "loss": 0.0957,
      "step": 50080
    },
    {
      "epoch": 5.57,
      "grad_norm": 6.533703804016113,
      "learning_rate": 3.258355555555556e-05,
      "loss": 0.0463,
      "step": 50090
    },
    {
      "epoch": 5.57,
      "grad_norm": 2.328429937362671,
      "learning_rate": 3.258207407407408e-05,
      "loss": 0.0637,
      "step": 50100
    },
    {
      "epoch": 5.57,
      "grad_norm": 7.118833065032959,
      "learning_rate": 3.2580592592592594e-05,
      "loss": 0.1103,
      "step": 50110
    },
    {
      "epoch": 5.57,
      "grad_norm": 0.5147518515586853,
      "learning_rate": 3.257911111111111e-05,
      "loss": 0.0352,
      "step": 50120
    },
    {
      "epoch": 5.57,
      "grad_norm": 1.240635871887207,
      "learning_rate": 3.257762962962963e-05,
      "loss": 0.0654,
      "step": 50130
    },
    {
      "epoch": 5.57,
      "grad_norm": 2.8598906993865967,
      "learning_rate": 3.2576148148148156e-05,
      "loss": 0.0408,
      "step": 50140
    },
    {
      "epoch": 5.57,
      "grad_norm": 4.776610851287842,
      "learning_rate": 3.257466666666667e-05,
      "loss": 0.0327,
      "step": 50150
    },
    {
      "epoch": 5.57,
      "grad_norm": 2.44997239112854,
      "learning_rate": 3.257318518518519e-05,
      "loss": 0.0463,
      "step": 50160
    },
    {
      "epoch": 5.57,
      "grad_norm": 4.425804138183594,
      "learning_rate": 3.2571703703703704e-05,
      "loss": 0.0721,
      "step": 50170
    },
    {
      "epoch": 5.58,
      "grad_norm": 4.725100517272949,
      "learning_rate": 3.257022222222222e-05,
      "loss": 0.0501,
      "step": 50180
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.4803323447704315,
      "learning_rate": 3.256874074074074e-05,
      "loss": 0.0595,
      "step": 50190
    },
    {
      "epoch": 5.58,
      "grad_norm": 1.89632248878479,
      "learning_rate": 3.2567259259259265e-05,
      "loss": 0.0577,
      "step": 50200
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.5274263024330139,
      "learning_rate": 3.256577777777778e-05,
      "loss": 0.032,
      "step": 50210
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.6368494629859924,
      "learning_rate": 3.25642962962963e-05,
      "loss": 0.05,
      "step": 50220
    },
    {
      "epoch": 5.58,
      "grad_norm": 6.110278606414795,
      "learning_rate": 3.2562814814814813e-05,
      "loss": 0.0621,
      "step": 50230
    },
    {
      "epoch": 5.58,
      "grad_norm": 1.5316336154937744,
      "learning_rate": 3.2561333333333336e-05,
      "loss": 0.04,
      "step": 50240
    },
    {
      "epoch": 5.58,
      "grad_norm": 5.830074310302734,
      "learning_rate": 3.255985185185186e-05,
      "loss": 0.0551,
      "step": 50250
    },
    {
      "epoch": 5.58,
      "grad_norm": 2.481753349304199,
      "learning_rate": 3.2558370370370375e-05,
      "loss": 0.0405,
      "step": 50260
    },
    {
      "epoch": 5.59,
      "grad_norm": 2.2662742137908936,
      "learning_rate": 3.255688888888889e-05,
      "loss": 0.0421,
      "step": 50270
    },
    {
      "epoch": 5.59,
      "grad_norm": 1.6753031015396118,
      "learning_rate": 3.255540740740741e-05,
      "loss": 0.0538,
      "step": 50280
    },
    {
      "epoch": 5.59,
      "grad_norm": 1.9653635025024414,
      "learning_rate": 3.255392592592593e-05,
      "loss": 0.0512,
      "step": 50290
    },
    {
      "epoch": 5.59,
      "grad_norm": 13.057156562805176,
      "learning_rate": 3.2552444444444446e-05,
      "loss": 0.1032,
      "step": 50300
    },
    {
      "epoch": 5.59,
      "grad_norm": 2.5222904682159424,
      "learning_rate": 3.255096296296297e-05,
      "loss": 0.0346,
      "step": 50310
    },
    {
      "epoch": 5.59,
      "grad_norm": 5.22493839263916,
      "learning_rate": 3.2549481481481485e-05,
      "loss": 0.0603,
      "step": 50320
    },
    {
      "epoch": 5.59,
      "grad_norm": 12.377540588378906,
      "learning_rate": 3.2548e-05,
      "loss": 0.0867,
      "step": 50330
    },
    {
      "epoch": 5.59,
      "grad_norm": 1.7117507457733154,
      "learning_rate": 3.254651851851852e-05,
      "loss": 0.0358,
      "step": 50340
    },
    {
      "epoch": 5.59,
      "grad_norm": 0.7665194272994995,
      "learning_rate": 3.254503703703704e-05,
      "loss": 0.026,
      "step": 50350
    },
    {
      "epoch": 5.6,
      "grad_norm": 2.9188034534454346,
      "learning_rate": 3.254355555555556e-05,
      "loss": 0.062,
      "step": 50360
    },
    {
      "epoch": 5.6,
      "grad_norm": 2.632983446121216,
      "learning_rate": 3.254207407407408e-05,
      "loss": 0.055,
      "step": 50370
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.953773856163025,
      "learning_rate": 3.2540592592592594e-05,
      "loss": 0.0526,
      "step": 50380
    },
    {
      "epoch": 5.6,
      "grad_norm": 3.124802827835083,
      "learning_rate": 3.253911111111111e-05,
      "loss": 0.0607,
      "step": 50390
    },
    {
      "epoch": 5.6,
      "grad_norm": 2.261915922164917,
      "learning_rate": 3.253762962962963e-05,
      "loss": 0.0332,
      "step": 50400
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.3130536675453186,
      "learning_rate": 3.253614814814815e-05,
      "loss": 0.0444,
      "step": 50410
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.0030802488327026,
      "learning_rate": 3.253466666666667e-05,
      "loss": 0.037,
      "step": 50420
    },
    {
      "epoch": 5.6,
      "grad_norm": 3.5206735134124756,
      "learning_rate": 3.253318518518519e-05,
      "loss": 0.0571,
      "step": 50430
    },
    {
      "epoch": 5.6,
      "grad_norm": 7.574679851531982,
      "learning_rate": 3.2531703703703704e-05,
      "loss": 0.0636,
      "step": 50440
    },
    {
      "epoch": 5.61,
      "grad_norm": 8.652127265930176,
      "learning_rate": 3.253022222222222e-05,
      "loss": 0.0669,
      "step": 50450
    },
    {
      "epoch": 5.61,
      "grad_norm": 4.868210315704346,
      "learning_rate": 3.252874074074074e-05,
      "loss": 0.0402,
      "step": 50460
    },
    {
      "epoch": 5.61,
      "grad_norm": 5.429182529449463,
      "learning_rate": 3.2527259259259266e-05,
      "loss": 0.0785,
      "step": 50470
    },
    {
      "epoch": 5.61,
      "grad_norm": 10.394261360168457,
      "learning_rate": 3.252577777777778e-05,
      "loss": 0.0429,
      "step": 50480
    },
    {
      "epoch": 5.61,
      "grad_norm": 6.948615074157715,
      "learning_rate": 3.25242962962963e-05,
      "loss": 0.0584,
      "step": 50490
    },
    {
      "epoch": 5.61,
      "grad_norm": 2.385392665863037,
      "learning_rate": 3.2522814814814814e-05,
      "loss": 0.0475,
      "step": 50500
    },
    {
      "epoch": 5.61,
      "grad_norm": 4.921020030975342,
      "learning_rate": 3.2521333333333337e-05,
      "loss": 0.0731,
      "step": 50510
    },
    {
      "epoch": 5.61,
      "grad_norm": 1.6475930213928223,
      "learning_rate": 3.251985185185185e-05,
      "loss": 0.035,
      "step": 50520
    },
    {
      "epoch": 5.61,
      "grad_norm": 4.057141304016113,
      "learning_rate": 3.2518370370370375e-05,
      "loss": 0.088,
      "step": 50530
    },
    {
      "epoch": 5.62,
      "grad_norm": 1.492222785949707,
      "learning_rate": 3.251688888888889e-05,
      "loss": 0.0503,
      "step": 50540
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.777072012424469,
      "learning_rate": 3.251540740740741e-05,
      "loss": 0.04,
      "step": 50550
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.299508810043335,
      "learning_rate": 3.2513925925925923e-05,
      "loss": 0.0837,
      "step": 50560
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.183908700942993,
      "learning_rate": 3.2512444444444446e-05,
      "loss": 0.0681,
      "step": 50570
    },
    {
      "epoch": 5.62,
      "grad_norm": 1.3632550239562988,
      "learning_rate": 3.251096296296297e-05,
      "loss": 0.0538,
      "step": 50580
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.1636810302734375,
      "learning_rate": 3.2509481481481485e-05,
      "loss": 0.0321,
      "step": 50590
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.69423770904541,
      "learning_rate": 3.2508e-05,
      "loss": 0.0787,
      "step": 50600
    },
    {
      "epoch": 5.62,
      "grad_norm": 5.917164325714111,
      "learning_rate": 3.250651851851852e-05,
      "loss": 0.0477,
      "step": 50610
    },
    {
      "epoch": 5.62,
      "grad_norm": 8.412760734558105,
      "learning_rate": 3.250503703703704e-05,
      "loss": 0.0657,
      "step": 50620
    },
    {
      "epoch": 5.63,
      "grad_norm": 3.4777791500091553,
      "learning_rate": 3.2503555555555556e-05,
      "loss": 0.0518,
      "step": 50630
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.23864126205444336,
      "learning_rate": 3.250207407407408e-05,
      "loss": 0.0484,
      "step": 50640
    },
    {
      "epoch": 5.63,
      "grad_norm": 15.000553131103516,
      "learning_rate": 3.2500592592592595e-05,
      "loss": 0.055,
      "step": 50650
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.6703367829322815,
      "learning_rate": 3.249911111111111e-05,
      "loss": 0.0568,
      "step": 50660
    },
    {
      "epoch": 5.63,
      "grad_norm": 1.8462218046188354,
      "learning_rate": 3.249762962962963e-05,
      "loss": 0.0583,
      "step": 50670
    },
    {
      "epoch": 5.63,
      "grad_norm": 3.165386199951172,
      "learning_rate": 3.249614814814815e-05,
      "loss": 0.0823,
      "step": 50680
    },
    {
      "epoch": 5.63,
      "grad_norm": 1.6569886207580566,
      "learning_rate": 3.249466666666667e-05,
      "loss": 0.0449,
      "step": 50690
    },
    {
      "epoch": 5.63,
      "grad_norm": 1.1572188138961792,
      "learning_rate": 3.249318518518519e-05,
      "loss": 0.0296,
      "step": 50700
    },
    {
      "epoch": 5.63,
      "grad_norm": 2.4051692485809326,
      "learning_rate": 3.2491703703703704e-05,
      "loss": 0.0676,
      "step": 50710
    },
    {
      "epoch": 5.64,
      "grad_norm": 4.70592737197876,
      "learning_rate": 3.249022222222222e-05,
      "loss": 0.0488,
      "step": 50720
    },
    {
      "epoch": 5.64,
      "grad_norm": 1.116942048072815,
      "learning_rate": 3.248874074074074e-05,
      "loss": 0.035,
      "step": 50730
    },
    {
      "epoch": 5.64,
      "grad_norm": 1.9257216453552246,
      "learning_rate": 3.2487259259259266e-05,
      "loss": 0.063,
      "step": 50740
    },
    {
      "epoch": 5.64,
      "grad_norm": 4.2710466384887695,
      "learning_rate": 3.248577777777778e-05,
      "loss": 0.0379,
      "step": 50750
    },
    {
      "epoch": 5.64,
      "grad_norm": 2.0246670246124268,
      "learning_rate": 3.24842962962963e-05,
      "loss": 0.0418,
      "step": 50760
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.22475457191467285,
      "learning_rate": 3.2482814814814814e-05,
      "loss": 0.0591,
      "step": 50770
    },
    {
      "epoch": 5.64,
      "grad_norm": 2.262190580368042,
      "learning_rate": 3.248133333333334e-05,
      "loss": 0.0568,
      "step": 50780
    },
    {
      "epoch": 5.64,
      "grad_norm": 2.6372711658477783,
      "learning_rate": 3.247985185185185e-05,
      "loss": 0.0728,
      "step": 50790
    },
    {
      "epoch": 5.64,
      "grad_norm": 6.870847702026367,
      "learning_rate": 3.2478370370370376e-05,
      "loss": 0.0989,
      "step": 50800
    },
    {
      "epoch": 5.65,
      "grad_norm": 2.601670026779175,
      "learning_rate": 3.247688888888889e-05,
      "loss": 0.055,
      "step": 50810
    },
    {
      "epoch": 5.65,
      "grad_norm": 4.254203796386719,
      "learning_rate": 3.247540740740741e-05,
      "loss": 0.0666,
      "step": 50820
    },
    {
      "epoch": 5.65,
      "grad_norm": 3.015622854232788,
      "learning_rate": 3.2473925925925924e-05,
      "loss": 0.0416,
      "step": 50830
    },
    {
      "epoch": 5.65,
      "grad_norm": 7.936769008636475,
      "learning_rate": 3.247244444444445e-05,
      "loss": 0.0429,
      "step": 50840
    },
    {
      "epoch": 5.65,
      "grad_norm": 1.9279178380966187,
      "learning_rate": 3.247096296296297e-05,
      "loss": 0.0219,
      "step": 50850
    },
    {
      "epoch": 5.65,
      "grad_norm": 1.686309576034546,
      "learning_rate": 3.2469481481481486e-05,
      "loss": 0.0851,
      "step": 50860
    },
    {
      "epoch": 5.65,
      "grad_norm": 6.911534786224365,
      "learning_rate": 3.2468e-05,
      "loss": 0.0687,
      "step": 50870
    },
    {
      "epoch": 5.65,
      "grad_norm": 9.672236442565918,
      "learning_rate": 3.246651851851852e-05,
      "loss": 0.1204,
      "step": 50880
    },
    {
      "epoch": 5.65,
      "grad_norm": 2.79795503616333,
      "learning_rate": 3.246503703703704e-05,
      "loss": 0.0675,
      "step": 50890
    },
    {
      "epoch": 5.66,
      "grad_norm": 6.300913333892822,
      "learning_rate": 3.2463555555555556e-05,
      "loss": 0.0565,
      "step": 50900
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.3331476151943207,
      "learning_rate": 3.246207407407408e-05,
      "loss": 0.0381,
      "step": 50910
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.1187512874603271,
      "learning_rate": 3.2460592592592595e-05,
      "loss": 0.072,
      "step": 50920
    },
    {
      "epoch": 5.66,
      "grad_norm": 4.154351234436035,
      "learning_rate": 3.245911111111111e-05,
      "loss": 0.0694,
      "step": 50930
    },
    {
      "epoch": 5.66,
      "grad_norm": 8.341139793395996,
      "learning_rate": 3.2457629629629634e-05,
      "loss": 0.0386,
      "step": 50940
    },
    {
      "epoch": 5.66,
      "grad_norm": 3.5240821838378906,
      "learning_rate": 3.245614814814815e-05,
      "loss": 0.101,
      "step": 50950
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.3316802680492401,
      "learning_rate": 3.245466666666667e-05,
      "loss": 0.032,
      "step": 50960
    },
    {
      "epoch": 5.66,
      "grad_norm": 2.8001275062561035,
      "learning_rate": 3.245318518518519e-05,
      "loss": 0.0651,
      "step": 50970
    },
    {
      "epoch": 5.66,
      "grad_norm": 7.3798041343688965,
      "learning_rate": 3.2451703703703705e-05,
      "loss": 0.0633,
      "step": 50980
    },
    {
      "epoch": 5.67,
      "grad_norm": 7.846176624298096,
      "learning_rate": 3.245022222222222e-05,
      "loss": 0.0564,
      "step": 50990
    },
    {
      "epoch": 5.67,
      "grad_norm": 2.0683090686798096,
      "learning_rate": 3.2448740740740744e-05,
      "loss": 0.042,
      "step": 51000
    },
    {
      "epoch": 5.67,
      "grad_norm": 1.5423333644866943,
      "learning_rate": 3.244725925925926e-05,
      "loss": 0.0686,
      "step": 51010
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.43271470069885254,
      "learning_rate": 3.244577777777778e-05,
      "loss": 0.0401,
      "step": 51020
    },
    {
      "epoch": 5.67,
      "grad_norm": 2.618070125579834,
      "learning_rate": 3.24442962962963e-05,
      "loss": 0.0589,
      "step": 51030
    },
    {
      "epoch": 5.67,
      "grad_norm": 2.7358927726745605,
      "learning_rate": 3.2442814814814815e-05,
      "loss": 0.0946,
      "step": 51040
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.3442717492580414,
      "learning_rate": 3.244133333333334e-05,
      "loss": 0.0449,
      "step": 51050
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.30466562509536743,
      "learning_rate": 3.2439851851851853e-05,
      "loss": 0.0646,
      "step": 51060
    },
    {
      "epoch": 5.67,
      "grad_norm": 7.402439117431641,
      "learning_rate": 3.2438370370370376e-05,
      "loss": 0.0622,
      "step": 51070
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.9295026063919067,
      "learning_rate": 3.243688888888889e-05,
      "loss": 0.053,
      "step": 51080
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.3470975160598755,
      "learning_rate": 3.243540740740741e-05,
      "loss": 0.1028,
      "step": 51090
    },
    {
      "epoch": 5.68,
      "grad_norm": 2.0067358016967773,
      "learning_rate": 3.2433925925925924e-05,
      "loss": 0.0633,
      "step": 51100
    },
    {
      "epoch": 5.68,
      "grad_norm": 2.5195367336273193,
      "learning_rate": 3.243244444444445e-05,
      "loss": 0.1562,
      "step": 51110
    },
    {
      "epoch": 5.68,
      "grad_norm": 3.4406535625457764,
      "learning_rate": 3.243096296296296e-05,
      "loss": 0.0571,
      "step": 51120
    },
    {
      "epoch": 5.68,
      "grad_norm": 4.899903774261475,
      "learning_rate": 3.2429481481481486e-05,
      "loss": 0.0666,
      "step": 51130
    },
    {
      "epoch": 5.68,
      "grad_norm": 6.614243984222412,
      "learning_rate": 3.2428e-05,
      "loss": 0.1537,
      "step": 51140
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.308321088552475,
      "learning_rate": 3.242651851851852e-05,
      "loss": 0.0343,
      "step": 51150
    },
    {
      "epoch": 5.68,
      "grad_norm": 5.170275688171387,
      "learning_rate": 3.242503703703704e-05,
      "loss": 0.0945,
      "step": 51160
    },
    {
      "epoch": 5.69,
      "grad_norm": 4.801329612731934,
      "learning_rate": 3.242355555555556e-05,
      "loss": 0.0736,
      "step": 51170
    },
    {
      "epoch": 5.69,
      "grad_norm": 1.964402675628662,
      "learning_rate": 3.242207407407408e-05,
      "loss": 0.0348,
      "step": 51180
    },
    {
      "epoch": 5.69,
      "grad_norm": 2.938002586364746,
      "learning_rate": 3.2420592592592596e-05,
      "loss": 0.0709,
      "step": 51190
    },
    {
      "epoch": 5.69,
      "grad_norm": 2.151427745819092,
      "learning_rate": 3.241911111111111e-05,
      "loss": 0.0393,
      "step": 51200
    },
    {
      "epoch": 5.69,
      "grad_norm": 3.5369842052459717,
      "learning_rate": 3.2417629629629634e-05,
      "loss": 0.0477,
      "step": 51210
    },
    {
      "epoch": 5.69,
      "grad_norm": 2.38724946975708,
      "learning_rate": 3.241614814814815e-05,
      "loss": 0.0583,
      "step": 51220
    },
    {
      "epoch": 5.69,
      "grad_norm": 1.9282286167144775,
      "learning_rate": 3.241466666666667e-05,
      "loss": 0.0448,
      "step": 51230
    },
    {
      "epoch": 5.69,
      "grad_norm": 1.9533305168151855,
      "learning_rate": 3.241318518518519e-05,
      "loss": 0.0474,
      "step": 51240
    },
    {
      "epoch": 5.69,
      "grad_norm": 3.0511670112609863,
      "learning_rate": 3.2411703703703705e-05,
      "loss": 0.0833,
      "step": 51250
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.622368335723877,
      "learning_rate": 3.241022222222222e-05,
      "loss": 0.0483,
      "step": 51260
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.22363169491291046,
      "learning_rate": 3.2408740740740744e-05,
      "loss": 0.0775,
      "step": 51270
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.8742661476135254,
      "learning_rate": 3.240725925925926e-05,
      "loss": 0.0802,
      "step": 51280
    },
    {
      "epoch": 5.7,
      "grad_norm": 3.4764575958251953,
      "learning_rate": 3.240577777777778e-05,
      "loss": 0.0501,
      "step": 51290
    },
    {
      "epoch": 5.7,
      "grad_norm": 4.3568010330200195,
      "learning_rate": 3.24042962962963e-05,
      "loss": 0.0781,
      "step": 51300
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.3974199295043945,
      "learning_rate": 3.2402814814814815e-05,
      "loss": 0.0316,
      "step": 51310
    },
    {
      "epoch": 5.7,
      "grad_norm": 4.106545925140381,
      "learning_rate": 3.240133333333334e-05,
      "loss": 0.0532,
      "step": 51320
    },
    {
      "epoch": 5.7,
      "grad_norm": 3.6279306411743164,
      "learning_rate": 3.2399851851851854e-05,
      "loss": 0.0547,
      "step": 51330
    },
    {
      "epoch": 5.7,
      "grad_norm": 7.605002403259277,
      "learning_rate": 3.2398370370370377e-05,
      "loss": 0.0826,
      "step": 51340
    },
    {
      "epoch": 5.71,
      "grad_norm": 4.04053258895874,
      "learning_rate": 3.239688888888889e-05,
      "loss": 0.0415,
      "step": 51350
    },
    {
      "epoch": 5.71,
      "grad_norm": 3.781362771987915,
      "learning_rate": 3.239540740740741e-05,
      "loss": 0.0766,
      "step": 51360
    },
    {
      "epoch": 5.71,
      "grad_norm": 4.227220058441162,
      "learning_rate": 3.2393925925925925e-05,
      "loss": 0.069,
      "step": 51370
    },
    {
      "epoch": 5.71,
      "grad_norm": 1.6252254247665405,
      "learning_rate": 3.239244444444445e-05,
      "loss": 0.0364,
      "step": 51380
    },
    {
      "epoch": 5.71,
      "grad_norm": 4.043648719787598,
      "learning_rate": 3.2390962962962963e-05,
      "loss": 0.0666,
      "step": 51390
    },
    {
      "epoch": 5.71,
      "grad_norm": 10.0340576171875,
      "learning_rate": 3.2389481481481486e-05,
      "loss": 0.0381,
      "step": 51400
    },
    {
      "epoch": 5.71,
      "grad_norm": 4.49154806137085,
      "learning_rate": 3.2388e-05,
      "loss": 0.0355,
      "step": 51410
    },
    {
      "epoch": 5.71,
      "grad_norm": 4.604608058929443,
      "learning_rate": 3.238651851851852e-05,
      "loss": 0.0291,
      "step": 51420
    },
    {
      "epoch": 5.71,
      "grad_norm": 0.2895120084285736,
      "learning_rate": 3.238503703703704e-05,
      "loss": 0.0373,
      "step": 51430
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.5658142566680908,
      "learning_rate": 3.238355555555556e-05,
      "loss": 0.0729,
      "step": 51440
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.7167575359344482,
      "learning_rate": 3.238207407407408e-05,
      "loss": 0.0819,
      "step": 51450
    },
    {
      "epoch": 5.72,
      "grad_norm": 7.349206447601318,
      "learning_rate": 3.2380592592592596e-05,
      "loss": 0.0697,
      "step": 51460
    },
    {
      "epoch": 5.72,
      "grad_norm": 3.4201271533966064,
      "learning_rate": 3.237911111111111e-05,
      "loss": 0.0722,
      "step": 51470
    },
    {
      "epoch": 5.72,
      "grad_norm": 7.594082832336426,
      "learning_rate": 3.2377629629629635e-05,
      "loss": 0.0825,
      "step": 51480
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.4938888549804688,
      "learning_rate": 3.237614814814815e-05,
      "loss": 0.0653,
      "step": 51490
    },
    {
      "epoch": 5.72,
      "grad_norm": 3.725959539413452,
      "learning_rate": 3.237466666666667e-05,
      "loss": 0.0517,
      "step": 51500
    },
    {
      "epoch": 5.72,
      "grad_norm": 8.1737699508667,
      "learning_rate": 3.237318518518519e-05,
      "loss": 0.0695,
      "step": 51510
    },
    {
      "epoch": 5.72,
      "grad_norm": 2.3420732021331787,
      "learning_rate": 3.2371703703703706e-05,
      "loss": 0.0747,
      "step": 51520
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.7559629082679749,
      "learning_rate": 3.237022222222222e-05,
      "loss": 0.065,
      "step": 51530
    },
    {
      "epoch": 5.73,
      "grad_norm": 5.742373466491699,
      "learning_rate": 3.2368740740740744e-05,
      "loss": 0.0583,
      "step": 51540
    },
    {
      "epoch": 5.73,
      "grad_norm": 18.45950698852539,
      "learning_rate": 3.236725925925926e-05,
      "loss": 0.0796,
      "step": 51550
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.5959960222244263,
      "learning_rate": 3.236577777777778e-05,
      "loss": 0.132,
      "step": 51560
    },
    {
      "epoch": 5.73,
      "grad_norm": 6.445610523223877,
      "learning_rate": 3.23642962962963e-05,
      "loss": 0.0848,
      "step": 51570
    },
    {
      "epoch": 5.73,
      "grad_norm": 4.787951469421387,
      "learning_rate": 3.2362814814814815e-05,
      "loss": 0.0589,
      "step": 51580
    },
    {
      "epoch": 5.73,
      "grad_norm": 1.9653280973434448,
      "learning_rate": 3.236133333333334e-05,
      "loss": 0.1147,
      "step": 51590
    },
    {
      "epoch": 5.73,
      "grad_norm": 7.151256561279297,
      "learning_rate": 3.2359851851851854e-05,
      "loss": 0.0738,
      "step": 51600
    },
    {
      "epoch": 5.73,
      "grad_norm": 1.0854521989822388,
      "learning_rate": 3.235837037037037e-05,
      "loss": 0.0356,
      "step": 51610
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.281052350997925,
      "learning_rate": 3.235688888888889e-05,
      "loss": 0.0247,
      "step": 51620
    },
    {
      "epoch": 5.74,
      "grad_norm": 14.23510456085205,
      "learning_rate": 3.235540740740741e-05,
      "loss": 0.062,
      "step": 51630
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.7673449516296387,
      "learning_rate": 3.2353925925925925e-05,
      "loss": 0.0468,
      "step": 51640
    },
    {
      "epoch": 5.74,
      "grad_norm": 6.382623672485352,
      "learning_rate": 3.235244444444445e-05,
      "loss": 0.0748,
      "step": 51650
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.7197376489639282,
      "learning_rate": 3.2350962962962964e-05,
      "loss": 0.0376,
      "step": 51660
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.961336374282837,
      "learning_rate": 3.234948148148149e-05,
      "loss": 0.0952,
      "step": 51670
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.2871525287628174,
      "learning_rate": 3.2348e-05,
      "loss": 0.0453,
      "step": 51680
    },
    {
      "epoch": 5.74,
      "grad_norm": 3.167856216430664,
      "learning_rate": 3.234651851851852e-05,
      "loss": 0.0926,
      "step": 51690
    },
    {
      "epoch": 5.74,
      "grad_norm": 3.535632610321045,
      "learning_rate": 3.234503703703704e-05,
      "loss": 0.082,
      "step": 51700
    },
    {
      "epoch": 5.75,
      "grad_norm": 4.232530117034912,
      "learning_rate": 3.234355555555556e-05,
      "loss": 0.0523,
      "step": 51710
    },
    {
      "epoch": 5.75,
      "grad_norm": 8.088179588317871,
      "learning_rate": 3.2342074074074074e-05,
      "loss": 0.0486,
      "step": 51720
    },
    {
      "epoch": 5.75,
      "grad_norm": 1.4910703897476196,
      "learning_rate": 3.2340592592592596e-05,
      "loss": 0.0902,
      "step": 51730
    },
    {
      "epoch": 5.75,
      "grad_norm": 2.579472780227661,
      "learning_rate": 3.233911111111111e-05,
      "loss": 0.1364,
      "step": 51740
    },
    {
      "epoch": 5.75,
      "grad_norm": 3.7775614261627197,
      "learning_rate": 3.2337629629629635e-05,
      "loss": 0.109,
      "step": 51750
    },
    {
      "epoch": 5.75,
      "grad_norm": 3.5030760765075684,
      "learning_rate": 3.233614814814815e-05,
      "loss": 0.0379,
      "step": 51760
    },
    {
      "epoch": 5.75,
      "grad_norm": 3.5364480018615723,
      "learning_rate": 3.233466666666667e-05,
      "loss": 0.0894,
      "step": 51770
    },
    {
      "epoch": 5.75,
      "grad_norm": 2.401662826538086,
      "learning_rate": 3.233318518518519e-05,
      "loss": 0.0813,
      "step": 51780
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.6389985084533691,
      "learning_rate": 3.2331703703703706e-05,
      "loss": 0.1052,
      "step": 51790
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.7960754036903381,
      "learning_rate": 3.233022222222222e-05,
      "loss": 0.0502,
      "step": 51800
    },
    {
      "epoch": 5.76,
      "grad_norm": 4.264707565307617,
      "learning_rate": 3.2328740740740745e-05,
      "loss": 0.0561,
      "step": 51810
    },
    {
      "epoch": 5.76,
      "grad_norm": 4.108318328857422,
      "learning_rate": 3.232725925925926e-05,
      "loss": 0.0728,
      "step": 51820
    },
    {
      "epoch": 5.76,
      "grad_norm": 2.2912895679473877,
      "learning_rate": 3.2325777777777784e-05,
      "loss": 0.0467,
      "step": 51830
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.3389323949813843,
      "learning_rate": 3.23242962962963e-05,
      "loss": 0.0665,
      "step": 51840
    },
    {
      "epoch": 5.76,
      "grad_norm": 2.9235177040100098,
      "learning_rate": 3.2322962962962963e-05,
      "loss": 0.2539,
      "step": 51850
    },
    {
      "epoch": 5.76,
      "grad_norm": 3.104032516479492,
      "learning_rate": 3.232148148148148e-05,
      "loss": 0.084,
      "step": 51860
    },
    {
      "epoch": 5.76,
      "grad_norm": 2.254769802093506,
      "learning_rate": 3.232e-05,
      "loss": 0.0396,
      "step": 51870
    },
    {
      "epoch": 5.76,
      "grad_norm": 2.406172513961792,
      "learning_rate": 3.2318518518518525e-05,
      "loss": 0.3258,
      "step": 51880
    },
    {
      "epoch": 5.77,
      "grad_norm": 2.791597843170166,
      "learning_rate": 3.231703703703704e-05,
      "loss": 0.3086,
      "step": 51890
    },
    {
      "epoch": 5.77,
      "grad_norm": 2.0561866760253906,
      "learning_rate": 3.231555555555556e-05,
      "loss": 0.0822,
      "step": 51900
    },
    {
      "epoch": 5.77,
      "grad_norm": 5.2500481605529785,
      "learning_rate": 3.231407407407407e-05,
      "loss": 0.0512,
      "step": 51910
    },
    {
      "epoch": 5.77,
      "grad_norm": 8.819172859191895,
      "learning_rate": 3.2312592592592596e-05,
      "loss": 0.0587,
      "step": 51920
    },
    {
      "epoch": 5.77,
      "grad_norm": 3.0107853412628174,
      "learning_rate": 3.231111111111111e-05,
      "loss": 0.0721,
      "step": 51930
    },
    {
      "epoch": 5.77,
      "grad_norm": 1.5433391332626343,
      "learning_rate": 3.2309629629629635e-05,
      "loss": 0.0254,
      "step": 51940
    },
    {
      "epoch": 5.77,
      "grad_norm": 9.017245292663574,
      "learning_rate": 3.230814814814815e-05,
      "loss": 0.0654,
      "step": 51950
    },
    {
      "epoch": 5.77,
      "grad_norm": 3.1253912448883057,
      "learning_rate": 3.230666666666667e-05,
      "loss": 0.0312,
      "step": 51960
    },
    {
      "epoch": 5.77,
      "grad_norm": 1.236945629119873,
      "learning_rate": 3.230518518518518e-05,
      "loss": 0.0274,
      "step": 51970
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.6879303455352783,
      "learning_rate": 3.2303703703703706e-05,
      "loss": 0.0646,
      "step": 51980
    },
    {
      "epoch": 5.78,
      "grad_norm": 3.6857852935791016,
      "learning_rate": 3.230222222222223e-05,
      "loss": 0.0609,
      "step": 51990
    },
    {
      "epoch": 5.78,
      "grad_norm": 3.4989683628082275,
      "learning_rate": 3.2300740740740744e-05,
      "loss": 0.0716,
      "step": 52000
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.4958336353302002,
      "learning_rate": 3.229925925925926e-05,
      "loss": 0.0764,
      "step": 52010
    },
    {
      "epoch": 5.78,
      "grad_norm": 3.9981906414031982,
      "learning_rate": 3.2297777777777776e-05,
      "loss": 0.1329,
      "step": 52020
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.2905267477035522,
      "learning_rate": 3.22962962962963e-05,
      "loss": 0.0526,
      "step": 52030
    },
    {
      "epoch": 5.78,
      "grad_norm": 2.2820959091186523,
      "learning_rate": 3.229481481481482e-05,
      "loss": 0.0531,
      "step": 52040
    },
    {
      "epoch": 5.78,
      "grad_norm": 4.887557506561279,
      "learning_rate": 3.229333333333334e-05,
      "loss": 0.0419,
      "step": 52050
    },
    {
      "epoch": 5.78,
      "grad_norm": 3.802544355392456,
      "learning_rate": 3.2291851851851854e-05,
      "loss": 0.0607,
      "step": 52060
    },
    {
      "epoch": 5.79,
      "grad_norm": 2.4812214374542236,
      "learning_rate": 3.229037037037037e-05,
      "loss": 0.0525,
      "step": 52070
    },
    {
      "epoch": 5.79,
      "grad_norm": 7.349134922027588,
      "learning_rate": 3.228888888888889e-05,
      "loss": 0.0293,
      "step": 52080
    },
    {
      "epoch": 5.79,
      "grad_norm": 3.020179271697998,
      "learning_rate": 3.228740740740741e-05,
      "loss": 0.0718,
      "step": 52090
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.745497465133667,
      "learning_rate": 3.228592592592593e-05,
      "loss": 0.0579,
      "step": 52100
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.9273006319999695,
      "learning_rate": 3.228444444444445e-05,
      "loss": 0.0768,
      "step": 52110
    },
    {
      "epoch": 5.79,
      "grad_norm": 1.5164130926132202,
      "learning_rate": 3.2282962962962964e-05,
      "loss": 0.063,
      "step": 52120
    },
    {
      "epoch": 5.79,
      "grad_norm": 3.346670627593994,
      "learning_rate": 3.228148148148148e-05,
      "loss": 0.0682,
      "step": 52130
    },
    {
      "epoch": 5.79,
      "grad_norm": 2.388127326965332,
      "learning_rate": 3.228e-05,
      "loss": 0.037,
      "step": 52140
    },
    {
      "epoch": 5.79,
      "grad_norm": 4.62101411819458,
      "learning_rate": 3.2278518518518525e-05,
      "loss": 0.09,
      "step": 52150
    },
    {
      "epoch": 5.8,
      "grad_norm": 3.1485843658447266,
      "learning_rate": 3.227703703703704e-05,
      "loss": 0.0532,
      "step": 52160
    },
    {
      "epoch": 5.8,
      "grad_norm": 4.313251972198486,
      "learning_rate": 3.227555555555556e-05,
      "loss": 0.0712,
      "step": 52170
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.13866740465164185,
      "learning_rate": 3.2274074074074074e-05,
      "loss": 0.0533,
      "step": 52180
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.1117881536483765,
      "learning_rate": 3.2272592592592596e-05,
      "loss": 0.0316,
      "step": 52190
    },
    {
      "epoch": 5.8,
      "grad_norm": 2.847933053970337,
      "learning_rate": 3.227111111111111e-05,
      "loss": 0.0741,
      "step": 52200
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.1812357902526855,
      "learning_rate": 3.2269629629629635e-05,
      "loss": 0.0836,
      "step": 52210
    },
    {
      "epoch": 5.8,
      "grad_norm": 3.7581334114074707,
      "learning_rate": 3.226814814814815e-05,
      "loss": 0.0686,
      "step": 52220
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.585870623588562,
      "learning_rate": 3.226666666666667e-05,
      "loss": 0.0554,
      "step": 52230
    },
    {
      "epoch": 5.8,
      "grad_norm": 2.014855146408081,
      "learning_rate": 3.226518518518518e-05,
      "loss": 0.044,
      "step": 52240
    },
    {
      "epoch": 5.81,
      "grad_norm": 3.245558023452759,
      "learning_rate": 3.2263703703703706e-05,
      "loss": 0.0576,
      "step": 52250
    },
    {
      "epoch": 5.81,
      "grad_norm": 4.988830089569092,
      "learning_rate": 3.226222222222223e-05,
      "loss": 0.0348,
      "step": 52260
    },
    {
      "epoch": 5.81,
      "grad_norm": 7.396153450012207,
      "learning_rate": 3.2260740740740745e-05,
      "loss": 0.0799,
      "step": 52270
    },
    {
      "epoch": 5.81,
      "grad_norm": 3.595107316970825,
      "learning_rate": 3.225925925925926e-05,
      "loss": 0.0812,
      "step": 52280
    },
    {
      "epoch": 5.81,
      "grad_norm": 5.922795295715332,
      "learning_rate": 3.225777777777778e-05,
      "loss": 0.074,
      "step": 52290
    },
    {
      "epoch": 5.81,
      "grad_norm": 7.325251579284668,
      "learning_rate": 3.22562962962963e-05,
      "loss": 0.0314,
      "step": 52300
    },
    {
      "epoch": 5.81,
      "grad_norm": 2.91536545753479,
      "learning_rate": 3.2254814814814816e-05,
      "loss": 0.0727,
      "step": 52310
    },
    {
      "epoch": 5.81,
      "grad_norm": 2.0936310291290283,
      "learning_rate": 3.225333333333334e-05,
      "loss": 0.0395,
      "step": 52320
    },
    {
      "epoch": 5.81,
      "grad_norm": 2.60445499420166,
      "learning_rate": 3.2251851851851855e-05,
      "loss": 0.1084,
      "step": 52330
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.5929187536239624,
      "learning_rate": 3.225037037037037e-05,
      "loss": 0.0855,
      "step": 52340
    },
    {
      "epoch": 5.82,
      "grad_norm": 13.152316093444824,
      "learning_rate": 3.2248888888888887e-05,
      "loss": 0.1033,
      "step": 52350
    },
    {
      "epoch": 5.82,
      "grad_norm": 3.017582893371582,
      "learning_rate": 3.224740740740741e-05,
      "loss": 0.0389,
      "step": 52360
    },
    {
      "epoch": 5.82,
      "grad_norm": 2.3126747608184814,
      "learning_rate": 3.224592592592593e-05,
      "loss": 0.0352,
      "step": 52370
    },
    {
      "epoch": 5.82,
      "grad_norm": 2.2030982971191406,
      "learning_rate": 3.224444444444445e-05,
      "loss": 0.0315,
      "step": 52380
    },
    {
      "epoch": 5.82,
      "grad_norm": 3.982485055923462,
      "learning_rate": 3.2242962962962964e-05,
      "loss": 0.0447,
      "step": 52390
    },
    {
      "epoch": 5.82,
      "grad_norm": 3.8432605266571045,
      "learning_rate": 3.224148148148148e-05,
      "loss": 0.0644,
      "step": 52400
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.8250636458396912,
      "learning_rate": 3.224e-05,
      "loss": 0.0834,
      "step": 52410
    },
    {
      "epoch": 5.82,
      "grad_norm": 9.673203468322754,
      "learning_rate": 3.223851851851852e-05,
      "loss": 0.0511,
      "step": 52420
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.24548956751823425,
      "learning_rate": 3.223703703703704e-05,
      "loss": 0.0535,
      "step": 52430
    },
    {
      "epoch": 5.83,
      "grad_norm": 4.935247421264648,
      "learning_rate": 3.223555555555556e-05,
      "loss": 0.0449,
      "step": 52440
    },
    {
      "epoch": 5.83,
      "grad_norm": 4.637390613555908,
      "learning_rate": 3.2234074074074074e-05,
      "loss": 0.0414,
      "step": 52450
    },
    {
      "epoch": 5.83,
      "grad_norm": 2.42366099357605,
      "learning_rate": 3.223259259259259e-05,
      "loss": 0.0546,
      "step": 52460
    },
    {
      "epoch": 5.83,
      "grad_norm": 2.2520291805267334,
      "learning_rate": 3.223111111111111e-05,
      "loss": 0.041,
      "step": 52470
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.09955587238073349,
      "learning_rate": 3.2229629629629636e-05,
      "loss": 0.0182,
      "step": 52480
    },
    {
      "epoch": 5.83,
      "grad_norm": 6.436296463012695,
      "learning_rate": 3.222814814814815e-05,
      "loss": 0.0758,
      "step": 52490
    },
    {
      "epoch": 5.83,
      "grad_norm": 5.698989391326904,
      "learning_rate": 3.222666666666667e-05,
      "loss": 0.0586,
      "step": 52500
    },
    {
      "epoch": 5.83,
      "grad_norm": 2.383868932723999,
      "learning_rate": 3.2225185185185184e-05,
      "loss": 0.0745,
      "step": 52510
    },
    {
      "epoch": 5.84,
      "grad_norm": 6.492386817932129,
      "learning_rate": 3.2223703703703706e-05,
      "loss": 0.1011,
      "step": 52520
    },
    {
      "epoch": 5.84,
      "grad_norm": 3.5840506553649902,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0698,
      "step": 52530
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.1138617992401123,
      "learning_rate": 3.2220740740740745e-05,
      "loss": 0.0587,
      "step": 52540
    },
    {
      "epoch": 5.84,
      "grad_norm": 3.5453827381134033,
      "learning_rate": 3.221925925925926e-05,
      "loss": 0.0406,
      "step": 52550
    },
    {
      "epoch": 5.84,
      "grad_norm": 3.071625232696533,
      "learning_rate": 3.221777777777778e-05,
      "loss": 0.0636,
      "step": 52560
    },
    {
      "epoch": 5.84,
      "grad_norm": 5.203312873840332,
      "learning_rate": 3.22162962962963e-05,
      "loss": 0.0441,
      "step": 52570
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.3674842119216919,
      "learning_rate": 3.2214814814814816e-05,
      "loss": 0.0501,
      "step": 52580
    },
    {
      "epoch": 5.84,
      "grad_norm": 4.085089683532715,
      "learning_rate": 3.221333333333334e-05,
      "loss": 0.0427,
      "step": 52590
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.658506155014038,
      "learning_rate": 3.2211851851851855e-05,
      "loss": 0.0439,
      "step": 52600
    },
    {
      "epoch": 5.85,
      "grad_norm": 3.601048469543457,
      "learning_rate": 3.221037037037037e-05,
      "loss": 0.0527,
      "step": 52610
    },
    {
      "epoch": 5.85,
      "grad_norm": 2.3244659900665283,
      "learning_rate": 3.220888888888889e-05,
      "loss": 0.075,
      "step": 52620
    },
    {
      "epoch": 5.85,
      "grad_norm": 1.3649468421936035,
      "learning_rate": 3.220740740740741e-05,
      "loss": 0.0219,
      "step": 52630
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.27532050013542175,
      "learning_rate": 3.220592592592593e-05,
      "loss": 0.0567,
      "step": 52640
    },
    {
      "epoch": 5.85,
      "grad_norm": 6.057807445526123,
      "learning_rate": 3.220444444444445e-05,
      "loss": 0.0569,
      "step": 52650
    },
    {
      "epoch": 5.85,
      "grad_norm": 9.674446105957031,
      "learning_rate": 3.2202962962962965e-05,
      "loss": 0.0451,
      "step": 52660
    },
    {
      "epoch": 5.85,
      "grad_norm": 27.556949615478516,
      "learning_rate": 3.220148148148148e-05,
      "loss": 0.067,
      "step": 52670
    },
    {
      "epoch": 5.85,
      "grad_norm": 2.4121198654174805,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.0553,
      "step": 52680
    },
    {
      "epoch": 5.85,
      "grad_norm": 3.7594075202941895,
      "learning_rate": 3.219851851851852e-05,
      "loss": 0.0564,
      "step": 52690
    },
    {
      "epoch": 5.86,
      "grad_norm": 6.039636135101318,
      "learning_rate": 3.219703703703704e-05,
      "loss": 0.069,
      "step": 52700
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.66028892993927,
      "learning_rate": 3.219555555555556e-05,
      "loss": 0.0244,
      "step": 52710
    },
    {
      "epoch": 5.86,
      "grad_norm": 5.333805561065674,
      "learning_rate": 3.2194074074074074e-05,
      "loss": 0.0621,
      "step": 52720
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.0907676219940186,
      "learning_rate": 3.219259259259259e-05,
      "loss": 0.034,
      "step": 52730
    },
    {
      "epoch": 5.86,
      "grad_norm": 3.252964973449707,
      "learning_rate": 3.219111111111111e-05,
      "loss": 0.086,
      "step": 52740
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.8975603580474854,
      "learning_rate": 3.2189629629629636e-05,
      "loss": 0.0214,
      "step": 52750
    },
    {
      "epoch": 5.86,
      "grad_norm": 7.123744964599609,
      "learning_rate": 3.218814814814815e-05,
      "loss": 0.1573,
      "step": 52760
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.3568772077560425,
      "learning_rate": 3.218666666666667e-05,
      "loss": 0.0507,
      "step": 52770
    },
    {
      "epoch": 5.86,
      "grad_norm": 2.8159170150756836,
      "learning_rate": 3.2185185185185184e-05,
      "loss": 0.0432,
      "step": 52780
    },
    {
      "epoch": 5.87,
      "grad_norm": 1.782963514328003,
      "learning_rate": 3.218370370370371e-05,
      "loss": 0.0422,
      "step": 52790
    },
    {
      "epoch": 5.87,
      "grad_norm": 2.680548667907715,
      "learning_rate": 3.218222222222222e-05,
      "loss": 0.0522,
      "step": 52800
    },
    {
      "epoch": 5.87,
      "grad_norm": 3.541867256164551,
      "learning_rate": 3.2180740740740746e-05,
      "loss": 0.0489,
      "step": 52810
    },
    {
      "epoch": 5.87,
      "grad_norm": 1.1678000688552856,
      "learning_rate": 3.217925925925926e-05,
      "loss": 0.0339,
      "step": 52820
    },
    {
      "epoch": 5.87,
      "grad_norm": 1.8167972564697266,
      "learning_rate": 3.217777777777778e-05,
      "loss": 0.0406,
      "step": 52830
    },
    {
      "epoch": 5.87,
      "grad_norm": 2.7032032012939453,
      "learning_rate": 3.21762962962963e-05,
      "loss": 0.0893,
      "step": 52840
    },
    {
      "epoch": 5.87,
      "grad_norm": 0.43077754974365234,
      "learning_rate": 3.2174814814814816e-05,
      "loss": 0.052,
      "step": 52850
    },
    {
      "epoch": 5.87,
      "grad_norm": 3.4791910648345947,
      "learning_rate": 3.217333333333334e-05,
      "loss": 0.0442,
      "step": 52860
    },
    {
      "epoch": 5.87,
      "grad_norm": 3.7926876544952393,
      "learning_rate": 3.2171851851851855e-05,
      "loss": 0.0421,
      "step": 52870
    },
    {
      "epoch": 5.88,
      "grad_norm": 2.4945881366729736,
      "learning_rate": 3.217037037037037e-05,
      "loss": 0.087,
      "step": 52880
    },
    {
      "epoch": 5.88,
      "grad_norm": 5.241199016571045,
      "learning_rate": 3.216888888888889e-05,
      "loss": 0.0614,
      "step": 52890
    },
    {
      "epoch": 5.88,
      "grad_norm": 7.337653636932373,
      "learning_rate": 3.216740740740741e-05,
      "loss": 0.0402,
      "step": 52900
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.3813265264034271,
      "learning_rate": 3.2165925925925926e-05,
      "loss": 0.0517,
      "step": 52910
    },
    {
      "epoch": 5.88,
      "grad_norm": 2.201425313949585,
      "learning_rate": 3.216444444444445e-05,
      "loss": 0.0748,
      "step": 52920
    },
    {
      "epoch": 5.88,
      "grad_norm": 3.09614896774292,
      "learning_rate": 3.2162962962962965e-05,
      "loss": 0.0677,
      "step": 52930
    },
    {
      "epoch": 5.88,
      "grad_norm": 2.4815499782562256,
      "learning_rate": 3.216148148148148e-05,
      "loss": 0.0511,
      "step": 52940
    },
    {
      "epoch": 5.88,
      "grad_norm": 2.265183210372925,
      "learning_rate": 3.2160000000000004e-05,
      "loss": 0.0511,
      "step": 52950
    },
    {
      "epoch": 5.88,
      "grad_norm": 3.113765001296997,
      "learning_rate": 3.215851851851852e-05,
      "loss": 0.0535,
      "step": 52960
    },
    {
      "epoch": 5.89,
      "grad_norm": 2.659370183944702,
      "learning_rate": 3.215703703703704e-05,
      "loss": 0.0374,
      "step": 52970
    },
    {
      "epoch": 5.89,
      "grad_norm": 1.6917386054992676,
      "learning_rate": 3.215555555555556e-05,
      "loss": 0.0361,
      "step": 52980
    },
    {
      "epoch": 5.89,
      "grad_norm": 4.108412742614746,
      "learning_rate": 3.2154074074074075e-05,
      "loss": 0.0553,
      "step": 52990
    },
    {
      "epoch": 5.89,
      "grad_norm": 5.475528240203857,
      "learning_rate": 3.215259259259259e-05,
      "loss": 0.0575,
      "step": 53000
    },
    {
      "epoch": 5.89,
      "grad_norm": 1.106911063194275,
      "learning_rate": 3.2151111111111113e-05,
      "loss": 0.0332,
      "step": 53010
    },
    {
      "epoch": 5.89,
      "grad_norm": 2.417379140853882,
      "learning_rate": 3.214962962962963e-05,
      "loss": 0.0574,
      "step": 53020
    },
    {
      "epoch": 5.89,
      "grad_norm": 3.4304826259613037,
      "learning_rate": 3.214814814814815e-05,
      "loss": 0.0722,
      "step": 53030
    },
    {
      "epoch": 5.89,
      "grad_norm": 4.36641263961792,
      "learning_rate": 3.214666666666667e-05,
      "loss": 0.0797,
      "step": 53040
    },
    {
      "epoch": 5.89,
      "grad_norm": 4.294862270355225,
      "learning_rate": 3.2145185185185184e-05,
      "loss": 0.0791,
      "step": 53050
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.6152492761611938,
      "learning_rate": 3.214370370370371e-05,
      "loss": 0.0374,
      "step": 53060
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.591304898262024,
      "learning_rate": 3.214222222222222e-05,
      "loss": 0.0466,
      "step": 53070
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.2747504711151123,
      "learning_rate": 3.2140740740740746e-05,
      "loss": 0.0646,
      "step": 53080
    },
    {
      "epoch": 5.9,
      "grad_norm": 6.417123794555664,
      "learning_rate": 3.213925925925926e-05,
      "loss": 0.0483,
      "step": 53090
    },
    {
      "epoch": 5.9,
      "grad_norm": 2.554260015487671,
      "learning_rate": 3.213777777777778e-05,
      "loss": 0.0678,
      "step": 53100
    },
    {
      "epoch": 5.9,
      "grad_norm": 3.2270612716674805,
      "learning_rate": 3.21362962962963e-05,
      "loss": 0.0692,
      "step": 53110
    },
    {
      "epoch": 5.9,
      "grad_norm": 3.89670991897583,
      "learning_rate": 3.213481481481482e-05,
      "loss": 0.0529,
      "step": 53120
    },
    {
      "epoch": 5.9,
      "grad_norm": 4.902414321899414,
      "learning_rate": 3.213333333333334e-05,
      "loss": 0.0502,
      "step": 53130
    },
    {
      "epoch": 5.9,
      "grad_norm": 4.553635120391846,
      "learning_rate": 3.2131851851851856e-05,
      "loss": 0.0758,
      "step": 53140
    },
    {
      "epoch": 5.91,
      "grad_norm": 11.453822135925293,
      "learning_rate": 3.213037037037037e-05,
      "loss": 0.0513,
      "step": 53150
    },
    {
      "epoch": 5.91,
      "grad_norm": 1.7612208127975464,
      "learning_rate": 3.212888888888889e-05,
      "loss": 0.0421,
      "step": 53160
    },
    {
      "epoch": 5.91,
      "grad_norm": 12.875171661376953,
      "learning_rate": 3.212740740740741e-05,
      "loss": 0.0533,
      "step": 53170
    },
    {
      "epoch": 5.91,
      "grad_norm": 2.579659938812256,
      "learning_rate": 3.2125925925925927e-05,
      "loss": 0.0762,
      "step": 53180
    },
    {
      "epoch": 5.91,
      "grad_norm": 2.639305830001831,
      "learning_rate": 3.212444444444445e-05,
      "loss": 0.0902,
      "step": 53190
    },
    {
      "epoch": 5.91,
      "grad_norm": 4.297587871551514,
      "learning_rate": 3.2122962962962965e-05,
      "loss": 0.0515,
      "step": 53200
    },
    {
      "epoch": 5.91,
      "grad_norm": 3.125054121017456,
      "learning_rate": 3.212148148148148e-05,
      "loss": 0.0868,
      "step": 53210
    },
    {
      "epoch": 5.91,
      "grad_norm": 4.058308124542236,
      "learning_rate": 3.2120000000000004e-05,
      "loss": 0.0477,
      "step": 53220
    },
    {
      "epoch": 5.91,
      "grad_norm": 1.1989388465881348,
      "learning_rate": 3.211851851851852e-05,
      "loss": 0.0644,
      "step": 53230
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.864159345626831,
      "learning_rate": 3.211703703703704e-05,
      "loss": 0.0904,
      "step": 53240
    },
    {
      "epoch": 5.92,
      "grad_norm": 12.141106605529785,
      "learning_rate": 3.211555555555556e-05,
      "loss": 0.0504,
      "step": 53250
    },
    {
      "epoch": 5.92,
      "grad_norm": 3.7090671062469482,
      "learning_rate": 3.2114074074074075e-05,
      "loss": 0.0489,
      "step": 53260
    },
    {
      "epoch": 5.92,
      "grad_norm": 3.160862922668457,
      "learning_rate": 3.21125925925926e-05,
      "loss": 0.0436,
      "step": 53270
    },
    {
      "epoch": 5.92,
      "grad_norm": 3.144299268722534,
      "learning_rate": 3.2111111111111114e-05,
      "loss": 0.028,
      "step": 53280
    },
    {
      "epoch": 5.92,
      "grad_norm": 5.71124792098999,
      "learning_rate": 3.210962962962963e-05,
      "loss": 0.0912,
      "step": 53290
    },
    {
      "epoch": 5.92,
      "grad_norm": 1.9411475658416748,
      "learning_rate": 3.210814814814815e-05,
      "loss": 0.051,
      "step": 53300
    },
    {
      "epoch": 5.92,
      "grad_norm": 4.287760257720947,
      "learning_rate": 3.210666666666667e-05,
      "loss": 0.055,
      "step": 53310
    },
    {
      "epoch": 5.92,
      "grad_norm": 6.021406173706055,
      "learning_rate": 3.2105185185185185e-05,
      "loss": 0.0284,
      "step": 53320
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.25667521357536316,
      "learning_rate": 3.210370370370371e-05,
      "loss": 0.0357,
      "step": 53330
    },
    {
      "epoch": 5.93,
      "grad_norm": 1.7708783149719238,
      "learning_rate": 3.2102222222222224e-05,
      "loss": 0.0664,
      "step": 53340
    },
    {
      "epoch": 5.93,
      "grad_norm": 10.34971809387207,
      "learning_rate": 3.2100740740740746e-05,
      "loss": 0.0642,
      "step": 53350
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.5600835680961609,
      "learning_rate": 3.209925925925926e-05,
      "loss": 0.0507,
      "step": 53360
    },
    {
      "epoch": 5.93,
      "grad_norm": 3.561427593231201,
      "learning_rate": 3.209777777777778e-05,
      "loss": 0.107,
      "step": 53370
    },
    {
      "epoch": 5.93,
      "grad_norm": 1.6259797811508179,
      "learning_rate": 3.20962962962963e-05,
      "loss": 0.0688,
      "step": 53380
    },
    {
      "epoch": 5.93,
      "grad_norm": 5.30299711227417,
      "learning_rate": 3.209481481481482e-05,
      "loss": 0.0801,
      "step": 53390
    },
    {
      "epoch": 5.93,
      "grad_norm": 4.232692718505859,
      "learning_rate": 3.209333333333333e-05,
      "loss": 0.0851,
      "step": 53400
    },
    {
      "epoch": 5.93,
      "grad_norm": 1.143160343170166,
      "learning_rate": 3.2091851851851856e-05,
      "loss": 0.0471,
      "step": 53410
    },
    {
      "epoch": 5.94,
      "grad_norm": 6.270195484161377,
      "learning_rate": 3.209037037037037e-05,
      "loss": 0.113,
      "step": 53420
    },
    {
      "epoch": 5.94,
      "grad_norm": 3.23022723197937,
      "learning_rate": 3.208888888888889e-05,
      "loss": 0.0308,
      "step": 53430
    },
    {
      "epoch": 5.94,
      "grad_norm": 3.393477201461792,
      "learning_rate": 3.208740740740741e-05,
      "loss": 0.0884,
      "step": 53440
    },
    {
      "epoch": 5.94,
      "grad_norm": 1.2640173435211182,
      "learning_rate": 3.208592592592593e-05,
      "loss": 0.0228,
      "step": 53450
    },
    {
      "epoch": 5.94,
      "grad_norm": 4.633253574371338,
      "learning_rate": 3.208444444444445e-05,
      "loss": 0.0356,
      "step": 53460
    },
    {
      "epoch": 5.94,
      "grad_norm": 1.0913141965866089,
      "learning_rate": 3.2082962962962966e-05,
      "loss": 0.0368,
      "step": 53470
    },
    {
      "epoch": 5.94,
      "grad_norm": 3.9081242084503174,
      "learning_rate": 3.208148148148148e-05,
      "loss": 0.0581,
      "step": 53480
    },
    {
      "epoch": 5.94,
      "grad_norm": 2.437953472137451,
      "learning_rate": 3.2080000000000005e-05,
      "loss": 0.067,
      "step": 53490
    },
    {
      "epoch": 5.94,
      "grad_norm": 3.495242118835449,
      "learning_rate": 3.207851851851852e-05,
      "loss": 0.0679,
      "step": 53500
    },
    {
      "epoch": 5.95,
      "grad_norm": 6.6708598136901855,
      "learning_rate": 3.2077037037037037e-05,
      "loss": 0.0534,
      "step": 53510
    },
    {
      "epoch": 5.95,
      "grad_norm": 3.3330657482147217,
      "learning_rate": 3.207555555555556e-05,
      "loss": 0.0535,
      "step": 53520
    },
    {
      "epoch": 5.95,
      "grad_norm": 1.2349518537521362,
      "learning_rate": 3.2074074074074075e-05,
      "loss": 0.0529,
      "step": 53530
    },
    {
      "epoch": 5.95,
      "grad_norm": 1.2692828178405762,
      "learning_rate": 3.20725925925926e-05,
      "loss": 0.0457,
      "step": 53540
    },
    {
      "epoch": 5.95,
      "grad_norm": 1.1797102689743042,
      "learning_rate": 3.2071111111111114e-05,
      "loss": 0.0418,
      "step": 53550
    },
    {
      "epoch": 5.95,
      "grad_norm": 2.977896213531494,
      "learning_rate": 3.206962962962963e-05,
      "loss": 0.0377,
      "step": 53560
    },
    {
      "epoch": 5.95,
      "grad_norm": 1.8128448724746704,
      "learning_rate": 3.206814814814815e-05,
      "loss": 0.0776,
      "step": 53570
    },
    {
      "epoch": 5.95,
      "grad_norm": 4.841933250427246,
      "learning_rate": 3.206666666666667e-05,
      "loss": 0.0552,
      "step": 53580
    },
    {
      "epoch": 5.95,
      "grad_norm": 1.707951307296753,
      "learning_rate": 3.2065185185185185e-05,
      "loss": 0.06,
      "step": 53590
    },
    {
      "epoch": 5.96,
      "grad_norm": 6.505437850952148,
      "learning_rate": 3.206370370370371e-05,
      "loss": 0.0656,
      "step": 53600
    },
    {
      "epoch": 5.96,
      "grad_norm": 4.56049108505249,
      "learning_rate": 3.2062222222222224e-05,
      "loss": 0.1133,
      "step": 53610
    },
    {
      "epoch": 5.96,
      "grad_norm": 17.95296287536621,
      "learning_rate": 3.206074074074075e-05,
      "loss": 0.1626,
      "step": 53620
    },
    {
      "epoch": 5.96,
      "grad_norm": 4.6395745277404785,
      "learning_rate": 3.205925925925926e-05,
      "loss": 0.0601,
      "step": 53630
    },
    {
      "epoch": 5.96,
      "grad_norm": 2.5490031242370605,
      "learning_rate": 3.205777777777778e-05,
      "loss": 0.0395,
      "step": 53640
    },
    {
      "epoch": 5.96,
      "grad_norm": 5.488868713378906,
      "learning_rate": 3.20562962962963e-05,
      "loss": 0.0541,
      "step": 53650
    },
    {
      "epoch": 5.96,
      "grad_norm": 2.783759117126465,
      "learning_rate": 3.205481481481482e-05,
      "loss": 0.041,
      "step": 53660
    },
    {
      "epoch": 5.96,
      "grad_norm": 13.091504096984863,
      "learning_rate": 3.2053333333333334e-05,
      "loss": 0.0857,
      "step": 53670
    },
    {
      "epoch": 5.96,
      "grad_norm": 4.019546031951904,
      "learning_rate": 3.2051851851851856e-05,
      "loss": 0.0376,
      "step": 53680
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.5159923434257507,
      "learning_rate": 3.205037037037037e-05,
      "loss": 0.0281,
      "step": 53690
    },
    {
      "epoch": 5.97,
      "grad_norm": 1.8243484497070312,
      "learning_rate": 3.204888888888889e-05,
      "loss": 0.0341,
      "step": 53700
    },
    {
      "epoch": 5.97,
      "grad_norm": 3.5852715969085693,
      "learning_rate": 3.204740740740741e-05,
      "loss": 0.0519,
      "step": 53710
    },
    {
      "epoch": 5.97,
      "grad_norm": 1.5897626876831055,
      "learning_rate": 3.204592592592593e-05,
      "loss": 0.0649,
      "step": 53720
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.30108824372291565,
      "learning_rate": 3.204444444444445e-05,
      "loss": 0.047,
      "step": 53730
    },
    {
      "epoch": 5.97,
      "grad_norm": 2.168445110321045,
      "learning_rate": 3.2042962962962966e-05,
      "loss": 0.033,
      "step": 53740
    },
    {
      "epoch": 5.97,
      "grad_norm": 39.79447555541992,
      "learning_rate": 3.204148148148148e-05,
      "loss": 0.0598,
      "step": 53750
    },
    {
      "epoch": 5.97,
      "grad_norm": 5.048728942871094,
      "learning_rate": 3.2040000000000005e-05,
      "loss": 0.0531,
      "step": 53760
    },
    {
      "epoch": 5.97,
      "grad_norm": 2.0279648303985596,
      "learning_rate": 3.203851851851852e-05,
      "loss": 0.0683,
      "step": 53770
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.5003674030303955,
      "learning_rate": 3.203703703703704e-05,
      "loss": 0.0716,
      "step": 53780
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.6728150844573975,
      "learning_rate": 3.203555555555556e-05,
      "loss": 0.0505,
      "step": 53790
    },
    {
      "epoch": 5.98,
      "grad_norm": 7.781451225280762,
      "learning_rate": 3.2034074074074076e-05,
      "loss": 0.0543,
      "step": 53800
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.970231533050537,
      "learning_rate": 3.20325925925926e-05,
      "loss": 0.1038,
      "step": 53810
    },
    {
      "epoch": 5.98,
      "grad_norm": 10.020787239074707,
      "learning_rate": 3.2031111111111115e-05,
      "loss": 0.0494,
      "step": 53820
    },
    {
      "epoch": 5.98,
      "grad_norm": 12.24332332611084,
      "learning_rate": 3.202962962962963e-05,
      "loss": 0.0643,
      "step": 53830
    },
    {
      "epoch": 5.98,
      "grad_norm": 4.4325079917907715,
      "learning_rate": 3.2028148148148153e-05,
      "loss": 0.0596,
      "step": 53840
    },
    {
      "epoch": 5.98,
      "grad_norm": 3.8132948875427246,
      "learning_rate": 3.202666666666667e-05,
      "loss": 0.0331,
      "step": 53850
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.1675047874450684,
      "learning_rate": 3.2025185185185186e-05,
      "loss": 0.0519,
      "step": 53860
    },
    {
      "epoch": 5.99,
      "grad_norm": 3.969068765640259,
      "learning_rate": 3.202370370370371e-05,
      "loss": 0.0637,
      "step": 53870
    },
    {
      "epoch": 5.99,
      "grad_norm": 5.748960971832275,
      "learning_rate": 3.2022222222222224e-05,
      "loss": 0.103,
      "step": 53880
    },
    {
      "epoch": 5.99,
      "grad_norm": 3.9315433502197266,
      "learning_rate": 3.202074074074074e-05,
      "loss": 0.0825,
      "step": 53890
    },
    {
      "epoch": 5.99,
      "grad_norm": 3.0249691009521484,
      "learning_rate": 3.201925925925926e-05,
      "loss": 0.0344,
      "step": 53900
    },
    {
      "epoch": 5.99,
      "grad_norm": 3.910722017288208,
      "learning_rate": 3.201777777777778e-05,
      "loss": 0.0546,
      "step": 53910
    },
    {
      "epoch": 5.99,
      "grad_norm": 6.179230213165283,
      "learning_rate": 3.20162962962963e-05,
      "loss": 0.077,
      "step": 53920
    },
    {
      "epoch": 5.99,
      "grad_norm": 0.7047728300094604,
      "learning_rate": 3.201481481481482e-05,
      "loss": 0.0535,
      "step": 53930
    },
    {
      "epoch": 5.99,
      "grad_norm": 2.6423327922821045,
      "learning_rate": 3.2013333333333334e-05,
      "loss": 0.0476,
      "step": 53940
    },
    {
      "epoch": 5.99,
      "grad_norm": 3.3005170822143555,
      "learning_rate": 3.201185185185186e-05,
      "loss": 0.0329,
      "step": 53950
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.573298454284668,
      "learning_rate": 3.201037037037037e-05,
      "loss": 0.0503,
      "step": 53960
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.0505027770996094,
      "learning_rate": 3.200888888888889e-05,
      "loss": 0.0338,
      "step": 53970
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.4290443658828735,
      "learning_rate": 3.200740740740741e-05,
      "loss": 0.0624,
      "step": 53980
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.7011677026748657,
      "learning_rate": 3.200592592592593e-05,
      "loss": 0.0993,
      "step": 53990
    },
    {
      "epoch": 6.0,
      "grad_norm": 7.970431327819824,
      "learning_rate": 3.2004444444444444e-05,
      "loss": 0.0623,
      "step": 54000
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.7350988388061523,
      "learning_rate": 3.2002962962962967e-05,
      "loss": 0.0326,
      "step": 54010
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3254704177379608,
      "learning_rate": 3.200148148148148e-05,
      "loss": 0.0463,
      "step": 54020
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.868056535720825,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0302,
      "step": 54030
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.4211947917938232,
      "learning_rate": 3.199851851851852e-05,
      "loss": 0.0479,
      "step": 54040
    },
    {
      "epoch": 6.01,
      "grad_norm": 5.626839637756348,
      "learning_rate": 3.199703703703704e-05,
      "loss": 0.0557,
      "step": 54050
    },
    {
      "epoch": 6.01,
      "grad_norm": 2.6090078353881836,
      "learning_rate": 3.199555555555556e-05,
      "loss": 0.0824,
      "step": 54060
    },
    {
      "epoch": 6.01,
      "grad_norm": 13.087677001953125,
      "learning_rate": 3.1994074074074076e-05,
      "loss": 0.0596,
      "step": 54070
    },
    {
      "epoch": 6.01,
      "grad_norm": 1.268447995185852,
      "learning_rate": 3.19925925925926e-05,
      "loss": 0.0463,
      "step": 54080
    },
    {
      "epoch": 6.01,
      "grad_norm": 4.432596206665039,
      "learning_rate": 3.1991111111111115e-05,
      "loss": 0.0585,
      "step": 54090
    },
    {
      "epoch": 6.01,
      "grad_norm": 6.258397579193115,
      "learning_rate": 3.198962962962963e-05,
      "loss": 0.0494,
      "step": 54100
    },
    {
      "epoch": 6.01,
      "grad_norm": 1.854607343673706,
      "learning_rate": 3.198814814814815e-05,
      "loss": 0.0402,
      "step": 54110
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.9206136465072632,
      "learning_rate": 3.198666666666667e-05,
      "loss": 0.0364,
      "step": 54120
    },
    {
      "epoch": 6.01,
      "grad_norm": 4.184159755706787,
      "learning_rate": 3.1985185185185186e-05,
      "loss": 0.0988,
      "step": 54130
    },
    {
      "epoch": 6.02,
      "grad_norm": 2.5541162490844727,
      "learning_rate": 3.198370370370371e-05,
      "loss": 0.0387,
      "step": 54140
    },
    {
      "epoch": 6.02,
      "grad_norm": 3.0069313049316406,
      "learning_rate": 3.1982222222222225e-05,
      "loss": 0.0496,
      "step": 54150
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.7123768329620361,
      "learning_rate": 3.198074074074074e-05,
      "loss": 0.0412,
      "step": 54160
    },
    {
      "epoch": 6.02,
      "grad_norm": 4.74331521987915,
      "learning_rate": 3.1979259259259264e-05,
      "loss": 0.0367,
      "step": 54170
    },
    {
      "epoch": 6.02,
      "grad_norm": 12.409819602966309,
      "learning_rate": 3.197777777777778e-05,
      "loss": 0.053,
      "step": 54180
    },
    {
      "epoch": 6.02,
      "grad_norm": 3.142404317855835,
      "learning_rate": 3.19762962962963e-05,
      "loss": 0.0601,
      "step": 54190
    },
    {
      "epoch": 6.02,
      "grad_norm": 2.4197354316711426,
      "learning_rate": 3.197481481481482e-05,
      "loss": 0.0345,
      "step": 54200
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.614461898803711,
      "learning_rate": 3.1973333333333334e-05,
      "loss": 0.0653,
      "step": 54210
    },
    {
      "epoch": 6.02,
      "grad_norm": 2.9381721019744873,
      "learning_rate": 3.197185185185186e-05,
      "loss": 0.0483,
      "step": 54220
    },
    {
      "epoch": 6.03,
      "grad_norm": 2.707642078399658,
      "learning_rate": 3.197037037037037e-05,
      "loss": 0.0514,
      "step": 54230
    },
    {
      "epoch": 6.03,
      "grad_norm": 5.7823100090026855,
      "learning_rate": 3.196888888888889e-05,
      "loss": 0.0754,
      "step": 54240
    },
    {
      "epoch": 6.03,
      "grad_norm": 1.57036292552948,
      "learning_rate": 3.196740740740741e-05,
      "loss": 0.0342,
      "step": 54250
    },
    {
      "epoch": 6.03,
      "grad_norm": 3.6800241470336914,
      "learning_rate": 3.196592592592593e-05,
      "loss": 0.049,
      "step": 54260
    },
    {
      "epoch": 6.03,
      "grad_norm": 4.4940924644470215,
      "learning_rate": 3.1964444444444444e-05,
      "loss": 0.05,
      "step": 54270
    },
    {
      "epoch": 6.03,
      "grad_norm": 1.8623560667037964,
      "learning_rate": 3.196296296296297e-05,
      "loss": 0.0715,
      "step": 54280
    },
    {
      "epoch": 6.03,
      "grad_norm": 2.653832197189331,
      "learning_rate": 3.196148148148148e-05,
      "loss": 0.0198,
      "step": 54290
    },
    {
      "epoch": 6.03,
      "grad_norm": 5.972567081451416,
      "learning_rate": 3.1960000000000006e-05,
      "loss": 0.093,
      "step": 54300
    },
    {
      "epoch": 6.03,
      "grad_norm": 1.9448713064193726,
      "learning_rate": 3.195851851851852e-05,
      "loss": 0.0368,
      "step": 54310
    },
    {
      "epoch": 6.04,
      "grad_norm": 10.883262634277344,
      "learning_rate": 3.195703703703704e-05,
      "loss": 0.0704,
      "step": 54320
    },
    {
      "epoch": 6.04,
      "grad_norm": 4.358019828796387,
      "learning_rate": 3.195555555555556e-05,
      "loss": 0.0576,
      "step": 54330
    },
    {
      "epoch": 6.04,
      "grad_norm": 6.285129070281982,
      "learning_rate": 3.1954074074074077e-05,
      "loss": 0.0686,
      "step": 54340
    },
    {
      "epoch": 6.04,
      "grad_norm": 3.82765793800354,
      "learning_rate": 3.19525925925926e-05,
      "loss": 0.0807,
      "step": 54350
    },
    {
      "epoch": 6.04,
      "grad_norm": 5.343025207519531,
      "learning_rate": 3.1951111111111115e-05,
      "loss": 0.0385,
      "step": 54360
    },
    {
      "epoch": 6.04,
      "grad_norm": 2.841445207595825,
      "learning_rate": 3.194962962962963e-05,
      "loss": 0.0538,
      "step": 54370
    },
    {
      "epoch": 6.04,
      "grad_norm": 4.238126277923584,
      "learning_rate": 3.194814814814815e-05,
      "loss": 0.0356,
      "step": 54380
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.270005464553833,
      "learning_rate": 3.194666666666667e-05,
      "loss": 0.0365,
      "step": 54390
    },
    {
      "epoch": 6.04,
      "grad_norm": 4.146922588348389,
      "learning_rate": 3.1945185185185186e-05,
      "loss": 0.042,
      "step": 54400
    },
    {
      "epoch": 6.05,
      "grad_norm": 1.7351535558700562,
      "learning_rate": 3.194370370370371e-05,
      "loss": 0.0647,
      "step": 54410
    },
    {
      "epoch": 6.05,
      "grad_norm": 6.495873928070068,
      "learning_rate": 3.1942222222222225e-05,
      "loss": 0.0379,
      "step": 54420
    },
    {
      "epoch": 6.05,
      "grad_norm": 1.4859063625335693,
      "learning_rate": 3.194074074074074e-05,
      "loss": 0.0386,
      "step": 54430
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.5194109678268433,
      "learning_rate": 3.1939259259259264e-05,
      "loss": 0.0393,
      "step": 54440
    },
    {
      "epoch": 6.05,
      "grad_norm": 3.3174662590026855,
      "learning_rate": 3.193777777777778e-05,
      "loss": 0.0391,
      "step": 54450
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.7972211837768555,
      "learning_rate": 3.19362962962963e-05,
      "loss": 0.0472,
      "step": 54460
    },
    {
      "epoch": 6.05,
      "grad_norm": 2.8836231231689453,
      "learning_rate": 3.193481481481482e-05,
      "loss": 0.0491,
      "step": 54470
    },
    {
      "epoch": 6.05,
      "grad_norm": 1.137176752090454,
      "learning_rate": 3.1933333333333335e-05,
      "loss": 0.0518,
      "step": 54480
    },
    {
      "epoch": 6.05,
      "grad_norm": 1.553760051727295,
      "learning_rate": 3.193185185185185e-05,
      "loss": 0.0831,
      "step": 54490
    },
    {
      "epoch": 6.06,
      "grad_norm": 6.785778522491455,
      "learning_rate": 3.1930370370370374e-05,
      "loss": 0.0956,
      "step": 54500
    },
    {
      "epoch": 6.06,
      "grad_norm": 6.320379734039307,
      "learning_rate": 3.1928888888888896e-05,
      "loss": 0.0397,
      "step": 54510
    },
    {
      "epoch": 6.06,
      "grad_norm": 4.490683555603027,
      "learning_rate": 3.192740740740741e-05,
      "loss": 0.0598,
      "step": 54520
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.446905493736267,
      "learning_rate": 3.192592592592593e-05,
      "loss": 0.0429,
      "step": 54530
    },
    {
      "epoch": 6.06,
      "grad_norm": 3.5534517765045166,
      "learning_rate": 3.1924444444444444e-05,
      "loss": 0.0327,
      "step": 54540
    },
    {
      "epoch": 6.06,
      "grad_norm": 4.167966365814209,
      "learning_rate": 3.192296296296297e-05,
      "loss": 0.0426,
      "step": 54550
    },
    {
      "epoch": 6.06,
      "grad_norm": 2.2121059894561768,
      "learning_rate": 3.192148148148148e-05,
      "loss": 0.0583,
      "step": 54560
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.422584056854248,
      "learning_rate": 3.1920000000000006e-05,
      "loss": 0.0233,
      "step": 54570
    },
    {
      "epoch": 6.06,
      "grad_norm": 3.769713878631592,
      "learning_rate": 3.191851851851852e-05,
      "loss": 0.0546,
      "step": 54580
    },
    {
      "epoch": 6.07,
      "grad_norm": 3.9605307579040527,
      "learning_rate": 3.191703703703704e-05,
      "loss": 0.0469,
      "step": 54590
    },
    {
      "epoch": 6.07,
      "grad_norm": 0.4064443111419678,
      "learning_rate": 3.1915555555555554e-05,
      "loss": 0.0575,
      "step": 54600
    },
    {
      "epoch": 6.07,
      "grad_norm": 6.318803787231445,
      "learning_rate": 3.191407407407408e-05,
      "loss": 0.0844,
      "step": 54610
    },
    {
      "epoch": 6.07,
      "grad_norm": 1.564308762550354,
      "learning_rate": 3.19125925925926e-05,
      "loss": 0.0458,
      "step": 54620
    },
    {
      "epoch": 6.07,
      "grad_norm": 0.34023764729499817,
      "learning_rate": 3.1911111111111116e-05,
      "loss": 0.041,
      "step": 54630
    },
    {
      "epoch": 6.07,
      "grad_norm": 3.6109988689422607,
      "learning_rate": 3.190962962962963e-05,
      "loss": 0.0691,
      "step": 54640
    },
    {
      "epoch": 6.07,
      "grad_norm": 7.556441783905029,
      "learning_rate": 3.190814814814815e-05,
      "loss": 0.068,
      "step": 54650
    },
    {
      "epoch": 6.07,
      "grad_norm": 4.906949996948242,
      "learning_rate": 3.190666666666667e-05,
      "loss": 0.0636,
      "step": 54660
    },
    {
      "epoch": 6.07,
      "grad_norm": 1.4954302310943604,
      "learning_rate": 3.190518518518519e-05,
      "loss": 0.0614,
      "step": 54670
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.0679398775100708,
      "learning_rate": 3.190370370370371e-05,
      "loss": 0.0309,
      "step": 54680
    },
    {
      "epoch": 6.08,
      "grad_norm": 3.09865665435791,
      "learning_rate": 3.1902222222222225e-05,
      "loss": 0.0712,
      "step": 54690
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.170152187347412,
      "learning_rate": 3.190074074074074e-05,
      "loss": 0.0349,
      "step": 54700
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.05035400390625,
      "learning_rate": 3.1899259259259264e-05,
      "loss": 0.0706,
      "step": 54710
    },
    {
      "epoch": 6.08,
      "grad_norm": 5.664079189300537,
      "learning_rate": 3.189777777777778e-05,
      "loss": 0.0387,
      "step": 54720
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.873623251914978,
      "learning_rate": 3.18962962962963e-05,
      "loss": 0.0398,
      "step": 54730
    },
    {
      "epoch": 6.08,
      "grad_norm": 5.447009086608887,
      "learning_rate": 3.189481481481482e-05,
      "loss": 0.0705,
      "step": 54740
    },
    {
      "epoch": 6.08,
      "grad_norm": 3.323734998703003,
      "learning_rate": 3.1893333333333335e-05,
      "loss": 0.0427,
      "step": 54750
    },
    {
      "epoch": 6.08,
      "grad_norm": 2.9333784580230713,
      "learning_rate": 3.189185185185185e-05,
      "loss": 0.055,
      "step": 54760
    },
    {
      "epoch": 6.09,
      "grad_norm": 1.431201457977295,
      "learning_rate": 3.1890370370370374e-05,
      "loss": 0.0765,
      "step": 54770
    },
    {
      "epoch": 6.09,
      "grad_norm": 1.0233795642852783,
      "learning_rate": 3.18888888888889e-05,
      "loss": 0.1269,
      "step": 54780
    },
    {
      "epoch": 6.09,
      "grad_norm": 2.281980514526367,
      "learning_rate": 3.188740740740741e-05,
      "loss": 0.0479,
      "step": 54790
    },
    {
      "epoch": 6.09,
      "grad_norm": 3.1968438625335693,
      "learning_rate": 3.188592592592593e-05,
      "loss": 0.0759,
      "step": 54800
    },
    {
      "epoch": 6.09,
      "grad_norm": 2.8837153911590576,
      "learning_rate": 3.1884444444444445e-05,
      "loss": 0.0254,
      "step": 54810
    },
    {
      "epoch": 6.09,
      "grad_norm": 2.4581446647644043,
      "learning_rate": 3.188296296296297e-05,
      "loss": 0.055,
      "step": 54820
    },
    {
      "epoch": 6.09,
      "grad_norm": 4.553652763366699,
      "learning_rate": 3.1881481481481484e-05,
      "loss": 0.0412,
      "step": 54830
    },
    {
      "epoch": 6.09,
      "grad_norm": 2.473292827606201,
      "learning_rate": 3.1880000000000006e-05,
      "loss": 0.0255,
      "step": 54840
    },
    {
      "epoch": 6.09,
      "grad_norm": 6.804787635803223,
      "learning_rate": 3.187851851851852e-05,
      "loss": 0.0829,
      "step": 54850
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.8005435466766357,
      "learning_rate": 3.187703703703704e-05,
      "loss": 0.04,
      "step": 54860
    },
    {
      "epoch": 6.1,
      "grad_norm": 5.309567928314209,
      "learning_rate": 3.1875555555555555e-05,
      "loss": 0.05,
      "step": 54870
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.790440797805786,
      "learning_rate": 3.187407407407408e-05,
      "loss": 0.0585,
      "step": 54880
    },
    {
      "epoch": 6.1,
      "grad_norm": 4.74250602722168,
      "learning_rate": 3.18725925925926e-05,
      "loss": 0.0426,
      "step": 54890
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.4583239555358887,
      "learning_rate": 3.1871111111111116e-05,
      "loss": 0.0735,
      "step": 54900
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.6281728744506836,
      "learning_rate": 3.186962962962963e-05,
      "loss": 0.046,
      "step": 54910
    },
    {
      "epoch": 6.1,
      "grad_norm": 4.34016227722168,
      "learning_rate": 3.186814814814815e-05,
      "loss": 0.0759,
      "step": 54920
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.36692410707473755,
      "learning_rate": 3.186666666666667e-05,
      "loss": 0.0607,
      "step": 54930
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.5201516151428223,
      "learning_rate": 3.186518518518519e-05,
      "loss": 0.0656,
      "step": 54940
    },
    {
      "epoch": 6.11,
      "grad_norm": 19.547992706298828,
      "learning_rate": 3.186370370370371e-05,
      "loss": 0.0346,
      "step": 54950
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.24617433547973633,
      "learning_rate": 3.1862222222222226e-05,
      "loss": 0.0279,
      "step": 54960
    },
    {
      "epoch": 6.11,
      "grad_norm": 1.3315454721450806,
      "learning_rate": 3.186074074074074e-05,
      "loss": 0.0303,
      "step": 54970
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.7321655750274658,
      "learning_rate": 3.185925925925926e-05,
      "loss": 0.0453,
      "step": 54980
    },
    {
      "epoch": 6.11,
      "grad_norm": 2.873462677001953,
      "learning_rate": 3.185777777777778e-05,
      "loss": 0.0383,
      "step": 54990
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.18541483581066132,
      "learning_rate": 3.1856296296296304e-05,
      "loss": 0.0404,
      "step": 55000
    },
    {
      "epoch": 6.11,
      "grad_norm": 4.694636344909668,
      "learning_rate": 3.185481481481482e-05,
      "loss": 0.0392,
      "step": 55010
    },
    {
      "epoch": 6.11,
      "grad_norm": 7.518099308013916,
      "learning_rate": 3.1853333333333336e-05,
      "loss": 0.0466,
      "step": 55020
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.11926310509443283,
      "learning_rate": 3.185185185185185e-05,
      "loss": 0.0411,
      "step": 55030
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.12858286499977112,
      "learning_rate": 3.1850370370370374e-05,
      "loss": 0.0783,
      "step": 55040
    },
    {
      "epoch": 6.12,
      "grad_norm": 2.309285879135132,
      "learning_rate": 3.184888888888889e-05,
      "loss": 0.0664,
      "step": 55050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.8651636838912964,
      "learning_rate": 3.184740740740741e-05,
      "loss": 0.0433,
      "step": 55060
    },
    {
      "epoch": 6.12,
      "grad_norm": 5.54053258895874,
      "learning_rate": 3.184592592592593e-05,
      "loss": 0.0576,
      "step": 55070
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.8536975979804993,
      "learning_rate": 3.1844444444444445e-05,
      "loss": 0.0369,
      "step": 55080
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.6721494197845459,
      "learning_rate": 3.184296296296296e-05,
      "loss": 0.0451,
      "step": 55090
    },
    {
      "epoch": 6.12,
      "grad_norm": 4.088085651397705,
      "learning_rate": 3.1841481481481484e-05,
      "loss": 0.0453,
      "step": 55100
    },
    {
      "epoch": 6.12,
      "grad_norm": 4.134459972381592,
      "learning_rate": 3.184000000000001e-05,
      "loss": 0.0535,
      "step": 55110
    },
    {
      "epoch": 6.12,
      "grad_norm": 2.0319628715515137,
      "learning_rate": 3.183851851851852e-05,
      "loss": 0.0282,
      "step": 55120
    },
    {
      "epoch": 6.13,
      "grad_norm": 2.423729658126831,
      "learning_rate": 3.183703703703704e-05,
      "loss": 0.0356,
      "step": 55130
    },
    {
      "epoch": 6.13,
      "grad_norm": 3.580981969833374,
      "learning_rate": 3.1835555555555555e-05,
      "loss": 0.0466,
      "step": 55140
    },
    {
      "epoch": 6.13,
      "grad_norm": 0.6972255110740662,
      "learning_rate": 3.183407407407408e-05,
      "loss": 0.0355,
      "step": 55150
    },
    {
      "epoch": 6.13,
      "grad_norm": 5.096137046813965,
      "learning_rate": 3.18325925925926e-05,
      "loss": 0.0543,
      "step": 55160
    },
    {
      "epoch": 6.13,
      "grad_norm": 6.004692554473877,
      "learning_rate": 3.1831111111111117e-05,
      "loss": 0.0593,
      "step": 55170
    },
    {
      "epoch": 6.13,
      "grad_norm": 3.578360080718994,
      "learning_rate": 3.182962962962963e-05,
      "loss": 0.0603,
      "step": 55180
    },
    {
      "epoch": 6.13,
      "grad_norm": 1.3570289611816406,
      "learning_rate": 3.182814814814815e-05,
      "loss": 0.0454,
      "step": 55190
    },
    {
      "epoch": 6.13,
      "grad_norm": 2.127568483352661,
      "learning_rate": 3.1826666666666665e-05,
      "loss": 0.0527,
      "step": 55200
    },
    {
      "epoch": 6.13,
      "grad_norm": 4.471144199371338,
      "learning_rate": 3.182518518518519e-05,
      "loss": 0.0442,
      "step": 55210
    },
    {
      "epoch": 6.14,
      "grad_norm": 7.673703193664551,
      "learning_rate": 3.182370370370371e-05,
      "loss": 0.0716,
      "step": 55220
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.2256510257720947,
      "learning_rate": 3.1822222222222226e-05,
      "loss": 0.0761,
      "step": 55230
    },
    {
      "epoch": 6.14,
      "grad_norm": 3.559523582458496,
      "learning_rate": 3.182074074074074e-05,
      "loss": 0.0529,
      "step": 55240
    },
    {
      "epoch": 6.14,
      "grad_norm": 3.8680789470672607,
      "learning_rate": 3.181925925925926e-05,
      "loss": 0.041,
      "step": 55250
    },
    {
      "epoch": 6.14,
      "grad_norm": 3.915262460708618,
      "learning_rate": 3.181777777777778e-05,
      "loss": 0.0585,
      "step": 55260
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.4991483986377716,
      "learning_rate": 3.1816296296296304e-05,
      "loss": 0.0353,
      "step": 55270
    },
    {
      "epoch": 6.14,
      "grad_norm": 3.730745553970337,
      "learning_rate": 3.181481481481482e-05,
      "loss": 0.0474,
      "step": 55280
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.78625750541687,
      "learning_rate": 3.1813333333333336e-05,
      "loss": 0.0282,
      "step": 55290
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.3400907516479492,
      "learning_rate": 3.181185185185185e-05,
      "loss": 0.0311,
      "step": 55300
    },
    {
      "epoch": 6.15,
      "grad_norm": 3.5687785148620605,
      "learning_rate": 3.1810370370370375e-05,
      "loss": 0.0523,
      "step": 55310
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.7488003373146057,
      "learning_rate": 3.180888888888889e-05,
      "loss": 0.0408,
      "step": 55320
    },
    {
      "epoch": 6.15,
      "grad_norm": 3.128290891647339,
      "learning_rate": 3.1807407407407414e-05,
      "loss": 0.0334,
      "step": 55330
    },
    {
      "epoch": 6.15,
      "grad_norm": 9.812551498413086,
      "learning_rate": 3.180592592592593e-05,
      "loss": 0.0313,
      "step": 55340
    },
    {
      "epoch": 6.15,
      "grad_norm": 5.067002773284912,
      "learning_rate": 3.1804444444444446e-05,
      "loss": 0.0587,
      "step": 55350
    },
    {
      "epoch": 6.15,
      "grad_norm": 3.7768445014953613,
      "learning_rate": 3.180296296296296e-05,
      "loss": 0.0398,
      "step": 55360
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.4676320552825928,
      "learning_rate": 3.1801481481481484e-05,
      "loss": 0.0216,
      "step": 55370
    },
    {
      "epoch": 6.15,
      "grad_norm": 2.9064176082611084,
      "learning_rate": 3.180000000000001e-05,
      "loss": 0.0337,
      "step": 55380
    },
    {
      "epoch": 6.15,
      "grad_norm": 2.3602795600891113,
      "learning_rate": 3.179851851851852e-05,
      "loss": 0.042,
      "step": 55390
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.5980095863342285,
      "learning_rate": 3.179703703703704e-05,
      "loss": 0.0575,
      "step": 55400
    },
    {
      "epoch": 6.16,
      "grad_norm": 6.206966876983643,
      "learning_rate": 3.1795555555555555e-05,
      "loss": 0.0555,
      "step": 55410
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.3853867053985596,
      "learning_rate": 3.179407407407408e-05,
      "loss": 0.0435,
      "step": 55420
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.269954800605774,
      "learning_rate": 3.1792592592592594e-05,
      "loss": 0.0677,
      "step": 55430
    },
    {
      "epoch": 6.16,
      "grad_norm": 3.3744616508483887,
      "learning_rate": 3.179111111111112e-05,
      "loss": 0.0555,
      "step": 55440
    },
    {
      "epoch": 6.16,
      "grad_norm": 3.6248481273651123,
      "learning_rate": 3.178962962962963e-05,
      "loss": 0.0322,
      "step": 55450
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.7030547857284546,
      "learning_rate": 3.178814814814815e-05,
      "loss": 0.0316,
      "step": 55460
    },
    {
      "epoch": 6.16,
      "grad_norm": 3.7393012046813965,
      "learning_rate": 3.1786666666666665e-05,
      "loss": 0.0284,
      "step": 55470
    },
    {
      "epoch": 6.16,
      "grad_norm": 6.835031986236572,
      "learning_rate": 3.178518518518519e-05,
      "loss": 0.056,
      "step": 55480
    },
    {
      "epoch": 6.17,
      "grad_norm": 1.4889577627182007,
      "learning_rate": 3.178370370370371e-05,
      "loss": 0.0507,
      "step": 55490
    },
    {
      "epoch": 6.17,
      "grad_norm": 1.504226803779602,
      "learning_rate": 3.178222222222223e-05,
      "loss": 0.0226,
      "step": 55500
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.9972009062767029,
      "learning_rate": 3.178074074074074e-05,
      "loss": 0.0601,
      "step": 55510
    },
    {
      "epoch": 6.17,
      "grad_norm": 5.796734809875488,
      "learning_rate": 3.177925925925926e-05,
      "loss": 0.0262,
      "step": 55520
    },
    {
      "epoch": 6.17,
      "grad_norm": 4.576592922210693,
      "learning_rate": 3.177777777777778e-05,
      "loss": 0.0691,
      "step": 55530
    },
    {
      "epoch": 6.17,
      "grad_norm": 7.065784931182861,
      "learning_rate": 3.17762962962963e-05,
      "loss": 0.045,
      "step": 55540
    },
    {
      "epoch": 6.17,
      "grad_norm": 3.1581008434295654,
      "learning_rate": 3.177481481481482e-05,
      "loss": 0.0492,
      "step": 55550
    },
    {
      "epoch": 6.17,
      "grad_norm": 2.351762294769287,
      "learning_rate": 3.1773333333333336e-05,
      "loss": 0.0633,
      "step": 55560
    },
    {
      "epoch": 6.17,
      "grad_norm": 4.198930263519287,
      "learning_rate": 3.177185185185185e-05,
      "loss": 0.0171,
      "step": 55570
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.7994453310966492,
      "learning_rate": 3.177037037037037e-05,
      "loss": 0.0569,
      "step": 55580
    },
    {
      "epoch": 6.18,
      "grad_norm": 4.188730716705322,
      "learning_rate": 3.176888888888889e-05,
      "loss": 0.0453,
      "step": 55590
    },
    {
      "epoch": 6.18,
      "grad_norm": 2.7327702045440674,
      "learning_rate": 3.1767407407407414e-05,
      "loss": 0.0353,
      "step": 55600
    },
    {
      "epoch": 6.18,
      "grad_norm": 2.5598223209381104,
      "learning_rate": 3.176592592592593e-05,
      "loss": 0.0462,
      "step": 55610
    },
    {
      "epoch": 6.18,
      "grad_norm": 2.898163318634033,
      "learning_rate": 3.1764444444444446e-05,
      "loss": 0.0415,
      "step": 55620
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.830715537071228,
      "learning_rate": 3.176296296296296e-05,
      "loss": 0.0508,
      "step": 55630
    },
    {
      "epoch": 6.18,
      "grad_norm": 8.46502685546875,
      "learning_rate": 3.1761481481481485e-05,
      "loss": 0.0537,
      "step": 55640
    },
    {
      "epoch": 6.18,
      "grad_norm": 7.131969928741455,
      "learning_rate": 3.176e-05,
      "loss": 0.047,
      "step": 55650
    },
    {
      "epoch": 6.18,
      "grad_norm": 1.7917476892471313,
      "learning_rate": 3.1758518518518524e-05,
      "loss": 0.0679,
      "step": 55660
    },
    {
      "epoch": 6.19,
      "grad_norm": 2.2645609378814697,
      "learning_rate": 3.175703703703704e-05,
      "loss": 0.0306,
      "step": 55670
    },
    {
      "epoch": 6.19,
      "grad_norm": 2.883247137069702,
      "learning_rate": 3.1755555555555556e-05,
      "loss": 0.0681,
      "step": 55680
    },
    {
      "epoch": 6.19,
      "grad_norm": 4.924345016479492,
      "learning_rate": 3.175407407407407e-05,
      "loss": 0.0932,
      "step": 55690
    },
    {
      "epoch": 6.19,
      "grad_norm": 2.6955339908599854,
      "learning_rate": 3.1752592592592595e-05,
      "loss": 0.0423,
      "step": 55700
    },
    {
      "epoch": 6.19,
      "grad_norm": 0.783420205116272,
      "learning_rate": 3.175111111111112e-05,
      "loss": 0.0994,
      "step": 55710
    },
    {
      "epoch": 6.19,
      "grad_norm": 1.9364166259765625,
      "learning_rate": 3.174962962962963e-05,
      "loss": 0.0559,
      "step": 55720
    },
    {
      "epoch": 6.19,
      "grad_norm": 0.7643426060676575,
      "learning_rate": 3.174814814814815e-05,
      "loss": 0.0623,
      "step": 55730
    },
    {
      "epoch": 6.19,
      "grad_norm": 3.0518853664398193,
      "learning_rate": 3.1746666666666665e-05,
      "loss": 0.0243,
      "step": 55740
    },
    {
      "epoch": 6.19,
      "grad_norm": 4.630919456481934,
      "learning_rate": 3.174518518518519e-05,
      "loss": 0.0455,
      "step": 55750
    },
    {
      "epoch": 6.2,
      "grad_norm": 3.763178586959839,
      "learning_rate": 3.174370370370371e-05,
      "loss": 0.054,
      "step": 55760
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.84562611579895,
      "learning_rate": 3.174222222222223e-05,
      "loss": 0.0209,
      "step": 55770
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.21362599730491638,
      "learning_rate": 3.174074074074074e-05,
      "loss": 0.0564,
      "step": 55780
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.89963436126709,
      "learning_rate": 3.173925925925926e-05,
      "loss": 0.0465,
      "step": 55790
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.7127982974052429,
      "learning_rate": 3.1737777777777775e-05,
      "loss": 0.0354,
      "step": 55800
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.6356558799743652,
      "learning_rate": 3.17362962962963e-05,
      "loss": 0.0426,
      "step": 55810
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.4853687286376953,
      "learning_rate": 3.173481481481482e-05,
      "loss": 0.04,
      "step": 55820
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.688018321990967,
      "learning_rate": 3.173333333333334e-05,
      "loss": 0.066,
      "step": 55830
    },
    {
      "epoch": 6.2,
      "grad_norm": 3.8274431228637695,
      "learning_rate": 3.173185185185185e-05,
      "loss": 0.0608,
      "step": 55840
    },
    {
      "epoch": 6.21,
      "grad_norm": 2.874035120010376,
      "learning_rate": 3.173037037037037e-05,
      "loss": 0.0524,
      "step": 55850
    },
    {
      "epoch": 6.21,
      "grad_norm": 4.1300272941589355,
      "learning_rate": 3.172888888888889e-05,
      "loss": 0.0447,
      "step": 55860
    },
    {
      "epoch": 6.21,
      "grad_norm": 1.844666838645935,
      "learning_rate": 3.1727407407407414e-05,
      "loss": 0.0276,
      "step": 55870
    },
    {
      "epoch": 6.21,
      "grad_norm": 3.6433932781219482,
      "learning_rate": 3.172592592592593e-05,
      "loss": 0.0691,
      "step": 55880
    },
    {
      "epoch": 6.21,
      "grad_norm": 4.148674011230469,
      "learning_rate": 3.1724444444444446e-05,
      "loss": 0.066,
      "step": 55890
    },
    {
      "epoch": 6.21,
      "grad_norm": 5.285488128662109,
      "learning_rate": 3.172296296296296e-05,
      "loss": 0.0232,
      "step": 55900
    },
    {
      "epoch": 6.21,
      "grad_norm": 3.0642149448394775,
      "learning_rate": 3.172162962962963e-05,
      "loss": 0.0574,
      "step": 55910
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.4825332760810852,
      "learning_rate": 3.172014814814815e-05,
      "loss": 0.0309,
      "step": 55920
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.8045178055763245,
      "learning_rate": 3.171866666666667e-05,
      "loss": 0.0406,
      "step": 55930
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.3994519710540771,
      "learning_rate": 3.171718518518519e-05,
      "loss": 0.0399,
      "step": 55940
    },
    {
      "epoch": 6.22,
      "grad_norm": 6.5757598876953125,
      "learning_rate": 3.1715703703703704e-05,
      "loss": 0.0287,
      "step": 55950
    },
    {
      "epoch": 6.22,
      "grad_norm": 5.134666919708252,
      "learning_rate": 3.1714222222222227e-05,
      "loss": 0.048,
      "step": 55960
    },
    {
      "epoch": 6.22,
      "grad_norm": 3.5249218940734863,
      "learning_rate": 3.171274074074074e-05,
      "loss": 0.0514,
      "step": 55970
    },
    {
      "epoch": 6.22,
      "grad_norm": 5.2057342529296875,
      "learning_rate": 3.1711259259259265e-05,
      "loss": 0.0411,
      "step": 55980
    },
    {
      "epoch": 6.22,
      "grad_norm": 4.834446907043457,
      "learning_rate": 3.170977777777778e-05,
      "loss": 0.0339,
      "step": 55990
    },
    {
      "epoch": 6.22,
      "grad_norm": 2.8778605461120605,
      "learning_rate": 3.17082962962963e-05,
      "loss": 0.0443,
      "step": 56000
    },
    {
      "epoch": 6.22,
      "eval_cer": 0.01085947252233694,
      "eval_loss": 0.34120380878448486,
      "eval_runtime": 1973.9503,
      "eval_samples_per_second": 4.053,
      "eval_steps_per_second": 0.507,
      "eval_wer": 0.028746982664033357,
      "step": 56000
    }
  ],
  "logging_steps": 10,
  "max_steps": 270000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 8000,
  "total_flos": 2.3878869419085005e+20,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
